diff --git a/.gitignore b/.gitignore
index 972360f..37f75e6 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,22 +1,47 @@
 # Rust
-/target/
+/target
 **/*.rs.bk
-
-# Runtime outputs
-/tmp/
-/datasets/
-/crates/**/datasets/
-/crates/**/tmp/
+Cargo.lock
 
 # Python
 __pycache__/
 *.py[cod]
-*.pyo
-.pytest_cache/
-.mypy_cache/
+*.so
+venv/
+.venv/
+env/
+.env
+
+# Datasets & Temp
+datasets/
+crates/replay_engine/datasets/
+tmp/
+*.log
+*.tar.gz
+
+# IDEs
+.idea
+.vscode
+*.iml
+
+# Deployment Artifacts
+setup_remote.sh
+deploy.tar.gz
+settings.local.json
+optimized.env.example
+debug_*.json
+scripts/deploy_optimize.sh
+scripts/network_optimize.sh
+scripts/latency_probe/live_latency.py
+
+# Secrets / keys (must never be committed)
+keys/
+temp_keys/
+*.pem
+*.ppk
+*.key
+*.p12
+*.pfx
 
-# OS / editors
-.DS_Store
-Thumbs.db
-.idea/
-.vscode/
+# Local machine artifacts
+*.marker
diff --git a/CLAUDE.md b/CLAUDE.md
new file mode 100644
index 0000000..e41251c
--- /dev/null
+++ b/CLAUDE.md
@@ -0,0 +1,150 @@
+# CLAUDE.md
+
+This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.
+
+## Project Overview
+
+PolyEdge is a high-frequency statistical arbitrage trading system for Polymarket. It implements an event-driven, no-mock architecture with maker strategy, inventory controls, risk gates, replay engine, and paper executor.
+
+## Commands
+
+### Running the Application
+
+```bash
+# Main application (requires clob_gateway running on port 9001)
+cargo run -p app_runner
+```
+
+On Windows, install prerequisites first:
+```powershell
+pwsh -File .\scripts\setup_windows.ps1
+```
+
+If `cargo test` fails with `link.exe not found`, run cargo via VS Build Tools:
+```powershell
+pwsh -File .\scripts\cargo_msvc.ps1 test -q
+```
+
+### Testing
+
+```bash
+cargo test
+```
+
+Run a single test:
+```bash
+cargo test -p <crate_name> <test_name>
+```
+
+### Benchmarks
+
+```bash
+# Primary benchmark (WS-first, ~60s default)
+python scripts/e2e_latency_test.py --profile quick --mode ws-first --base-url http://127.0.0.1:8080 --symbol BTCUSDT
+
+# Parameter regression
+python scripts/param_regression.py --profile quick --base-url http://127.0.0.1:8080 --run-id r1
+
+# Long-run orchestrator with rollback
+python scripts/long_regression_orchestrator.py --profile quick --base-url http://127.0.0.1:8080 --run-id long1
+
+# Storm/fault-tolerance test
+python scripts/storm_test.py --base-url http://127.0.0.1:8080 --duration-sec 300 --burst-rps 20 --concurrency 8
+
+# Cross-region A/B comparison
+python scripts/ab_region_compare.py --base-a http://<eu-host>:8080 --base-b http://<us-host>:8080 --seconds 600
+```
+
+### Control API
+
+The app exposes HTTP control endpoints on port 8080:
+- `GET /health` - Health check
+- `GET /metrics` - Prometheus metrics
+- `GET /state/positions` - Current positions
+- `GET /state/pnl` - P&L state
+- `POST /control/pause` / `POST /control/resume` - Trading control
+- `POST /control/flatten` - Flatten all positions
+- `POST /control/reload_strategy` - Hot-reload strategy config
+
+### clob_gateway (Required Dependency)
+
+The Rust engine requires the Python clob_gateway to be running for order signing:
+
+```bash
+# Install dependencies
+python3 -m pip install -r ops/clob_gateway/requirements.txt
+
+# Run gateway (set CLOB_PRIVATE_KEY, CLOB_API_KEY, etc. env vars first)
+python3 ops/clob_gateway/app.py --host 127.0.0.1 --port 9001
+```
+
+## Architecture
+
+### Crate Organization
+
+The workspace contains 21 crates in `crates/`:
+
+**Data Feeds:**
+- `feed_polymarket` - Polymarket WebSocket feed for orders/books
+- `feed_reference` - External reference price feeds
+- `feed_udp` - Low-latency UDP receiver for Binance BookTicker
+- `feeder_tokyo` - UDP sender service (Binance -> UDP)
+- `poly_wire` - Binary protocol definitions for UDP feed
+
+**Strategy Layer:**
+- `strategy_maker` - Maker quote generation with inventory skew
+- `fair_value` - Basis MR fair value model
+- `direction_detector` - Market direction signal detection
+- `timeframe_router` - Multi-timeframe opportunity routing
+- `taker_sniper` - Taker order execution logic
+- `settlement_compounder` - Position compounding across settlements
+
+**Risk & Execution:**
+- `risk_engine` - Risk limits and position checks
+- `execution_clob` - CLOB order execution (communicates with clob_gateway)
+- `portfolio` - Position and inventory management
+
+**Infrastructure:**
+- `infra_bus` - RingBus event bus for inter-component communication
+- `infra_clock` - Time synchronization
+- `core_types` - Shared types and traits
+- `observability` - Metrics and tracing setup
+
+**Backtesting & Replay:**
+- `paper_executor` - Shadow executor for paper trading
+- `replay_engine` - Historical market replay for backtesting
+- `market_discovery` - Market scanning and discovery
+
+**Application:**
+- `app_runner` - Main entry point orchestrating all components
+
+### Data Flow
+
+```
+Feed Layer          Strategy Layer         Risk Layer        Execution
+   â”‚                     â”‚                     â”‚                 â”‚
+   â–¼                     â–¼                     â–¼                 â–¼
+Polymarket WS  â”€â”€â–º  Fair Value  â”€â”€â–º  Risk Engine  â”€â”€â–º  clob_gateway
+Reference Feed       Maker Quotes      Position Limits       (HTTP)
+                     Direction           Hard Gates
+```
+
+Events flow through `RingBus<EngineEvent>` - the central event bus connecting all components.
+
+### Configuration
+
+- `configs/strategy.toml` - Maker strategy parameters
+- `configs/risk.toml` - Risk limits
+- `configs/execution.toml` - Execution settings
+- `configs/latency.toml` - Runtime performance tuning
+- `configs/universe.toml` - Market universe (symbols, timeframes)
+
+### Hard Gates (from docs/metrics_contract.md)
+
+The system enforces these live trading thresholds:
+- `data_valid_ratio >= 0.999`
+- `seq_gap_rate <= 0.001`
+- `tick_to_ack_p99_ms < 450`
+- `executed_over_eligible >= 0.60`
+- `quote_block_ratio < 0.10`
+- `ev_net_usdc_p50 > 0`
diff --git a/Cargo.lock b/Cargo.lock
index 564b8d9..5e86dbb 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -2,6 +2,12 @@
 # It is not intended for manual editing.
 version = 4
 
+[[package]]
+name = "adler2"
+version = "2.0.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "320119579fcad9c21884f5c4861d16174d0e06250625266f50fe6898340abefa"
+
 [[package]]
 name = "ahash"
 version = "0.8.12"
@@ -46,27 +52,44 @@ dependencies = [
  "axum",
  "chrono",
  "core_types",
+ "dashmap",
+ "direction_detector",
  "execution_clob",
+ "exit_manager",
  "fair_value",
  "feed_polymarket",
  "feed_reference",
+ "feed_udp",
+ "flate2",
  "futures",
  "infra_bus",
  "market_discovery",
  "metrics",
  "metrics-exporter-prometheus",
+ "mimalloc",
  "observability",
  "paper_executor",
+ "poly_wire",
  "portfolio",
+ "probability_engine",
  "reqwest",
  "risk_engine",
+ "rusqlite",
  "rustls",
  "serde",
  "serde_json",
+ "settlement_compounder",
  "sha2",
+ "smol_str",
+ "socket2",
  "strategy_maker",
+ "taker_sniper",
+ "timeframe_router",
  "tokio",
+ "tokio-tungstenite",
+ "toml",
  "tracing",
+ "tracing-subscriber",
 ]
 
 [[package]]
@@ -184,6 +207,15 @@ version = "0.22.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "72b3254f16251a8381aa12e40e3c4d2f0199f8c6508fbecb9d91f575e0fbb8c6"
 
+[[package]]
+name = "bincode"
+version = "1.3.3"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "b1f45e9417d87227c7a56d22e471c6206462cba514c7590c09aff4cf6d1ddcad"
+dependencies = [
+ "serde",
+]
+
 [[package]]
 name = "bitflags"
 version = "2.10.0"
@@ -199,6 +231,15 @@ dependencies = [
  "generic-array",
 ]
 
+[[package]]
+name = "borsh"
+version = "1.6.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "d1da5ab77c1437701eeff7c88d968729e7766172279eab0676857b3d63af7a6f"
+dependencies = [
+ "cfg_aliases",
+]
+
 [[package]]
 name = "bumpalo"
 version = "3.19.1"
@@ -294,6 +335,7 @@ dependencies = [
  "futures",
  "serde",
  "serde_json",
+ "smol_str",
  "thiserror 2.0.18",
  "uuid",
 ]
@@ -307,6 +349,24 @@ dependencies = [
  "libc",
 ]
 
+[[package]]
+name = "crc32fast"
+version = "1.5.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "9481c1c90cbf2ac953f07c8d4a58aa3945c425b7185c9154d67a65e4230da511"
+dependencies = [
+ "cfg-if",
+]
+
+[[package]]
+name = "crossbeam-channel"
+version = "0.5.15"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "82b8f8f868b36967f9606790d1903570de9ceaf870a7bf9fbbd3016d636a2cb2"
+dependencies = [
+ "crossbeam-utils",
+]
+
 [[package]]
 name = "crossbeam-epoch"
 version = "0.9.18"
@@ -332,12 +392,35 @@ dependencies = [
  "typenum",
 ]
 
+[[package]]
+name = "dashmap"
+version = "6.1.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5041cc499144891f3790297212f32a74fb938e5136a14943f338ef9e0ae276cf"
+dependencies = [
+ "cfg-if",
+ "crossbeam-utils",
+ "hashbrown 0.14.5",
+ "lock_api",
+ "once_cell",
+ "parking_lot_core",
+]
+
 [[package]]
 name = "data-encoding"
 version = "2.10.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d7a1e2f27636f116493b8b860f5546edb47c8d8f8ea73e1d2a20be88e28d1fea"
 
+[[package]]
+name = "deranged"
+version = "0.5.6"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "cc3dc5ad92c2e2d1c193bbbbdf2ea477cb81331de4f3103f267ca18368b988c4"
+dependencies = [
+ "powerfmt",
+]
+
 [[package]]
 name = "digest"
 version = "0.10.7"
@@ -348,6 +431,14 @@ dependencies = [
  "crypto-common",
 ]
 
+[[package]]
+name = "direction_detector"
+version = "0.1.0"
+dependencies = [
+ "core_types",
+ "serde",
+]
+
 [[package]]
 name = "displaydoc"
 version = "0.2.5"
@@ -398,10 +489,21 @@ dependencies = [
  "async-trait",
  "chrono",
  "core_types",
+ "futures",
  "parking_lot",
  "reqwest",
  "serde",
  "serde_json",
+ "tokio",
+ "tokio-tungstenite",
+ "tracing",
+]
+
+[[package]]
+name = "exit_manager"
+version = "0.1.0"
+dependencies = [
+ "serde",
 ]
 
 [[package]]
@@ -409,9 +511,22 @@ name = "fair_value"
 version = "0.1.0"
 dependencies = [
  "core_types",
+ "parking_lot",
  "serde",
 ]
 
+[[package]]
+name = "fallible-iterator"
+version = "0.3.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "2acce4a10f12dc2fb14a218589d4f1f62ef011b2d0cc4b3cb1bba8e94da14649"
+
+[[package]]
+name = "fallible-streaming-iterator"
+version = "0.1.9"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "7360491ce676a36bf9bb3c56c1aa791658183a54d2744120f27285738d90465a"
+
 [[package]]
 name = "fastrand"
 version = "2.3.0"
@@ -459,12 +574,48 @@ dependencies = [
  "url",
 ]
 
+[[package]]
+name = "feed_udp"
+version = "0.1.0"
+dependencies = [
+ "anyhow",
+ "async-trait",
+ "core_types",
+ "libc",
+ "poly_wire",
+ "tokio",
+ "tokio-stream",
+]
+
+[[package]]
+name = "feeder_tokyo"
+version = "0.1.0"
+dependencies = [
+ "anyhow",
+ "futures",
+ "libc",
+ "poly_wire",
+ "rustls",
+ "tokio",
+ "tokio-tungstenite",
+]
+
 [[package]]
 name = "find-msvc-tools"
 version = "0.1.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "5baebc0774151f905a1a2cc41989300b1e6fbb29aff0ceffa1064fdd3088d582"
 
+[[package]]
+name = "flate2"
+version = "1.1.9"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "843fba2746e448b37e26a819579957415c8cef339bf08564fe8b7ddbd959573c"
+dependencies = [
+ "crc32fast",
+ "miniz_oxide",
+]
+
 [[package]]
 name = "fnv"
 version = "1.0.7"
@@ -665,6 +816,15 @@ dependencies = [
  "tracing",
 ]
 
+[[package]]
+name = "hashbrown"
+version = "0.14.5"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "e5274423e17b7c9fc20b6e7e208532f9b19825d82dfd615708b70edd83df41f1"
+dependencies = [
+ "ahash",
+]
+
 [[package]]
 name = "hashbrown"
 version = "0.15.5"
@@ -680,6 +840,15 @@ version = "0.16.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "841d1cc9bed7f9236f321df977030373f4a4163ae1a7dbfe1a51a2c1a51d9100"
 
+[[package]]
+name = "hashlink"
+version = "0.9.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "6ba4ff7128dee98c7dc9794b6a411377e1404dba1c97deb8d1a55297bd25d8af"
+dependencies = [
+ "hashbrown 0.14.5",
+]
+
 [[package]]
 name = "heck"
 version = "0.5.0"
@@ -1035,6 +1204,27 @@ version = "0.2.182"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6800badb6cb2082ffd7b6a67e6125bb39f18782f793520caee8cb8846be06112"
 
+[[package]]
+name = "libmimalloc-sys"
+version = "0.1.44"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "667f4fec20f29dfc6bc7357c582d91796c169ad7e2fce709468aefeb2c099870"
+dependencies = [
+ "cc",
+ "libc",
+]
+
+[[package]]
+name = "libsqlite3-sys"
+version = "0.28.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "0c10584274047cb335c23d3e61bcef8e323adae7c5c8c760540f73610177fc3f"
+dependencies = [
+ "cc",
+ "pkg-config",
+ "vcpkg",
+]
+
 [[package]]
 name = "linux-raw-sys"
 version = "0.11.0"
@@ -1146,12 +1336,31 @@ dependencies = [
  "sketches-ddsketch",
 ]
 
+[[package]]
+name = "mimalloc"
+version = "0.1.48"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "e1ee66a4b64c74f4ef288bcbb9192ad9c3feaad75193129ac8509af543894fd8"
+dependencies = [
+ "libmimalloc-sys",
+]
+
 [[package]]
 name = "mime"
 version = "0.3.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6877bb514081ee2a7ff5ef9de3281f14a4dd4bceac4c09388074a6b5df8a139a"
 
+[[package]]
+name = "miniz_oxide"
+version = "0.8.9"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "1fa76a2c86f704bdb222d66965fb3d63269ce38518b83cb0575fca855ebb6316"
+dependencies = [
+ "adler2",
+ "simd-adler32",
+]
+
 [[package]]
 name = "mio"
 version = "1.1.1"
@@ -1189,6 +1398,12 @@ dependencies = [
  "windows-sys 0.61.2",
 ]
 
+[[package]]
+name = "num-conv"
+version = "0.2.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "cf97ec579c3c42f953ef76dbf8d55ac91fb219dde70e49aa4a6b7d74e9919050"
+
 [[package]]
 name = "num-traits"
 version = "0.2.19"
@@ -1205,6 +1420,7 @@ dependencies = [
  "metrics",
  "metrics-exporter-prometheus",
  "tracing",
+ "tracing-appender",
  "tracing-subscriber",
 ]
 
@@ -1321,6 +1537,14 @@ version = "0.3.32"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7edddbd0b52d732b21ad9a5fab5c704c14cd949e5e9a1ec5929a24fded1b904c"
 
+[[package]]
+name = "poly_wire"
+version = "0.1.0"
+dependencies = [
+ "bincode",
+ "serde",
+]
+
 [[package]]
 name = "portable-atomic"
 version = "1.13.1"
@@ -1346,6 +1570,12 @@ dependencies = [
  "zerovec",
 ]
 
+[[package]]
+name = "powerfmt"
+version = "0.2.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "439ee305def115ba05938db6eb1644ff94165c5ab5e9420d1c1bcedbba909391"
+
 [[package]]
 name = "ppv-lite86"
 version = "0.2.21"
@@ -1365,6 +1595,14 @@ dependencies = [
  "syn",
 ]
 
+[[package]]
+name = "probability_engine"
+version = "0.1.0"
+dependencies = [
+ "core_types",
+ "serde",
+]
+
 [[package]]
 name = "proc-macro2"
 version = "1.0.106"
@@ -1610,6 +1848,20 @@ dependencies = [
  "serde",
 ]
 
+[[package]]
+name = "rusqlite"
+version = "0.31.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "b838eba278d213a8beaf485bd313fd580ca4505a00d5871caeb1457c55322cae"
+dependencies = [
+ "bitflags",
+ "fallible-iterator",
+ "fallible-streaming-iterator",
+ "hashlink",
+ "libsqlite3-sys",
+ "smallvec",
+]
+
 [[package]]
 name = "rustc-hash"
 version = "2.1.1"
@@ -1802,6 +2054,15 @@ dependencies = [
  "serde_core",
 ]
 
+[[package]]
+name = "serde_spanned"
+version = "0.6.9"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "bf41e0cfaf7226dca15e8197172c295a782857fcb97fad1808a166870dee75a3"
+dependencies = [
+ "serde",
+]
+
 [[package]]
 name = "serde_urlencoded"
 version = "0.7.1"
@@ -1814,6 +2075,14 @@ dependencies = [
  "serde",
 ]
 
+[[package]]
+name = "settlement_compounder"
+version = "0.1.0"
+dependencies = [
+ "core_types",
+ "serde",
+]
+
 [[package]]
 name = "sha1"
 version = "0.10.6"
@@ -1861,6 +2130,12 @@ dependencies = [
  "libc",
 ]
 
+[[package]]
+name = "simd-adler32"
+version = "0.3.8"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "e320a6c5ad31d271ad523dcf3ad13e2767ad8b1cb8f047f75a8aeaf8da139da2"
+
 [[package]]
 name = "sketches-ddsketch"
 version = "0.3.0"
@@ -1879,6 +2154,16 @@ version = "1.15.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "67b1b7a3b5fe4f1376887184045fcf45c69e92af734b7aaddc05fb777b6fbd03"
 
+[[package]]
+name = "smol_str"
+version = "0.3.5"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "0f7a918bd2a9951d18ee6e48f076843e8e73a9a5d22cf05bcd4b7a81bdd04e17"
+dependencies = [
+ "borsh",
+ "serde_core",
+]
+
 [[package]]
 name = "socket2"
 version = "0.6.2"
@@ -1961,6 +2246,14 @@ dependencies = [
  "libc",
 ]
 
+[[package]]
+name = "taker_sniper"
+version = "0.1.0"
+dependencies = [
+ "core_types",
+ "serde",
+]
+
 [[package]]
 name = "tempfile"
 version = "3.25.0"
@@ -2023,6 +2316,45 @@ dependencies = [
  "cfg-if",
 ]
 
+[[package]]
+name = "time"
+version = "0.3.47"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "743bd48c283afc0388f9b8827b976905fb217ad9e647fae3a379a9283c4def2c"
+dependencies = [
+ "deranged",
+ "itoa",
+ "num-conv",
+ "powerfmt",
+ "serde_core",
+ "time-core",
+ "time-macros",
+]
+
+[[package]]
+name = "time-core"
+version = "0.1.8"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "7694e1cfe791f8d31026952abf09c69ca6f6fa4e1a1229e18988f06a04a12dca"
+
+[[package]]
+name = "time-macros"
+version = "0.2.27"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "2e70e4c5a0e0a8a4823ad65dfe1a6930e4f4d756dcd9dd7939022b5e8c501215"
+dependencies = [
+ "num-conv",
+ "time-core",
+]
+
+[[package]]
+name = "timeframe_router"
+version = "0.1.0"
+dependencies = [
+ "core_types",
+ "serde",
+]
+
 [[package]]
 name = "tinystr"
 version = "0.8.2"
@@ -2136,6 +2468,47 @@ dependencies = [
  "tokio",
 ]
 
+[[package]]
+name = "toml"
+version = "0.8.23"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "dc1beb996b9d83529a9e75c17a1686767d148d70663143c7854d8b4a09ced362"
+dependencies = [
+ "serde",
+ "serde_spanned",
+ "toml_datetime",
+ "toml_edit",
+]
+
+[[package]]
+name = "toml_datetime"
+version = "0.6.11"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "22cddaf88f4fbc13c51aebbf5f8eceb5c7c5a9da2ac40a13519eb5b0a0e8f11c"
+dependencies = [
+ "serde",
+]
+
+[[package]]
+name = "toml_edit"
+version = "0.22.27"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "41fe8c660ae4257887cf66394862d21dbca4a6ddd26f04a3560410406a2f819a"
+dependencies = [
+ "indexmap",
+ "serde",
+ "serde_spanned",
+ "toml_datetime",
+ "toml_write",
+ "winnow",
+]
+
+[[package]]
+name = "toml_write"
+version = "0.1.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5d99f8c9a7727884afe522e9bd5edbfc91a3312b36a77b5fb8926e4c31a41801"
+
 [[package]]
 name = "tower"
 version = "0.5.3"
@@ -2194,6 +2567,18 @@ dependencies = [
  "tracing-core",
 ]
 
+[[package]]
+name = "tracing-appender"
+version = "0.2.4"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "786d480bce6247ab75f005b14ae1624ad978d3029d9113f0a22fa1ac773faeaf"
+dependencies = [
+ "crossbeam-channel",
+ "thiserror 2.0.18",
+ "time",
+ "tracing-subscriber",
+]
+
 [[package]]
 name = "tracing-attributes"
 version = "0.1.31"
@@ -2772,6 +3157,15 @@ version = "0.53.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d6bbff5f0aada427a1e5a6da5f1f98158182f26556f345ac9e04d36d0ebed650"
 
+[[package]]
+name = "winnow"
+version = "0.7.14"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5a5364e9d77fcdeeaa6062ced926ee3381faa2ee02d3eb83a5c27a8825540829"
+dependencies = [
+ "memchr",
+]
+
 [[package]]
 name = "wit-bindgen"
 version = "0.51.0"
diff --git a/Cargo.toml b/Cargo.toml
index 338f9c3..a1847d7 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -9,6 +9,12 @@ members = [
   "crates/market_discovery",
   "crates/fair_value",
   "crates/strategy_maker",
+  "crates/direction_detector",
+  "crates/taker_sniper",
+  "crates/exit_manager",
+  "crates/probability_engine",
+  "crates/timeframe_router",
+  "crates/settlement_compounder",
   "crates/risk_engine",
   "crates/execution_clob",
   "crates/portfolio",
@@ -16,6 +22,9 @@ members = [
   "crates/paper_executor",
   "crates/observability",
   "crates/app_runner",
+  "crates/poly_wire",
+  "crates/feeder_tokyo",
+  "crates/feed_udp",
 ]
 
 [workspace.package]
@@ -37,20 +46,26 @@ metrics-exporter-prometheus = "0.16"
 parking_lot = "0.12"
 rand = "0.9"
 reqwest = { version = "0.12", features = ["json", "rustls-tls"] }
-rustls = { version = "0.23", features = ["aws_lc_rs"] }
+rustls = { version = "0.23", features = ["ring"] }
 serde = { version = "1", features = ["derive"] }
 serde_json = "1"
 sha2 = "0.10"
+smol_str = { version = "0.3", features = ["serde"] }
 thiserror = "2"
 tokio = { version = "1", features = ["full"] }
 tokio-stream = "0.1"
+bincode = "1"
+tungstenite = { version = "0.24", features = ["rustls-tls-native-roots"] }
+url = "2"
 tokio-tungstenite = { version = "0.27", features = ["rustls-tls-webpki-roots"] }
 tracing = "0.1"
 tracing-subscriber = { version = "0.3", features = ["env-filter", "fmt", "json"] }
-url = "2"
+tracing-appender = "0.2"
+toml = "0.8"
+
 uuid = { version = "1", features = ["v4", "serde"] }
 
 [profile.release]
 panic = "abort"
-lto = "thin"
+lto = "fat"
 codegen-units = 1
diff --git a/README.md b/README.md
index 9722f8e..5d7f897 100644
--- a/README.md
+++ b/README.md
@@ -45,6 +45,9 @@ pwsh -File .\scripts\cargo_msvc.ps1 test -q
 - `POST /control/reload_allocator`
 - `POST /control/reload_risk`
 - `POST /control/reload_toxicity`
+- `POST /control/reload_fusion`
+- `POST /control/reload_edge_model`
+- `POST /control/reload_exit`
 - `POST /control/reload_perf_profile`
 
 ## Benchmarks
@@ -63,12 +66,6 @@ python scripts/e2e_latency_test.py --profile standard # ~120s
 python scripts/e2e_latency_test.py --profile deep     # ~300s
 ```
 
-Legacy REST comparison:
-
-```bash
-python scripts/legacy_rest_probe.py --symbol BTCUSDT --iterations 80
-```
-
 Conservative parameter regression:
 
 ```bash
@@ -81,18 +78,46 @@ python scripts/param_regression.py --profile quick --base-url http://127.0.0.1:8
 python scripts/param_regression.py --profile quick --max-estimated-sec 900 --max-runtime-sec 1200
 ```
 
+Walk-forward robust auto-tuning (recommended):
+
+```bash
+python scripts/param_regression.py --profile quick --selection-mode robust --walkforward-windows 2 --top-k-consensus 3
+```
+
+This now writes `auto_tuned_thresholds.json` (consensus payloads for `reload_strategy/reload_taker/reload_allocator/reload_toxicity`) under `datasets/reports/<utc-date>/runs/<run-id>/`.
+
 Long-run orchestrator with rollback:
 
 ```bash
 python scripts/long_regression_orchestrator.py --profile quick --base-url http://127.0.0.1:8080 --run-id long1
 ```
 
-`long_regression_orchestrator.py` also supports `quick/standard/deep` plus cycle/runtime budget guards:
+`long_regression_orchestrator.py` supports `quick/standard/deep`, champion/challenger drift, automatic rollback, and objective-driven promotion:
 
 ```bash
-python scripts/long_regression_orchestrator.py --profile quick --max-estimated-sec 1800 --max-runtime-sec 1800
+python scripts/long_regression_orchestrator.py --profile quick --max-estimated-sec 1800 --max-runtime-sec 1800 --min-objective-delta 0.0005
+```
+
+Objective is optimized online as:
+
+```text
+EV_net - penalty(latency, decision_compute, feed, block_ratio, execution_shortfall, data_valid, instability, gate_fail)
+```
+
+Continuous optimization mode (recommended for remote shadow runs):
+
+```bash
+python scripts/long_regression_orchestrator.py --profile standard --continuous --base-url http://127.0.0.1:8080 --state-file datasets/reports/champion_state.json --stop-file datasets/reports/STOP_OPTIMIZER
+```
+
+Windows one-command wrapper (opens SSH tunnel + runs continuous optimizer):
+
+```powershell
+pwsh -File .\scripts\run_continuous_optimizer.ps1 -SshHost 54.77.232.166 -KeyPath "C:\Users\Shini\Documents\PolyEdge.pem" -Profile standard
 ```
 
+The orchestrator forwards walk-forward tuning flags to `param_regression.py`, prefers consensus payloads from `auto_tuned_thresholds.json`, and persists champion state for restart-safe operation.
+
 Storm / fault-tolerance test (bounded runtime, no infinite loop):
 
 ```bash
@@ -111,6 +136,32 @@ Remote deploy + validate (from Windows host):
 pwsh -File .\scripts\remote_deploy_validate.ps1 -RemoteHost 13.43.23.190 -KeyPath "C:\Users\Shini\Documents\test.pem" -BenchSeconds 180 -RegressionSeconds 1200 -Symbol BTCUSDT
 ```
 
+## UDP Relay Binaries
+
+Tokyo sender (`tokio-tungstenite` + 24-byte bincode UDP packet):
+
+```bash
+TARGET=10.0.3.123:6666 SYMBOL=btcusdt cargo run -p feeder_tokyo --bin sender --release
+```
+
+Ireland receiver (busy-spin UDP read loop + latency print):
+
+```bash
+BIND_ADDR=0.0.0.0:6666 PRINT_EVERY=1 cargo run -p feeder_tokyo --bin receiver --release
+```
+
+Pin receiver to dedicated core (recommended on Linux):
+
+```bash
+taskset -c 2 BIND_ADDR=0.0.0.0:6666 PRINT_EVERY=1 cargo run -p feeder_tokyo --bin receiver --release
+```
+
+Kernel tuning helper (run as root on Linux):
+
+```bash
+sudo bash scripts/hft_kernel_tune.sh
+```
+
 ## Key Live Metrics
 
 - `quote_block_ratio`
@@ -129,6 +180,8 @@ pwsh -File .\scripts\remote_deploy_validate.ps1 -RemoteHost 13.43.23.190 -KeyPat
 - `queue_depth_p99/event_backlog_p99`
 
 Metric formulas, units, and gate thresholds are defined in `docs/metrics_contract.md`.
+Runtime control/fusion state transitions are documented in `docs/runtime_state_machines.md`.
+SEAT v2.3 runtime controls and remote acceptance workflow are documented in `docs/seat_v23_runbook.md`.
 CI validates contract drift with:
 
 ```bash
diff --git a/benchmark.py b/benchmark.py
new file mode 100644
index 0000000..c9f9310
--- /dev/null
+++ b/benchmark.py
@@ -0,0 +1,77 @@
+import time
+import requests
+import statistics
+import os
+import socket
+import socks  # Requires PySocks
+
+# Configuration
+TARGET_URL = "https://api.binance.com/api/v3/ping"
+PROXY_HOST = "127.0.0.1"
+PROXY_PORT = 1080
+ITERATIONS = 50
+
+def get_latency(use_proxy=False):
+    session = requests.Session()
+    if use_proxy:
+        session.proxies = {
+            'http': f'socks5://{PROXY_HOST}:{PROXY_PORT}',
+            'https': f'socks5://{PROXY_HOST}:{PROXY_PORT}'
+        }
+
+    start = time.perf_counter()
+    try:
+        resp = session.get(TARGET_URL, timeout=5)
+        resp.raise_for_status()
+        end = time.perf_counter()
+        return (end - start) * 1000  # ms
+    except Exception as e:
+        return None
+
+def run_test(name, use_proxy):
+    print(f"\n>>> Running Test: {name} (Proxy={use_proxy})...")
+    latencies = []
+    errors = 0
+
+    for i in range(ITERATIONS):
+        lat = get_latency(use_proxy)
+        if lat:
+            latencies.append(lat)
+            print(f"#{i+1}: {lat:.2f} ms", end="\r")
+        else:
+            errors += 1
+            print(f"#{i+1}: ERROR", end="\r")
+        time.sleep(0.1)
+
+    print("\n" + "-"*30)
+    if not latencies:
+        print("All failed.")
+        return
+
+    avg = statistics.mean(latencies)
+    median = statistics.median(latencies)
+    stdev = statistics.stdev(latencies) if len(latencies) > 1 else 0
+    min_lat = min(latencies)
+    max_lat = max(latencies)
+
+    print(f"Results for {name}:")
+    print(f"  Samples: {len(latencies)}/{ITERATIONS}")
+    print(f"  Errors : {errors}")
+    print(f"  Min    : {min_lat:.2f} ms")
+    print(f"  Max    : {max_lat:.2f} ms")
+    print(f"  Avg    : {avg:.2f} ms")
+    print(f"  Jitter : {stdev:.2f} ms (Lower is Better)")
+
+if __name__ == "__main__":
+    print("Installing requirements...")
+    os.system("pip install requests PySocks -q")
+
+    print("=== BENCHMARK START ===")
+
+    # 1. Direct (Optimized Kernel)
+    run_test("Ireland -> Public Internet -> Binance", False)
+
+    # 2. Tunnel (Backbone)
+    run_test("Ireland -> AWS Backbone -> Tokyo -> Binance", True)
+
+    print("\n=== BENCHMARK END ===")
diff --git a/configs/execution.toml b/configs/execution.toml
index 3d4a2bf..ba01743 100644
--- a/configs/execution.toml
+++ b/configs/execution.toml
@@ -1,5 +1,10 @@
 [execution]
-mode = "paper"
-rate_limit_rps = 15
+mode = "live"
+rate_limit_rps = 2
 http_timeout_ms = 3000
 clob_endpoint = "https://clob.polymarket.com"
+# Optional: separate endpoint for authenticated order operations (typically a localhost gateway).
+# If omitted, the engine uses `clob_endpoint` for both reads and order writes.
+order_endpoint = "http://127.0.0.1:9001"
+order_backup_endpoint = "http://127.0.0.1:9002"
+order_failover_timeout_ms = 200
diff --git a/configs/seat.toml b/configs/seat.toml
new file mode 100644
index 0000000..bbddd24
--- /dev/null
+++ b/configs/seat.toml
@@ -0,0 +1,32 @@
+[seat]
+enabled = true
+control_base_url = "http://127.0.0.1:8080"
+optimizer_url = "http://127.0.0.1:8091"
+
+runtime_tick_sec = 60
+activation_check_sec = 3600
+
+layer1_interval_sec = 3600
+layer2_interval_sec = 21600
+layer3_interval_sec = 86400
+
+layer2_shadow_sec = 2700
+layer3_shadow_sec = 6000
+
+smoothing_sec = 1800
+monitor_sec = 3600
+
+rollback_pause_sec = 86400
+global_pause_sec = 172800
+layer0_lock_sec = 172800
+black_swan_lock_sec = 172800
+
+layer1_min_trades = 300
+layer2_min_trades = 800
+layer2_min_uptime_sec = 259200
+layer3_min_trades = 2000
+layer3_min_uptime_sec = 1209600
+
+source_health_floor = 0.30
+history_retention_days = 180
+objective_drawdown_penalty = 5.0
diff --git a/configs/settlement.toml b/configs/settlement.toml
new file mode 100644
index 0000000..a94b5f0
--- /dev/null
+++ b/configs/settlement.toml
@@ -0,0 +1,10 @@
+[settlement]
+enabled = true
+# Example: https://your-chainlink-proxy.example.com/prices
+# Response JSON should be an object with symbol keys, e.g.
+# { "BTCUSDT": 69012.5, "ETHUSDT": 3810.2, "SOLUSDT": 186.3, "XRPUSDT": 0.91 }
+endpoint = ""
+required_for_live = true
+poll_interval_ms = 1000
+timeout_ms = 800
+symbols = ["BTCUSDT", "ETHUSDT", "SOLUSDT", "XRPUSDT"]
diff --git a/configs/strategy.toml b/configs/strategy.toml
index 3bb92a6..2486faf 100644
--- a/configs/strategy.toml
+++ b/configs/strategy.toml
@@ -1,20 +1,20 @@
 [maker]
-base_quote_size = 2.0
-min_edge_bps = 4.0
+base_quote_size = 1.0
+min_edge_bps = 1.0
 inventory_skew = 0.15
-max_spread = 0.03
-ttl_ms = 400
+max_spread = 0.08
+ttl_ms = 500
 
 [taker]
-trigger_bps = 7.0
+trigger_bps = 4.0
 max_slippage_bps = 30.0
-stale_tick_filter_ms = 2000
+stale_tick_filter_ms = 120
 market_tier_profile = "balanced_sol_guard"
 
 [online_calibration]
 capital_fraction_kelly = 0.35
 variance_penalty_lambda = 0.25
-min_eval_notional_usdc = 0.05
+min_eval_notional_usdc = 0.01
 min_expected_edge_usdc = 0.0002
 
 [fair_value.basis_mr]
@@ -33,3 +33,256 @@ enabled = true
 outlier_method = "iqr"
 iqr_k = 1.5
 min_samples = 5
+
+# ===== Predator C+ (MVP) =====
+# Edge-confirmed: Direction only decides YES/NO side; EV thresholds are still enforced.
+
+[predator_c]
+enabled = true
+# "maker_first" | "taker_first" | "taker_only"
+priority = "maker_first"
+
+[predator_c.direction_detector]
+window_max_sec = 120
+threshold_5m_pct = 0.03
+threshold_15m_pct = 0.05
+threshold_1h_pct = 0.20
+threshold_1d_pct = 0.50
+lookback_short_sec = 15
+lookback_long_sec = 60
+min_sources_for_high_confidence = 2
+min_ticks_for_signal = 3
+min_consecutive_ticks = 1
+min_velocity_bps_per_sec = 3.0
+min_acceleration = 0.0
+momentum_spike_multiplier = 1.8
+min_tick_rate_spike_ratio = 1.8
+tick_rate_short_ms = 300
+tick_rate_long_ms = 3000
+enable_source_vote_gate = true
+require_secondary_confirmation = true
+source_vote_max_age_ms = 2000
+
+[predator_c.probability_engine]
+momentum_gain = 2.0
+lag_penalty_per_ms = 0.0002
+confidence_floor = 0.05
+sigma_annual = 0.90
+horizon_sec = 30
+drift_annual = 0.0
+velocity_drift_gain = 0.35
+acceleration_drift_gain = 0.02
+fair_blend_weight = 0.35
+
+[predator_c.taker_sniper]
+min_direction_confidence = 0.60
+min_edge_net_bps = 8.5
+max_spread = 0.08
+cooldown_ms_per_market = 800
+
+[predator_c.regime]
+enabled = true
+active_min_confidence = 0.65
+active_min_magnitude_pct = 0.04
+defend_tox_score = 0.90
+defend_on_toxic_danger = false
+defend_min_source_health = 0.15
+quiet_min_edge_multiplier = 1.05
+quiet_chunk_scale = 0.50
+
+[predator_c.cross_symbol]
+enabled = true
+leader_symbol = "BTCUSDT"
+follower_symbols = ["ETHUSDT", "SOLUSDT"]
+min_leader_confidence = 0.80
+min_leader_magnitude_pct = 0.12
+follower_stale_confidence_max = 0.65
+max_correlated_positions = 2
+
+[predator_c.gatling]
+enabled = true
+chunk_notional_usdc = 5.0
+min_chunks = 1
+max_chunks = 4
+spacing_ms = 12
+stop_on_reject = true
+
+[predator_c.gatling_symbols.BTCUSDT]
+chunk_notional_usdc = 8.0
+min_chunks = 1
+max_chunks = 4
+spacing_ms = 10
+
+[predator_c.gatling_symbols.ETHUSDT]
+chunk_notional_usdc = 5.0
+min_chunks = 1
+max_chunks = 4
+spacing_ms = 12
+
+[predator_c.gatling_symbols.SOLUSDT]
+chunk_notional_usdc = 3.0
+min_chunks = 1
+max_chunks = 5
+spacing_ms = 14
+
+[predator_c.gatling_symbols.XRPUSDT]
+chunk_notional_usdc = 2.0
+min_chunks = 1
+max_chunks = 6
+spacing_ms = 14
+
+[predator_c.strategy_d]
+enabled = false
+min_gap_bps = 25.0
+min_edge_net_bps = 12.75
+min_confidence = 0.65
+max_notional_usdc = 25.0
+cooldown_ms_per_market = 500
+
+[predator_c.exit]
+enabled = true
+t100ms_reversal_bps = -3.0
+t300ms_reversal_bps = -2.0
+convergence_exit_ratio = 0.85
+t3_take_ratio = 0.60
+t15_min_unrealized_usdc = 0.0
+t60_true_prob_floor = 0.70
+t300_force_exit_ms = 300000
+t300_hold_prob_threshold = 0.95
+t300_hold_time_to_expiry_ms = 300000
+max_single_trade_loss_usdc = 1.0
+flatten_on_trigger = true
+
+[predator_c.router]
+max_locked_pct_5m = 0.30
+max_locked_pct_15m = 0.40
+max_locked_pct_1h = 0.50
+max_locked_pct_1d = 0.30
+max_concurrent_positions = 8
+liquidity_reserve_pct = 0.20
+# Micro-live hard caps (keep permissive in paper/shadow; override when armed)
+max_order_notional_usdc = 1000000.0
+max_total_notional_usdc = 1000000.0
+
+[predator_c.compounder]
+enabled = false
+initial_capital_usdc = 100.0
+compound_ratio = 1.0
+position_fraction = 0.15
+min_quote_size = 1.0
+# For micro-live: loss <= -1U triggers pause+flatten (enforced only when live-armed).
+daily_loss_cap_usdc = 1.0
+
+[v52.time_phase]
+early_min_ratio = 0.55
+late_max_ratio = 0.10
+early_size_scale = 0.80
+maturity_size_scale = 1.00
+late_size_scale = 1.25
+allow_timeframes = ["5m", "15m"]
+
+[v52.execution]
+late_force_taker_remaining_ms = 30000
+maker_wait_ms_before_force = 800
+apply_force_taker_in_maturity = true
+apply_force_taker_in_late = true
+alpha_window_enabled = true
+alpha_window_move_bps = 3.0
+alpha_window_poll_ms = 10
+alpha_window_max_wait_ms = 1000
+require_compounder_when_live = true
+
+[v52.dual_arb]
+enabled = true
+safety_margin_bps = 3.0
+threshold = 0.99
+fee_buffer_mode = "conservative_taker"
+
+[v52.reversal]
+same_market_opposite_first = true
+
+[transport]
+# Production baseline: direct-only transport.
+mode = "direct_only"
+udp_local_only = true
+udp_share_cap = 0.35
+dedupe_window_ms = 8
+jitter_threshold_ms = 25
+fallback_arm_duration_ms = 8000
+fallback_cooldown_sec = 300
+
+[fusion]
+enable_udp = true
+# SEAT Latency Fabric v1.0: WebSocket ä¸ºä¸»é€šé“ï¼ŒUDP ä»…ç´§æ€¥ fallback
+# å¯é€‰: "direct_only"(WSä¼˜å…ˆ) / "active_active"(åŒè·¯) / "udp_only"(ä»…UDP)
+mode = "direct_only"
+udp_port = 6666
+# æ›´æ¿€è¿›åŽ»é‡çª—å£
+dedupe_window_ms = 8
+dedupe_price_bps = 0.2
+
+[source_health]
+min_samples = 64
+gap_window_ms = 2000
+jitter_limit_ms = 10.0
+deviation_limit_bps = 30.0
+freshness_limit_ms = 1500.0
+min_score_for_trading = 0.40
+
+[edge_model]
+model = "ev_net"
+gate_mode = "dynamic"
+version = "v2-ev-net"
+base_gate_bps = 0.5
+congestion_penalty_bps = 2.0
+latency_penalty_bps = 2.0
+fail_cost_bps = 1.0
+
+[exit]
+enabled = true
+t100ms_reversal_bps = -3.0
+t300ms_reversal_bps = -2.0
+convergence_exit_ratio = 0.85
+time_stop_ms = 300000
+edge_decay_bps = -2.0
+adverse_move_bps = -8.0
+flatten_on_trigger = true
+t3_take_ratio = 0.60
+t15_min_unrealized_usdc = 0.0
+t60_true_prob_floor = 0.70
+t300_force_exit_ms = 300000
+t300_hold_prob_threshold = 0.95
+t300_hold_time_to_expiry_ms = 300000
+max_single_trade_loss_usdc = 1.0
+
+# ===== Risk Controls (P2) =====
+
+[risk_controls]
+enabled = true
+
+[risk_controls.market_quality]
+# Filter out low-quality markets
+max_spread_bps = 150                  # Skip if spread > 1.5%
+min_survival_rate = 0.80              # Skip if market survival < 80%
+min_liquidity_usdc = 50.0             # Skip if best bid/ask < $50
+
+[risk_controls.exposure_limits]
+# Position size caps
+max_total_exposure_usdc = 2.0        # Total across all positions
+max_per_market_exposure_usdc = 2.0    # Per market ID
+max_per_symbol_exposure_usdc = 2.0   # Per underlying symbol
+max_concurrent_positions = 8          # Already in predator_c.router
+
+[risk_controls.kill_switch]
+# Automatic pause conditions
+max_daily_loss_usdc = 5.0             # Pause if daily loss > $5
+max_drawdown_pct = 0.20               # Pause if drawdown > 20%
+max_latency_p99_ms = 100.0            # Pause if p99 latency > 100ms
+min_execution_success_rate = 0.50     # Pause if success rate < 50%
+
+[risk_controls.progressive_limits]
+enabled = true
+drawdown_tier1_ratio = 0.50
+drawdown_tier2_ratio = 0.80
+tier1_size_scale = 0.70
+tier2_size_scale = 0.40
diff --git a/configs/universe.toml b/configs/universe.toml
index 8bad560..d74a940 100644
--- a/configs/universe.toml
+++ b/configs/universe.toml
@@ -3,17 +3,6 @@ assets = [
   "ETHUSDT",
   "SOLUSDT",
   "XRPUSDT",
-  "BNBUSDT",
-  "DOGEUSDT",
-  "ADAUSDT",
-  "AVAXUSDT",
-  "LINKUSDT",
-  "MATICUSDT",
-  "LTCUSDT",
-  "DOTUSDT",
-  "TRXUSDT",
-  "TONUSDT",
-  "NEARUSDT",
 ]
 market_types = ["updown"]
 timeframes = ["5m", "15m", "1h", "1d"]
diff --git a/crates/app_runner/Cargo.toml b/crates/app_runner/Cargo.toml
index 96a6ae7..8ac7493 100644
--- a/crates/app_runner/Cargo.toml
+++ b/crates/app_runner/Cargo.toml
@@ -8,11 +8,15 @@ license.workspace = true
 anyhow.workspace = true
 axum.workspace = true
 chrono.workspace = true
+dashmap.workspace = true
 core_types = { path = "../core_types" }
+direction_detector = { path = "../direction_detector" }
+exit_manager = { path = "../exit_manager" }
 execution_clob = { path = "../execution_clob" }
 fair_value = { path = "../fair_value" }
 feed_polymarket = { path = "../feed_polymarket" }
 feed_reference = { path = "../feed_reference" }
+feed_udp = { path = "../feed_udp" }
 futures.workspace = true
 infra_bus = { path = "../infra_bus" }
 market_discovery = { path = "../market_discovery" }
@@ -21,12 +25,25 @@ metrics-exporter-prometheus.workspace = true
 observability = { path = "../observability" }
 paper_executor = { path = "../paper_executor" }
 portfolio = { path = "../portfolio" }
+probability_engine = { path = "../probability_engine" }
 reqwest.workspace = true
 risk_engine = { path = "../risk_engine" }
 rustls.workspace = true
 serde.workspace = true
 serde_json.workspace = true
+settlement_compounder = { path = "../settlement_compounder" }
 sha2.workspace = true
+smol_str.workspace = true
 strategy_maker = { path = "../strategy_maker" }
+taker_sniper = { path = "../taker_sniper" }
+timeframe_router = { path = "../timeframe_router" }
 tokio.workspace = true
 tracing.workspace = true
+toml.workspace = true
+mimalloc = "0.1"
+poly_wire = { path = "../poly_wire" }
+tokio-tungstenite.workspace = true
+tracing-subscriber.workspace = true
+socket2 = "0.6.2"
+flate2 = "1.0"
+rusqlite = { version = "0.31", features = ["bundled"] }
diff --git a/crates/app_runner/src/bin/bench_feed.rs b/crates/app_runner/src/bin/bench_feed.rs
new file mode 100644
index 0000000..6708db4
--- /dev/null
+++ b/crates/app_runner/src/bin/bench_feed.rs
@@ -0,0 +1,261 @@
+use anyhow::Result;
+use futures::StreamExt;
+use poly_wire::{
+    decode_auto, WirePacket, WIRE_BOOK_TOP24_SIZE, WIRE_MAX_PACKET_SIZE, WIRE_MOMENTUM_TICK32_SIZE,
+    WIRE_RELAY_TICK40_SIZE,
+};
+use serde::Deserialize;
+use std::collections::HashMap;
+use std::io::Write;
+use std::sync::Arc;
+use std::time::{SystemTime, UNIX_EPOCH};
+use tokio::net::UdpSocket;
+use tokio::sync::Mutex;
+use tokio_tungstenite::connect_async;
+use tokio_tungstenite::tungstenite::Message;
+use tracing::{info, warn};
+use tracing_subscriber::FmtSubscriber;
+
+#[derive(Debug, Deserialize)]
+struct BookTicker {
+    #[serde(default, rename = "E")]
+    event_time_ms: u64,
+}
+
+fn now_micros() -> u64 {
+    SystemTime::now()
+        .duration_since(UNIX_EPOCH)
+        .unwrap()
+        .as_micros() as u64
+}
+
+#[inline]
+fn percentile(sorted: &[f64], q: f64) -> f64 {
+    let idx = (((sorted.len() - 1) as f64) * q.clamp(0.0, 1.0)).round() as usize;
+    sorted[idx]
+}
+
+#[tokio::main]
+async fn main() -> Result<()> {
+    rustls::crypto::ring::default_provider()
+        .install_default()
+        .unwrap();
+    tracing::subscriber::set_global_default(
+        FmtSubscriber::builder()
+            .with_max_level(tracing::Level::INFO)
+            .finish(),
+    )
+    .expect("setting default subscriber failed");
+
+    let symbol = std::env::var("SYMBOL").unwrap_or_else(|_| "btcusdt".to_string());
+    let udp_port = 6666;
+
+    info!("ðŸš€ Starting Feed Benchmark (Symbol: {})", symbol);
+    info!("   - Direct: Binance WS (Ireland)");
+    info!("   - Relay:  UDP Port {} (Tokyo)", udp_port);
+
+    // 1. Setup UDP Listener (Optimized)
+    use socket2::{Domain, Protocol, Socket, Type};
+    use std::net::SocketAddr;
+
+    let socket = Socket::new(Domain::IPV4, Type::DGRAM, Some(Protocol::UDP))?;
+    let _ = socket.set_recv_buffer_size(8 * 1024 * 1024); // 8MB
+    let _ = socket.set_nonblocking(true);
+    let addr_str = format!("0.0.0.0:{}", udp_port);
+    let addr: SocketAddr = addr_str.parse()?;
+    #[cfg(target_os = "linux")]
+    let _ = socket.set_reuse_port(true);
+    let _ = socket.set_reuse_address(true);
+    socket.bind(&addr.into())?;
+
+    let socket = UdpSocket::from_std(socket.into())?;
+
+    info!("âœ… UDP Listening on {} (Buffer: 8MB)", addr_str);
+
+    // 2. Setup WS Listener
+    let ws_url = format!(
+        "wss://stream.binance.com:9443/ws/{}@bookTicker",
+        symbol.to_lowercase()
+    );
+    let (ws_stream, _) = connect_async(&ws_url).await?;
+    info!("âœ… WS Connected to {}", ws_url);
+    let (_, mut read) = ws_stream.split();
+
+    // 3. Shared State
+    // Map<event_ts_ms, (ws_recv_ts, udp_recv_ts)>
+    let tracker: Arc<Mutex<HashMap<u64, (Option<u64>, Option<u64>)>>> =
+        Arc::new(Mutex::new(HashMap::new()));
+
+    // I/O Thread Setup
+    struct LogEntry {
+        id: u64,
+        udp: u64,
+        ws: u64,
+        delta: f64,
+        faster: &'static str,
+    }
+
+    let (tx_log, rx_log) = std::sync::mpsc::channel::<LogEntry>();
+    let tx_log_udp = tx_log.clone();
+    let tx_log_ws = tx_log.clone();
+    let (tx_delta, rx_delta) = std::sync::mpsc::channel::<f64>();
+    let tx_delta_udp = tx_delta.clone();
+    let tx_delta_ws = tx_delta.clone();
+
+    // Spawn Writer Thread
+    std::thread::spawn(move || {
+        let file = std::fs::File::create("latency_report.csv").unwrap();
+        let mut writer = std::io::BufWriter::new(file);
+        writeln!(writer, "event_ts_ms,udp_ts,ws_ts,delta_ms,faster_source").unwrap();
+
+        while let Ok(entry) = rx_log.recv() {
+            writeln!(
+                writer,
+                "{},{},{},{:.3},{}",
+                entry.id, entry.udp, entry.ws, entry.delta, entry.faster
+            )
+            .unwrap();
+        }
+    });
+
+    let tracker_udp = tracker.clone();
+    let tracker_ws = tracker.clone();
+
+    // 4. UDP Task
+    tokio::spawn(async move {
+        let mut buf = [0u8; WIRE_MAX_PACKET_SIZE];
+        let mut last_event_ts_ms = 0_u64;
+        loop {
+            match socket.recv_from(&mut buf).await {
+                Ok((amt, _)) => {
+                    let recv_ts = now_micros();
+                    if amt != WIRE_BOOK_TOP24_SIZE
+                        && amt != WIRE_MOMENTUM_TICK32_SIZE
+                        && amt != WIRE_RELAY_TICK40_SIZE
+                    {
+                        continue;
+                    }
+                    if let Ok(packet) = decode_auto(&buf[..amt]) {
+                        let event_ts_ms = match packet {
+                            WirePacket::BookTop24(v) => v.ts_micros / 1_000,
+                            WirePacket::MomentumTick32(v) => v.ts_micros / 1_000,
+                            WirePacket::RelayTick40(v) => v.ts_micros / 1_000,
+                        };
+                        if last_event_ts_ms > 0 && event_ts_ms < last_event_ts_ms {
+                            warn!(
+                                "âš ï¸ UDP timestamp backjump: {} -> {}",
+                                last_event_ts_ms, event_ts_ms
+                            );
+                        }
+                        last_event_ts_ms = event_ts_ms;
+                        let mut map = tracker_udp.lock().await;
+                        let entry = map.entry(event_ts_ms).or_insert((None, None));
+                        entry.1 = Some(recv_ts);
+
+                        // Check match inside lock, but do NOT do I/O
+                        let match_found = entry.0;
+
+                        if let Some(ws_ts) = match_found {
+                            map.remove(&event_ts_ms);
+
+                            let delta = (recv_ts as i64) - (ws_ts as i64);
+                            let ms = delta as f64 / 1000.0;
+                            let faster = if ms < 0.0 { "UDP" } else { "WS" };
+
+                            let _ = tx_log_udp.send(LogEntry {
+                                id: event_ts_ms,
+                                udp: recv_ts,
+                                ws: ws_ts,
+                                delta: ms,
+                                faster,
+                            });
+                            let _ = tx_delta_udp.send(ms);
+                        }
+
+                        // Prune (Optimized: Check size less often?)
+                        if map.len() > 5000 {
+                            map.retain(|k, _| *k > event_ts_ms.saturating_sub(10_000));
+                        }
+                    }
+                }
+                Err(e) => warn!("UDP Error: {}", e),
+            }
+        }
+    });
+
+    // 5. WS Loop
+    let mut last_stat_time = std::time::Instant::now();
+    let mut stats_window: Vec<f64> = Vec::with_capacity(16_384);
+
+    while let Some(msg) = read.next().await {
+        match msg {
+            Ok(Message::Text(text)) => {
+                let recv_ts = now_micros();
+                if let Ok(ticker) = serde_json::from_str::<BookTicker>(&text) {
+                    if ticker.event_time_ms == 0 {
+                        continue;
+                    }
+                    let mut map = tracker_ws.lock().await;
+                    let entry = map.entry(ticker.event_time_ms).or_insert((None, None));
+                    entry.0 = Some(recv_ts);
+
+                    let match_found = entry.1;
+
+                    if let Some(udp_ts) = match_found {
+                        map.remove(&ticker.event_time_ms);
+
+                        let delta = (udp_ts as i64) - (recv_ts as i64);
+                        let ms = delta as f64 / 1000.0;
+                        let faster = if ms < 0.0 { "UDP" } else { "WS" };
+
+                        let _ = tx_log_ws.send(LogEntry {
+                            id: ticker.event_time_ms,
+                            udp: udp_ts,
+                            ws: recv_ts,
+                            delta: ms,
+                            faster,
+                        });
+                        let _ = tx_delta_ws.send(ms);
+                    }
+
+                    if map.len() > 5000 {
+                        map.retain(|k, _| *k > ticker.event_time_ms.saturating_sub(10_000));
+                    }
+                }
+            }
+            Ok(Message::Ping(_)) => {}
+            _ => {}
+        }
+
+        // Periodic Stats Log (Every 10s)
+        if last_stat_time.elapsed().as_secs() >= 10 {
+            while let Ok(delta) = rx_delta.try_recv() {
+                stats_window.push(delta);
+            }
+            if !stats_window.is_empty() {
+                stats_window.sort_by(|a, b| a.total_cmp(b));
+                let len = stats_window.len();
+                let p50 = percentile(&stats_window, 0.50);
+                let p90 = percentile(&stats_window, 0.90);
+                let p99 = percentile(&stats_window, 0.99);
+                let udp_fast_count = stats_window.iter().filter(|&&x| x < 0.0).count();
+
+                info!(
+                    "ðŸ“Š STATS (Last 10s): Count={} | P50={:.3}ms | P90={:.3}ms | P99={:.3}ms | UDP Faster: {}/{} ({:.1}%)",
+                    len,
+                    p50,
+                    p90,
+                    p99,
+                    udp_fast_count,
+                    len,
+                    (udp_fast_count as f64 / len as f64) * 100.0
+                );
+
+                stats_window.clear();
+            }
+            last_stat_time = std::time::Instant::now();
+        }
+    }
+
+    Ok(())
+}
diff --git a/crates/app_runner/src/bootstrap.rs b/crates/app_runner/src/bootstrap.rs
new file mode 100644
index 0000000..930e6f2
--- /dev/null
+++ b/crates/app_runner/src/bootstrap.rs
@@ -0,0 +1,373 @@
+use std::collections::HashMap;
+use std::net::SocketAddr;
+use std::sync::{Arc, RwLock as StdRwLock};
+use std::time::Duration;
+
+use anyhow::{Context, Result};
+use dashmap::DashMap;
+use direction_detector::DirectionDetector;
+use execution_clob::{ClobExecution, ExecutionMode};
+use exit_manager::ExitManager;
+use infra_bus::RingBus;
+use observability::{init_metrics, init_tracing};
+use paper_executor::ShadowExecutor;
+use portfolio::PortfolioBook;
+use probability_engine::ProbabilityEngine;
+use reqwest::Client;
+use risk_engine::DefaultRiskManager;
+use settlement_compounder::SettlementCompounder;
+use taker_sniper::TakerSniper;
+use timeframe_router::TimeframeRouter;
+use tokio::sync::{mpsc, RwLock};
+
+use crate::config_loader::{
+    load_edge_model_config, load_execution_config, load_exit_config, load_fair_value_config,
+    load_fusion_config, load_perf_profile_config, load_predator_c_config, load_risk_limits_config,
+    load_seat_config, load_settlement_config, load_source_health_config, load_strategy_config,
+    load_universe_config,
+};
+use crate::feed_runtime::{spawn_market_feed, spawn_reference_feed, spawn_settlement_feed};
+use crate::paper_runtime::{set_global_paper_runtime, PaperRuntimeHandle};
+use crate::report_io::{ensure_dataset_dirs, init_jsonl_writer};
+use crate::seat_runtime::SeatRuntimeHandle;
+use crate::state::{
+    settlement_live_gate_status, to_exit_manager_config, AllocatorConfig, AppState, EngineShared,
+    ShadowStats, StrategyIngressMsg, ToxicityConfig,
+};
+use crate::{control_api, orchestration, spawn_detached, spawn_strategy_engine};
+
+fn env_flag_enabled(name: &str) -> bool {
+    std::env::var(name)
+        .ok()
+        .map(|v| {
+            let normalized = v.trim().to_ascii_lowercase();
+            matches!(normalized.as_str(), "1" | "true" | "yes" | "on")
+        })
+        .unwrap_or(false)
+}
+
+pub(super) async fn async_main() -> Result<()> {
+    let _guard = init_tracing("app_runner");
+    let prometheus = init_metrics();
+    ensure_dataset_dirs();
+    let control_port = std::env::var("POLYEDGE_CONTROL_PORT")
+        .ok()
+        .and_then(|v| v.parse::<u16>().ok())
+        .unwrap_or(8080);
+    tracing::info!(control_port, "resolved control port");
+    std::env::set_var("POLYEDGE_CONTROL_PORT", control_port.to_string());
+    let mut seat_cfg = load_seat_config();
+    if seat_cfg.control_base_url.trim().is_empty() {
+        seat_cfg.control_base_url = format!("http://127.0.0.1:{control_port}");
+    }
+    let seat = SeatRuntimeHandle::spawn(seat_cfg);
+    let seat_fill_counter = seat.live_fill_counter();
+    let paper_enabled = std::env::var("POLYEDGE_PAPER_ENABLED")
+        .ok()
+        .map(|v| !matches!(v.trim().to_ascii_lowercase().as_str(), "0" | "false" | "off" | "no"))
+        .unwrap_or(true);
+    let paper_initial_capital = std::env::var("POLYEDGE_PAPER_INITIAL_CAPITAL")
+        .ok()
+        .and_then(|v| v.parse::<f64>().ok())
+        .unwrap_or(100.0)
+        .max(1.0);
+    let paper_run_id = std::env::var("POLYEDGE_PAPER_RUN_ID")
+        .ok()
+        .filter(|v| !v.trim().is_empty())
+        .unwrap_or_else(|| format!("paper-{}", chrono::Utc::now().format("%Y%m%d%H%M%S")));
+    let paper_sqlite_enabled = std::env::var("POLYEDGE_PAPER_SQLITE_ENABLED")
+        .ok()
+        .map(|v| !matches!(v.trim().to_ascii_lowercase().as_str(), "0" | "false" | "off" | "no"))
+        .unwrap_or(true);
+    let paper = PaperRuntimeHandle::new(
+        paper_enabled,
+        paper_run_id,
+        paper_initial_capital,
+        paper_sqlite_enabled,
+        seat.clone(),
+    );
+    set_global_paper_runtime(paper.clone());
+
+    let execution_cfg = load_execution_config();
+    let universe_cfg = load_universe_config();
+    let settlement_cfg_boot = load_settlement_config();
+    let bus_capacity = std::env::var("POLYEDGE_BUS_CAPACITY")
+        .ok()
+        .and_then(|v| v.parse::<usize>().ok())
+        .unwrap_or(32_768)
+        .clamp(4_096, 262_144);
+    let bus = RingBus::new(bus_capacity);
+    let portfolio = Arc::new(PortfolioBook::default());
+    let live_armed = env_flag_enabled("POLYEDGE_LIVE_ARMED");
+    let force_paper = env_flag_enabled("POLYEDGE_FORCE_PAPER");
+    let live_gate = settlement_live_gate_status(&settlement_cfg_boot);
+    let exec_mode = if force_paper {
+        if execution_cfg.mode.eq_ignore_ascii_case("live") {
+            tracing::warn!(
+                "POLYEDGE_FORCE_PAPER is enabled; forcing paper mode despite execution.mode=live"
+            );
+        }
+        ExecutionMode::Paper
+    } else if execution_cfg.mode.eq_ignore_ascii_case("live") {
+        if !live_armed {
+            tracing::warn!(
+                "execution.mode=live but POLYEDGE_LIVE_ARMED is not true; forcing paper mode"
+            );
+            ExecutionMode::Paper
+        } else if !live_gate.ready {
+            tracing::warn!(
+                reason = %live_gate.reason,
+                "execution.mode=live requested but settlement live gate failed; forcing paper mode"
+            );
+            ExecutionMode::Paper
+        } else {
+            ExecutionMode::Live
+        }
+    } else {
+        ExecutionMode::Paper
+    };
+    let execution = Arc::new(ClobExecution::new_with_order_routing(
+        exec_mode,
+        execution_cfg.clob_endpoint.clone(),
+        execution_cfg.order_endpoint.clone(),
+        execution_cfg.order_backup_endpoint.clone(),
+        Duration::from_millis(execution_cfg.http_timeout_ms),
+        Duration::from_millis(execution_cfg.order_failover_timeout_ms.max(10)),
+    ));
+
+    // Optional: prewarm the execution HTTP client pool to reduce first-ack latency spikes.
+    // Uses the *same* reqwest client inside the execution layer (unlike ad-hoc curl probes).
+    if let Ok(raw) = std::env::var("POLYEDGE_HTTP_PREWARM_URLS") {
+        let urls = raw
+            .split(',')
+            .map(str::trim)
+            .filter(|u| u.starts_with("http://") || u.starts_with("https://"))
+            .map(|u| u.to_string())
+            .collect::<Vec<_>>();
+        if !urls.is_empty() {
+            tracing::info!(count = urls.len(), "prewarming execution http pool");
+            let exec = execution.clone();
+            spawn_detached("execution_http_prewarm", false, async move {
+                exec.prewarm_urls(&urls).await;
+            });
+        }
+    }
+    let shadow = Arc::new(ShadowExecutor::default());
+    let strategy_cfg = Arc::new(RwLock::new(Arc::new(load_strategy_config())));
+    let settlement_cfg = Arc::new(RwLock::new(settlement_cfg_boot));
+    let fusion_cfg = Arc::new(RwLock::new(load_fusion_config()));
+    let source_health_cfg = Arc::new(RwLock::new(load_source_health_config()));
+    let edge_model_cfg = Arc::new(RwLock::new(load_edge_model_config()));
+    let exit_cfg = Arc::new(RwLock::new(load_exit_config()));
+    let exit_cfg0 = exit_cfg.read().await.clone();
+    let fair_value_cfg = Arc::new(StdRwLock::new(load_fair_value_config()));
+    let toxicity_cfg = Arc::new(RwLock::new(Arc::new(ToxicityConfig::default())));
+    let risk_limits = Arc::new(StdRwLock::new(load_risk_limits_config()));
+    let perf_profile = Arc::new(RwLock::new(load_perf_profile_config()));
+    let allocator_cfg = {
+        let strategy = strategy_cfg.read().await.clone();
+        let tox = toxicity_cfg.read().await.clone();
+        Arc::new(RwLock::new(AllocatorConfig {
+            capital_fraction_kelly: strategy.capital_fraction_kelly,
+            variance_penalty_lambda: strategy.variance_penalty_lambda,
+            active_top_n_markets: tox.active_top_n_markets,
+            ..AllocatorConfig::default()
+        }))
+    };
+    let tox_state = Arc::new(RwLock::new(HashMap::new()));
+    let shadow_stats = Arc::new(ShadowStats::new());
+    let paused = Arc::new(RwLock::new(false));
+    let universe_symbols = Arc::new(universe_cfg.assets.clone());
+    let universe_market_types = Arc::new(universe_cfg.market_types.clone());
+    let universe_timeframes = Arc::new(universe_cfg.timeframes.clone());
+    init_jsonl_writer(perf_profile.clone()).await;
+
+    let risk_manager = Arc::new(DefaultRiskManager::new(risk_limits.clone()));
+    let predator_cfg = Arc::new(RwLock::new(load_predator_c_config()));
+    let predator_cfg0 = predator_cfg.read().await.clone();
+    let predator_direction_detector = Arc::new(RwLock::new(DirectionDetector::new(
+        predator_cfg0.direction_detector.clone(),
+    )));
+    let predator_latest_direction = Arc::new(RwLock::new(HashMap::new()));
+    let predator_latest_probability = Arc::new(RwLock::new(HashMap::new()));
+    let predator_probability_engine = Arc::new(RwLock::new(ProbabilityEngine::new(
+        predator_cfg0.probability_engine.clone(),
+    )));
+    let predator_taker_sniper = Arc::new(RwLock::new(TakerSniper::new(
+        predator_cfg0.taker_sniper.clone(),
+    )));
+    let predator_d_last_fire_ms = Arc::new(RwLock::new(HashMap::new()));
+    let predator_router = Arc::new(RwLock::new(TimeframeRouter::new(
+        predator_cfg0.router.clone(),
+    )));
+    let predator_compounder = Arc::new(RwLock::new(SettlementCompounder::new(
+        predator_cfg0.compounder.clone(),
+    )));
+    let predator_exit_manager = Arc::new(RwLock::new(ExitManager::new(to_exit_manager_config(
+        &exit_cfg0,
+    ))));
+    let shared = Arc::new(EngineShared {
+        latest_books: Arc::new(RwLock::new(HashMap::new())),
+        latest_signals: Arc::new(DashMap::new()),
+        latest_fast_ticks: Arc::new(DashMap::new()),
+        latest_anchor_ticks: Arc::new(DashMap::new()),
+        market_to_symbol: Arc::new(RwLock::new(HashMap::new())),
+        token_to_symbol: Arc::new(RwLock::new(HashMap::new())),
+        market_to_timeframe: Arc::new(RwLock::new(HashMap::new())),
+        symbol_to_markets: Arc::new(RwLock::new(HashMap::new())),
+        fee_cache: Arc::new(RwLock::new(HashMap::new())),
+        fee_refresh_inflight: Arc::new(RwLock::new(HashMap::new())),
+        scoring_cache: Arc::new(RwLock::new(HashMap::new())),
+        http: Client::new(),
+        clob_endpoint: execution_cfg.clob_endpoint.clone(),
+        strategy_cfg,
+        settlement_cfg: settlement_cfg.clone(),
+        source_health_cfg: source_health_cfg.clone(),
+        source_health_latest: Arc::new(RwLock::new(HashMap::new())),
+        settlement_prices: Arc::new(RwLock::new(HashMap::new())),
+        fusion_cfg: fusion_cfg.clone(),
+        edge_model_cfg: edge_model_cfg.clone(),
+        exit_cfg: exit_cfg.clone(),
+        fair_value_cfg,
+        toxicity_cfg,
+        risk_manager,
+        risk_limits: risk_limits.clone(),
+        universe_symbols: universe_symbols.clone(),
+        universe_market_types: universe_market_types.clone(),
+        universe_timeframes: universe_timeframes.clone(),
+        rate_limit_rps: execution_cfg.rate_limit_rps.max(0.1),
+        tox_state,
+        shadow_stats,
+        predator_cfg: predator_cfg.clone(),
+        predator_direction_detector,
+        predator_latest_direction,
+        predator_latest_probability,
+        predator_probability_engine,
+        predator_taker_sniper,
+        predator_d_last_fire_ms,
+        predator_router,
+        predator_compounder,
+        predator_exit_manager,
+        // WSS User Channel: live æ¨¡å¼ä¸‹å¯åŠ¨å®žæ—¶ fill é€šçŸ¥
+        // paper æ¨¡å¼ä¸‹ wss_fill_tx = Noneï¼Œexit lifecycle å›žé€€åˆ°çº¯ timer è·¯å¾„
+        wss_fill_tx: {
+            let is_live = matches!(exec_mode, ExecutionMode::Live);
+            let api_key = std::env::var("POLYEDGE_CLOB_API_KEY").unwrap_or_default();
+            if is_live && !api_key.is_empty() {
+                let wss_url = std::env::var("POLYEDGE_WSS_USER_URL").unwrap_or_else(|_| {
+                    "wss://ws-subscriptions-clob.polymarket.com/ws/user".to_string()
+                });
+                let (tx, _rx) = tokio::sync::broadcast::channel::<
+                    execution_clob::wss_user_feed::WssFillEvent,
+                >(64);
+                let tx = Arc::new(tx);
+                let tx_clone = tx.clone();
+                let fill_counter = seat_fill_counter.clone();
+                tokio::spawn(async move {
+                    execution_clob::wss_user_feed::run_wss_loop_with_sender(
+                        tx_clone, wss_url, api_key,
+                    )
+                    .await;
+                });
+                let mut fill_rx = tx.subscribe();
+                let execution_for_fill = execution.clone();
+                spawn_detached("seat_live_fill_counter", false, async move {
+                    loop {
+                        match fill_rx.recv().await {
+                            Ok(event) => {
+                                if event.event_type == "trade" {
+                                    fill_counter.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
+                                    execution_for_fill.mark_order_closed_local(&event.order_id);
+                                }
+                            }
+                            Err(tokio::sync::broadcast::error::RecvError::Lagged(_)) => continue,
+                            Err(tokio::sync::broadcast::error::RecvError::Closed) => break,
+                        }
+                    }
+                });
+                Some(tx)
+            } else {
+                None
+            }
+        },
+    });
+    let strategy_input_queue_cap = std::env::var("POLYEDGE_STRATEGY_INPUT_QUEUE_CAP")
+        .ok()
+        .and_then(|v| v.parse::<usize>().ok())
+        .unwrap_or(512)
+        .clamp(128, 5_760);
+    let (strategy_ingress_tx, strategy_ingress_rx) =
+        mpsc::channel::<StrategyIngressMsg>(strategy_input_queue_cap);
+
+    let state = AppState {
+        paused: paused.clone(),
+        bus: bus.clone(),
+        portfolio: portfolio.clone(),
+        execution: execution.clone(),
+        _shadow: shadow.clone(),
+        prometheus,
+        strategy_cfg: shared.strategy_cfg.clone(),
+        fair_value_cfg: shared.fair_value_cfg.clone(),
+        toxicity_cfg: shared.toxicity_cfg.clone(),
+        allocator_cfg: allocator_cfg.clone(),
+        risk_limits: risk_limits.clone(),
+        tox_state: shared.tox_state.clone(),
+        shadow_stats: shared.shadow_stats.clone(),
+        perf_profile: perf_profile.clone(),
+        shared: shared.clone(),
+        seat: seat.clone(),
+        paper: paper.clone(),
+    };
+
+    spawn_reference_feed(
+        bus.clone(),
+        shared.shadow_stats.clone(),
+        (*universe_symbols).clone(),
+        shared.fusion_cfg.clone(),
+        shared.clone(),
+        strategy_ingress_tx.clone(),
+    );
+    spawn_settlement_feed(shared.clone());
+    spawn_market_feed(
+        bus.clone(),
+        shared.shadow_stats.clone(),
+        (*universe_symbols).clone(),
+        (*universe_market_types).clone(),
+        (*universe_timeframes).clone(),
+        strategy_ingress_tx,
+    );
+    spawn_strategy_engine(
+        bus.clone(),
+        portfolio,
+        execution.clone(),
+        shadow,
+        paused.clone(),
+        shared.clone(),
+        strategy_ingress_rx,
+    );
+    orchestration::spawn_periodic_report_persistor(
+        shared.shadow_stats.clone(),
+        shared.tox_state.clone(),
+        execution.clone(),
+        shared.toxicity_cfg.clone(),
+    );
+    orchestration::spawn_data_reconcile_task(
+        bus.clone(),
+        paused.clone(),
+        shared.shadow_stats.clone(),
+    );
+
+    let app = control_api::build_router(state);
+
+    let addr: SocketAddr = format!("0.0.0.0:{control_port}").parse()?;
+    tracing::info!(%addr, "control api started");
+    let listener = tokio::net::TcpListener::bind(addr)
+        .await
+        .with_context(|| format!("bind control api listener at {addr}"))?;
+    axum::serve(listener, app).await?;
+    Ok(())
+}
+
+pub(super) fn install_rustls_provider() {
+    let _ = rustls::crypto::aws_lc_rs::default_provider().install_default();
+}
diff --git a/crates/app_runner/src/config_loader.rs b/crates/app_runner/src/config_loader.rs
new file mode 100644
index 0000000..b3b967d
--- /dev/null
+++ b/crates/app_runner/src/config_loader.rs
@@ -0,0 +1,1841 @@
+use std::fs;
+use std::path::{Path, PathBuf};
+
+use fair_value::BasisMrConfig;
+use risk_engine::RiskLimits;
+use serde::{Deserialize, Serialize};
+use strategy_maker::MakerConfig;
+
+use crate::seat_types::SeatConfig;
+use crate::state::{
+    EdgeModelConfig, ExecutionConfig, ExitConfig, FusionConfig, PerfProfile, PredatorCConfig,
+    PredatorCPriority, SettlementConfig, SourceHealthConfig,
+};
+
+fn strategy_config_path() -> PathBuf {
+    std::env::var("POLYEDGE_STRATEGY_CONFIG_PATH")
+        .ok()
+        .filter(|v| !v.trim().is_empty())
+        .map(PathBuf::from)
+        .unwrap_or_else(|| PathBuf::from("configs/strategy.toml"))
+}
+
+pub(super) fn load_fair_value_config() -> BasisMrConfig {
+    let path = strategy_config_path();
+    let Ok(raw) = fs::read_to_string(path) else {
+        return BasisMrConfig::default();
+    };
+
+    let mut cfg = BasisMrConfig::default();
+    let mut in_section = false;
+    for line in raw.lines() {
+        let line = line.trim();
+        if line.is_empty() || line.starts_with('#') {
+            continue;
+        }
+        if line.starts_with('[') && line.ends_with(']') {
+            in_section = line == "[fair_value.basis_mr]";
+            continue;
+        }
+        if !in_section {
+            continue;
+        }
+        let Some((k, v)) = line.split_once('=') else {
+            continue;
+        };
+        let key = k.trim();
+        let val = v.trim().trim_matches('"');
+        match key {
+            "enabled" => {
+                if let Ok(parsed) = val.parse::<bool>() {
+                    cfg.enabled = parsed;
+                }
+            }
+            "alpha_mean" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.alpha_mean = parsed.clamp(0.0, 1.0);
+                }
+            }
+            "alpha_var" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.alpha_var = parsed.clamp(0.0, 1.0);
+                }
+            }
+            "alpha_ret" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.alpha_ret = parsed.clamp(0.0, 1.0);
+                }
+            }
+            "alpha_vol" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.alpha_vol = parsed.clamp(0.0, 1.0);
+                }
+            }
+            "k_revert" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.k_revert = parsed.clamp(0.0, 5.0);
+                }
+            }
+            "z_cap" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.z_cap = parsed.clamp(0.5, 8.0);
+                }
+            }
+            "min_confidence" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.min_confidence = parsed.clamp(0.0, 1.0);
+                }
+            }
+            "warmup_ticks" => {
+                if let Ok(parsed) = val.parse::<usize>() {
+                    cfg.warmup_ticks = parsed.max(1);
+                }
+            }
+            _ => {}
+        }
+    }
+    cfg
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(super) struct UniverseConfig {
+    pub(super) assets: Vec<String>,
+    pub(super) market_types: Vec<String>,
+    pub(super) timeframes: Vec<String>,
+    pub(super) tier_whitelist: Vec<String>,
+    pub(super) tier_blacklist: Vec<String>,
+}
+
+impl Default for UniverseConfig {
+    fn default() -> Self {
+        Self {
+            assets: vec![
+                "BTCUSDT".to_string(),
+                "ETHUSDT".to_string(),
+                "SOLUSDT".to_string(),
+                "XRPUSDT".to_string(),
+            ],
+            market_types: vec![
+                "updown".to_string(),
+                "above_below".to_string(),
+                "range".to_string(),
+            ],
+            timeframes: vec![
+                "5m".to_string(),
+                "15m".to_string(),
+                "1h".to_string(),
+                "1d".to_string(),
+            ],
+            tier_whitelist: Vec::new(),
+            tier_blacklist: Vec::new(),
+        }
+    }
+}
+
+fn parse_toml_array_of_strings(val: &str) -> Vec<String> {
+    let trimmed = val.trim();
+    if !(trimmed.starts_with('[') && trimmed.ends_with(']')) {
+        return Vec::new();
+    }
+    let inner = &trimmed[1..trimmed.len() - 1];
+    inner
+        .split(',')
+        .map(|s| s.trim().trim_matches('"').trim_matches('\'').to_string())
+        .filter(|s| !s.is_empty())
+        .collect::<Vec<_>>()
+}
+
+#[cfg(test)]
+pub(crate) fn parse_toml_array_for_key(raw: &str, key: &str) -> Option<Vec<String>> {
+    let Ok(value) = toml::from_str::<toml::Value>(raw) else {
+        return None;
+    };
+    let arr = value.get(key)?.as_array()?;
+    let parsed = arr
+        .iter()
+        .filter_map(|v| v.as_str().map(ToString::to_string))
+        .collect::<Vec<_>>();
+    if parsed.is_empty() {
+        None
+    } else {
+        Some(parsed)
+    }
+}
+
+fn parse_gatling_symbol_section(section: &str) -> Option<String> {
+    const PREFIX: &str = "[predator_c.gatling_symbols.";
+    if !(section.starts_with(PREFIX) && section.ends_with(']')) {
+        return None;
+    }
+    let inner = &section[PREFIX.len()..section.len() - 1];
+    let symbol = inner.trim();
+    if symbol.is_empty() {
+        None
+    } else {
+        Some(symbol.to_string())
+    }
+}
+
+pub(super) fn load_strategy_config() -> MakerConfig {
+    let path = strategy_config_path();
+    let Ok(raw) = fs::read_to_string(path) else {
+        return MakerConfig::default();
+    };
+    let mut cfg = MakerConfig::default();
+    let mut in_maker = false;
+    let mut in_taker = false;
+    let mut in_online = false;
+    for line in raw.lines() {
+        let line = line.trim();
+        if line.is_empty() || line.starts_with('#') {
+            continue;
+        }
+        if line.starts_with('[') && line.ends_with(']') {
+            in_maker = line == "[maker]";
+            in_taker = line == "[taker]";
+            in_online = line == "[online_calibration]";
+            continue;
+        }
+        let Some((k, v)) = line.split_once('=') else {
+            continue;
+        };
+        let key = k.trim();
+        let val = v.trim().trim_matches('"');
+        if in_maker {
+            match key {
+                "base_quote_size" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.base_quote_size = parsed.max(0.01);
+                    }
+                }
+                "min_edge_bps" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.min_edge_bps = parsed.max(0.0);
+                    }
+                }
+                "inventory_skew" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.inventory_skew = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_spread" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.max_spread = parsed.max(0.0001);
+                    }
+                }
+                "ttl_ms" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.ttl_ms = parsed.max(50);
+                    }
+                }
+                _ => {}
+            }
+        } else if in_taker {
+            match key {
+                "trigger_bps" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.taker_trigger_bps = parsed.max(0.0);
+                    }
+                }
+                "max_slippage_bps" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.taker_max_slippage_bps = parsed.max(0.0);
+                    }
+                }
+                "stale_tick_filter_ms" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.stale_tick_filter_ms = parsed.clamp(50.0, 5_000.0);
+                    }
+                }
+                "market_tier_profile" => {
+                    cfg.market_tier_profile = val.to_string();
+                }
+                _ => {}
+            }
+        } else if in_online {
+            match key {
+                "capital_fraction_kelly" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.capital_fraction_kelly = parsed.clamp(0.01, 1.0);
+                    }
+                }
+                "variance_penalty_lambda" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.variance_penalty_lambda = parsed.clamp(0.0, 5.0);
+                    }
+                }
+                "min_eval_notional_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.min_eval_notional_usdc = parsed.max(0.0);
+                    }
+                }
+                "min_expected_edge_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.min_expected_edge_usdc = parsed.max(0.0);
+                    }
+                }
+                _ => {}
+            }
+        }
+    }
+    cfg
+}
+
+pub(super) fn load_fusion_config() -> FusionConfig {
+    let path = strategy_config_path();
+    let Ok(raw) = fs::read_to_string(path) else {
+        let cfg = FusionConfig::default();
+        std::env::set_var(
+            "POLYEDGE_UDP_LOCAL_ONLY",
+            if cfg.udp_local_only { "true" } else { "false" },
+        );
+        return cfg;
+    };
+
+    #[derive(Default)]
+    struct FusionPatch {
+        enable_udp: Option<bool>,
+        mode: Option<String>,
+        udp_port: Option<u16>,
+        dedupe_window_ms: Option<i64>,
+        dedupe_price_bps: Option<f64>,
+        udp_share_cap: Option<f64>,
+        jitter_threshold_ms: Option<f64>,
+        fallback_arm_duration_ms: Option<u64>,
+        fallback_cooldown_sec: Option<u64>,
+        udp_local_only: Option<bool>,
+    }
+
+    impl FusionPatch {
+        fn apply_to(self, cfg: &mut FusionConfig) {
+            if let Some(v) = self.enable_udp {
+                cfg.enable_udp = v;
+            }
+            if let Some(v) = self.mode {
+                cfg.mode = v;
+            }
+            if let Some(v) = self.udp_port {
+                cfg.udp_port = v.max(1);
+            }
+            if let Some(v) = self.dedupe_window_ms {
+                cfg.dedupe_window_ms = v.clamp(0, 2_000);
+            }
+            if let Some(v) = self.dedupe_price_bps {
+                cfg.dedupe_price_bps = v.clamp(0.0, 50.0);
+            }
+            if let Some(v) = self.udp_share_cap {
+                cfg.udp_share_cap = v.clamp(0.05, 0.95);
+            }
+            if let Some(v) = self.jitter_threshold_ms {
+                cfg.jitter_threshold_ms = v.clamp(1.0, 2_000.0);
+            }
+            if let Some(v) = self.fallback_arm_duration_ms {
+                cfg.fallback_arm_duration_ms = v.clamp(200, 15_000);
+            }
+            if let Some(v) = self.fallback_cooldown_sec {
+                cfg.fallback_cooldown_sec = v.clamp(0, 3_600);
+            }
+            if let Some(v) = self.udp_local_only {
+                cfg.udp_local_only = v;
+            }
+        }
+    }
+
+    #[derive(Clone, Copy, PartialEq, Eq)]
+    enum Section {
+        None,
+        Fusion,
+        Transport,
+    }
+
+    let mut cfg = FusionConfig::default();
+    let mut fusion_patch = FusionPatch::default();
+    let mut transport_patch = FusionPatch::default();
+    let mut section = Section::None;
+    let mut saw_fusion = false;
+    let mut saw_transport = false;
+
+    for line in raw.lines() {
+        let line = line.trim();
+        if line.is_empty() || line.starts_with('#') {
+            continue;
+        }
+        if line.starts_with('[') && line.ends_with(']') {
+            section = match line {
+                "[fusion]" => {
+                    saw_fusion = true;
+                    Section::Fusion
+                }
+                "[transport]" => {
+                    saw_transport = true;
+                    Section::Transport
+                }
+                _ => Section::None,
+            };
+            continue;
+        }
+        if section == Section::None {
+            continue;
+        }
+        let Some((k, v)) = line.split_once('=') else {
+            continue;
+        };
+        let key = k.trim();
+        let val = v.trim().trim_matches('"');
+        let target = if section == Section::Transport {
+            &mut transport_patch
+        } else {
+            &mut fusion_patch
+        };
+        match key {
+            "enable_udp" => {
+                if let Ok(parsed) = val.parse::<bool>() {
+                    target.enable_udp = Some(parsed);
+                }
+            }
+            "mode" => {
+                let norm = val.to_ascii_lowercase();
+                if matches!(
+                    norm.as_str(),
+                    "active_active" | "direct_only" | "udp_only" | "websocket_primary"
+                ) {
+                    target.mode = Some(norm);
+                }
+            }
+            "udp_port" => {
+                if let Ok(parsed) = val.parse::<u16>() {
+                    target.udp_port = Some(parsed.max(1));
+                }
+            }
+            "dedupe_window_ms" => {
+                if let Ok(parsed) = val.parse::<i64>() {
+                    target.dedupe_window_ms = Some(parsed.clamp(0, 2_000));
+                }
+            }
+            "dedupe_price_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    target.dedupe_price_bps = Some(parsed.clamp(0.0, 50.0));
+                }
+            }
+            "udp_share_cap" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    target.udp_share_cap = Some(parsed.clamp(0.05, 0.95));
+                }
+            }
+            "jitter_threshold_ms" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    target.jitter_threshold_ms = Some(parsed.clamp(1.0, 2_000.0));
+                }
+            }
+            "fallback_arm_duration_ms" => {
+                if let Ok(parsed) = val.parse::<u64>() {
+                    target.fallback_arm_duration_ms = Some(parsed.clamp(200, 15_000));
+                }
+            }
+            "fallback_cooldown_sec" => {
+                if let Ok(parsed) = val.parse::<u64>() {
+                    target.fallback_cooldown_sec = Some(parsed.clamp(0, 3_600));
+                }
+            }
+            "udp_local_only" => {
+                if let Ok(parsed) = val.parse::<bool>() {
+                    target.udp_local_only = Some(parsed);
+                }
+            }
+            _ => {}
+        }
+    }
+
+    fusion_patch.apply_to(&mut cfg);
+    if saw_transport {
+        transport_patch.apply_to(&mut cfg);
+    }
+    if cfg.mode == "websocket_primary" {
+        cfg.udp_local_only = true;
+        cfg.udp_share_cap = cfg.udp_share_cap.clamp(0.05, 0.35);
+        cfg.jitter_threshold_ms = cfg.jitter_threshold_ms.max(25.0);
+        cfg.fallback_arm_duration_ms = cfg.fallback_arm_duration_ms.max(8_000);
+        cfg.fallback_cooldown_sec = cfg.fallback_cooldown_sec.max(300);
+    }
+    if let Ok(raw) = std::env::var("POLYEDGE_UDP_PORT") {
+        if let Ok(parsed) = raw.parse::<u16>() {
+            cfg.udp_port = parsed.max(1);
+        }
+    }
+    if saw_fusion && saw_transport {
+        tracing::warn!(
+            "both [fusion] and [transport] are present; [transport] now takes precedence"
+        );
+    }
+    std::env::set_var(
+        "POLYEDGE_UDP_LOCAL_ONLY",
+        if cfg.udp_local_only { "true" } else { "false" },
+    );
+    cfg
+}
+
+pub(super) fn load_source_health_config() -> SourceHealthConfig {
+    let path = strategy_config_path();
+    let Ok(raw) = fs::read_to_string(path) else {
+        return SourceHealthConfig::default();
+    };
+    let mut cfg = SourceHealthConfig::default();
+    let mut in_section = false;
+    for line in raw.lines() {
+        let line = line.trim();
+        if line.is_empty() || line.starts_with('#') {
+            continue;
+        }
+        if line.starts_with('[') && line.ends_with(']') {
+            in_section = line == "[source_health]";
+            continue;
+        }
+        if !in_section {
+            continue;
+        }
+        let Some((k, v)) = line.split_once('=') else {
+            continue;
+        };
+        let key = k.trim();
+        let val = v.trim().trim_matches('"');
+        match key {
+            "min_samples" => {
+                if let Ok(parsed) = val.parse::<u64>() {
+                    cfg.min_samples = parsed.max(1);
+                }
+            }
+            "gap_window_ms" => {
+                if let Ok(parsed) = val.parse::<i64>() {
+                    cfg.gap_window_ms = parsed.clamp(50, 60_000);
+                }
+            }
+            "jitter_limit_ms" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.jitter_limit_ms = parsed.clamp(0.1, 2_000.0);
+                }
+            }
+            "deviation_limit_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.deviation_limit_bps = parsed.clamp(0.1, 10_000.0);
+                }
+            }
+            "freshness_limit_ms" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.freshness_limit_ms = parsed.clamp(50.0, 60_000.0);
+                }
+            }
+            "min_score_for_trading" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.min_score_for_trading = parsed.clamp(0.0, 1.0);
+                }
+            }
+            _ => {}
+        }
+    }
+    cfg
+}
+
+pub(super) fn load_edge_model_config() -> EdgeModelConfig {
+    let path = strategy_config_path();
+    let Ok(raw) = fs::read_to_string(path) else {
+        return EdgeModelConfig::default();
+    };
+    let mut cfg = EdgeModelConfig::default();
+    let mut in_section = false;
+    for line in raw.lines() {
+        let line = line.trim();
+        if line.is_empty() || line.starts_with('#') {
+            continue;
+        }
+        if line.starts_with('[') && line.ends_with(']') {
+            in_section = line == "[edge_model]";
+            continue;
+        }
+        if !in_section {
+            continue;
+        }
+        let Some((k, v)) = line.split_once('=') else {
+            continue;
+        };
+        let key = k.trim();
+        let val = v.trim().trim_matches('"');
+        match key {
+            "model" => cfg.model = val.to_string(),
+            "gate_mode" => cfg.gate_mode = val.to_string(),
+            "version" => cfg.version = val.to_string(),
+            "base_gate_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.base_gate_bps = parsed.max(0.0);
+                }
+            }
+            "congestion_penalty_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.congestion_penalty_bps = parsed.max(0.0);
+                }
+            }
+            "latency_penalty_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.latency_penalty_bps = parsed.max(0.0);
+                }
+            }
+            "fail_cost_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.fail_cost_bps = parsed.max(0.0);
+                }
+            }
+            _ => {}
+        }
+    }
+    cfg
+}
+
+pub(super) fn load_exit_config() -> ExitConfig {
+    let path = strategy_config_path();
+    let Ok(raw) = fs::read_to_string(path) else {
+        return ExitConfig::default();
+    };
+    let mut cfg = ExitConfig::default();
+    let mut in_section = false;
+    for line in raw.lines() {
+        let line = line.trim();
+        if line.is_empty() || line.starts_with('#') {
+            continue;
+        }
+        if line.starts_with('[') && line.ends_with(']') {
+            in_section = line == "[exit]" || line == "[predator_c.exit]";
+            continue;
+        }
+        if !in_section {
+            continue;
+        }
+        let Some((k, v)) = line.split_once('=') else {
+            continue;
+        };
+        let key = k.trim();
+        let val = v.trim().trim_matches('"');
+        match key {
+            "enabled" => {
+                if let Ok(parsed) = val.parse::<bool>() {
+                    cfg.enabled = parsed;
+                }
+            }
+            "t300ms_reversal_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.t300ms_reversal_bps = parsed;
+                }
+            }
+            "t100ms_reversal_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.t100ms_reversal_bps = parsed;
+                }
+            }
+            "convergence_exit_ratio" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.convergence_exit_ratio = parsed.clamp(0.0, 1.0);
+                }
+            }
+            "time_stop_ms" => {
+                if let Ok(parsed) = val.parse::<u64>() {
+                    cfg.time_stop_ms = parsed.clamp(50, 600_000);
+                }
+            }
+            "edge_decay_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.edge_decay_bps = parsed;
+                }
+            }
+            "adverse_move_bps" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.adverse_move_bps = parsed;
+                }
+            }
+            "flatten_on_trigger" => {
+                if let Ok(parsed) = val.parse::<bool>() {
+                    cfg.flatten_on_trigger = parsed;
+                }
+            }
+            "t3_take_ratio" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.t3_take_ratio = parsed.clamp(0.0, 5.0);
+                }
+            }
+            "t15_min_unrealized_usdc" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.t15_min_unrealized_usdc = parsed;
+                }
+            }
+            "t60_true_prob_floor" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.t60_true_prob_floor = parsed.clamp(0.0, 1.0);
+                }
+            }
+            "t300_force_exit_ms" => {
+                if let Ok(parsed) = val.parse::<u64>() {
+                    cfg.t300_force_exit_ms = parsed.clamp(1_000, 1_800_000);
+                }
+            }
+            "t300_hold_prob_threshold" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.t300_hold_prob_threshold = parsed.clamp(0.0, 1.0);
+                }
+            }
+            "t300_hold_time_to_expiry_ms" => {
+                if let Ok(parsed) = val.parse::<u64>() {
+                    cfg.t300_hold_time_to_expiry_ms = parsed.clamp(1_000, 1_800_000);
+                }
+            }
+            "max_single_trade_loss_usdc" => {
+                if let Ok(parsed) = val.parse::<f64>() {
+                    cfg.max_single_trade_loss_usdc = parsed.max(0.0);
+                }
+            }
+            _ => {}
+        }
+    }
+    cfg
+}
+
+pub(super) fn load_predator_c_config() -> PredatorCConfig {
+    let path = strategy_config_path();
+    let Ok(raw) = fs::read_to_string(path) else {
+        return PredatorCConfig::default();
+    };
+
+    let mut cfg = PredatorCConfig::default();
+
+    let mut in_root = false;
+    let mut in_dir = false;
+    let mut in_prob = false;
+    let mut in_sniper = false;
+    let mut in_gatling = false;
+    let mut in_strategy_d = false;
+    let mut in_regime = false;
+    let mut in_cross = false;
+    let mut in_router = false;
+    let mut in_compounder = false;
+    let mut in_v52_time_phase = false;
+    let mut in_v52_execution = false;
+    let mut in_v52_dual_arb = false;
+    let mut in_v52_reversal = false;
+    let mut gatling_symbol_section: Option<String> = None;
+
+    for line in raw.lines() {
+        let line = line.trim();
+        if line.is_empty() || line.starts_with('#') {
+            continue;
+        }
+        if line.starts_with('[') && line.ends_with(']') {
+            gatling_symbol_section = parse_gatling_symbol_section(line);
+            in_root = line == "[predator_c]";
+            in_dir = line == "[predator_c.direction_detector]";
+            in_prob = line == "[predator_c.probability_engine]";
+            in_sniper = line == "[predator_c.taker_sniper]";
+            in_gatling = line == "[predator_c.gatling]";
+            in_strategy_d = line == "[predator_c.strategy_d]";
+            in_regime = line == "[predator_c.regime]";
+            in_cross = line == "[predator_c.cross_symbol]";
+            in_router = line == "[predator_c.router]";
+            in_compounder = line == "[predator_c.compounder]";
+            in_v52_time_phase = line == "[v52.time_phase]" || line == "[predator_c.v52.time_phase]";
+            in_v52_execution = line == "[v52.execution]" || line == "[predator_c.v52.execution]";
+            in_v52_dual_arb = line == "[v52.dual_arb]" || line == "[predator_c.v52.dual_arb]";
+            in_v52_reversal = line == "[v52.reversal]" || line == "[predator_c.v52.reversal]";
+            continue;
+        }
+        if !(in_root
+            || in_dir
+            || in_prob
+            || in_sniper
+            || in_gatling
+            || in_strategy_d
+            || in_regime
+            || in_cross
+            || in_router
+            || in_compounder
+            || in_v52_time_phase
+            || in_v52_execution
+            || in_v52_dual_arb
+            || in_v52_reversal
+            || gatling_symbol_section.is_some())
+        {
+            continue;
+        }
+
+        let Some((k, v)) = line.split_once('=') else {
+            continue;
+        };
+        let key = k.trim();
+        let val = v.trim().trim_matches('"');
+
+        if in_root {
+            match key {
+                "enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.enabled = parsed;
+                    }
+                }
+                "priority" => {
+                    let norm = val.trim().to_ascii_lowercase();
+                    cfg.priority = match norm.as_str() {
+                        "maker_first" => PredatorCPriority::MakerFirst,
+                        "taker_first" => PredatorCPriority::TakerFirst,
+                        "taker_only" => PredatorCPriority::TakerOnly,
+                        _ => cfg.priority.clone(),
+                    };
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_dir {
+            match key {
+                "window_max_sec" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.direction_detector.window_max_sec = parsed.max(10);
+                    }
+                }
+                "threshold_5m_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.threshold_5m_pct = parsed.max(0.0);
+                    }
+                }
+                "threshold_15m_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.threshold_15m_pct = parsed.max(0.0);
+                    }
+                }
+                "threshold_1h_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.threshold_1h_pct = parsed.max(0.0);
+                    }
+                }
+                "threshold_1d_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.threshold_1d_pct = parsed.max(0.0);
+                    }
+                }
+                "lookback_short_sec" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.direction_detector.lookback_short_sec = parsed.max(1);
+                    }
+                }
+                "lookback_long_sec" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.direction_detector.lookback_long_sec = parsed.max(1);
+                    }
+                }
+                "min_sources_for_high_confidence" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        cfg.direction_detector.min_sources_for_high_confidence = parsed.max(1);
+                    }
+                }
+                "min_ticks_for_signal" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        cfg.direction_detector.min_ticks_for_signal = parsed.max(1);
+                    }
+                }
+                "min_consecutive_ticks" => {
+                    if let Ok(parsed) = val.parse::<u8>() {
+                        cfg.direction_detector.min_consecutive_ticks = parsed.max(1);
+                    }
+                }
+                "min_velocity_bps_per_sec" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.min_velocity_bps_per_sec = parsed.max(0.0);
+                    }
+                }
+                "min_acceleration" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.min_acceleration = parsed.max(0.0);
+                    }
+                }
+                "momentum_spike_multiplier" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.momentum_spike_multiplier = parsed.max(1.0);
+                    }
+                }
+                "min_tick_rate_spike_ratio" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.min_tick_rate_spike_ratio = parsed.max(1.0);
+                    }
+                }
+                "tick_rate_short_ms" => {
+                    if let Ok(parsed) = val.parse::<i64>() {
+                        cfg.direction_detector.tick_rate_short_ms = parsed.clamp(50, 10_000);
+                    }
+                }
+                "tick_rate_long_ms" => {
+                    if let Ok(parsed) = val.parse::<i64>() {
+                        cfg.direction_detector.tick_rate_long_ms = parsed.clamp(100, 60_000);
+                    }
+                }
+                "enable_source_vote_gate" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.direction_detector.enable_source_vote_gate = parsed;
+                    }
+                }
+                "require_secondary_confirmation" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.direction_detector.require_secondary_confirmation = parsed;
+                    }
+                }
+                "source_vote_max_age_ms" => {
+                    if let Ok(parsed) = val.parse::<i64>() {
+                        cfg.direction_detector.source_vote_max_age_ms = parsed.clamp(50, 60_000);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_prob {
+            match key {
+                "momentum_gain" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.probability_engine.momentum_gain = parsed.clamp(0.0, 20.0);
+                    }
+                }
+                "lag_penalty_per_ms" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.probability_engine.lag_penalty_per_ms = parsed.clamp(0.0, 0.1);
+                    }
+                }
+                "confidence_floor" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.probability_engine.confidence_floor = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "sigma_annual" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.probability_engine.sigma_annual = parsed.clamp(0.05, 5.0);
+                    }
+                }
+                "horizon_sec" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.probability_engine.horizon_sec = parsed.clamp(1.0, 900.0);
+                    }
+                }
+                "drift_annual" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.probability_engine.drift_annual = parsed.clamp(-10.0, 10.0);
+                    }
+                }
+                "velocity_drift_gain" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.probability_engine.velocity_drift_gain = parsed.clamp(0.0, 5.0);
+                    }
+                }
+                "acceleration_drift_gain" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.probability_engine.acceleration_drift_gain = parsed.clamp(0.0, 5.0);
+                    }
+                }
+                "fair_blend_weight" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.probability_engine.fair_blend_weight = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_sniper || in_gatling {
+            match key {
+                "enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.taker_sniper.gatling_enabled = parsed;
+                    }
+                }
+                "min_direction_confidence" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.taker_sniper.min_direction_confidence = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "min_edge_net_bps" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.taker_sniper.min_edge_net_bps = parsed.max(0.0);
+                    }
+                }
+                "max_spread" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.taker_sniper.max_spread = parsed.max(0.0001);
+                    }
+                }
+                "cooldown_ms_per_market" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.taker_sniper.cooldown_ms_per_market = parsed;
+                    }
+                }
+                "gatling_enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.taker_sniper.gatling_enabled = parsed;
+                    }
+                }
+                "chunk_notional_usdc" | "gatling_chunk_notional_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.taker_sniper.gatling_chunk_notional_usdc = parsed.max(0.1);
+                    }
+                }
+                "min_chunks" | "gatling_min_chunks" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        cfg.taker_sniper.gatling_min_chunks = parsed.max(1);
+                    }
+                }
+                "max_chunks" | "gatling_max_chunks" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        cfg.taker_sniper.gatling_max_chunks = parsed.max(1);
+                    }
+                }
+                "spacing_ms" | "gatling_spacing_ms" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.taker_sniper.gatling_spacing_ms = parsed.min(250);
+                    }
+                }
+                "stop_on_reject" | "gatling_stop_on_reject" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.taker_sniper.gatling_stop_on_reject = parsed;
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_strategy_d {
+            match key {
+                "enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.strategy_d.enabled = parsed;
+                    }
+                }
+                "min_gap_bps" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.strategy_d.min_gap_bps = parsed.max(0.0);
+                    }
+                }
+                "min_edge_net_bps" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.strategy_d.min_edge_net_bps = parsed.max(0.0);
+                    }
+                }
+                "min_confidence" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.strategy_d.min_confidence = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_notional_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.strategy_d.max_notional_usdc = parsed.max(0.0);
+                    }
+                }
+                "cooldown_ms_per_market" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.strategy_d.cooldown_ms_per_market = parsed;
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if let Some(symbol) = gatling_symbol_section.as_deref() {
+            let entry = cfg
+                .taker_sniper
+                .gatling_by_symbol
+                .entry(symbol.to_ascii_uppercase())
+                .or_default();
+            match key {
+                "enabled" | "gatling_enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        entry.enabled = Some(parsed);
+                    }
+                }
+                "chunk_notional_usdc" | "gatling_chunk_notional_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        entry.chunk_notional_usdc = Some(parsed.max(0.01));
+                    }
+                }
+                "min_chunks" | "gatling_min_chunks" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        entry.min_chunks = Some(parsed.max(1));
+                    }
+                }
+                "max_chunks" | "gatling_max_chunks" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        entry.max_chunks = Some(parsed.max(1));
+                    }
+                }
+                "spacing_ms" | "gatling_spacing_ms" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        entry.spacing_ms = Some(parsed.min(1_000));
+                    }
+                }
+                "stop_on_reject" | "gatling_stop_on_reject" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        entry.stop_on_reject = Some(parsed);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_regime {
+            match key {
+                "enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.regime.enabled = parsed;
+                    }
+                }
+                "active_min_confidence" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.regime.active_min_confidence = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "active_min_magnitude_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.regime.active_min_magnitude_pct = parsed.max(0.0);
+                    }
+                }
+                "defend_tox_score" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.regime.defend_tox_score = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "defend_on_toxic_danger" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.regime.defend_on_toxic_danger = parsed;
+                    }
+                }
+                "defend_min_source_health" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.regime.defend_min_source_health = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "quiet_min_edge_multiplier" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.regime.quiet_min_edge_multiplier = parsed.clamp(1.0, 10.0);
+                    }
+                }
+                "quiet_chunk_scale" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.regime.quiet_chunk_scale = parsed.clamp(0.05, 1.0);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_cross {
+            match key {
+                "enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.cross_symbol.enabled = parsed;
+                    }
+                }
+                "leader_symbol" => {
+                    cfg.cross_symbol.leader_symbol = val.trim().to_string();
+                }
+                "follower_symbols" => {
+                    let parsed = parse_toml_array_of_strings(v.trim());
+                    if !parsed.is_empty() {
+                        cfg.cross_symbol.follower_symbols = parsed;
+                    }
+                }
+                "min_leader_confidence" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.cross_symbol.min_leader_confidence = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "min_leader_magnitude_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.cross_symbol.min_leader_magnitude_pct = parsed.max(0.0);
+                    }
+                }
+                "follower_stale_confidence_max" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.cross_symbol.follower_stale_confidence_max = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_correlated_positions" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        cfg.cross_symbol.max_correlated_positions = parsed.max(1);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_router {
+            match key {
+                "max_locked_pct_5m" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_locked_pct_5m = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_locked_pct_15m" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_locked_pct_15m = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_locked_pct_1h" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_locked_pct_1h = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_locked_pct_1d" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_locked_pct_1d = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_concurrent_positions" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        cfg.router.max_concurrent_positions = parsed.max(1);
+                    }
+                }
+                "liquidity_reserve_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.liquidity_reserve_pct = parsed.clamp(0.0, 0.95);
+                    }
+                }
+                "max_order_notional_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_order_notional_usdc = parsed.max(0.0);
+                    }
+                }
+                "max_total_notional_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_total_notional_usdc = parsed.max(0.0);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_compounder {
+            match key {
+                "enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.compounder.enabled = parsed;
+                    }
+                }
+                "initial_capital_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.initial_capital_usdc = parsed.max(0.0);
+                    }
+                }
+                "compound_ratio" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.compound_ratio = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "position_fraction" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.position_fraction = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "min_quote_size" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.min_quote_size = parsed.max(0.0);
+                    }
+                }
+                "daily_loss_cap_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.daily_loss_cap_usdc = parsed.max(0.0);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_v52_time_phase {
+            match key {
+                "early_min_ratio" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.v52.time_phase.early_min_ratio = parsed;
+                    }
+                }
+                "late_max_ratio" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.v52.time_phase.late_max_ratio = parsed;
+                    }
+                }
+                "early_size_scale" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.v52.time_phase.early_size_scale = parsed;
+                    }
+                }
+                "maturity_size_scale" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.v52.time_phase.maturity_size_scale = parsed;
+                    }
+                }
+                "late_size_scale" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.v52.time_phase.late_size_scale = parsed;
+                    }
+                }
+                "allow_timeframes" => {
+                    let parsed = parse_toml_array_of_strings(v.trim())
+                        .into_iter()
+                        .map(|s| s.to_ascii_lowercase())
+                        .collect::<Vec<_>>();
+                    if !parsed.is_empty() {
+                        cfg.v52.time_phase.allow_timeframes = parsed;
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_v52_execution {
+            match key {
+                "late_force_taker_remaining_ms" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.v52.execution.late_force_taker_remaining_ms = parsed;
+                    }
+                }
+                "maker_wait_ms_before_force" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.v52.execution.maker_wait_ms_before_force = parsed;
+                    }
+                }
+                "apply_force_taker_in_maturity" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.v52.execution.apply_force_taker_in_maturity = parsed;
+                    }
+                }
+                "apply_force_taker_in_late" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.v52.execution.apply_force_taker_in_late = parsed;
+                    }
+                }
+                "alpha_window_enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.v52.execution.alpha_window_enabled = parsed;
+                    }
+                }
+                "alpha_window_move_bps" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.v52.execution.alpha_window_move_bps = parsed;
+                    }
+                }
+                "alpha_window_poll_ms" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.v52.execution.alpha_window_poll_ms = parsed;
+                    }
+                }
+                "alpha_window_max_wait_ms" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.v52.execution.alpha_window_max_wait_ms = parsed;
+                    }
+                }
+                "require_compounder_when_live" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.v52.execution.require_compounder_when_live = parsed;
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_v52_dual_arb {
+            match key {
+                "enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.v52.dual_arb.enabled = parsed;
+                    }
+                }
+                "safety_margin_bps" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.v52.dual_arb.safety_margin_bps = parsed;
+                    }
+                }
+                "threshold" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.v52.dual_arb.threshold = parsed;
+                    }
+                }
+                "fee_buffer_mode" => {
+                    cfg.v52.dual_arb.fee_buffer_mode = val.trim().to_ascii_lowercase();
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_v52_reversal {
+            match key {
+                "same_market_opposite_first" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.v52.reversal.same_market_opposite_first = parsed;
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+    }
+
+    cfg.v52.time_phase.early_min_ratio = cfg.v52.time_phase.early_min_ratio.clamp(0.11, 0.99);
+    cfg.v52.time_phase.late_max_ratio = cfg.v52.time_phase.late_max_ratio.clamp(0.01, 0.54);
+    cfg.v52.time_phase.early_size_scale = cfg.v52.time_phase.early_size_scale.clamp(0.10, 5.0);
+    cfg.v52.time_phase.maturity_size_scale =
+        cfg.v52.time_phase.maturity_size_scale.clamp(0.10, 5.0);
+    cfg.v52.time_phase.late_size_scale = cfg.v52.time_phase.late_size_scale.clamp(0.10, 5.0);
+    if cfg.v52.time_phase.late_max_ratio >= cfg.v52.time_phase.early_min_ratio {
+        cfg.v52.time_phase.late_max_ratio = 0.10;
+        cfg.v52.time_phase.early_min_ratio = 0.55;
+    }
+    cfg.v52.time_phase.allow_timeframes = cfg
+        .v52
+        .time_phase
+        .allow_timeframes
+        .iter()
+        .map(|s| s.to_ascii_lowercase())
+        .filter(|s| s == "5m" || s == "15m")
+        .collect::<Vec<_>>();
+    if cfg.v52.time_phase.allow_timeframes.is_empty() {
+        cfg.v52.time_phase.allow_timeframes = vec!["5m".to_string(), "15m".to_string()];
+    }
+    cfg.v52.execution.late_force_taker_remaining_ms =
+        cfg.v52.execution.late_force_taker_remaining_ms.clamp(1_000, 60_000);
+    cfg.v52.execution.maker_wait_ms_before_force =
+        cfg.v52.execution.maker_wait_ms_before_force.clamp(50, 10_000);
+    cfg.v52.execution.alpha_window_move_bps =
+        cfg.v52.execution.alpha_window_move_bps.clamp(0.1, 50.0);
+    cfg.v52.execution.alpha_window_poll_ms = cfg.v52.execution.alpha_window_poll_ms.clamp(1, 200);
+    cfg.v52.execution.alpha_window_max_wait_ms =
+        cfg.v52.execution.alpha_window_max_wait_ms.clamp(50, 5_000);
+    cfg.v52.dual_arb.safety_margin_bps = cfg.v52.dual_arb.safety_margin_bps.clamp(0.0, 100.0);
+    cfg.v52.dual_arb.threshold = cfg.v52.dual_arb.threshold.clamp(0.50, 1.10);
+    if cfg.v52.dual_arb.fee_buffer_mode != "conservative_taker" {
+        cfg.v52.dual_arb.fee_buffer_mode = "conservative_taker".to_string();
+    }
+
+    cfg
+}
+
+pub(super) fn load_risk_limits_config() -> RiskLimits {
+    let path = strategy_config_path();
+    let Ok(raw) = fs::read_to_string(path) else {
+        println!("Warn: strategy.toml not found for risk config, using defaults");
+        return RiskLimits::default();
+    };
+
+    // Conservative fallback values when parsing is partial or malformed.
+    // Keep defaults via struct update syntax to avoid piecemeal re-assignment.
+    let mut cfg = RiskLimits {
+        max_drawdown_pct: 0.20,
+        max_asset_notional: 50.0,
+        max_market_notional: 10.0,
+        ..RiskLimits::default()
+    };
+
+    let mut section = "";
+    for line in raw.lines() {
+        let line = line.trim();
+        if line.is_empty() || line.starts_with('#') {
+            continue;
+        }
+        if line.starts_with('[') && line.ends_with(']') {
+            section = line;
+            continue;
+        }
+        let Some((k, v)) = line.split_once('=') else {
+            continue;
+        };
+        let key = k.trim();
+        let val = v.trim().trim_matches('"');
+
+        match section {
+            "[risk_controls.exposure_limits]" => match key {
+                "max_total_exposure_usdc" => {
+                    if let Ok(p) = val.parse::<f64>() {
+                        cfg.max_asset_notional = p.max(0.0);
+                    }
+                }
+                "max_per_market_exposure_usdc" => {
+                    if let Ok(p) = val.parse::<f64>() {
+                        cfg.max_market_notional = p.max(0.0);
+                    }
+                }
+                "max_concurrent_positions" => {
+                    if let Ok(p) = val.parse::<usize>() {
+                        cfg.max_open_orders = p.max(1);
+                    }
+                }
+                _ => {}
+            },
+            "[risk_controls.kill_switch]" => match key {
+                "max_drawdown_pct" => {
+                    if let Ok(p) = val.parse::<f64>() {
+                        cfg.max_drawdown_pct = p.clamp(0.001, 1.0);
+                    }
+                }
+                "max_loss_streak" => {
+                    if let Ok(p) = val.parse::<u32>() {
+                        cfg.max_loss_streak = p.max(1);
+                    }
+                }
+                "cooldown_sec" => {
+                    if let Ok(p) = val.parse::<u64>() {
+                        cfg.cooldown_sec = p.max(1);
+                    }
+                }
+                _ => {}
+            },
+            "[risk_controls.progressive_limits]" => match key {
+                "enabled" => {
+                    if let Ok(p) = val.parse::<bool>() {
+                        cfg.progressive_enabled = p;
+                    }
+                }
+                "drawdown_tier1_ratio" => {
+                    if let Ok(p) = val.parse::<f64>() {
+                        cfg.drawdown_tier1_ratio = p.clamp(0.05, 0.99);
+                    }
+                }
+                "drawdown_tier2_ratio" => {
+                    if let Ok(p) = val.parse::<f64>() {
+                        cfg.drawdown_tier2_ratio = p.clamp(cfg.drawdown_tier1_ratio, 0.999);
+                    }
+                }
+                "tier1_size_scale" => {
+                    if let Ok(p) = val.parse::<f64>() {
+                        cfg.tier1_size_scale = p.clamp(0.01, 1.0);
+                    }
+                }
+                "tier2_size_scale" => {
+                    if let Ok(p) = val.parse::<f64>() {
+                        cfg.tier2_size_scale = p.clamp(0.01, 1.0);
+                    }
+                }
+                _ => {}
+            },
+            _ => {}
+        }
+    }
+    cfg
+}
+
+pub(super) fn load_execution_config() -> ExecutionConfig {
+    let path = Path::new("configs/execution.toml");
+    let Ok(raw) = fs::read_to_string(path) else {
+        return ExecutionConfig::default();
+    };
+    #[derive(Debug, Deserialize, Default)]
+    struct ExecutionFile {
+        execution: Option<ExecutionSection>,
+    }
+
+    #[derive(Debug, Deserialize, Default)]
+    struct ExecutionSection {
+        mode: Option<String>,
+        rate_limit_rps: Option<f64>,
+        http_timeout_ms: Option<u64>,
+        clob_endpoint: Option<String>,
+        order_endpoint: Option<String>,
+        order_backup_endpoint: Option<String>,
+        order_failover_timeout_ms: Option<u64>,
+    }
+
+    let Ok(parsed) = toml::from_str::<ExecutionFile>(&raw) else {
+        return ExecutionConfig::default();
+    };
+    let Some(section) = parsed.execution else {
+        return ExecutionConfig::default();
+    };
+    let mut cfg = ExecutionConfig::default();
+    if let Some(v) = section.mode {
+        cfg.mode = v;
+    }
+    if let Some(v) = section.rate_limit_rps {
+        cfg.rate_limit_rps = v.max(0.1);
+    }
+    if let Some(v) = section.http_timeout_ms {
+        cfg.http_timeout_ms = v.max(100);
+    }
+    if let Some(v) = section.clob_endpoint {
+        cfg.clob_endpoint = v;
+    }
+    if let Some(v) = section.order_endpoint {
+        cfg.order_endpoint = (!v.trim().is_empty()).then_some(v);
+    }
+    if let Some(v) = section.order_backup_endpoint {
+        cfg.order_backup_endpoint = (!v.trim().is_empty()).then_some(v);
+    }
+    if let Some(v) = section.order_failover_timeout_ms {
+        cfg.order_failover_timeout_ms = v.clamp(10, 5_000);
+    }
+    cfg
+}
+
+pub(super) fn load_settlement_config() -> SettlementConfig {
+    let path = Path::new("configs/settlement.toml");
+    let Ok(raw) = fs::read_to_string(path) else {
+        return SettlementConfig::default();
+    };
+    #[derive(Debug, Deserialize, Default)]
+    struct SettlementFile {
+        settlement: Option<SettlementSection>,
+    }
+
+    #[derive(Debug, Deserialize, Default)]
+    struct SettlementSection {
+        enabled: Option<bool>,
+        endpoint: Option<String>,
+        required_for_live: Option<bool>,
+        poll_interval_ms: Option<u64>,
+        timeout_ms: Option<u64>,
+        symbols: Option<Vec<String>>,
+    }
+
+    let Ok(parsed) = toml::from_str::<SettlementFile>(&raw) else {
+        return SettlementConfig::default();
+    };
+    let Some(section) = parsed.settlement else {
+        return SettlementConfig::default();
+    };
+    let mut cfg = SettlementConfig::default();
+    if let Some(v) = section.enabled {
+        cfg.enabled = v;
+    }
+    if let Some(v) = section.endpoint {
+        cfg.endpoint = v;
+    }
+    if let Some(v) = section.required_for_live {
+        cfg.required_for_live = v;
+    }
+    if let Some(v) = section.poll_interval_ms {
+        cfg.poll_interval_ms = v.clamp(250, 10_000);
+    }
+    if let Some(v) = section.timeout_ms {
+        cfg.timeout_ms = v.clamp(100, 5_000);
+    }
+    if let Some(v) = section.symbols {
+        cfg.symbols = v;
+    }
+    cfg
+}
+
+pub(super) fn load_universe_config() -> UniverseConfig {
+    let path = Path::new("configs/universe.toml");
+    let Ok(raw) = fs::read_to_string(path) else {
+        return UniverseConfig::default();
+    };
+    #[derive(Debug, Deserialize, Default)]
+    struct UniverseFile {
+        assets: Option<Vec<String>>,
+        market_types: Option<Vec<String>>,
+        timeframes: Option<Vec<String>>,
+        tier_whitelist: Option<Vec<String>>,
+        tier_blacklist: Option<Vec<String>>,
+    }
+
+    let Ok(parsed) = toml::from_str::<UniverseFile>(&raw) else {
+        return UniverseConfig::default();
+    };
+    let mut cfg = UniverseConfig::default();
+    if let Some(v) = parsed.assets {
+        cfg.assets = v;
+    }
+    if let Some(v) = parsed.market_types {
+        cfg.market_types = v;
+    }
+    if let Some(v) = parsed.timeframes {
+        cfg.timeframes = v;
+    }
+    if let Some(v) = parsed.tier_whitelist {
+        cfg.tier_whitelist = v;
+    }
+    if let Some(v) = parsed.tier_blacklist {
+        cfg.tier_blacklist = v;
+    }
+    cfg
+}
+
+pub(super) fn load_perf_profile_config() -> PerfProfile {
+    let path = Path::new("configs/latency.toml");
+    let Ok(raw) = fs::read_to_string(path) else {
+        return PerfProfile::default();
+    };
+    #[derive(Debug, Deserialize, Default)]
+    struct LatencyFile {
+        runtime: Option<RuntimeSection>,
+    }
+
+    #[derive(Debug, Deserialize, Default)]
+    struct RuntimeSection {
+        tail_guard: Option<f64>,
+        io_flush_batch: Option<usize>,
+        io_queue_capacity: Option<usize>,
+        json_mode: Option<String>,
+        io_drop_on_full: Option<bool>,
+    }
+
+    let Ok(parsed) = toml::from_str::<LatencyFile>(&raw) else {
+        return PerfProfile::default();
+    };
+    let Some(section) = parsed.runtime else {
+        return PerfProfile::default();
+    };
+    let mut cfg = PerfProfile::default();
+    if let Some(v) = section.tail_guard {
+        cfg.tail_guard = v.clamp(0.50, 0.9999);
+    }
+    if let Some(v) = section.io_flush_batch {
+        cfg.io_flush_batch = v.clamp(1, 4096);
+    }
+    if let Some(v) = section.io_queue_capacity {
+        cfg.io_queue_capacity = v.clamp(256, 262_144);
+    }
+    if let Some(v) = section.json_mode {
+        cfg.json_mode = v;
+    }
+    if let Some(v) = section.io_drop_on_full {
+        cfg.io_drop_on_full = v;
+    }
+    cfg
+}
+
+pub(super) fn load_seat_config() -> SeatConfig {
+    let path = Path::new("configs/seat.toml");
+    let Ok(raw) = fs::read_to_string(path) else {
+        let mut cfg = SeatConfig::default();
+        if let Ok(url) = std::env::var("POLYEDGE_SEAT_OPTIMIZER_URL") {
+            if !url.trim().is_empty() {
+                cfg.optimizer_url = url;
+            }
+        }
+        return cfg;
+    };
+
+    #[derive(Debug, Deserialize, Default)]
+    struct SeatFile {
+        seat: Option<SeatSection>,
+    }
+
+    #[derive(Debug, Deserialize, Default)]
+    struct SeatSection {
+        enabled: Option<bool>,
+        control_base_url: Option<String>,
+        optimizer_url: Option<String>,
+        runtime_tick_sec: Option<u64>,
+        activation_check_sec: Option<u64>,
+        layer1_interval_sec: Option<u64>,
+        layer2_interval_sec: Option<u64>,
+        layer3_interval_sec: Option<u64>,
+        layer2_shadow_sec: Option<u64>,
+        layer3_shadow_sec: Option<u64>,
+        smoothing_sec: Option<u64>,
+        monitor_sec: Option<u64>,
+        rollback_pause_sec: Option<u64>,
+        global_pause_sec: Option<u64>,
+        layer0_lock_sec: Option<u64>,
+        layer1_min_trades: Option<u64>,
+        layer2_min_trades: Option<u64>,
+        layer2_min_uptime_sec: Option<u64>,
+        layer3_min_trades: Option<u64>,
+        layer3_min_uptime_sec: Option<u64>,
+        black_swan_lock_sec: Option<u64>,
+        source_health_floor: Option<f64>,
+        history_retention_days: Option<u32>,
+        objective_drawdown_penalty: Option<f64>,
+    }
+
+    let Ok(parsed) = toml::from_str::<SeatFile>(&raw) else {
+        return SeatConfig::default();
+    };
+    let Some(section) = parsed.seat else {
+        return SeatConfig::default();
+    };
+    let mut cfg = SeatConfig::default();
+    if let Some(v) = section.enabled {
+        cfg.enabled = v;
+    }
+    if let Some(v) = section.control_base_url {
+        cfg.control_base_url = v;
+    }
+    if let Some(v) = section.optimizer_url {
+        cfg.optimizer_url = v;
+    }
+    if let Some(v) = section.runtime_tick_sec {
+        cfg.runtime_tick_sec = v.clamp(5, 300);
+    }
+    if let Some(v) = section.activation_check_sec {
+        cfg.activation_check_sec = v.clamp(60, 86_400);
+    }
+    if let Some(v) = section.layer1_interval_sec {
+        cfg.layer1_interval_sec = v.clamp(60, 86_400);
+    }
+    if let Some(v) = section.layer2_interval_sec {
+        cfg.layer2_interval_sec = v.clamp(300, 86_400);
+    }
+    if let Some(v) = section.layer3_interval_sec {
+        cfg.layer3_interval_sec = v.clamp(900, 7 * 86_400);
+    }
+    if let Some(v) = section.layer2_shadow_sec {
+        cfg.layer2_shadow_sec = v.clamp(60, 8 * 3_600);
+    }
+    if let Some(v) = section.layer3_shadow_sec {
+        cfg.layer3_shadow_sec = v.clamp(6_000, 12 * 3_600);
+    }
+    if let Some(v) = section.smoothing_sec {
+        cfg.smoothing_sec = v.clamp(60, 12 * 3_600);
+    }
+    if let Some(v) = section.monitor_sec {
+        cfg.monitor_sec = v.clamp(60, 24 * 3_600);
+    }
+    if let Some(v) = section.rollback_pause_sec {
+        cfg.rollback_pause_sec = v.clamp(60, 7 * 24 * 3_600);
+    }
+    if let Some(v) = section.global_pause_sec {
+        cfg.global_pause_sec = v.clamp(60, 14 * 24 * 3_600);
+    }
+    if let Some(v) = section.layer0_lock_sec {
+        cfg.layer0_lock_sec = v.clamp(60, 14 * 24 * 3_600);
+    }
+    if let Some(v) = section.layer1_min_trades {
+        cfg.layer1_min_trades = v.max(1);
+    }
+    if let Some(v) = section.layer2_min_trades {
+        cfg.layer2_min_trades = v.max(cfg.layer1_min_trades);
+    }
+    if let Some(v) = section.layer2_min_uptime_sec {
+        cfg.layer2_min_uptime_sec = v.max(3_600);
+    }
+    if let Some(v) = section.layer3_min_trades {
+        cfg.layer3_min_trades = v.max(cfg.layer2_min_trades);
+    }
+    if let Some(v) = section.layer3_min_uptime_sec {
+        cfg.layer3_min_uptime_sec = v.max(24 * 3_600);
+    }
+    if let Some(v) = section.black_swan_lock_sec {
+        cfg.black_swan_lock_sec = v.clamp(60, 14 * 24 * 3_600);
+    }
+    if let Some(v) = section.source_health_floor {
+        cfg.source_health_floor = v.clamp(0.0, 1.0);
+    }
+    if let Some(v) = section.history_retention_days {
+        cfg.history_retention_days = v.clamp(7, 720);
+    }
+    if let Some(v) = section.objective_drawdown_penalty {
+        cfg.objective_drawdown_penalty = v.clamp(0.1, 100.0);
+    }
+    if let Ok(url) = std::env::var("POLYEDGE_SEAT_OPTIMIZER_URL") {
+        if !url.trim().is_empty() {
+            cfg.optimizer_url = url;
+        }
+    }
+    cfg
+}
diff --git a/crates/app_runner/src/control_api.rs b/crates/app_runner/src/control_api.rs
index c707414..a52fada 100644
--- a/crates/app_runner/src/control_api.rs
+++ b/crates/app_runner/src/control_api.rs
@@ -1,25 +1,85 @@
-use super::*;
+use std::collections::HashMap;
+use std::sync::atomic::Ordering;
+
+use axum::extract::{Query, State};
+use axum::http::StatusCode;
+use axum::response::IntoResponse;
+use axum::routing::{get, post};
+use axum::{Json, Router};
+use chrono::Utc;
+use core_types::{ControlCommand, EngineEvent, ExecutionVenue, PaperDailySummary, PaperTradeRecord, ToxicRegime};
+use direction_detector::DirectionConfig;
+use fair_value::BasisMrConfig;
+use probability_engine::ProbabilityEngineConfig;
+use serde::{Deserialize, Serialize};
+use settlement_compounder::{CompounderConfig, SettlementCompounder};
+use taker_sniper::{TakerSniper, TakerSniperConfig};
+use timeframe_router::{RouterConfig, TimeframeRouter};
+
+use crate::report_io::{
+    append_jsonl, dataset_path, persist_engine_pnl_report, persist_final_report_files,
+    persist_live_report_files, persist_toxicity_report_files, JSONL_DROP_ON_FULL,
+};
+use crate::state::{
+    settlement_live_gate_status, to_exit_manager_config, AllocatorConfig, AllocatorReloadReq,
+    AllocatorReloadResp, AppState, EdgeModelConfig, EdgeModelReloadReq, EnginePnlReport,
+    ExitConfig, ExitReloadReq, FusionConfig, FusionReloadReq, HealthResp, PerfProfile,
+    PerfProfileReloadReq, PredatorCConfig, PredatorCPriority, PredatorCrossSymbolConfig,
+    PredatorDConfig, PredatorRegimeConfig, ProbabilityReloadReq, RiskReloadReq, RiskReloadResp,
+    ShadowFinalReport, ShadowLiveReport, SourceHealthConfig, SourceHealthReloadReq,
+    StrategyReloadReq, StrategyReloadResp, TakerReloadReq, TakerReloadResp, ToxicityConfig,
+    ToxicityFinalReport, ToxicityLiveReport, ToxicityReloadReq,
+    V52Config, V52DualArbConfig, V52ExecutionConfig, V52ReversalConfig, V52TimePhaseConfig,
+};
+use crate::seat_types::{SeatForceLayerReq, SeatManualOverrideReq};
+use crate::stats_utils::percentile;
+use crate::toxicity_report::build_toxicity_live_report;
 
 pub(super) fn build_router(state: AppState) -> Router {
     Router::new()
         .route("/health", get(health))
+        .route("/health/latency", get(health_latency)) // P4: lightweight latency probe
         .route("/metrics", get(metrics))
         .route("/state/positions", get(positions))
         .route("/state/pnl", get(pnl))
         .route("/report/shadow/live", get(report_shadow_live))
         .route("/report/shadow/final", get(report_shadow_final))
         .route("/report/pnl/by_engine", get(report_pnl_by_engine))
+        .route("/report/direction", get(report_direction))
+        .route("/report/router", get(report_router))
+        .route("/report/capital", get(report_capital))
         .route("/report/toxicity/live", get(report_toxicity_live))
         .route("/report/toxicity/final", get(report_toxicity_final))
+        .route("/report/seat/status", get(report_seat_status))
+        .route("/report/seat/history", get(report_seat_history))
+        .route("/report/paper/live", get(report_paper_live))
+        .route("/report/paper/history", get(report_paper_history))
+        .route("/report/paper/daily", get(report_paper_daily))
+        .route("/report/paper/summary", get(report_paper_summary))
         .route("/control/pause", post(pause))
         .route("/control/resume", post(resume))
         .route("/control/flatten", post(flatten))
+        .route("/control/arm_live", post(arm_live))
+        .route("/control/seat/pause", post(seat_pause))
+        .route("/control/seat/resume", post(seat_resume))
+        .route("/control/seat/force_layer", post(seat_force_layer))
+        .route("/control/seat/manual_override", post(seat_manual_override))
+        .route("/control/seat/clear_override", post(seat_clear_override))
+        .route("/control/paper/reset", post(reset_paper))
         .route("/control/reset_shadow", post(reset_shadow))
         .route("/control/reload_strategy", post(reload_strategy))
         .route("/control/reload_taker", post(reload_taker))
         .route("/control/reload_allocator", post(reload_allocator))
         .route("/control/reload_toxicity", post(reload_toxicity))
         .route("/control/reload_risk", post(reload_risk))
+        .route("/control/reload_predator_c", post(reload_predator_c))
+        .route("/control/reload_fusion", post(reload_fusion))
+        .route("/control/reload_edge_model", post(reload_edge_model))
+        .route("/control/reload_probability", post(reload_probability))
+        .route("/control/reload_source_health", post(reload_source_health))
+        .route("/control/reload_exit", post(reload_exit))
+        .route("/control/reload_exit_manager", post(reload_exit))
+        .route("/control/reload_regime", post(reload_regime))
         .route("/control/reload_perf_profile", post(reload_perf_profile))
         .with_state(state)
 }
@@ -32,6 +92,22 @@ async fn health(State(state): State<AppState>) -> Json<HealthResp> {
     })
 }
 
+// P4: lightweight latency probe endpoint.
+// Used by storm_test to measure realistic HTTP RTT with minimal server-side work.
+async fn health_latency(State(state): State<AppState>) -> Json<serde_json::Value> {
+    let paused = *state.paused.read().await;
+    let now = std::time::Instant::now();
+
+    // Keep this handler intentionally small and allocation-light.
+    Json(serde_json::json!({
+        "status": "ok",
+        "paused": paused,
+        "timestamp_ms": chrono::Utc::now().timestamp_millis(),
+        "probe_latency_us": now.elapsed().as_micros() as u64,
+        "note": "lightweight endpoint for storm-test RTT probing"
+    }))
+}
+
 async fn metrics(State(state): State<AppState>) -> impl IntoResponse {
     (
         StatusCode::OK,
@@ -82,55 +158,668 @@ async fn flatten(State(state): State<AppState>) -> impl IntoResponse {
     }
 }
 
+#[derive(Debug, Deserialize)]
+struct ArmLiveReq {
+    armed: Option<bool>,
+}
+
+async fn arm_live(State(state): State<AppState>, Json(req): Json<ArmLiveReq>) -> impl IntoResponse {
+    let force_paper = std::env::var("POLYEDGE_FORCE_PAPER")
+        .ok()
+        .map(|v| {
+            let normalized = v.trim().to_ascii_lowercase();
+            matches!(normalized.as_str(), "1" | "true" | "yes" | "on")
+        })
+        .unwrap_or(false);
+    if force_paper {
+        return (
+            StatusCode::BAD_REQUEST,
+            Json(serde_json::json!({
+                "ok": false,
+                "armed": false,
+                "error": "force_paper_guard_enabled",
+            })),
+        )
+            .into_response();
+    }
+
+    let armed = req.armed.unwrap_or(true);
+    if !armed {
+        std::env::set_var("POLYEDGE_LIVE_ARMED", "false");
+        return Json(
+            serde_json::json!({"ok": true, "armed": false, "execution_live": state.execution.is_live()}),
+        )
+        .into_response();
+    }
+
+    let settlement_cfg = state.shared.settlement_cfg.read().await.clone();
+    let gate = settlement_live_gate_status(&settlement_cfg);
+    if !gate.ready {
+        return (
+            StatusCode::BAD_REQUEST,
+            Json(serde_json::json!({
+                "ok": false,
+                "armed": false,
+                "error": "settlement_live_gate_failed",
+                "reason": gate.reason,
+            })),
+        )
+            .into_response();
+    }
+
+    std::env::set_var("POLYEDGE_LIVE_ARMED", "true");
+    let execution_live = state.execution.is_live();
+    let payload = serde_json::json!({
+        "ok": true,
+        "armed": true,
+        "execution_live": execution_live,
+        "restart_required": !execution_live,
+    });
+    if execution_live {
+        Json(payload).into_response()
+    } else {
+        (StatusCode::ACCEPTED, Json(payload)).into_response()
+    }
+}
+
+async fn seat_pause(State(state): State<AppState>) -> impl IntoResponse {
+    let status = state.seat.pause("manual_pause".to_string()).await;
+    Json(serde_json::json!({"ok": true, "status": status}))
+}
+
+async fn seat_resume(State(state): State<AppState>) -> impl IntoResponse {
+    let status = state.seat.resume().await;
+    Json(serde_json::json!({"ok": true, "status": status}))
+}
+
+async fn seat_force_layer(
+    State(state): State<AppState>,
+    Json(req): Json<SeatForceLayerReq>,
+) -> impl IntoResponse {
+    let status = state.seat.force_layer(req).await;
+    Json(serde_json::json!({"ok": true, "status": status}))
+}
+
+async fn seat_manual_override(
+    State(state): State<AppState>,
+    Json(req): Json<SeatManualOverrideReq>,
+) -> impl IntoResponse {
+    match state.seat.manual_override(req).await {
+        Ok(status) => Json(serde_json::json!({"ok": true, "status": status})).into_response(),
+        Err(err) => (
+            StatusCode::BAD_REQUEST,
+            Json(serde_json::json!({"ok": false, "error": err.to_string()})),
+        )
+            .into_response(),
+    }
+}
+
+async fn seat_clear_override(State(state): State<AppState>) -> impl IntoResponse {
+    let status = state.seat.clear_manual_override().await;
+    Json(serde_json::json!({"ok": true, "status": status}))
+}
+
+#[derive(Debug, Deserialize)]
+struct SeatHistoryQuery {
+    limit: Option<usize>,
+}
+
+async fn report_seat_status(State(state): State<AppState>) -> impl IntoResponse {
+    Json(state.seat.status().await)
+}
+
+async fn report_seat_history(
+    State(state): State<AppState>,
+    Query(query): Query<SeatHistoryQuery>,
+) -> impl IntoResponse {
+    let limit = query.limit.unwrap_or(120).clamp(1, 2_000);
+    Json(state.seat.history(limit))
+}
+
+#[derive(Debug, Deserialize)]
+struct PaperHistoryQuery {
+    limit: Option<usize>,
+}
+
+async fn report_paper_live(State(state): State<AppState>) -> impl IntoResponse {
+    Json(state.paper.live_report().await)
+}
+
+async fn report_paper_history(
+    State(state): State<AppState>,
+    Query(query): Query<PaperHistoryQuery>,
+) -> impl IntoResponse {
+    let limit = query.limit.unwrap_or(200).clamp(1, 5000);
+    let rows: Vec<PaperTradeRecord> = state.paper.history(limit).await;
+    Json(rows)
+}
+
+async fn report_paper_daily(State(state): State<AppState>) -> impl IntoResponse {
+    let rows: Vec<PaperDailySummary> = state.paper.daily().await;
+    Json(rows)
+}
+
+async fn report_paper_summary(State(state): State<AppState>) -> impl IntoResponse {
+    Json(state.paper.summary_json().await)
+}
+
+async fn reset_paper(State(state): State<AppState>) -> impl IntoResponse {
+    state.paper.reset().await;
+    Json(serde_json::json!({"ok": true, "paper_reset": true}))
+}
+
 async fn reset_shadow(State(state): State<AppState>) -> impl IntoResponse {
     let window_id = state.shadow_stats.reset().await;
     state.tox_state.write().await.clear();
+    {
+        let mut router = state.shared.predator_router.write().await;
+        *router = TimeframeRouter::new(router.cfg().clone());
+    }
+    {
+        let mut sniper = state.shared.predator_taker_sniper.write().await;
+        *sniper = TakerSniper::new(sniper.cfg().clone());
+    }
+    {
+        let cfg = state.shared.predator_cfg.read().await.clone();
+        let mut compounder = state.shared.predator_compounder.write().await;
+        *compounder = SettlementCompounder::new(cfg.compounder);
+    }
+    state.shared.predator_d_last_fire_ms.write().await.clear();
     Json(serde_json::json!({"ok": true, "shadow_reset": true, "window_id": window_id}))
 }
 
+#[derive(Debug, Deserialize)]
+struct PredatorCReloadReq {
+    enabled: Option<bool>,
+    priority: Option<PredatorCPriority>,
+    direction_detector: Option<DirectionConfig>,
+    taker_sniper: Option<TakerSniperConfig>,
+    strategy_d: Option<PredatorDConfig>,
+    regime: Option<PredatorRegimeConfig>,
+    cross_symbol: Option<PredatorCrossSymbolConfig>,
+    router: Option<RouterConfig>,
+    compounder: Option<CompounderConfig>,
+    v52: Option<V52Config>,
+    v52_time_phase: Option<V52TimePhaseConfig>,
+    v52_execution: Option<V52ExecutionConfig>,
+    v52_dual_arb: Option<V52DualArbConfig>,
+    v52_reversal: Option<V52ReversalConfig>,
+}
+
+#[derive(Debug, Serialize)]
+struct PredatorCReloadResp {
+    predator_c: PredatorCConfig,
+}
+
+fn normalize_v52_config(v52: &mut V52Config) {
+    v52.time_phase.early_min_ratio = v52.time_phase.early_min_ratio.clamp(0.11, 0.99);
+    v52.time_phase.late_max_ratio = v52.time_phase.late_max_ratio.clamp(0.01, 0.54);
+    v52.time_phase.early_size_scale = v52.time_phase.early_size_scale.clamp(0.10, 5.0);
+    v52.time_phase.maturity_size_scale = v52.time_phase.maturity_size_scale.clamp(0.10, 5.0);
+    v52.time_phase.late_size_scale = v52.time_phase.late_size_scale.clamp(0.10, 5.0);
+    if v52.time_phase.late_max_ratio >= v52.time_phase.early_min_ratio {
+        v52.time_phase.late_max_ratio = 0.10;
+        v52.time_phase.early_min_ratio = 0.55;
+    }
+    v52.time_phase.allow_timeframes = v52
+        .time_phase
+        .allow_timeframes
+        .iter()
+        .map(|s| s.to_ascii_lowercase())
+        .filter(|s| s == "5m" || s == "15m")
+        .collect::<Vec<_>>();
+    if v52.time_phase.allow_timeframes.is_empty() {
+        v52.time_phase.allow_timeframes = vec!["5m".to_string(), "15m".to_string()];
+    }
+    v52.execution.late_force_taker_remaining_ms =
+        v52.execution.late_force_taker_remaining_ms.clamp(1_000, 60_000);
+    v52.execution.maker_wait_ms_before_force =
+        v52.execution.maker_wait_ms_before_force.clamp(50, 10_000);
+    v52.execution.alpha_window_move_bps = v52.execution.alpha_window_move_bps.clamp(0.1, 50.0);
+    v52.execution.alpha_window_poll_ms = v52.execution.alpha_window_poll_ms.clamp(1, 200);
+    v52.execution.alpha_window_max_wait_ms =
+        v52.execution.alpha_window_max_wait_ms.clamp(50, 5_000);
+    v52.dual_arb.safety_margin_bps = v52.dual_arb.safety_margin_bps.clamp(0.0, 100.0);
+    v52.dual_arb.threshold = v52.dual_arb.threshold.clamp(0.50, 1.10);
+    v52.dual_arb.fee_buffer_mode = "conservative_taker".to_string();
+}
+
+async fn reload_predator_c(
+    State(state): State<AppState>,
+    Json(req): Json<PredatorCReloadReq>,
+) -> Json<PredatorCReloadResp> {
+    let mut cfg = state.shared.predator_cfg.write().await;
+    if let Some(v) = req.enabled {
+        cfg.enabled = v;
+    }
+    if let Some(v) = req.priority {
+        cfg.priority = v;
+    }
+    if let Some(v) = req.direction_detector {
+        cfg.direction_detector = v;
+    }
+    if let Some(v) = req.taker_sniper {
+        cfg.taker_sniper = v;
+    }
+    if let Some(v) = req.strategy_d {
+        cfg.strategy_d = v;
+    }
+    if let Some(v) = req.regime {
+        cfg.regime = v;
+    }
+    if let Some(v) = req.cross_symbol {
+        cfg.cross_symbol = v;
+    }
+    if let Some(v) = req.router {
+        cfg.router = v;
+    }
+    if let Some(v) = req.compounder {
+        cfg.compounder = v;
+    }
+    if let Some(v) = req.v52 {
+        cfg.v52 = v;
+    }
+    if let Some(v) = req.v52_time_phase {
+        cfg.v52.time_phase = v;
+    }
+    if let Some(v) = req.v52_execution {
+        cfg.v52.execution = v;
+    }
+    if let Some(v) = req.v52_dual_arb {
+        cfg.v52.dual_arb = v;
+    }
+    if let Some(v) = req.v52_reversal {
+        cfg.v52.reversal = v;
+    }
+    normalize_v52_config(&mut cfg.v52);
+    let snapshot = cfg.clone();
+    drop(cfg);
+
+    state.shadow_stats.set_predator_enabled(snapshot.enabled);
+    {
+        let mut det = state.shared.predator_direction_detector.write().await;
+        det.set_cfg(snapshot.direction_detector.clone());
+    }
+    {
+        let mut sniper = state.shared.predator_taker_sniper.write().await;
+        sniper.set_cfg(snapshot.taker_sniper.clone());
+    }
+    {
+        let mut router = state.shared.predator_router.write().await;
+        router.set_cfg(snapshot.router.clone());
+    }
+    {
+        let mut compounder = state.shared.predator_compounder.write().await;
+        compounder.set_cfg(snapshot.compounder.clone());
+    }
+
+    append_jsonl(
+        &dataset_path("reports", "predator_c_reload.jsonl"),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "predator_c": snapshot}),
+    );
+
+    Json(PredatorCReloadResp {
+        predator_c: snapshot,
+    })
+}
+
+async fn reload_regime(
+    State(state): State<AppState>,
+    Json(regime): Json<PredatorRegimeConfig>,
+) -> Json<PredatorRegimeConfig> {
+    let mut cfg = state.shared.predator_cfg.write().await;
+    cfg.regime = regime.clone();
+    let snapshot = cfg.regime.clone();
+    drop(cfg);
+
+    append_jsonl(
+        &dataset_path("reports", "regime_reload.jsonl"),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "regime": snapshot}),
+    );
+
+    Json(regime)
+}
+
+async fn reload_fusion(
+    State(state): State<AppState>,
+    Json(req): Json<FusionReloadReq>,
+) -> Json<FusionConfig> {
+    let mut cfg = state.shared.fusion_cfg.write().await;
+    if let Some(v) = req.enable_udp {
+        cfg.enable_udp = v;
+    }
+    if let Some(v) = req.mode {
+        let norm = v.to_ascii_lowercase();
+        if matches!(
+            norm.as_str(),
+            "active_active" | "direct_only" | "udp_only" | "websocket_primary"
+        ) {
+            cfg.mode = norm;
+        }
+    }
+    if let Some(v) = req.udp_port {
+        cfg.udp_port = v.max(1);
+    }
+    if let Some(v) = req.dedupe_window_ms {
+        cfg.dedupe_window_ms = v.clamp(0, 2_000);
+    }
+    if let Some(v) = req.dedupe_price_bps {
+        cfg.dedupe_price_bps = v.clamp(0.0, 50.0);
+    }
+    if let Some(v) = req.udp_share_cap {
+        cfg.udp_share_cap = v.clamp(0.05, 0.95);
+    }
+    if let Some(v) = req.jitter_threshold_ms {
+        cfg.jitter_threshold_ms = v.clamp(1.0, 2_000.0);
+    }
+    if let Some(v) = req.fallback_arm_duration_ms {
+        cfg.fallback_arm_duration_ms = v.clamp(200, 15_000);
+    }
+    if let Some(v) = req.fallback_cooldown_sec {
+        cfg.fallback_cooldown_sec = v.clamp(0, 3_600);
+    }
+    if let Some(v) = req.udp_local_only {
+        cfg.udp_local_only = v;
+    }
+    if cfg.mode == "websocket_primary" {
+        cfg.udp_local_only = true;
+        cfg.udp_share_cap = cfg.udp_share_cap.clamp(0.05, 0.35);
+        cfg.jitter_threshold_ms = cfg.jitter_threshold_ms.max(25.0);
+        cfg.fallback_arm_duration_ms = cfg.fallback_arm_duration_ms.max(8_000);
+        cfg.fallback_cooldown_sec = cfg.fallback_cooldown_sec.max(300);
+    }
+    let snapshot = cfg.clone();
+    std::env::set_var(
+        "POLYEDGE_UDP_LOCAL_ONLY",
+        if snapshot.udp_local_only {
+            "true"
+        } else {
+            "false"
+        },
+    );
+    append_jsonl(
+        &dataset_path("reports", "fusion_reload.jsonl"),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "fusion": snapshot}),
+    );
+    Json(snapshot)
+}
+
+async fn reload_edge_model(
+    State(state): State<AppState>,
+    Json(req): Json<EdgeModelReloadReq>,
+) -> Json<EdgeModelConfig> {
+    let mut cfg = state.shared.edge_model_cfg.write().await;
+    if let Some(v) = req.model {
+        cfg.model = v;
+    }
+    if let Some(v) = req.gate_mode {
+        cfg.gate_mode = v;
+    }
+    if let Some(v) = req.version {
+        cfg.version = v;
+    }
+    if let Some(v) = req.base_gate_bps {
+        cfg.base_gate_bps = v.max(0.0);
+    }
+    if let Some(v) = req.congestion_penalty_bps {
+        cfg.congestion_penalty_bps = v.max(0.0);
+    }
+    if let Some(v) = req.latency_penalty_bps {
+        cfg.latency_penalty_bps = v.max(0.0);
+    }
+    if let Some(v) = req.fail_cost_bps {
+        cfg.fail_cost_bps = v.max(0.0);
+    }
+    let snapshot = cfg.clone();
+    append_jsonl(
+        &dataset_path("reports", "edge_model_reload.jsonl"),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "edge_model": snapshot}),
+    );
+    Json(snapshot)
+}
+
+async fn reload_probability(
+    State(state): State<AppState>,
+    Json(req): Json<ProbabilityReloadReq>,
+) -> Json<ProbabilityEngineConfig> {
+    let mut engine = state.shared.predator_probability_engine.write().await;
+    let mut cfg = engine.cfg().clone();
+    if let Some(v) = req.momentum_gain {
+        cfg.momentum_gain = v.clamp(0.0, 20.0);
+    }
+    if let Some(v) = req.lag_penalty_per_ms {
+        cfg.lag_penalty_per_ms = v.clamp(0.0, 0.1);
+    }
+    if let Some(v) = req.confidence_floor {
+        cfg.confidence_floor = v.clamp(0.0, 1.0);
+    }
+    if let Some(v) = req.sigma_annual {
+        cfg.sigma_annual = v.clamp(0.05, 5.0);
+    }
+    if let Some(v) = req.horizon_sec {
+        cfg.horizon_sec = v.clamp(1.0, 900.0);
+    }
+    if let Some(v) = req.drift_annual {
+        cfg.drift_annual = v.clamp(-10.0, 10.0);
+    }
+    if let Some(v) = req.velocity_drift_gain {
+        cfg.velocity_drift_gain = v.clamp(0.0, 5.0);
+    }
+    if let Some(v) = req.acceleration_drift_gain {
+        cfg.acceleration_drift_gain = v.clamp(0.0, 5.0);
+    }
+    if let Some(v) = req.fair_blend_weight {
+        cfg.fair_blend_weight = v.clamp(0.0, 1.0);
+    }
+    engine.set_cfg(cfg.clone());
+    drop(engine);
+    append_jsonl(
+        &dataset_path("reports", "probability_reload.jsonl"),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "probability": cfg}),
+    );
+    Json(cfg)
+}
+
+async fn reload_source_health(
+    State(state): State<AppState>,
+    Json(req): Json<SourceHealthReloadReq>,
+) -> Json<SourceHealthConfig> {
+    let mut cfg = state.shared.source_health_cfg.write().await;
+    if let Some(v) = req.min_samples {
+        cfg.min_samples = v.max(1);
+    }
+    if let Some(v) = req.gap_window_ms {
+        cfg.gap_window_ms = v.clamp(50, 60_000);
+    }
+    if let Some(v) = req.jitter_limit_ms {
+        cfg.jitter_limit_ms = v.clamp(0.1, 2_000.0);
+    }
+    if let Some(v) = req.deviation_limit_bps {
+        cfg.deviation_limit_bps = v.clamp(0.1, 10_000.0);
+    }
+    if let Some(v) = req.freshness_limit_ms {
+        cfg.freshness_limit_ms = v.clamp(50.0, 60_000.0);
+    }
+    if let Some(v) = req.min_score_for_trading {
+        cfg.min_score_for_trading = v.clamp(0.0, 1.0);
+    }
+    let snapshot = cfg.clone();
+    append_jsonl(
+        &dataset_path("reports", "source_health_reload.jsonl"),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "source_health": snapshot}),
+    );
+    Json(snapshot)
+}
+
+async fn reload_exit(
+    State(state): State<AppState>,
+    Json(req): Json<ExitReloadReq>,
+) -> Json<ExitConfig> {
+    let mut cfg = state.shared.exit_cfg.write().await;
+    if let Some(v) = req.enabled {
+        cfg.enabled = v;
+    }
+    if let Some(v) = req.t100ms_reversal_bps {
+        cfg.t100ms_reversal_bps = v;
+    }
+    if let Some(v) = req.t300ms_reversal_bps {
+        cfg.t300ms_reversal_bps = v;
+    }
+    if let Some(v) = req.convergence_exit_ratio {
+        cfg.convergence_exit_ratio = v.clamp(0.0, 1.0);
+    }
+    if let Some(v) = req.time_stop_ms {
+        cfg.time_stop_ms = v.clamp(50, 60_000);
+    }
+    if let Some(v) = req.edge_decay_bps {
+        cfg.edge_decay_bps = v;
+    }
+    if let Some(v) = req.adverse_move_bps {
+        cfg.adverse_move_bps = v;
+    }
+    if let Some(v) = req.flatten_on_trigger {
+        cfg.flatten_on_trigger = v;
+    }
+    if let Some(v) = req.t3_take_ratio {
+        cfg.t3_take_ratio = v.clamp(0.0, 5.0);
+    }
+    if let Some(v) = req.t15_min_unrealized_usdc {
+        cfg.t15_min_unrealized_usdc = v;
+    }
+    if let Some(v) = req.t60_true_prob_floor {
+        cfg.t60_true_prob_floor = v.clamp(0.0, 1.0);
+    }
+    if let Some(v) = req.t300_force_exit_ms {
+        cfg.t300_force_exit_ms = v.clamp(1_000, 1_800_000);
+    }
+    if let Some(v) = req.t300_hold_prob_threshold {
+        cfg.t300_hold_prob_threshold = v.clamp(0.0, 1.0);
+    }
+    if let Some(v) = req.t300_hold_time_to_expiry_ms {
+        cfg.t300_hold_time_to_expiry_ms = v.clamp(1_000, 1_800_000);
+    }
+    if let Some(v) = req.max_single_trade_loss_usdc {
+        cfg.max_single_trade_loss_usdc = v.max(0.0);
+    }
+    let manager_cfg = to_exit_manager_config(&cfg);
+    state
+        .shared
+        .predator_exit_manager
+        .write()
+        .await
+        .set_cfg(manager_cfg);
+    let snapshot = cfg.clone();
+    append_jsonl(
+        &dataset_path("reports", "exit_reload.jsonl"),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "exit": snapshot}),
+    );
+    Json(snapshot)
+}
+
+async fn report_direction(State(state): State<AppState>) -> Json<serde_json::Value> {
+    let now = Utc::now().timestamp_millis();
+    let latest = state.shared.predator_latest_direction.read().await.clone();
+    Json(serde_json::json!({"ts_ms": now, "latest": latest}))
+}
+
+async fn report_router(State(state): State<AppState>) -> Json<serde_json::Value> {
+    let now = Utc::now().timestamp_millis();
+    let mut router = state.shared.predator_router.write().await;
+    let locks = router.snapshot_locks(now);
+    let locked_by_tf = router.locked_by_tf_usdc(now);
+    let mut locked_by_tf_usdc = HashMap::<String, f64>::new();
+    for (tf, v) in locked_by_tf {
+        locked_by_tf_usdc.insert(tf.to_string(), v);
+    }
+    Json(serde_json::json!({
+        "ts_ms": now,
+        "locks": locks,
+        "locked_by_tf_usdc": locked_by_tf_usdc,
+        "active_positions": router.active_positions(now),
+        "locked_total_usdc": router.locked_total_usdc(now)
+    }))
+}
+
+async fn report_capital(State(state): State<AppState>) -> Json<serde_json::Value> {
+    let now = Utc::now().timestamp_millis();
+    let compounder = state.shared.predator_compounder.read().await;
+    let cfg = compounder.cfg().clone();
+    Json(serde_json::json!({
+        "ts_ms": now,
+        "cfg": cfg,
+        "available_usdc": compounder.available(),
+        "total_pnl_usdc": compounder.total_pnl(),
+        "daily_pnl_usdc": compounder.daily_pnl(),
+        "halted": compounder.halted(),
+        "win_rate": compounder.win_rate(),
+        "recommended_quote_notional_usdc": compounder.recommended_quote_notional_usdc(),
+    }))
+}
+
 async fn reload_strategy(
     State(state): State<AppState>,
     Json(req): Json<StrategyReloadReq>,
 ) -> Json<StrategyReloadResp> {
-    let mut cfg = state.strategy_cfg.write().await;
+    let cur = state.strategy_cfg.read().await.clone();
+    let mut next = (*cur).clone();
     if let Some(v) = req.min_edge_bps {
-        cfg.min_edge_bps = v.max(0.0);
+        next.min_edge_bps = v.max(0.0);
     }
     if let Some(v) = req.ttl_ms {
-        cfg.ttl_ms = v.max(50);
+        next.ttl_ms = v.max(50);
     }
     if let Some(v) = req.inventory_skew {
-        cfg.inventory_skew = v.clamp(0.0, 1.0);
+        next.inventory_skew = v.clamp(0.0, 1.0);
     }
     if let Some(v) = req.base_quote_size {
-        cfg.base_quote_size = v.max(0.01);
+        next.base_quote_size = v.max(0.01);
     }
     if let Some(v) = req.max_spread {
-        cfg.max_spread = v.max(0.0001);
+        next.max_spread = v.max(0.0001);
     }
     if let Some(v) = req.taker_trigger_bps {
-        cfg.taker_trigger_bps = v.max(0.0);
+        next.taker_trigger_bps = v.max(0.0);
     }
     if let Some(v) = req.taker_max_slippage_bps {
-        cfg.taker_max_slippage_bps = v.max(0.0);
+        next.taker_max_slippage_bps = v.max(0.0);
     }
     if let Some(v) = req.stale_tick_filter_ms {
-        cfg.stale_tick_filter_ms = v.clamp(50.0, 5_000.0);
-    }
-    if let Some(v) = req.market_tier_profile {
-        cfg.market_tier_profile = v;
+        next.stale_tick_filter_ms = v.clamp(50.0, 5_000.0);
     }
     if let Some(v) = req.capital_fraction_kelly {
-        cfg.capital_fraction_kelly = v.clamp(0.01, 1.0);
+        next.capital_fraction_kelly = v.clamp(0.01, 1.0);
     }
     if let Some(v) = req.variance_penalty_lambda {
-        cfg.variance_penalty_lambda = v.clamp(0.0, 5.0);
+        next.variance_penalty_lambda = v.clamp(0.0, 5.0);
     }
     if let Some(v) = req.min_eval_notional_usdc {
-        cfg.min_eval_notional_usdc = v.max(0.0);
+        next.min_eval_notional_usdc = v.max(0.0);
     }
     if let Some(v) = req.min_expected_edge_usdc {
-        cfg.min_expected_edge_usdc = v.max(0.0);
+        next.min_expected_edge_usdc = v.max(0.0);
+    }
+    let v52_cfg = {
+        let mut predator_cfg = state.shared.predator_cfg.write().await;
+        if let Some(v) = req.v52 {
+            predator_cfg.v52 = v;
+        }
+        if let Some(v) = req.v52_time_phase {
+            predator_cfg.v52.time_phase = v;
+        }
+        if let Some(v) = req.v52_execution {
+            predator_cfg.v52.execution = v;
+        }
+        if let Some(v) = req.v52_dual_arb {
+            predator_cfg.v52.dual_arb = v;
+        }
+        if let Some(v) = req.v52_reversal {
+            predator_cfg.v52.reversal = v;
+        }
+        normalize_v52_config(&mut predator_cfg.v52);
+        predator_cfg.v52.clone()
+    };
+    if let Some(v) = req.market_tier_profile {
+        next.market_tier_profile = v;
     }
     let mut fair_cfg = state
         .fair_value_cfg
@@ -149,19 +838,21 @@ async fn reload_strategy(
     if let Ok(mut guard) = state.fair_value_cfg.write() {
         *guard = fair_cfg.clone();
     }
-    let maker_cfg = cfg.clone();
-    drop(cfg);
+    *state.strategy_cfg.write().await = std::sync::Arc::new(next.clone());
+    let maker_cfg = next;
     append_jsonl(
         &dataset_path("reports", "strategy_reload.jsonl"),
         &serde_json::json!({
             "ts_ms": Utc::now().timestamp_millis(),
             "maker": maker_cfg,
-            "fair_value": fair_cfg
+            "fair_value": fair_cfg,
+            "v52": v52_cfg
         }),
     );
     Json(StrategyReloadResp {
         maker: maker_cfg,
         fair_value: fair_cfg,
+        v52: v52_cfg,
     })
 }
 
@@ -169,24 +860,26 @@ async fn reload_taker(
     State(state): State<AppState>,
     Json(req): Json<TakerReloadReq>,
 ) -> Json<TakerReloadResp> {
-    let mut cfg = state.strategy_cfg.write().await;
+    let cur = state.strategy_cfg.read().await.clone();
+    let mut next = (*cur).clone();
     if let Some(v) = req.trigger_bps {
-        cfg.taker_trigger_bps = v.max(0.0);
+        next.taker_trigger_bps = v.max(0.0);
     }
     if let Some(v) = req.max_slippage_bps {
-        cfg.taker_max_slippage_bps = v.max(0.0);
+        next.taker_max_slippage_bps = v.max(0.0);
     }
     if let Some(v) = req.stale_tick_filter_ms {
-        cfg.stale_tick_filter_ms = v.clamp(50.0, 5_000.0);
+        next.stale_tick_filter_ms = v.clamp(50.0, 5_000.0);
     }
     if let Some(v) = req.market_tier_profile {
-        cfg.market_tier_profile = v;
+        next.market_tier_profile = v;
     }
+    *state.strategy_cfg.write().await = std::sync::Arc::new(next.clone());
     let resp = TakerReloadResp {
-        trigger_bps: cfg.taker_trigger_bps,
-        max_slippage_bps: cfg.taker_max_slippage_bps,
-        stale_tick_filter_ms: cfg.stale_tick_filter_ms,
-        market_tier_profile: cfg.market_tier_profile.clone(),
+        trigger_bps: next.taker_trigger_bps,
+        max_slippage_bps: next.taker_max_slippage_bps,
+        stale_tick_filter_ms: next.stale_tick_filter_ms,
+        market_tier_profile: next.market_tier_profile.clone(),
     };
     append_jsonl(
         &dataset_path("reports", "taker_reload.jsonl"),
@@ -228,13 +921,17 @@ async fn reload_allocator(
     }
 
     {
-        let mut strategy = state.strategy_cfg.write().await;
-        strategy.capital_fraction_kelly = allocator.capital_fraction_kelly;
-        strategy.variance_penalty_lambda = allocator.variance_penalty_lambda;
+        let cur = state.strategy_cfg.read().await.clone();
+        let mut next = (*cur).clone();
+        next.capital_fraction_kelly = allocator.capital_fraction_kelly;
+        next.variance_penalty_lambda = allocator.variance_penalty_lambda;
+        *state.strategy_cfg.write().await = std::sync::Arc::new(next);
     }
     {
-        let mut tox = state.toxicity_cfg.write().await;
-        tox.active_top_n_markets = allocator.active_top_n_markets;
+        let cur = state.toxicity_cfg.read().await.clone();
+        let mut next = (*cur).clone();
+        next.active_top_n_markets = allocator.active_top_n_markets;
+        *state.toxicity_cfg.write().await = std::sync::Arc::new(next);
     }
 
     let resp = AllocatorReloadResp {
@@ -251,10 +948,7 @@ async fn reload_risk(
     State(state): State<AppState>,
     Json(req): Json<RiskReloadReq>,
 ) -> Json<RiskReloadResp> {
-    let mut cfg = state
-        .risk_limits
-        .write()
-        .unwrap_or_else(|e| e.into_inner());
+    let mut cfg = state.risk_limits.write().unwrap_or_else(|e| e.into_inner());
     if let Some(v) = req.max_market_notional {
         cfg.max_market_notional = v.max(0.0);
     }
@@ -273,6 +967,21 @@ async fn reload_risk(
     if let Some(v) = req.cooldown_sec {
         cfg.cooldown_sec = v.max(1);
     }
+    if let Some(v) = req.progressive_enabled {
+        cfg.progressive_enabled = v;
+    }
+    if let Some(v) = req.drawdown_tier1_ratio {
+        cfg.drawdown_tier1_ratio = v.clamp(0.05, 0.99);
+    }
+    if let Some(v) = req.drawdown_tier2_ratio {
+        cfg.drawdown_tier2_ratio = v.clamp(cfg.drawdown_tier1_ratio, 0.999);
+    }
+    if let Some(v) = req.tier1_size_scale {
+        cfg.tier1_size_scale = v.clamp(0.01, 1.0);
+    }
+    if let Some(v) = req.tier2_size_scale {
+        cfg.tier2_size_scale = v.clamp(0.01, 1.0);
+    }
     let snapshot = cfg.clone();
     append_jsonl(
         &dataset_path("reports", "risk_reload.jsonl"),
@@ -285,68 +994,71 @@ async fn reload_toxicity(
     State(state): State<AppState>,
     Json(req): Json<ToxicityReloadReq>,
 ) -> Json<ToxicityConfig> {
-    let mut cfg = state.toxicity_cfg.write().await;
+    let cur = state.toxicity_cfg.read().await.clone();
+    let mut next = (*cur).clone();
     if let Some(v) = req.safe_threshold {
-        cfg.safe_threshold = v.clamp(0.0, 1.0);
+        next.safe_threshold = v.clamp(0.0, 1.0);
     }
     if let Some(v) = req.caution_threshold {
-        cfg.caution_threshold = v.clamp(0.0, 1.0);
+        next.caution_threshold = v.clamp(0.0, 1.0);
     }
     if let Some(v) = req.cooldown_min_sec {
-        cfg.cooldown_min_sec = v.max(1);
+        next.cooldown_min_sec = v.max(1);
     }
     if let Some(v) = req.cooldown_max_sec {
-        cfg.cooldown_max_sec = v.max(cfg.cooldown_min_sec);
+        next.cooldown_max_sec = v.max(next.cooldown_min_sec);
     }
     if let Some(v) = req.min_market_score {
-        cfg.min_market_score = v.clamp(0.0, 100.0);
+        next.min_market_score = v.clamp(0.0, 100.0);
     }
     if let Some(v) = req.active_top_n_markets {
-        cfg.active_top_n_markets = v;
+        next.active_top_n_markets = v;
     }
     if let Some(v) = req.markout_1s_caution_bps {
-        cfg.markout_1s_caution_bps = v;
+        next.markout_1s_caution_bps = v;
     }
     if let Some(v) = req.markout_5s_caution_bps {
-        cfg.markout_5s_caution_bps = v;
+        next.markout_5s_caution_bps = v;
     }
     if let Some(v) = req.markout_10s_caution_bps {
-        cfg.markout_10s_caution_bps = v;
+        next.markout_10s_caution_bps = v;
     }
     if let Some(v) = req.markout_1s_danger_bps {
-        cfg.markout_1s_danger_bps = v;
+        next.markout_1s_danger_bps = v;
     }
     if let Some(v) = req.markout_5s_danger_bps {
-        cfg.markout_5s_danger_bps = v;
+        next.markout_5s_danger_bps = v;
     }
     if let Some(v) = req.markout_10s_danger_bps {
-        cfg.markout_10s_danger_bps = v;
+        next.markout_10s_danger_bps = v;
     }
-    if cfg.safe_threshold > cfg.caution_threshold {
-        let safe = cfg.safe_threshold;
-        cfg.safe_threshold = cfg.caution_threshold;
-        cfg.caution_threshold = safe;
+    if next.safe_threshold > next.caution_threshold {
+        std::mem::swap(&mut next.safe_threshold, &mut next.caution_threshold);
     }
-    if cfg.markout_1s_caution_bps < cfg.markout_1s_danger_bps {
-        let v = cfg.markout_1s_caution_bps;
-        cfg.markout_1s_caution_bps = cfg.markout_1s_danger_bps;
-        cfg.markout_1s_danger_bps = v;
+    if next.markout_1s_caution_bps < next.markout_1s_danger_bps {
+        std::mem::swap(
+            &mut next.markout_1s_caution_bps,
+            &mut next.markout_1s_danger_bps,
+        );
     }
-    if cfg.markout_5s_caution_bps < cfg.markout_5s_danger_bps {
-        let v = cfg.markout_5s_caution_bps;
-        cfg.markout_5s_caution_bps = cfg.markout_5s_danger_bps;
-        cfg.markout_5s_danger_bps = v;
+    if next.markout_5s_caution_bps < next.markout_5s_danger_bps {
+        std::mem::swap(
+            &mut next.markout_5s_caution_bps,
+            &mut next.markout_5s_danger_bps,
+        );
     }
-    if cfg.markout_10s_caution_bps < cfg.markout_10s_danger_bps {
-        let v = cfg.markout_10s_caution_bps;
-        cfg.markout_10s_caution_bps = cfg.markout_10s_danger_bps;
-        cfg.markout_10s_danger_bps = v;
+    if next.markout_10s_caution_bps < next.markout_10s_danger_bps {
+        std::mem::swap(
+            &mut next.markout_10s_caution_bps,
+            &mut next.markout_10s_danger_bps,
+        );
     }
+    *state.toxicity_cfg.write().await = std::sync::Arc::new(next.clone());
     append_jsonl(
         &dataset_path("reports", "toxicity_reload.jsonl"),
-        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "config": *cfg}),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "config": next}),
     );
-    Json(cfg.clone())
+    Json(next)
 }
 
 async fn reload_perf_profile(
@@ -378,13 +1090,27 @@ async fn reload_perf_profile(
 }
 
 async fn report_shadow_live(State(state): State<AppState>) -> Json<ShadowLiveReport> {
-    let live = state.shadow_stats.build_live_report().await;
+    let mut live = state.shadow_stats.build_live_report().await;
+    live.edge_model_version = state.shared.edge_model_cfg.read().await.version.clone();
+    {
+        let map = state.shared.source_health_latest.read().await;
+        let mut rows = map.values().cloned().collect::<Vec<_>>();
+        rows.sort_by(|a, b| b.score.total_cmp(&a.score));
+        live.source_health = rows;
+    }
     persist_live_report_files(&live);
     Json(live)
 }
 
 async fn report_shadow_final(State(state): State<AppState>) -> Json<ShadowFinalReport> {
-    let final_report = state.shadow_stats.build_final_report().await;
+    let mut final_report = state.shadow_stats.build_final_report().await;
+    final_report.live.edge_model_version = state.shared.edge_model_cfg.read().await.version.clone();
+    {
+        let map = state.shared.source_health_latest.read().await;
+        let mut rows = map.values().cloned().collect::<Vec<_>>();
+        rows.sort_by(|a, b| b.score.total_cmp(&a.score));
+        final_report.live.source_health = rows;
+    }
     persist_final_report_files(&final_report);
     Json(final_report)
 }
diff --git a/crates/app_runner/src/engine_core.rs b/crates/app_runner/src/engine_core.rs
index 9825e78..1118522 100644
--- a/crates/app_runner/src/engine_core.rs
+++ b/crates/app_runner/src/engine_core.rs
@@ -1,47 +1,28 @@
-use super::*;
-
 pub(super) fn is_quote_reject_reason(reason: &str) -> bool {
     reason.starts_with("execution_") || reason.starts_with("exchange_reject")
 }
 
 pub(super) fn is_policy_block_reason(reason: &str) -> bool {
+    // Metrics contract: policy_blocked only counts hard risk blocks.
     reason == "risk_capped_zero" || reason.starts_with("risk:")
 }
 
-pub(super) fn classify_execution_style(
-    book: &BookTop,
-    intent: &core_types::QuoteIntent,
-) -> ExecutionStyle {
-    match intent.side {
-        OrderSide::BuyYes => {
-            if intent.price >= book.ask_yes {
-                ExecutionStyle::Taker
-            } else {
-                ExecutionStyle::Maker
-            }
-        }
-        OrderSide::SellYes => {
-            if intent.price <= book.bid_yes {
-                ExecutionStyle::Taker
-            } else {
-                ExecutionStyle::Maker
-            }
-        }
-        OrderSide::BuyNo => {
-            if intent.price >= book.ask_no {
-                ExecutionStyle::Taker
-            } else {
-                ExecutionStyle::Maker
-            }
-        }
-        OrderSide::SellNo => {
-            if intent.price <= book.bid_no {
-                ExecutionStyle::Taker
-            } else {
-                ExecutionStyle::Maker
-            }
-        }
-    }
+pub(super) fn is_gate_block_reason(reason: &str) -> bool {
+    is_policy_block_reason(reason)
+        || reason.starts_with("rate_budget_")
+        || matches!(
+            reason,
+            "open_orders_pressure_precheck"
+                | "taker_slippage_budget"
+                | "market_rank_blocked"
+                | "market_score_low"
+                | "symbol_quality_guard"
+                | "decision_backlog_guard"
+                | "no_quote_policy"
+                | "no_quote_edge"
+                | "edge_below_dynamic_gate"
+                | "edge_notional_too_small"
+        )
 }
 
 pub(super) fn normalize_reject_code(raw: &str) -> String {
@@ -74,3 +55,27 @@ pub(super) fn classify_execution_error_reason(err: &anyhow::Error) -> &'static s
         "execution_error"
     }
 }
+
+#[cfg(test)]
+mod tests {
+    use super::{is_gate_block_reason, is_policy_block_reason};
+
+    #[test]
+    fn policy_block_reason_only_counts_hard_risk() {
+        assert!(is_policy_block_reason("risk:exposure"));
+        assert!(is_policy_block_reason("risk_capped_zero"));
+        assert!(!is_policy_block_reason("rate_budget_global"));
+        assert!(!is_policy_block_reason("open_orders_pressure_precheck"));
+        assert!(!is_policy_block_reason("decision_backlog_guard"));
+        assert!(!is_policy_block_reason("ref_dedupe_dropped"));
+    }
+
+    #[test]
+    fn gate_block_reason_keeps_soft_gates_for_diagnosis() {
+        assert!(is_gate_block_reason("risk:exposure"));
+        assert!(is_gate_block_reason("rate_budget_global"));
+        assert!(is_gate_block_reason("market_rank_blocked"));
+        assert!(is_gate_block_reason("edge_below_dynamic_gate"));
+        assert!(!is_gate_block_reason("ref_dedupe_dropped"));
+    }
+}
diff --git a/crates/app_runner/src/engine_loop.rs b/crates/app_runner/src/engine_loop.rs
new file mode 100644
index 0000000..354d751
--- /dev/null
+++ b/crates/app_runner/src/engine_loop.rs
@@ -0,0 +1,1646 @@
+use std::collections::HashMap;
+use std::sync::atomic::{AtomicBool, Ordering};
+use std::sync::Arc;
+use std::time::{Duration, Instant};
+
+use chrono::Utc;
+use core_types::{
+    new_id, BookTop, ControlCommand, Direction, EdgeAttribution, EngineEvent,
+    ExecutionStyle, ExecutionVenue, FairValueModel, InventoryState, MarketHealth, OrderAck,
+    OrderIntentV2, OrderSide, OrderTimeInForce, PaperAction, QuoteEval, QuoteIntent, RefTick,
+    ShadowOutcome, ShadowShot, Stage, TimeframeClass, ToxicRegime,
+};
+use execution_clob::ClobExecution;
+use exit_manager::{ExitReason, MarketEvalInput};
+use fair_value::BasisMrFairValue;
+use infra_bus::RingBus;
+use market_discovery::{DiscoveryConfig, MarketDiscovery};
+use paper_executor::ShadowExecutor;
+use portfolio::PortfolioBook;
+use tokio::sync::{mpsc, RwLock};
+
+use crate::paper_runtime::{global_paper_runtime, PaperIntentCtx};
+use crate::execution_eval::{
+    aggressive_price_for_side, classify_filled_outcome, classify_unfilled_outcome, edge_for_intent,
+    evaluate_fillable, evaluate_survival, get_fee_rate_bps_cached, get_rebate_bps_cached,
+    is_crossable, pnl_after_horizon,
+};
+use crate::fusion_engine::{
+    compute_coalesce_policy, estimate_feed_latency, fast_tick_allowed_in_fusion_mode,
+    insert_latest_ref_tick, is_anchor_ref_source, pick_latest_tick, ref_event_ts_ms, TokenBucket,
+};
+use crate::report_io::{
+    append_jsonl, current_jsonl_queue_depth, dataset_path, next_normalized_ingest_seq,
+};
+use crate::state::{
+    exit_reason_label, EngineShared, SignalCacheEntry, StrategyIngress, StrategyIngressMsg,
+};
+use crate::stats_utils::{freshness_ms, now_ns, percentile_deque_capped};
+use crate::strategy_policy::{
+    adaptive_max_spread, bps_to_usdc, build_toxic_features, compute_market_score_from_snapshot,
+    cooldown_secs_for_score, estimate_entry_notional_usdc, estimate_queue_fill_proxy,
+    evaluate_toxicity, inventory_for_market, is_market_in_top_n, net_markout, roi_bps_from_usdc,
+    should_observe_only_symbol,
+};
+use crate::strategy_runtime::{
+    classify_time_phase, evaluate_and_route_v52, stage_for_phase, timeframe_total_ms,
+};
+use crate::toxicity_runtime::update_toxic_state_from_outcome;
+use crate::{publish_if_telemetry_subscribers, spawn_detached};
+
+pub(crate) fn spawn_strategy_engine(
+    bus: RingBus<EngineEvent>,
+    portfolio: Arc<PortfolioBook>,
+    execution: Arc<ClobExecution>,
+    shadow: Arc<ShadowExecutor>,
+    paused: Arc<RwLock<bool>>,
+    shared: Arc<EngineShared>,
+    mut ingress_rx: mpsc::Receiver<StrategyIngressMsg>,
+) {
+    spawn_detached("strategy_engine", true, async move {
+        let fair = BasisMrFairValue::new(shared.fair_value_cfg.clone());
+        // Separate fast reference ticks (exchange WS) from anchor ticks (Chainlink RTDS).
+        // Fast ticks drive stale filtering + fair value evaluation; anchor ticks are tracked for
+        // auditing/diagnostics so the trigger stays latency-sensitive.
+        let mut latest_fast_ticks: HashMap<String, RefTick> = HashMap::new();
+        let mut latest_anchor_ticks: HashMap<String, RefTick> = HashMap::new();
+        let mut last_direction_tick_event_ms: HashMap<String, i64> = HashMap::new();
+        let mut market_inventory: HashMap<String, InventoryState> = HashMap::new();
+        let mut market_rate_budget: HashMap<String, TokenBucket> = HashMap::new();
+        let mut untracked_issue_cooldown: HashMap<String, Instant> = HashMap::new();
+        let mut book_lag_sample_at: HashMap<String, Instant> = HashMap::new();
+        let mut global_rate_budget = TokenBucket::new(
+            shared.rate_limit_rps,
+            (shared.rate_limit_rps * 2.0).max(1.0),
+        );
+        let mut control_rx = bus.subscribe();
+        let mut last_discovery_refresh = Instant::now() - Duration::from_secs(3600);
+        let mut last_symbol_retry_refresh = Instant::now() - Duration::from_secs(3600);
+        let mut last_fusion_mode = shared.fusion_cfg.read().await.mode.clone();
+        let strategy_max_coalesce = std::env::var("POLYEDGE_STRATEGY_MAX_COALESCE")
+            .ok()
+            .and_then(|v| v.parse::<usize>().ok())
+            .unwrap_or(256)
+            .clamp(8, 1_024);
+        let strategy_coalesce_min = std::env::var("POLYEDGE_STRATEGY_MIN_COALESCE")
+            .ok()
+            .and_then(|v| v.parse::<usize>().ok())
+            .unwrap_or(4)
+            .clamp(1, 128);
+        let strategy_coalesce_budget_us = std::env::var("POLYEDGE_STRATEGY_COALESCE_BUDGET_US")
+            .ok()
+            .and_then(|v| v.parse::<u64>().ok())
+            .unwrap_or(120)
+            .clamp(20, 2_000);
+        let strategy_drop_stale_book_ms = std::env::var("POLYEDGE_STRATEGY_DROP_STALE_BOOK_MS")
+            .ok()
+            .and_then(|v| v.parse::<f64>().ok())
+            .unwrap_or(800.0)
+            .clamp(50.0, 5_000.0);
+        let strategy_max_decision_backlog_ms = std::env::var("POLYEDGE_MAX_DECISION_BACKLOG_MS")
+            .ok()
+            .and_then(|v| v.parse::<f64>().ok())
+            .unwrap_or(0.90)
+            .clamp(0.10, 50.0);
+        let mut stale_book_drops: u64 = 0;
+        let symbol_refresh_inflight = Arc::new(AtomicBool::new(false));
+        refresh_market_symbol_map(&shared).await;
+
+        loop {
+            if last_discovery_refresh.elapsed() >= Duration::from_secs(300) {
+                refresh_market_symbol_map(&shared).await;
+                last_discovery_refresh = Instant::now();
+            }
+
+            let ingress_msg = tokio::select! {
+                ctrl = control_rx.recv() => {
+                    match ctrl {
+                        Ok(EngineEvent::Control(ControlCommand::Pause)) => {
+                            *paused.write().await = true;
+                            shared.shadow_stats.set_paused(true);
+                        }
+                        Ok(EngineEvent::Control(ControlCommand::Resume)) => {
+                            *paused.write().await = false;
+                            shared.shadow_stats.set_paused(false);
+                        }
+                        Ok(EngineEvent::Control(ControlCommand::Flatten)) => {
+                            if let Err(err) = execution.flatten_all().await {
+                                tracing::warn!(?err, "flatten from control event failed");
+                            }
+                        }
+                        Ok(_) => {}
+                        Err(_) => {}
+                    }
+                    continue;
+                }
+                maybe_ingress = ingress_rx.recv() => {
+                    let Some(event) = maybe_ingress else {
+                        shared.shadow_stats.record_issue("strategy_ingress_closed").await;
+                        break;
+                    };
+                    event
+                }
+            };
+            let mut ingress_enqueued_ns = ingress_msg.enqueued_ns;
+            let ingress_event = ingress_msg.payload;
+
+            let dispatch_start = Instant::now();
+            let current_fusion_mode = shared.fusion_cfg.read().await.mode.clone();
+            if current_fusion_mode != last_fusion_mode {
+                latest_fast_ticks.retain(|_, tick| {
+                    fast_tick_allowed_in_fusion_mode(tick.source.as_str(), &current_fusion_mode)
+                });
+                shared.latest_fast_ticks.retain(|_, tick| {
+                    fast_tick_allowed_in_fusion_mode(tick.source.as_str(), &current_fusion_mode)
+                });
+                last_fusion_mode = current_fusion_mode.clone();
+                shared
+                    .shadow_stats
+                    .record_issue("fusion_mode_switch_fast_cache_reset")
+                    .await;
+            }
+
+            match ingress_event {
+                StrategyIngress::RefTick(tick) => {
+                    let parse_us = dispatch_start.elapsed().as_secs_f64() * 1_000_000.0;
+                    shared.shadow_stats.push_parse_us(parse_us).await;
+                    if !is_anchor_ref_source(tick.source.as_str())
+                        && !fast_tick_allowed_in_fusion_mode(
+                            tick.source.as_str(),
+                            &current_fusion_mode,
+                        )
+                    {
+                        continue;
+                    }
+                    insert_latest_ref_tick(&mut latest_fast_ticks, &mut latest_anchor_ticks, tick);
+                }
+                StrategyIngress::BookTop(mut book) => {
+                    let parse_us = dispatch_start.elapsed().as_secs_f64() * 1_000_000.0;
+                    shared.shadow_stats.push_parse_us(parse_us).await;
+                    // Keep only the freshest observable state under burst.
+                    let mut coalesced = 0_u64;
+                    let coalesce_start = Instant::now();
+                    let queue_len = ingress_rx.len();
+                    let coalesce_policy = compute_coalesce_policy(
+                        queue_len,
+                        shared
+                            .shadow_stats
+                            .book_top_lag_p50_ms_for_symbol_sync(book.market_id.as_str()),
+                        strategy_max_coalesce,
+                        strategy_coalesce_min,
+                        strategy_coalesce_budget_us,
+                    );
+                    while coalesced < coalesce_policy.max_events as u64 {
+                        if coalesced > 0
+                            && (coalesce_start.elapsed().as_micros() as u64)
+                                >= coalesce_policy.budget_us
+                        {
+                            break;
+                        }
+                        match ingress_rx.try_recv() {
+                            Ok(StrategyIngressMsg {
+                                enqueued_ns,
+                                payload: StrategyIngress::BookTop(next_book),
+                            }) => {
+                                book = next_book;
+                                ingress_enqueued_ns = enqueued_ns;
+                                coalesced += 1;
+                            }
+                            Ok(StrategyIngressMsg {
+                                payload: StrategyIngress::RefTick(next_tick),
+                                ..
+                            }) => {
+                                let next_is_anchor =
+                                    is_anchor_ref_source(next_tick.source.as_str());
+                                if !next_is_anchor
+                                    && !fast_tick_allowed_in_fusion_mode(
+                                        next_tick.source.as_str(),
+                                        &current_fusion_mode,
+                                    )
+                                {
+                                    coalesced += 1;
+                                    continue;
+                                }
+                                insert_latest_ref_tick(
+                                    &mut latest_fast_ticks,
+                                    &mut latest_anchor_ticks,
+                                    next_tick,
+                                );
+                                coalesced += 1;
+                            }
+                            Err(tokio::sync::mpsc::error::TryRecvError::Empty) => break,
+                            Err(tokio::sync::mpsc::error::TryRecvError::Disconnected) => {
+                                shared
+                                    .shadow_stats
+                                    .record_issue("strategy_ingress_disconnected")
+                                    .await;
+                                break;
+                            }
+                        }
+                    }
+                    if coalesced > 0 {
+                        metrics::counter!("runtime.coalesced_events").increment(coalesced);
+                    }
+                    if book.recv_ts_local_ns > 0 {
+                        let book_age_ms =
+                            ((now_ns() - book.recv_ts_local_ns).max(0) as f64) / 1_000_000.0;
+                        if book_age_ms > strategy_drop_stale_book_ms {
+                            stale_book_drops = stale_book_drops.saturating_add(1);
+                            metrics::counter!("strategy.stale_book_dropped").increment(1);
+                            metrics::histogram!("latency.stale_book_drop_age_ms")
+                                .record(book_age_ms);
+                            if stale_book_drops.is_multiple_of(128) {
+                                shared.shadow_stats.record_issue("stale_book_dropped").await;
+                            }
+                            continue;
+                        }
+                    }
+
+                    let backlog_depth = ingress_rx.len() as f64;
+                    metrics::histogram!("runtime.event_backlog_depth").record(backlog_depth);
+                    let queue_depth = execution.open_orders_count() as f64;
+                    metrics::histogram!("runtime.open_order_depth").record(queue_depth);
+                    let io_depth = current_jsonl_queue_depth() as f64;
+                    shared
+                        .shadow_stats
+                        .push_depth_sample(backlog_depth, queue_depth, io_depth)
+                        .await;
+                    metrics::histogram!("runtime.jsonl_queue_depth").record(io_depth);
+                    shared
+                        .latest_books
+                        .write()
+                        .await
+                        .insert(book.market_id.clone(), book.clone());
+
+                    if let Some(paper) = global_paper_runtime() {
+                        let chainlink_settlement_price =
+                            if let Some(symbol) = pick_market_symbol(&shared, &book).await {
+                                shared.settlement_prices.read().await.get(&symbol).copied()
+                            } else {
+                                None
+                            };
+                        paper.on_book(&book, chainlink_settlement_price).await;
+                    }
+                    let fills = shadow.on_book(&book);
+                    shared.shadow_stats.mark_filled(fills.len() as u64);
+                    for fill in fills {
+                        execution.mark_order_closed_local(&fill.order_id);
+                        portfolio.apply_fill(&fill);
+                        if let Some(paper) = global_paper_runtime() {
+                            paper.on_fill(&fill).await;
+                        }
+                        publish_if_telemetry_subscribers(&bus, EngineEvent::Fill(fill.clone()));
+                        let ingest_seq = next_normalized_ingest_seq();
+                        append_jsonl(
+                            &dataset_path("normalized", "fills.jsonl"),
+                            &serde_json::json!({
+                                "ts_ms": Utc::now().timestamp_millis(),
+                                "source_seq": Utc::now().timestamp_millis().max(0) as u64,
+                                "ingest_seq": ingest_seq,
+                                "fill": fill
+                            }),
+                        );
+                    }
+
+                    if *paused.read().await {
+                        shared.shadow_stats.record_issue("paused").await;
+                        continue;
+                    }
+                    if shared.shadow_stats.observe_only() {
+                        shared.shadow_stats.record_issue("observe_only").await;
+                        continue;
+                    }
+
+                    let symbol = pick_market_symbol(&shared, &book).await;
+                    let Some(symbol) = symbol else {
+                        if market_is_tracked(&shared, &book).await {
+                            {
+                                let mut states = shared.tox_state.write().await;
+                                let st = states.entry(book.market_id.clone()).or_default();
+                                st.symbol_missing = st.symbol_missing.saturating_add(1);
+                            }
+                            shared.shadow_stats.record_issue("symbol_missing").await;
+                        } else {
+                            let now = Instant::now();
+                            let should_record = untracked_issue_cooldown
+                                .get(&book.market_id)
+                                .map(|last| last.elapsed() >= Duration::from_secs(60))
+                                .unwrap_or(true);
+                            if should_record {
+                                shared.shadow_stats.record_issue("market_untracked").await;
+                                untracked_issue_cooldown.insert(book.market_id.clone(), now);
+                            }
+                        }
+                        if last_symbol_retry_refresh.elapsed() >= Duration::from_secs(15)
+                            && !symbol_refresh_inflight.swap(true, Ordering::AcqRel)
+                        {
+                            last_symbol_retry_refresh = Instant::now();
+                            let shared_refresh = shared.clone();
+                            let inflight = symbol_refresh_inflight.clone();
+                            spawn_detached("symbol_map_refresh", false, async move {
+                                refresh_market_symbol_map(&shared_refresh).await;
+                                inflight.store(false, Ordering::Release);
+                            });
+                        }
+                        continue;
+                    };
+                    let tick_fast_owned = shared
+                        .latest_fast_ticks
+                        .get(symbol.as_str())
+                        .map(|entry| entry.value().clone())
+                        .and_then(|tick| {
+                            if fast_tick_allowed_in_fusion_mode(
+                                tick.source.as_str(),
+                                &current_fusion_mode,
+                            ) {
+                                Some(tick)
+                            } else {
+                                None
+                            }
+                        });
+                    let tick_fast = tick_fast_owned
+                        .as_ref()
+                        .or_else(|| pick_latest_tick(&latest_fast_ticks, &symbol));
+                    let Some(tick_fast) = tick_fast else {
+                        shared.shadow_stats.record_issue("tick_missing").await;
+                        continue;
+                    };
+                    let fusion_mode = {
+                        let fusion = shared.fusion_cfg.read().await;
+                        fusion.mode.clone()
+                    };
+                    if !fast_tick_allowed_in_fusion_mode(tick_fast.source.as_str(), &fusion_mode) {
+                        shared
+                            .shadow_stats
+                            .record_issue("tick_source_mode_mismatch")
+                            .await;
+                        continue;
+                    }
+                    let tick_anchor_owned = shared
+                        .latest_anchor_ticks
+                        .get(symbol.as_str())
+                        .map(|entry| entry.value().clone());
+                    let tick_anchor = tick_anchor_owned
+                        .as_ref()
+                        .or_else(|| pick_latest_tick(&latest_anchor_ticks, &symbol));
+                    if let Some(anchor) = tick_anchor {
+                        let now_ms = Utc::now().timestamp_millis();
+                        let age_ms = now_ms - ref_event_ts_ms(anchor);
+                        if age_ms > 5_000 {
+                            shared.shadow_stats.record_issue("anchor_stale").await;
+                        }
+                    } else {
+                        shared.shadow_stats.record_issue("anchor_missing").await;
+                    }
+                    // For latency-sensitive trading, evaluate fair value on the fastest observable
+                    // reference tick. The Chainlink anchor is tracked for correctness auditing and
+                    // can be used for future calibration, but should not slow down the trigger.
+                    let eval_tick = tick_fast;
+                    if !is_anchor_ref_source(eval_tick.source.as_str()) {
+                        let event_ms = ref_event_ts_ms(eval_tick);
+                        let should_update_direction = last_direction_tick_event_ms
+                            .get(symbol.as_str())
+                            .map(|prev| event_ms > *prev)
+                            .unwrap_or(true);
+                        if should_update_direction {
+                            shared
+                                .predator_direction_detector
+                                .write()
+                                .await
+                                .on_tick(eval_tick);
+                            last_direction_tick_event_ms.insert(symbol.clone(), event_ms);
+                        }
+                    }
+                    shared.shadow_stats.mark_seen();
+
+                    // Positive value means: our fast reference tick arrived earlier than the
+                    // Polymarket book update (i.e. the exploitable lag window).
+                    //
+                    // Guardrail: if the tick is already old, this is not a meaningful "lag window"
+                    // measurement and would inflate p50/p99. We only sample when the tick is fresh.
+                    let tick_age_ms =
+                        freshness_ms(Utc::now().timestamp_millis(), tick_fast.recv_ts_ms);
+                    let stale_ms = tick_age_ms.max(0) as f64;
+                    let book_top_lag_ms = if tick_age_ms <= 1_500
+                        && tick_fast.recv_ts_local_ns > 0
+                        && book.recv_ts_local_ns > 0
+                    {
+                        ((book.recv_ts_local_ns - tick_fast.recv_ts_local_ns).max(0) as f64)
+                            / 1_000_000.0
+                    } else {
+                        0.0
+                    };
+                    let should_sample_book_lag = book_lag_sample_at
+                        .get(&symbol)
+                        .map(|t| t.elapsed() >= Duration::from_millis(200))
+                        .unwrap_or(true);
+                    if should_sample_book_lag {
+                        book_lag_sample_at.insert(symbol.clone(), Instant::now());
+                        shared
+                            .shadow_stats
+                            .push_book_top_lag_ms(&symbol, book_top_lag_ms)
+                            .await;
+                    }
+
+                    let latency_sample = estimate_feed_latency(tick_fast, &book);
+                    let feed_in_ms = latency_sample.feed_in_ms;
+                    let stale_tick_filter_ms =
+                        shared.strategy_cfg.read().await.stale_tick_filter_ms;
+                    shared
+                        .shadow_stats
+                        .push_latency_sample(
+                            feed_in_ms,
+                            latency_sample.source_latency_ms,
+                            latency_sample.exchange_lag_ms,
+                            latency_sample.path_lag_ms,
+                            latency_sample.book_latency_ms,
+                            latency_sample.local_backlog_ms,
+                            latency_sample.ref_decode_ms,
+                        )
+                        .await;
+                    metrics::histogram!("latency.feed_in_ms").record(feed_in_ms);
+                    metrics::histogram!("latency.source_latency_ms")
+                        .record(latency_sample.source_latency_ms);
+                    metrics::histogram!("latency.exchange_lag_ms")
+                        .record(latency_sample.exchange_lag_ms);
+                    if latency_sample.path_lag_ms.is_finite() && latency_sample.path_lag_ms >= 0.0 {
+                        metrics::histogram!("latency.path_lag_ms")
+                            .record(latency_sample.path_lag_ms);
+                    }
+                    metrics::histogram!("latency.book_latency_ms")
+                        .record(latency_sample.book_latency_ms);
+                    metrics::histogram!("latency.local_backlog_ms")
+                        .record(latency_sample.local_backlog_ms);
+                    metrics::histogram!("latency.ref_decode_ms")
+                        .record(latency_sample.ref_decode_ms);
+                    // Stale tick filtering must be based on *local* staleness/age, not exchange
+                    // event timestamps (which can be skewed across venues).
+                    if stale_ms > stale_tick_filter_ms {
+                        shared.shadow_stats.mark_stale_tick_dropped();
+                        shared.shadow_stats.record_issue("stale_tick_dropped").await;
+                        continue;
+                    }
+                    if latency_sample.local_backlog_ms > strategy_max_decision_backlog_ms {
+                        shared
+                            .shadow_stats
+                            .mark_blocked_with_reason("decision_backlog_guard")
+                            .await;
+                        metrics::counter!("strategy.decision_backlog_guard").increment(1);
+                        continue;
+                    }
+                    let queue_wait_ms = if ingress_enqueued_ns > 0 {
+                        ((now_ns() - ingress_enqueued_ns).max(0) as f64) / 1_000_000.0
+                    } else {
+                        latency_sample.local_backlog_ms
+                    };
+                    shared
+                        .shadow_stats
+                        .push_decision_queue_wait_ms(queue_wait_ms)
+                        .await;
+                    metrics::histogram!("latency.decision_queue_wait_ms").record(queue_wait_ms);
+                    let signal_start = Instant::now();
+                    let signal = fair.evaluate(eval_tick, &book);
+                    if signal.edge_bps_bid > 0.0 || signal.edge_bps_ask > 0.0 {
+                        shared.shadow_stats.mark_candidate();
+                    }
+                    let signal_us = signal_start.elapsed().as_secs_f64() * 1_000_000.0;
+                    shared.shadow_stats.push_signal_us(signal_us).await;
+                    metrics::histogram!("latency.signal_us").record(signal_us);
+                    publish_if_telemetry_subscribers(&bus, EngineEvent::Signal(signal.clone()));
+                    shared.latest_signals.insert(
+                        book.market_id.clone(),
+                        SignalCacheEntry {
+                            signal: signal.clone(),
+                            ts_ms: Utc::now().timestamp_millis(),
+                        },
+                    );
+                    if should_sample_book_lag && book_top_lag_ms >= 5.0 {
+                        // "Orderless" survival probe: measure whether an observed top-of-book
+                        // price survives for +Î” ms, independent of order placement.
+                        let mid_yes = (book.bid_yes + book.ask_yes) * 0.5;
+                        let probe_side = if signal.fair_yes >= mid_yes {
+                            OrderSide::BuyYes
+                        } else {
+                            OrderSide::BuyNo
+                        };
+                        let probe_px = aggressive_price_for_side(&book, &probe_side);
+                        if probe_px > 0.0 {
+                            for delay_ms in [5_u64, 10_u64, 25_u64] {
+                                spawn_survival_probe_task(
+                                    shared.clone(),
+                                    book.market_id.clone(),
+                                    symbol.clone(),
+                                    probe_side.clone(),
+                                    probe_px,
+                                    delay_ms,
+                                );
+                            }
+                        }
+                    }
+
+                    let cfg = shared.strategy_cfg.read().await.clone();
+                    let tox_cfg = shared.toxicity_cfg.read().await.clone();
+                    let pending_market_exposure =
+                        execution.open_order_notional_for_market(&book.market_id);
+
+                    let (
+                        tox_features,
+                        tox_decision,
+                        market_score,
+                        pending_exposure,
+                        no_quote_rate,
+                        symbol_missing_rate,
+                        markout_samples,
+                        active_by_rank,
+                    ) = {
+                        // Step A: snapshot (read-lock) the state needed for computation.
+                        let (
+                            attempted0,
+                            no_quote0,
+                            symbol_missing0,
+                            cooldown_until_ms0,
+                            markout_samples0,
+                            markout_1s_p50,
+                            markout_5s_p50,
+                            markout_10s_p50,
+                        ) = {
+                            let states = shared.tox_state.read().await;
+                            if let Some(st) = states.get(&book.market_id) {
+                                let samples = st
+                                    .markout_1s
+                                    .len()
+                                    .max(st.markout_5s.len())
+                                    .max(st.markout_10s.len());
+                                (
+                                    st.attempted,
+                                    st.no_quote,
+                                    st.symbol_missing,
+                                    st.cooldown_until_ms,
+                                    samples,
+                                    percentile_deque_capped(&st.markout_1s, 0.50, 1024)
+                                        .unwrap_or(0.0),
+                                    percentile_deque_capped(&st.markout_5s, 0.50, 1024)
+                                        .unwrap_or(0.0),
+                                    percentile_deque_capped(&st.markout_10s, 0.50, 2048)
+                                        .unwrap_or(0.0),
+                                )
+                            } else {
+                                (0, 0, 0, 0, 0, 0.0, 0.0, 0.0)
+                            }
+                        };
+
+                        // Step B: compute without holding a write lock.
+                        let attempted1 = attempted0.saturating_add(1).max(1);
+                        let tox_features = build_toxic_features(
+                            &book,
+                            &symbol,
+                            stale_ms,
+                            signal.fair_yes,
+                            attempted1,
+                            no_quote0,
+                            markout_1s_p50,
+                            markout_5s_p50,
+                            markout_10s_p50,
+                        );
+                        let mut tox_decision = evaluate_toxicity(&tox_features, &tox_cfg);
+                        let score_scale = (tox_cfg.k_spread / 1.5).clamp(0.25, 4.0);
+                        tox_decision.tox_score =
+                            (tox_decision.tox_score * score_scale).clamp(0.0, 1.0);
+                        tox_decision.regime = if tox_decision.tox_score >= tox_cfg.caution_threshold
+                        {
+                            ToxicRegime::Danger
+                        } else if tox_decision.tox_score >= tox_cfg.safe_threshold {
+                            ToxicRegime::Caution
+                        } else {
+                            ToxicRegime::Safe
+                        };
+
+                        let now_ms = Utc::now().timestamp_millis();
+                        let mut cooldown_until_ms1 = cooldown_until_ms0;
+                        if now_ms < cooldown_until_ms0 {
+                            tox_decision.regime = ToxicRegime::Danger;
+                            tox_decision
+                                .reason_codes
+                                .push("cooldown_active".to_string());
+                        }
+                        // Note: cooldown is based on the pre-warmup regime, matching the old behavior.
+                        if matches!(tox_decision.regime, ToxicRegime::Danger) {
+                            let cool = cooldown_secs_for_score(tox_decision.tox_score, &tox_cfg);
+                            cooldown_until_ms1 =
+                                cooldown_until_ms1.max(now_ms + (cool as i64) * 1_000);
+                        }
+                        let markout_samples = markout_samples0;
+                        if markout_samples < 20 {
+                            tox_decision.tox_score =
+                                tox_decision.tox_score.min(tox_cfg.safe_threshold * 0.8);
+                            tox_decision.regime = ToxicRegime::Safe;
+                            tox_decision
+                                .reason_codes
+                                .push("warmup_samples_lt_20".to_string());
+                        }
+
+                        let market_score = compute_market_score_from_snapshot(
+                            attempted1,
+                            no_quote0,
+                            symbol_missing0,
+                            tox_decision.tox_score,
+                            markout_samples,
+                            markout_10s_p50,
+                        );
+                        let no_quote_rate = (no_quote0 as f64 / attempted1 as f64).clamp(0.0, 1.0);
+                        let symbol_missing_rate =
+                            (symbol_missing0 as f64 / attempted1 as f64).clamp(0.0, 1.0);
+
+                        // Step C: short write-back only.
+                        {
+                            let mut states = shared.tox_state.write().await;
+                            let st = states.entry(book.market_id.clone()).or_default();
+                            st.attempted = st.attempted.saturating_add(1);
+                            st.symbol = symbol.clone();
+                            st.last_tox_score = tox_decision.tox_score;
+                            st.last_regime = tox_decision.regime.clone();
+                            st.cooldown_until_ms = st.cooldown_until_ms.max(cooldown_until_ms1);
+                            st.market_score = market_score;
+                        }
+
+                        // Step D: rank decision (read-lock, uses updated market_score).
+                        let active_by_rank = {
+                            let states = shared.tox_state.read().await;
+                            is_market_in_top_n(
+                                &states,
+                                &book.market_id,
+                                tox_cfg.active_top_n_markets,
+                            )
+                        };
+
+                        (
+                            tox_features,
+                            tox_decision,
+                            market_score,
+                            pending_market_exposure,
+                            no_quote_rate,
+                            symbol_missing_rate,
+                            markout_samples,
+                            active_by_rank,
+                        )
+                    };
+                    let spread_yes = (book.ask_yes - book.bid_yes).max(0.0);
+                    let effective_max_spread = adaptive_max_spread(
+                        cfg.max_spread,
+                        tox_decision.tox_score,
+                        markout_samples,
+                    );
+                    if should_observe_only_symbol(
+                        &symbol,
+                        &cfg,
+                        &tox_decision,
+                        stale_ms,
+                        spread_yes,
+                        book_top_lag_ms,
+                    ) {
+                        shared
+                            .shadow_stats
+                            .mark_blocked_with_reason("symbol_quality_guard")
+                            .await;
+                        continue;
+                    }
+                    let queue_fill_proxy =
+                        estimate_queue_fill_proxy(tox_decision.tox_score, spread_yes, stale_ms);
+
+                    if spread_yes > effective_max_spread {
+                        {
+                            let mut states = shared.tox_state.write().await;
+                            let st = states.entry(book.market_id.clone()).or_default();
+                            st.no_quote = st.no_quote.saturating_add(1);
+                        }
+                        shared
+                            .shadow_stats
+                            .mark_blocked_with_reason("no_quote_spread")
+                            .await;
+                        continue;
+                    }
+                    if signal.confidence <= 0.0 {
+                        {
+                            let mut states = shared.tox_state.write().await;
+                            let st = states.entry(book.market_id.clone()).or_default();
+                            st.no_quote = st.no_quote.saturating_add(1);
+                        }
+                        shared
+                            .shadow_stats
+                            .mark_blocked_with_reason("no_quote_confidence")
+                            .await;
+                        continue;
+                    }
+
+                    publish_if_telemetry_subscribers(
+                        &bus,
+                        EngineEvent::ToxicFeatures(tox_features.clone()),
+                    );
+                    publish_if_telemetry_subscribers(
+                        &bus,
+                        EngineEvent::ToxicDecision(tox_decision.clone()),
+                    );
+                    let ingest_seq_features = next_normalized_ingest_seq();
+                    append_jsonl(
+                        &dataset_path("normalized", "tox_features.jsonl"),
+                        &serde_json::json!({
+                            "ts_ms": Utc::now().timestamp_millis(),
+                            "source_seq": book.ts_ms.max(0) as u64,
+                            "ingest_seq": ingest_seq_features,
+                            "features": tox_features
+                        }),
+                    );
+                    let ingest_seq_decisions = next_normalized_ingest_seq();
+                    append_jsonl(
+                        &dataset_path("normalized", "tox_decisions.jsonl"),
+                        &serde_json::json!({
+                            "ts_ms": Utc::now().timestamp_millis(),
+                            "source_seq": book.ts_ms.max(0) as u64,
+                            "ingest_seq": ingest_seq_decisions,
+                            "decision": tox_decision
+                        }),
+                    );
+                    let market_health = MarketHealth {
+                        market_id: book.market_id.clone(),
+                        symbol: symbol.clone(),
+                        symbol_missing_rate,
+                        no_quote_rate,
+                        pending_exposure,
+                        queue_fill_proxy,
+                        ts_ns: now_ns(),
+                    };
+                    let ingest_seq_health = next_normalized_ingest_seq();
+                    append_jsonl(
+                        &dataset_path("normalized", "market_health.jsonl"),
+                        &serde_json::json!({
+                            "ts_ms": Utc::now().timestamp_millis(),
+                            "source_seq": book.ts_ms.max(0) as u64,
+                            "ingest_seq": ingest_seq_health,
+                            "health": market_health
+                        }),
+                    );
+
+                    if market_score < tox_cfg.min_market_score {
+                        shared
+                            .shadow_stats
+                            .mark_blocked_with_reason("market_score_low")
+                            .await;
+                        continue;
+                    }
+                    if !active_by_rank {
+                        shared
+                            .shadow_stats
+                            .mark_blocked_with_reason("market_rank_blocked")
+                            .await;
+                        continue;
+                    }
+
+                    let predator_cfg = shared.predator_cfg.read().await.clone();
+                    if predator_cfg.enabled {
+                        let now_ms = Utc::now().timestamp_millis();
+                        let _ = evaluate_and_route_v52(
+                            &shared,
+                            &bus,
+                            &portfolio,
+                            &execution,
+                            &shadow,
+                            &mut market_rate_budget,
+                            &mut global_rate_budget,
+                            &predator_cfg,
+                            &symbol,
+                            tick_fast.recv_ts_ms,
+                            tick_fast.recv_ts_local_ns,
+                            now_ms,
+                            None,
+                        )
+                        .await;
+                        continue;
+                    }
+
+                    market_inventory.insert(
+                        book.market_id.clone(),
+                        inventory_for_market(&portfolio, &book.market_id),
+                    );
+                    shared
+                        .shadow_stats
+                        .mark_blocked_with_reason("predator_c_disabled")
+                        .await;
+                    continue;
+                }
+            }
+        }
+    });
+}
+
+#[derive(Debug, Default, Clone, Copy)]
+pub(crate) struct PredatorExecResult {
+    pub(crate) attempted: u64,
+    pub(crate) executed: u64,
+    pub(crate) stop_firing: bool,
+}
+
+fn opposite_side_for_reentry(side: &OrderSide) -> OrderSide {
+    match side {
+        OrderSide::BuyYes => OrderSide::BuyNo,
+        OrderSide::BuyNo => OrderSide::BuyYes,
+        OrderSide::SellYes => OrderSide::SellNo,
+        OrderSide::SellNo => OrderSide::SellYes,
+    }
+}
+
+fn maker_reentry_price_for_side(book: &BookTop, side: &OrderSide) -> f64 {
+    match side {
+        OrderSide::BuyYes => book.bid_yes,
+        OrderSide::BuyNo => book.bid_no,
+        OrderSide::SellYes => book.ask_yes,
+        OrderSide::SellNo => book.ask_no,
+    }
+}
+
+pub(crate) fn build_reversal_reentry_order(
+    market_id: &str,
+    side: &OrderSide,
+    book: &BookTop,
+    size: f64,
+    ttl_ms: u64,
+    fee_rate_bps: f64,
+) -> Option<OrderIntentV2> {
+    let reentry_side = opposite_side_for_reentry(side);
+    let price = maker_reentry_price_for_side(book, &reentry_side);
+    if !price.is_finite() || price <= 0.0 {
+        return None;
+    }
+    let token_id = match reentry_side {
+        OrderSide::BuyYes | OrderSide::SellYes => book.token_id_yes.clone(),
+        OrderSide::BuyNo | OrderSide::SellNo => book.token_id_no.clone(),
+    };
+    Some(OrderIntentV2 {
+        market_id: market_id.to_string(),
+        token_id: Some(token_id),
+        side: reentry_side,
+        price,
+        size: size.max(0.01),
+        ttl_ms: ttl_ms.max(100),
+        style: ExecutionStyle::Maker,
+        tif: OrderTimeInForce::PostOnly,
+        max_slippage_bps: 0.0,
+        fee_rate_bps,
+        expected_edge_net_bps: 0.0,
+        client_order_id: Some(new_id()),
+        hold_to_resolution: false,
+        prebuilt_payload: None,
+    })
+}
+
+async fn reentry_candidate_for_market(
+    shared: &Arc<EngineShared>,
+    target_market_id: &str,
+    side: &OrderSide,
+    size: f64,
+    maker_ttl_ms: u64,
+    maker_min_edge_bps: f64,
+    fail_cost_bps: f64,
+) -> Option<(OrderIntentV2, BookTop)> {
+    let book = shared.latest_books.read().await.get(target_market_id).cloned()?;
+    let fee_rate_bps = get_fee_rate_bps_cached(shared, target_market_id).await;
+    let mut order = build_reversal_reentry_order(
+        target_market_id,
+        side,
+        &book,
+        size,
+        maker_ttl_ms,
+        fee_rate_bps,
+    )?;
+    let fair_yes = shared
+        .latest_signals
+        .get(target_market_id)
+        .map(|sig| sig.value().signal.fair_yes.clamp(0.0, 1.0))
+        .unwrap_or(0.5);
+    let quote_intent = QuoteIntent {
+        market_id: target_market_id.to_string(),
+        side: order.side.clone(),
+        price: order.price,
+        size: order.size,
+        ttl_ms: order.ttl_ms,
+    };
+    let rebate_bps = get_rebate_bps_cached(shared, target_market_id, fee_rate_bps).await;
+    let edge_net_bps =
+        edge_for_intent(fair_yes, &quote_intent) - fee_rate_bps + rebate_bps - fail_cost_bps;
+    if edge_net_bps < maker_min_edge_bps {
+        return None;
+    }
+    order.expected_edge_net_bps = edge_net_bps;
+    Some((order, book))
+}
+
+pub(crate) fn spawn_predator_exit_lifecycle(
+    shared: Arc<EngineShared>,
+    bus: RingBus<EngineEvent>,
+    execution: Arc<ClobExecution>,
+    shadow: Arc<ShadowExecutor>,
+    position_id: String,
+    market_id: String,
+    symbol: String,
+    side: OrderSide,
+    entry_price: f64,
+    size: f64,
+    maker_ttl_ms: u64,
+    entry_fair_yes: f64,
+) {
+    let mut fill_rx = shared.wss_fill_tx.as_ref().map(|tx| tx.subscribe());
+    let entry_pm_mid_yes = entry_price;
+
+    spawn_detached("predator_exit_lifecycle", false, async move {
+        let checkpoints = [3_000_u64, 15_000_u64, 60_000_u64, 300_000_u64];
+        let mut elapsed_ms = 0_u64;
+
+        'outer: for checkpoint in checkpoints {
+            let wait_ms = checkpoint.saturating_sub(elapsed_ms);
+            elapsed_ms = checkpoint;
+
+            if wait_ms > 0 {
+                let sleep = tokio::time::sleep(Duration::from_millis(wait_ms));
+                tokio::pin!(sleep);
+
+                loop {
+                    let fill_fut =
+                        futures::future::OptionFuture::from(fill_rx.as_mut().map(|rx| rx.recv()));
+                    tokio::select! {
+                        biased;
+                        Some(fill_result) = fill_fut => {
+                            if let Ok(fill) = fill_result {
+                                if fill.order_id == position_id || fill.market_id == market_id {
+                                    tracing::info!(
+                                        position_id = %position_id,
+                                        market_id = %market_id,
+                                        fill_price = fill.price,
+                                        fill_size = fill.size,
+                                        event_type = %fill.event_type,
+                                        "wss_user_feed: fill detected, triggering early exit eval"
+                                    );
+                                    metrics::counter!("wss.fill_detected").increment(1);
+                                    break;
+                                }
+                            }
+                        }
+                        _ = &mut sleep => break,
+                    }
+                }
+            }
+
+            let exit_cfg = shared.exit_cfg.read().await.clone();
+            if !exit_cfg.enabled {
+                continue 'outer;
+            }
+
+            let now_ms = Utc::now().timestamp_millis();
+            let true_prob = estimate_true_prob_for_side(&shared, &market_id, &side).await;
+            let unrealized_pnl_usdc =
+                estimate_unrealized_pnl_usdc(&shared, &market_id, &side, entry_price, size)
+                    .await
+                    .unwrap_or(0.0);
+            let time_to_expiry_ms = estimate_time_to_expiry_ms(&shared, &market_id, now_ms).await;
+
+            let pm_mid_yes = {
+                let books = shared.latest_books.read().await;
+                books
+                    .get(&market_id)
+                    .map(|b| (b.bid_yes + b.ask_yes) / 2.0)
+                    .unwrap_or(0.0)
+            };
+
+            let action = {
+                let mut manager = shared.predator_exit_manager.write().await;
+                manager.evaluate_market(
+                    &market_id,
+                    MarketEvalInput {
+                        now_ms,
+                        unrealized_pnl_usdc,
+                        true_prob,
+                        time_to_expiry_ms,
+                        pm_mid_yes,
+                        entry_pm_mid_yes,
+                        entry_fair_yes,
+                    },
+                )
+            };
+
+            if let Some(action) = action {
+                let reason_kind = action.reason.clone();
+                let reason = exit_reason_label(reason_kind.clone());
+                shared.shadow_stats.record_exit_reason(reason).await;
+                if exit_cfg.flatten_on_trigger {
+                    let _ = bus.publish(EngineEvent::Control(ControlCommand::Flatten));
+                }
+                if matches!(
+                    reason_kind,
+                    ExitReason::Reversal100ms | ExitReason::Reversal300ms
+                ) {
+                    let maker_cfg = shared.strategy_cfg.read().await.clone();
+                    let fail_cost_bps = shared.edge_model_cfg.read().await.fail_cost_bps;
+                    let same_market_first = shared
+                        .predator_cfg
+                        .read()
+                        .await
+                        .v52
+                        .reversal
+                        .same_market_opposite_first;
+                    let mut selected: Option<(OrderIntentV2, BookTop, String)> = None;
+
+                    if same_market_first {
+                        selected = reentry_candidate_for_market(
+                            &shared,
+                            &market_id,
+                            &side,
+                            size,
+                            maker_ttl_ms,
+                            maker_cfg.min_edge_bps,
+                            fail_cost_bps,
+                        )
+                        .await
+                        .map(|(order, book)| (order, book, market_id.clone()));
+                        if selected.is_none() {
+                            shared
+                                .shadow_stats
+                                .mark_blocked_with_reason("reversal_rebuild_same_market_no_edge")
+                                .await;
+                        }
+                    }
+
+                    if selected.is_none() {
+                        let other_markets = shared
+                            .symbol_to_markets
+                            .read()
+                            .await
+                            .get(symbol.as_str())
+                            .cloned()
+                            .unwrap_or_default();
+                        for other_market_id in other_markets {
+                            if same_market_first && other_market_id == market_id {
+                                continue;
+                            }
+                            if !same_market_first && other_market_id != market_id {
+                                if let Some((order, book)) = reentry_candidate_for_market(
+                                    &shared,
+                                    other_market_id.as_str(),
+                                    &side,
+                                    size,
+                                    maker_ttl_ms,
+                                    maker_cfg.min_edge_bps,
+                                    fail_cost_bps,
+                                )
+                                .await
+                                {
+                                    selected = Some((order, book, other_market_id));
+                                    break;
+                                }
+                                continue;
+                            }
+                            if let Some((order, book)) = reentry_candidate_for_market(
+                                &shared,
+                                other_market_id.as_str(),
+                                &side,
+                                size,
+                                maker_ttl_ms,
+                                maker_cfg.min_edge_bps,
+                                fail_cost_bps,
+                            )
+                            .await
+                            {
+                                selected = Some((order, book, other_market_id));
+                                break;
+                            }
+                        }
+                        if selected.is_none() {
+                            shared
+                                .shadow_stats
+                                .mark_blocked_with_reason("reversal_rebuild_cross_market_no_edge")
+                                .await;
+                        }
+                    }
+
+                    if let Some((reentry_order, book, target_market_id)) = selected {
+                        let reentry_fee_ref_bps = reentry_order.fee_rate_bps;
+                        let quote_intent = QuoteIntent {
+                            market_id: reentry_order.market_id.clone(),
+                            side: reentry_order.side.clone(),
+                            price: reentry_order.price,
+                            size: reentry_order.size,
+                            ttl_ms: reentry_order.ttl_ms,
+                        };
+                        publish_if_telemetry_subscribers(
+                            &bus,
+                            EngineEvent::QuoteIntent(quote_intent.clone()),
+                        );
+                        match execution.place_order_v2(reentry_order).await {
+                            Ok(ack) if ack.accepted => {
+                                shared.shadow_stats.mark_executed();
+                                let ack_event = OrderAck {
+                                    order_id: ack.order_id,
+                                    market_id: ack.market_id,
+                                    accepted: true,
+                                    ts_ms: ack.ts_ms,
+                                };
+                                publish_if_telemetry_subscribers(
+                                    &bus,
+                                    EngineEvent::OrderAck(ack_event.clone()),
+                                );
+                                if let Some(paper) = global_paper_runtime() {
+                                    let timeframe_class = shared
+                                        .market_to_timeframe
+                                        .read()
+                                        .await
+                                        .get(&target_market_id)
+                                        .cloned();
+                                    let timeframe = timeframe_class
+                                        .as_ref()
+                                        .map(ToString::to_string)
+                                        .unwrap_or_else(|| "unknown".to_string());
+                                    let stage = if let Some(tf) = timeframe_class {
+                                        if let Some(total_ms) = timeframe_total_ms(tf.clone()) {
+                                            let rem_ms =
+                                                (total_ms - now_ms.rem_euclid(total_ms)).max(0);
+                                            let rem_ratio =
+                                                (rem_ms as f64 / total_ms as f64).clamp(0.0, 1.0);
+                                            let predator_cfg = shared.predator_cfg.read().await.clone();
+                                            let phase =
+                                                classify_time_phase(rem_ratio, &predator_cfg.v52.time_phase);
+                                            stage_for_phase(phase, true)
+                                        } else {
+                                            Stage::Maturity
+                                        }
+                                    } else {
+                                        Stage::Maturity
+                                    };
+                                    let entry_price = match quote_intent.side {
+                                        OrderSide::BuyYes | OrderSide::SellYes => {
+                                            (book.bid_yes + book.ask_yes) * 0.5
+                                        }
+                                        OrderSide::BuyNo | OrderSide::SellNo => {
+                                            (book.bid_no + book.ask_no) * 0.5
+                                        }
+                                    };
+                                    paper
+                                        .register_order_intent(
+                                            &ack_event,
+                                            PaperIntentCtx {
+                                                market_id: target_market_id.clone(),
+                                                symbol: symbol.clone(),
+                                                timeframe,
+                                                stage,
+                                                direction: match quote_intent.side {
+                                                    OrderSide::BuyYes | OrderSide::SellNo => {
+                                                        Direction::Up
+                                                    }
+                                                    OrderSide::BuyNo | OrderSide::SellYes => {
+                                                        Direction::Down
+                                                    }
+                                                },
+                                                velocity_bps_per_sec: 0.0,
+                                                edge_bps: 0.0,
+                                                prob_fast: 0.5,
+                                                prob_settle: 0.5,
+                                                confidence: 0.0,
+                                                action: PaperAction::ReversalExit,
+                                                intent: ExecutionStyle::Maker,
+                                                requested_size_usdc: (quote_intent.price
+                                                    * quote_intent.size)
+                                                    .max(0.0),
+                                                requested_size_contracts: quote_intent.size,
+                                                entry_price,
+                                            },
+                                        )
+                                        .await;
+                                }
+                                shadow.register_order(
+                                    &ack_event,
+                                    quote_intent.clone(),
+                                    ExecutionStyle::Maker,
+                                    ((book.bid_yes + book.ask_yes) * 0.5).max(0.0),
+                                    -get_rebate_bps_cached(
+                                        &shared,
+                                        &target_market_id,
+                                        reentry_fee_ref_bps,
+                                    )
+                                    .await
+                                    .max(0.0),
+                                );
+                            }
+                            Ok(_) => {}
+                            Err(err) => {
+                                tracing::warn!(
+                                    market_id = %target_market_id,
+                                    symbol = %symbol,
+                                    error = %err,
+                                    "reversal maker re-entry failed"
+                                );
+                            }
+                        }
+                    }
+                }
+                tracing::info!(
+                    position_id = %position_id,
+                    market_id = %market_id,
+                    symbol = %symbol,
+                    reason,
+                    "predator exit lifecycle triggered"
+                );
+                break 'outer;
+            }
+        }
+
+        // Ensure stale lifecycle entries don't leak forever if no exit action is triggered.
+        if elapsed_ms >= 300_000 {
+            let _ = shared
+                .predator_exit_manager
+                .write()
+                .await
+                .close(&position_id);
+        }
+    });
+}
+
+async fn estimate_true_prob_for_side(
+    shared: &Arc<EngineShared>,
+    market_id: &str,
+    side: &OrderSide,
+) -> f64 {
+    let p_yes = shared
+        .latest_signals
+        .get(market_id)
+        .map(|sig| sig.value().signal.fair_yes.clamp(0.0, 1.0))
+        .unwrap_or(0.5);
+    match side {
+        OrderSide::BuyYes | OrderSide::SellNo => p_yes,
+        OrderSide::BuyNo | OrderSide::SellYes => 1.0 - p_yes,
+    }
+}
+
+pub(crate) async fn estimate_time_to_expiry_ms(
+    shared: &Arc<EngineShared>,
+    market_id: &str,
+    now_ms: i64,
+) -> i64 {
+    let timeframe = shared
+        .market_to_timeframe
+        .read()
+        .await
+        .get(market_id)
+        .cloned();
+    let frame_ms = match timeframe {
+        Some(TimeframeClass::Tf5m) => 5 * 60 * 1_000,
+        Some(TimeframeClass::Tf15m) => 15 * 60 * 1_000,
+        Some(TimeframeClass::Tf1h) => 60 * 60 * 1_000,
+        Some(TimeframeClass::Tf1d) => 24 * 60 * 60 * 1_000,
+        None => return i64::MAX,
+    } as i64;
+    let rem = frame_ms - now_ms.rem_euclid(frame_ms);
+    rem.max(0)
+}
+
+async fn estimate_unrealized_pnl_usdc(
+    shared: &Arc<EngineShared>,
+    market_id: &str,
+    side: &OrderSide,
+    entry_price: f64,
+    size: f64,
+) -> Option<f64> {
+    let book = shared.latest_books.read().await.get(market_id).cloned()?;
+    let mark = match side {
+        OrderSide::BuyYes | OrderSide::SellYes => book.bid_yes.max(0.0),
+        OrderSide::BuyNo | OrderSide::SellNo => book.bid_no.max(0.0),
+    };
+    let dir = match side {
+        OrderSide::BuyYes | OrderSide::BuyNo => 1.0,
+        OrderSide::SellYes | OrderSide::SellNo => -1.0,
+    };
+    Some((mark - entry_price) * size * dir)
+}
+
+pub(crate) fn spawn_shadow_outcome_task(
+    shared: Arc<EngineShared>,
+    bus: RingBus<EngineEvent>,
+    shot: ShadowShot,
+) {
+    spawn_detached("shadow_outcome", false, async move {
+        tokio::time::sleep(Duration::from_millis(shot.delay_ms)).await;
+        if !shared.shadow_stats.is_current_window_ts_ns(shot.t0_ns) {
+            metrics::counter!("shadow.outcome_window_mismatch").increment(1);
+            return;
+        }
+
+        let book = shared
+            .latest_books
+            .read()
+            .await
+            .get(&shot.market_id)
+            .cloned();
+        let latency_ms = ((now_ns() - shot.t0_ns).max(0) as f64) / 1_000_000.0;
+        shared.shadow_stats.push_shadow_fill_ms(latency_ms).await;
+        metrics::histogram!("latency.shadow_fill_ms").record(latency_ms);
+
+        let (
+            survived,
+            fillable,
+            slippage_bps,
+            queue_fill_prob,
+            attribution,
+            pnl_1s_bps,
+            pnl_5s_bps,
+            pnl_10s_bps,
+        ) = if let Some(book) = book {
+            let survived = evaluate_survival(&shot, &book);
+            let (fillable, slippage_bps, queue_fill_prob) =
+                evaluate_fillable(&shot, &book, latency_ms);
+            if fillable {
+                let p1 = pnl_after_horizon(&shared, &shot, Duration::from_secs(1)).await;
+                let p5 = pnl_after_horizon(&shared, &shot, Duration::from_secs(5)).await;
+                let p10 = pnl_after_horizon(&shared, &shot, Duration::from_secs(10)).await;
+                let attribution = classify_filled_outcome(shot.edge_net_bps, p10, slippage_bps);
+                (
+                    survived,
+                    true,
+                    slippage_bps,
+                    queue_fill_prob,
+                    attribution,
+                    p1,
+                    p5,
+                    p10,
+                )
+            } else {
+                let attribution = classify_unfilled_outcome(
+                    &book,
+                    latency_ms,
+                    shot.delay_ms,
+                    survived,
+                    queue_fill_prob,
+                );
+                (
+                    survived,
+                    false,
+                    slippage_bps,
+                    queue_fill_prob,
+                    attribution,
+                    None,
+                    None,
+                    None,
+                )
+            }
+        } else {
+            (
+                false,
+                false,
+                None,
+                0.0,
+                EdgeAttribution::SignalLag,
+                None,
+                None,
+                None,
+            )
+        };
+        let net_markout_1s_bps = net_markout(pnl_1s_bps, &shot);
+        let net_markout_5s_bps = net_markout(pnl_5s_bps, &shot);
+        let net_markout_10s_bps = net_markout(pnl_10s_bps, &shot);
+        let entry_notional_usdc = estimate_entry_notional_usdc(&shot);
+        let net_markout_10s_usdc = bps_to_usdc(net_markout_10s_bps, entry_notional_usdc);
+        let roi_notional_10s_bps = roi_bps_from_usdc(net_markout_10s_usdc, entry_notional_usdc);
+
+        let outcome = ShadowOutcome {
+            shot_id: shot.shot_id.clone(),
+            market_id: shot.market_id.clone(),
+            symbol: shot.symbol.clone(),
+            side: shot.side.clone(),
+            delay_ms: shot.delay_ms,
+            survived,
+            fillable,
+            execution_style: shot.execution_style.clone(),
+            slippage_bps,
+            pnl_1s_bps,
+            pnl_5s_bps,
+            pnl_10s_bps,
+            net_markout_1s_bps,
+            net_markout_5s_bps,
+            net_markout_10s_bps,
+            entry_notional_usdc,
+            net_markout_10s_usdc,
+            roi_notional_10s_bps,
+            queue_fill_prob,
+            is_stale_tick: false,
+            is_outlier: false,
+            robust_weight: 1.0,
+            attribution,
+            ts_ns: now_ns(),
+        };
+        if !shared.shadow_stats.is_current_window_ts_ns(outcome.ts_ns) {
+            metrics::counter!("shadow.outcome_window_mismatch").increment(1);
+            return;
+        }
+        shared.shadow_stats.push_outcome(outcome.clone()).await;
+        if shot.delay_ms == 10 {
+            let exit_cfg = shared.exit_cfg.read().await.clone();
+            if exit_cfg.enabled {
+                let true_prob = shared
+                    .latest_signals
+                    .get(&shot.market_id)
+                    .map(|sig| {
+                        let p_yes = sig.value().signal.fair_yes.clamp(0.0, 1.0);
+                        match shot.side {
+                            OrderSide::BuyYes | OrderSide::SellNo => p_yes,
+                            OrderSide::BuyNo | OrderSide::SellYes => 1.0 - p_yes,
+                        }
+                    })
+                    .unwrap_or(0.5);
+                let action = {
+                    let mut manager = shared.predator_exit_manager.write().await;
+                    manager.evaluate_market(
+                        &shot.market_id,
+                        MarketEvalInput {
+                            now_ms: Utc::now().timestamp_millis(),
+                            unrealized_pnl_usdc: outcome.net_markout_10s_usdc.unwrap_or(0.0),
+                            true_prob,
+                            time_to_expiry_ms: i64::MAX,
+                            pm_mid_yes: 0.0,
+                            entry_pm_mid_yes: 0.0,
+                            entry_fair_yes: 0.0,
+                        },
+                    )
+                };
+                if let Some(action) = action {
+                    let reason = exit_reason_label(action.reason);
+                    shared.shadow_stats.record_exit_reason(reason).await;
+                    if exit_cfg.flatten_on_trigger {
+                        let _ = bus.publish(EngineEvent::Control(ControlCommand::Flatten));
+                    }
+                }
+            }
+        }
+        update_toxic_state_from_outcome(&shared, &outcome).await;
+        if shot.delay_ms == 10 {
+            if let Some(pnl_usdc) = outcome.net_markout_10s_usdc {
+                let compounder_enabled = shared.predator_cfg.read().await.compounder.enabled;
+                if compounder_enabled {
+                    let (update, halt) = {
+                        let mut c = shared.predator_compounder.write().await;
+                        let update = c.on_markout(pnl_usdc);
+                        (update, c.halted())
+                    };
+                    shared
+                        .shadow_stats
+                        .set_predator_capital(update.clone(), halt)
+                        .await;
+                    publish_if_telemetry_subscribers(&bus, EngineEvent::CapitalUpdate(update));
+
+                    if halt {
+                        let live_armed = std::env::var("POLYEDGE_LIVE_ARMED")
+                            .map(|v| v.eq_ignore_ascii_case("true") || v == "1")
+                            .unwrap_or(false);
+                        if live_armed {
+                            shared.shadow_stats.record_issue("capital_halt").await;
+                            let _ = bus.publish(EngineEvent::Control(ControlCommand::Pause));
+                            let _ = bus.publish(EngineEvent::Control(ControlCommand::Flatten));
+                        }
+                    }
+                }
+            }
+            let eval = QuoteEval {
+                market_id: shot.market_id.clone(),
+                symbol: shot.symbol.clone(),
+                survival_10ms: if outcome.survived { 1.0 } else { 0.0 },
+                maker_markout_10s_bps: outcome.net_markout_10s_bps.unwrap_or(0.0),
+                adverse_flag: outcome.net_markout_10s_bps.unwrap_or(0.0) < 0.0,
+                ts_ns: now_ns(),
+            };
+            let ingest_seq = next_normalized_ingest_seq();
+            append_jsonl(
+                &dataset_path("normalized", "quote_eval.jsonl"),
+                &serde_json::json!({
+                    "ts_ms": Utc::now().timestamp_millis(),
+                    "source_seq": shot.t0_ns.max(0) as u64,
+                    "ingest_seq": ingest_seq,
+                    "eval": eval
+                }),
+            );
+            publish_if_telemetry_subscribers(&bus, EngineEvent::QuoteEval(eval));
+        }
+        publish_if_telemetry_subscribers(&bus, EngineEvent::ShadowOutcome(outcome));
+    });
+}
+
+fn spawn_survival_probe_task(
+    shared: Arc<EngineShared>,
+    market_id: String,
+    symbol: String,
+    side: OrderSide,
+    probe_px: f64,
+    delay_ms: u64,
+) {
+    spawn_detached("survival_probe", false, async move {
+        tokio::time::sleep(Duration::from_millis(delay_ms)).await;
+        let book = shared.latest_books.read().await.get(&market_id).cloned();
+        let survived = match book {
+            Some(ref b) => is_crossable(&side, probe_px, b),
+            None => false,
+        };
+        shared
+            .shadow_stats
+            .record_survival_probe(&symbol, delay_ms, survived)
+            .await;
+    });
+}
+
+async fn refresh_market_symbol_map(shared: &EngineShared) {
+    let discovery = MarketDiscovery::new(DiscoveryConfig {
+        symbols: (*shared.universe_symbols).clone(),
+        market_types: (*shared.universe_market_types).clone(),
+        timeframes: (*shared.universe_timeframes).clone(),
+        ..DiscoveryConfig::default()
+    });
+    match discovery.discover().await {
+        Ok(markets) => {
+            let mut market_map = HashMap::new();
+            let mut token_map = HashMap::new();
+            let mut timeframe_map = HashMap::new();
+            let mut symbol_to_markets = HashMap::<String, Vec<String>>::new();
+            for m in markets {
+                market_map.insert(m.market_id.clone(), m.symbol.clone());
+                symbol_to_markets
+                    .entry(m.symbol.clone())
+                    .or_default()
+                    .push(m.market_id.clone());
+                if let Some(tf) = m.timeframe.as_deref().and_then(parse_timeframe_class) {
+                    timeframe_map.insert(m.market_id.clone(), tf);
+                }
+                if let Some(t) = m.token_id_yes {
+                    token_map.insert(t, m.symbol.clone());
+                }
+                if let Some(t) = m.token_id_no {
+                    token_map.insert(t, m.symbol.clone());
+                }
+            }
+            for v in symbol_to_markets.values_mut() {
+                v.sort();
+                v.dedup();
+            }
+            {
+                let mut map = shared.market_to_symbol.write().await;
+                *map = market_map;
+            }
+            {
+                let mut map = shared.token_to_symbol.write().await;
+                *map = token_map;
+            }
+            {
+                let mut map = shared.market_to_timeframe.write().await;
+                *map = timeframe_map;
+            }
+            {
+                let mut map = shared.symbol_to_markets.write().await;
+                *map = symbol_to_markets;
+            }
+        }
+        Err(err) => {
+            tracing::warn!(?err, "market discovery refresh failed");
+        }
+    }
+}
+
+fn parse_timeframe_class(tf: &str) -> Option<TimeframeClass> {
+    match tf.trim().to_ascii_lowercase().as_str() {
+        "5m" | "tf5m" => Some(TimeframeClass::Tf5m),
+        "15m" | "tf15m" => Some(TimeframeClass::Tf15m),
+        "1h" | "tf1h" => Some(TimeframeClass::Tf1h),
+        "1d" | "tf1d" => Some(TimeframeClass::Tf1d),
+        _ => None,
+    }
+}
+
+async fn pick_market_symbol(shared: &EngineShared, book: &BookTop) -> Option<String> {
+    if let Some(v) = shared
+        .market_to_symbol
+        .read()
+        .await
+        .get(&book.market_id)
+        .cloned()
+    {
+        return Some(v);
+    }
+    let token_map = shared.token_to_symbol.read().await;
+    token_map
+        .get(&book.token_id_yes)
+        .cloned()
+        .or_else(|| token_map.get(&book.token_id_no).cloned())
+}
+
+async fn market_is_tracked(shared: &EngineShared, book: &BookTop) -> bool {
+    if shared
+        .market_to_symbol
+        .read()
+        .await
+        .contains_key(&book.market_id)
+    {
+        return true;
+    }
+    let token_map = shared.token_to_symbol.read().await;
+    token_map.contains_key(&book.token_id_yes) || token_map.contains_key(&book.token_id_no)
+}
+
diff --git a/crates/app_runner/src/execution_eval.rs b/crates/app_runner/src/execution_eval.rs
new file mode 100644
index 0000000..0abb339
--- /dev/null
+++ b/crates/app_runner/src/execution_eval.rs
@@ -0,0 +1,342 @@
+use std::time::{Duration, Instant};
+
+use core_types::{BookTop, EdgeAttribution, OrderIntentV2, OrderSide, QuoteIntent, ShadowShot};
+use reqwest::Client;
+use serde::Serialize;
+
+use crate::state::{EngineShared, FeeRateEntry};
+use crate::stats_utils::value_to_f64;
+use crate::strategy_policy::estimate_queue_fill_prob;
+use crate::spawn_detached;
+
+pub(super) async fn get_fee_rate_bps_cached(shared: &EngineShared, market_id: &str) -> f64 {
+    const DEFAULT_FEE_BPS: f64 = 2.0;
+    const TTL: Duration = Duration::from_secs(60);
+    const REFRESH_BACKOFF: Duration = Duration::from_secs(3);
+
+    let now = Instant::now();
+    let (cached_fee, needs_refresh) =
+        if let Some(entry) = shared.fee_cache.read().await.get(market_id).cloned() {
+            (
+                entry.fee_bps,
+                now.duration_since(entry.fetched_at) >= TTL || entry.fee_bps <= 0.0,
+            )
+        } else {
+            (DEFAULT_FEE_BPS, true)
+        };
+
+    if needs_refresh {
+        maybe_spawn_fee_refresh(shared, market_id, now, REFRESH_BACKOFF).await;
+    }
+
+    cached_fee
+}
+
+pub(super) async fn get_rebate_bps_cached(
+    shared: &EngineShared,
+    market_id: &str,
+    fee_bps: f64,
+) -> f64 {
+    const TTL: Duration = Duration::from_secs(120);
+    let now = Instant::now();
+    let maybe = shared.scoring_cache.read().await.get(market_id).cloned();
+    match maybe {
+        Some(entry) if now.duration_since(entry.fetched_at) <= TTL => {
+            entry.rebate_bps_est.clamp(0.0, fee_bps.max(0.0))
+        }
+        _ => 0.0,
+    }
+}
+
+pub(super) async fn maybe_spawn_fee_refresh(
+    shared: &EngineShared,
+    market_id: &str,
+    now: Instant,
+    refresh_backoff: Duration,
+) {
+    {
+        let inflight = shared.fee_refresh_inflight.read().await;
+        if let Some(last_attempt) = inflight.get(market_id) {
+            if now.duration_since(*last_attempt) < refresh_backoff {
+                return;
+            }
+        }
+    }
+
+    {
+        let mut inflight = shared.fee_refresh_inflight.write().await;
+        if let Some(last_attempt) = inflight.get(market_id) {
+            if now.duration_since(*last_attempt) < refresh_backoff {
+                return;
+            }
+        }
+        inflight.insert(market_id.to_string(), now);
+    }
+
+    let market = market_id.to_string();
+    let http = shared.http.clone();
+    let clob_endpoint = shared.clob_endpoint.clone();
+    let fee_cache = shared.fee_cache.clone();
+    let inflight = shared.fee_refresh_inflight.clone();
+    spawn_detached("fee_refresh", false, async move {
+        if let Some(fee_bps) = fetch_fee_rate_bps(&http, &clob_endpoint, &market).await {
+            fee_cache.write().await.insert(
+                market.clone(),
+                FeeRateEntry {
+                    fee_bps,
+                    fetched_at: Instant::now(),
+                },
+            );
+        }
+        inflight.write().await.remove(&market);
+    });
+}
+
+pub(super) async fn fetch_fee_rate_bps(
+    http: &Client,
+    clob_endpoint: &str,
+    market_id: &str,
+) -> Option<f64> {
+    let base = clob_endpoint.trim_end_matches('/');
+    let endpoints = [
+        format!("{base}/fee-rate?market_id={market_id}"),
+        format!("{base}/fee-rate?market={market_id}"),
+        format!("{base}/fee-rate?token_id={market_id}"),
+    ];
+
+    for url in endpoints {
+        let Ok(resp) = http.get(&url).send().await else {
+            continue;
+        };
+        let Ok(resp) = resp.error_for_status() else {
+            continue;
+        };
+        let Ok(v) = resp.json::<serde_json::Value>().await else {
+            continue;
+        };
+        let candidate = v
+            .get("fee_rate_bps")
+            .and_then(value_to_f64)
+            .or_else(|| v.get("feeRateBps").and_then(value_to_f64))
+            .or_else(|| v.get("makerFeeRateBps").and_then(value_to_f64))
+            .or_else(|| v.get("maker_fee_rate_bps").and_then(value_to_f64));
+        if candidate.is_some() {
+            return candidate;
+        }
+    }
+    None
+}
+
+pub(super) async fn pnl_after_horizon(
+    shared: &EngineShared,
+    shot: &ShadowShot,
+    horizon: Duration,
+) -> Option<f64> {
+    tokio::time::sleep(horizon).await;
+    let book = shared
+        .latest_books
+        .read()
+        .await
+        .get(&shot.market_id)
+        .cloned()?;
+    let mark = mid_for_side(&book, &shot.side);
+    if shot.intended_price <= 0.0 {
+        return None;
+    }
+    let pnl = match shot.side {
+        OrderSide::BuyYes | OrderSide::BuyNo => {
+            ((mark - shot.intended_price) / shot.intended_price) * 10_000.0
+        }
+        OrderSide::SellYes | OrderSide::SellNo => {
+            ((shot.intended_price - mark) / shot.intended_price) * 10_000.0
+        }
+    };
+    Some(pnl)
+}
+
+pub(super) fn evaluate_survival(shot: &ShadowShot, book: &BookTop) -> bool {
+    let probe_px = if shot.survival_probe_price > 0.0 {
+        shot.survival_probe_price
+    } else {
+        shot.intended_price
+    };
+    is_crossable(&shot.side, probe_px, book)
+}
+
+pub(super) fn is_crossable(side: &OrderSide, probe_px: f64, book: &BookTop) -> bool {
+    if probe_px <= 0.0 {
+        return false;
+    }
+    match side {
+        OrderSide::BuyYes => probe_px >= book.ask_yes,
+        OrderSide::SellYes => probe_px <= book.bid_yes,
+        OrderSide::BuyNo => probe_px >= book.ask_no,
+        OrderSide::SellNo => probe_px <= book.bid_no,
+    }
+}
+
+pub(super) fn evaluate_fillable(
+    shot: &ShadowShot,
+    book: &BookTop,
+    latency_ms: f64,
+) -> (bool, Option<f64>, f64) {
+    let probe_px = if shot.survival_probe_price > 0.0 {
+        shot.survival_probe_price
+    } else {
+        shot.intended_price
+    };
+    let (crossable, fill_px) = match shot.side {
+        OrderSide::BuyYes => (probe_px >= book.ask_yes, book.ask_yes),
+        OrderSide::SellYes => (probe_px <= book.bid_yes, book.bid_yes),
+        OrderSide::BuyNo => (probe_px >= book.ask_no, book.ask_no),
+        OrderSide::SellNo => (probe_px <= book.bid_no, book.bid_no),
+    };
+    if !crossable || probe_px <= 0.0 {
+        return (false, None, 0.0);
+    }
+    let queue_fill_prob = estimate_queue_fill_prob(shot, book, latency_ms);
+    if queue_fill_prob < 0.45 {
+        return (false, None, queue_fill_prob);
+    }
+    let mut slippage = match shot.side {
+        OrderSide::BuyYes | OrderSide::BuyNo => ((fill_px - probe_px) / probe_px) * 10_000.0,
+        OrderSide::SellYes | OrderSide::SellNo => ((probe_px - fill_px) / probe_px) * 10_000.0,
+    };
+    slippage += (1.0 - queue_fill_prob) * 8.0;
+    (true, Some(slippage), queue_fill_prob)
+}
+
+pub(super) fn classify_unfilled_outcome(
+    book: &BookTop,
+    latency_ms: f64,
+    delay_ms: u64,
+    survived: bool,
+    queue_fill_prob: f64,
+) -> EdgeAttribution {
+    let spread = (book.ask_yes - book.bid_yes).max(0.0);
+    if delay_ms >= 400 {
+        return EdgeAttribution::StaleQuote;
+    }
+    if !survived {
+        return EdgeAttribution::BookMoved;
+    }
+    if book.ask_yes <= 0.0 || book.bid_yes <= 0.0 {
+        return EdgeAttribution::LiquidityThin;
+    }
+    if spread > 0.05 {
+        return EdgeAttribution::SpreadTooWide;
+    }
+    if queue_fill_prob < 0.45 {
+        return EdgeAttribution::LatencyTail;
+    }
+    if latency_ms > 100.0 {
+        return EdgeAttribution::LatencyTail;
+    }
+    EdgeAttribution::BookMoved
+}
+
+pub(super) fn classify_filled_outcome(
+    edge_net_bps: f64,
+    pnl_10s_bps: Option<f64>,
+    slippage_bps: Option<f64>,
+) -> EdgeAttribution {
+    if edge_net_bps < 0.0 {
+        return EdgeAttribution::FeeOverrun;
+    }
+    if slippage_bps.unwrap_or(0.0) > edge_net_bps.abs() {
+        return EdgeAttribution::SignalLag;
+    }
+    if pnl_10s_bps.unwrap_or(0.0) < 0.0 {
+        return EdgeAttribution::AdverseSelection;
+    }
+    EdgeAttribution::Unknown
+}
+
+pub(super) fn mid_for_side(book: &BookTop, side: &OrderSide) -> f64 {
+    match side {
+        OrderSide::BuyYes | OrderSide::SellYes => (book.bid_yes + book.ask_yes) * 0.5,
+        OrderSide::BuyNo | OrderSide::SellNo => (book.bid_no + book.ask_no) * 0.5,
+    }
+}
+
+pub(super) fn aggressive_price_for_side(book: &BookTop, side: &OrderSide) -> f64 {
+    match side {
+        OrderSide::BuyYes => book.ask_yes,
+        OrderSide::SellYes => book.bid_yes,
+        OrderSide::BuyNo => book.ask_no,
+        OrderSide::SellNo => book.bid_no,
+    }
+}
+
+#[derive(Serialize)]
+pub(super) struct PrebuiltOrderPayload<'a> {
+    market_id: &'a str,
+    token_id: Option<&'a str>,
+    side: &'a str,
+    price: f64,
+    size: f64,
+    ttl_ms: u64,
+    style: &'a str,
+    tif: &'a str,
+    max_slippage_bps: f64,
+    fee_rate_bps: f64,
+    expected_edge_net_bps: f64,
+    hold_to_resolution: bool,
+}
+
+pub(super) fn prebuild_order_payload(intent: &OrderIntentV2) -> Option<Vec<u8>> {
+    let side = intent.side.to_string();
+    let style = intent.style.to_string();
+    let tif = intent.tif.to_string();
+    let payload = PrebuiltOrderPayload {
+        market_id: intent.market_id.as_str(),
+        token_id: intent.token_id.as_deref(),
+        side: side.as_str(),
+        price: intent.price,
+        size: intent.size,
+        ttl_ms: intent.ttl_ms,
+        style: style.as_str(),
+        tif: tif.as_str(),
+        max_slippage_bps: intent.max_slippage_bps,
+        fee_rate_bps: intent.fee_rate_bps,
+        expected_edge_net_bps: intent.expected_edge_net_bps,
+        hold_to_resolution: intent.hold_to_resolution,
+    };
+    serde_json::to_vec(&payload).ok()
+}
+
+pub(super) fn spread_for_side(book: &BookTop, side: &OrderSide) -> f64 {
+    match side {
+        OrderSide::BuyYes | OrderSide::SellYes => (book.ask_yes - book.bid_yes).max(0.0),
+        OrderSide::BuyNo | OrderSide::SellNo => (book.ask_no - book.bid_no).max(0.0),
+    }
+}
+
+pub(super) fn fair_for_side(fair_yes: f64, side: &OrderSide) -> f64 {
+    match side {
+        OrderSide::BuyYes | OrderSide::SellYes => fair_yes,
+        OrderSide::BuyNo | OrderSide::SellNo => (1.0 - fair_yes).clamp(0.001, 0.999),
+    }
+}
+
+pub(super) fn edge_gross_bps_for_side(fair_yes: f64, side: &OrderSide, entry_price: f64) -> f64 {
+    let fair = fair_for_side(fair_yes, side);
+    let px = entry_price.max(1e-6);
+    match side {
+        OrderSide::BuyYes | OrderSide::BuyNo => ((fair - px) / px) * 10_000.0,
+        OrderSide::SellYes | OrderSide::SellNo => ((px - fair) / px) * 10_000.0,
+    }
+}
+
+pub(super) fn edge_for_intent(fair_yes: f64, intent: &QuoteIntent) -> f64 {
+    let px = intent.price.max(1e-6);
+    let fair = match intent.side {
+        OrderSide::BuyYes | OrderSide::SellYes => fair_yes,
+        OrderSide::BuyNo | OrderSide::SellNo => (1.0 - fair_yes).clamp(0.001, 0.999),
+    };
+    match intent.side {
+        // Expected edge vs. intended entry price in bps of entry.
+        OrderSide::BuyYes | OrderSide::BuyNo => ((fair - px) / px) * 10_000.0,
+        OrderSide::SellYes | OrderSide::SellNo => ((px - fair) / px) * 10_000.0,
+    }
+}
diff --git a/crates/app_runner/src/feed_runtime.rs b/crates/app_runner/src/feed_runtime.rs
new file mode 100644
index 0000000..96b4d18
--- /dev/null
+++ b/crates/app_runner/src/feed_runtime.rs
@@ -0,0 +1,899 @@
+use std::collections::HashMap;
+use std::sync::Arc;
+use std::time::{Duration, Instant};
+
+use anyhow::Result;
+use chrono::Utc;
+use core_types::{EngineEvent, MarketFeed, RefPriceFeed, RefTick, SourceHealth};
+use feed_polymarket::PolymarketFeed;
+use feed_reference::MultiSourceRefFeed;
+use futures::StreamExt;
+use infra_bus::RingBus;
+use smol_str::SmolStr;
+use tokio::sync::{mpsc, RwLock};
+
+use crate::fusion_engine::{
+    is_anchor_ref_source, is_ref_tick_duplicate, max_book_top_diff_bps, ref_event_ts_ms,
+    should_arm_ws_primary_fallback, should_enforce_udp_share_cap, should_log_ref_tick,
+    should_replace_anchor_tick, should_replace_ref_tick, udp_downweight_keep_every,
+    udp_min_freshness_score, upsert_latest_tick_slot, ws_primary_fallback_gap_ns,
+};
+use crate::report_io::{append_jsonl_line, dataset_path, sha256_hex};
+use crate::state::{EngineShared, FusionConfig, ShadowStats, SourceHealthConfig, StrategyIngress, StrategyIngressMsg};
+use crate::stats_utils::{now_ns, value_to_f64};
+use crate::{publish_if_telemetry_subscribers, spawn_detached};
+
+pub(super) fn spawn_reference_feed(
+    bus: RingBus<EngineEvent>,
+    stats: Arc<ShadowStats>,
+    symbols: Vec<String>,
+    fusion_cfg: Arc<RwLock<FusionConfig>>,
+    shared: Arc<EngineShared>,
+    strategy_tx: mpsc::Sender<StrategyIngressMsg>,
+) {
+    #[derive(Clone, Copy)]
+    enum RefLane {
+        Direct,
+        Udp,
+    }
+    const TS_INVERSION_TOLERANCE_MS: i64 = 250;
+    const TS_BACKJUMP_RESET_MS: i64 = 5_000;
+    spawn_detached("reference_feed_orchestrator", true, async move {
+        let symbols = if symbols.is_empty() {
+            vec!["BTCUSDT".to_string()]
+        } else {
+            symbols
+        };
+        let ref_merge_queue_cap = std::env::var("POLYEDGE_REF_MERGE_QUEUE_CAP")
+            .ok()
+            .and_then(|v| v.parse::<usize>().ok())
+            .unwrap_or(4_096)
+            .clamp(1_024, 32_768);
+        let ref_merge_drop_on_full = std::env::var("POLYEDGE_REF_MERGE_DROP_ON_FULL")
+            .ok()
+            .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+            .unwrap_or(true);
+        let strategy_ingress_drop_on_full = std::env::var("POLYEDGE_STRATEGY_INGRESS_DROP_ON_FULL")
+            .ok()
+            .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+            .unwrap_or(true);
+        let strategy_ref_ingress_enabled = std::env::var("POLYEDGE_STRATEGY_REF_INGRESS_ENABLED")
+            .ok()
+            .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+            .unwrap_or(false);
+        let (tx, mut rx) = mpsc::channel::<(RefLane, Result<RefTick>)>(ref_merge_queue_cap);
+
+        let tx_direct = tx.clone();
+        let symbols_direct = symbols.clone();
+        spawn_detached("reference_feed_direct_lane", true, async move {
+            loop {
+                let feed = MultiSourceRefFeed::new(Duration::from_millis(50));
+                match feed.stream_ticks(symbols_direct.clone()).await {
+                    Ok(mut stream) => {
+                        while let Some(item) = stream.next().await {
+                            let lane_item = (RefLane::Direct, item);
+                            if ref_merge_drop_on_full {
+                                match tx_direct.try_send(lane_item) {
+                                    Ok(()) => {}
+                                    Err(mpsc::error::TrySendError::Full(_)) => {
+                                        metrics::counter!("fusion.ref_merge_drop").increment(1);
+                                    }
+                                    Err(mpsc::error::TrySendError::Closed(_)) => return,
+                                }
+                            } else if tx_direct.send(lane_item).await.is_err() {
+                                return;
+                            }
+                        }
+                    }
+                    Err(err) => tracing::warn!(?err, "direct reference feed failed to start"),
+                }
+                tokio::time::sleep(Duration::from_millis(500)).await;
+            }
+        });
+
+        let tx_udp = tx.clone();
+        let symbols_udp = symbols.clone();
+        let fusion_cfg_udp = fusion_cfg.clone();
+        spawn_detached("reference_feed_udp_lane", true, async move {
+            loop {
+                let cfg = fusion_cfg_udp.read().await.clone();
+                if !cfg.enable_udp || cfg.mode == "direct_only" {
+                    tokio::time::sleep(Duration::from_millis(500)).await;
+                    continue;
+                }
+                let feed = feed_udp::UdpBinanceFeed::new(cfg.udp_port);
+                match feed.stream_ticks(symbols_udp.clone()).await {
+                    Ok(mut stream) => {
+                        while let Some(item) = stream.next().await {
+                            let lane_item = (RefLane::Udp, item);
+                            if ref_merge_drop_on_full {
+                                match tx_udp.try_send(lane_item) {
+                                    Ok(()) => {}
+                                    Err(mpsc::error::TrySendError::Full(_)) => {
+                                        metrics::counter!("fusion.ref_merge_drop").increment(1);
+                                    }
+                                    Err(mpsc::error::TrySendError::Closed(_)) => return,
+                                }
+                            } else if tx_udp.send(lane_item).await.is_err() {
+                                return;
+                            }
+                        }
+                    }
+                    Err(err) => tracing::warn!(?err, "udp reference feed failed to start"),
+                }
+                tokio::time::sleep(Duration::from_millis(250)).await;
+            }
+        });
+        drop(tx);
+
+        let mut ingest_seq: u64 = 0;
+        let mut last_source_ts_by_stream: HashMap<String, i64> = HashMap::new();
+        let mut last_published_by_symbol: HashMap<String, (i64, f64)> = HashMap::new();
+        let mut source_runtime: HashMap<SmolStr, SourceRuntimeStats> = HashMap::new();
+        let mut latest_price_by_symbol_source: HashMap<String, HashMap<SmolStr, f64>> =
+            HashMap::new();
+        let mut latest_ws_recv_ns_global: i64 = 0;
+        let mut ws_primary_fallback_until_ns: i64 = 0;
+        let mut ws_primary_ready_seen = false;
+        let mut ws_cap_breach_started_ns: i64 = 0;
+        let mut accepted_fast_mix_by_symbol: HashMap<String, (u64, u64)> = HashMap::new();
+        let mut accepted_fast_mix_total: (u64, u64) = (0, 0);
+        let mut fusion = fusion_cfg.read().await.clone();
+        let mut last_fusion_mode = fusion.mode.clone();
+        let fusion_cfg_refresh_interval_ms = std::env::var("POLYEDGE_FUSION_CFG_REFRESH_MS")
+            .ok()
+            .and_then(|v| v.parse::<u64>().ok())
+            .unwrap_or(200)
+            .clamp(50, 2_000);
+        let mut fusion_cfg_refresh_at = Instant::now();
+        let mut source_health_cfg = shared.source_health_cfg.read().await.clone();
+        let mut source_health_cfg_refresh_at = Instant::now();
+        let ref_tick_bus_enabled = std::env::var("POLYEDGE_REF_TICK_BUS_ENABLED")
+            .ok()
+            .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+            .unwrap_or(false);
+
+        while let Some((lane, item)) = rx.recv().await {
+            match item {
+                Ok(tick) => {
+                    if fusion_cfg_refresh_at.elapsed()
+                        >= Duration::from_millis(fusion_cfg_refresh_interval_ms)
+                    {
+                        let next_fusion = fusion_cfg.read().await.clone();
+                        if next_fusion.mode != last_fusion_mode {
+                            accepted_fast_mix_by_symbol.clear();
+                            accepted_fast_mix_total = (0, 0);
+                            ws_primary_ready_seen = false;
+                            ws_primary_fallback_until_ns = 0;
+                            ws_cap_breach_started_ns = 0;
+                            stats.record_issue("fusion_mode_switch_fast_cache_reset").await;
+                            last_fusion_mode = next_fusion.mode.clone();
+                        }
+                        fusion = next_fusion;
+                        fusion_cfg_refresh_at = Instant::now();
+                    }
+                    let is_anchor = is_anchor_ref_source(tick.source.as_str());
+                    if fusion.mode == "udp_only" && !matches!(lane, RefLane::Udp) && !is_anchor {
+                        continue;
+                    }
+                    if fusion.mode == "direct_only"
+                        && !matches!(lane, RefLane::Direct)
+                        && !is_anchor
+                    {
+                        continue;
+                    }
+                    ingest_seq = ingest_seq.saturating_add(1);
+                    let source_ts = tick.event_ts_exchange_ms.max(tick.event_ts_ms);
+                    let source_seq = source_ts.max(0) as u64;
+                    let valid = !tick.symbol.is_empty()
+                        && tick.price.is_finite()
+                        && tick.price > 0.0
+                        && source_seq > 0;
+                    stats.mark_data_validity(valid);
+                    let stream_key = format!("{}:{}", tick.source, tick.symbol);
+                    if let Some(prev) = last_source_ts_by_stream.get(&stream_key).copied() {
+                        if source_ts + TS_INVERSION_TOLERANCE_MS < prev {
+                            let back_jump_ms = prev.saturating_sub(source_ts);
+                            if back_jump_ms > TS_BACKJUMP_RESET_MS {
+                                stats.record_issue("ref_ts_backjump_reset").await;
+                            } else {
+                                stats.mark_ts_inversion();
+                            }
+                        }
+                    }
+                    last_source_ts_by_stream.insert(stream_key, source_ts);
+                    if let Some((prev_ts, prev_px)) = last_published_by_symbol.get(&tick.symbol) {
+                        if is_ref_tick_duplicate(source_ts, tick.price, *prev_ts, *prev_px, &fusion)
+                        {
+                            stats.mark_ref_dedupe_dropped();
+                            continue;
+                        }
+                    }
+                    last_published_by_symbol.insert(tick.symbol.clone(), (source_ts, tick.price));
+                    if source_health_cfg_refresh_at.elapsed() >= Duration::from_millis(500) {
+                        source_health_cfg = shared.source_health_cfg.read().await.clone();
+                        source_health_cfg_refresh_at = Instant::now();
+                    }
+                    let source_key = tick.source.clone();
+                    let symbol_key = tick.symbol.clone();
+                    let recv_ts_ms = tick.recv_ts_ms;
+                    if source_key == "binance_ws" {
+                        let recv_ns = if tick.recv_ts_local_ns > 0 {
+                            tick.recv_ts_local_ns
+                        } else {
+                            now_ns()
+                        };
+                        latest_ws_recv_ns_global = latest_ws_recv_ns_global.max(recv_ns);
+                    }
+                    let latency_ms = recv_ts_ms.saturating_sub(source_ts).max(0) as f64;
+                    let runtime = source_runtime.entry(source_key.clone()).or_default();
+                    runtime.sample_count = runtime.sample_count.saturating_add(1);
+                    runtime.latency_sum_ms += latency_ms;
+                    runtime.latency_sq_sum_ms += latency_ms * latency_ms;
+                    if runtime.last_event_ts_ms > 0
+                        && source_ts + TS_INVERSION_TOLERANCE_MS < runtime.last_event_ts_ms
+                    {
+                        runtime.out_of_order_count = runtime.out_of_order_count.saturating_add(1);
+                    }
+                    if runtime.last_recv_ts_ms > 0
+                        && recv_ts_ms.saturating_sub(runtime.last_recv_ts_ms)
+                            > source_health_cfg.gap_window_ms
+                    {
+                        runtime.gap_count = runtime.gap_count.saturating_add(1);
+                    }
+                    runtime.last_event_ts_ms = source_ts;
+                    runtime.last_recv_ts_ms = recv_ts_ms;
+
+                    {
+                        let per_symbol = latest_price_by_symbol_source
+                            .entry(symbol_key.clone())
+                            .or_default();
+                        per_symbol.insert(source_key.clone(), tick.price);
+                        if per_symbol.len() >= 2 {
+                            let values = per_symbol.values().copied().collect::<Vec<_>>();
+                            if let Some(median) = median_price(&values) {
+                                if median.is_finite() && median > 0.0 {
+                                    let dev_bps = ((tick.price - median).abs() / median * 10_000.0)
+                                        .clamp(0.0, 10_000.0);
+                                    if runtime.sample_count <= 1 {
+                                        runtime.deviation_ema_bps = dev_bps;
+                                    } else {
+                                        runtime.deviation_ema_bps =
+                                            (runtime.deviation_ema_bps * 0.90) + (dev_bps * 0.10);
+                                    }
+                                }
+                            }
+                        }
+                    }
+                    let source_health = build_source_health_snapshot(
+                        source_key.as_str(),
+                        runtime,
+                        &source_health_cfg,
+                        Utc::now().timestamp_millis(),
+                    );
+                    if runtime.sample_count % 8 == 0 {
+                        let mut map = shared.source_health_latest.write().await;
+                        map.insert(source_key.to_string(), source_health.clone());
+                    }
+                    if tick.source == "binance_udp" {
+                        let (udp_samples, ws_samples) = accepted_fast_mix_total;
+                        let fast_total = udp_samples.saturating_add(ws_samples);
+                        let udp_share = if fast_total > 0 {
+                            udp_samples as f64 / fast_total as f64
+                        } else {
+                            0.0
+                        };
+                        let (sym_udp_samples, sym_ws_samples) = accepted_fast_mix_by_symbol
+                            .get(tick.symbol.as_str())
+                            .copied()
+                            .unwrap_or((0, 0));
+                        let sym_fast_total = sym_udp_samples.saturating_add(sym_ws_samples);
+                        let udp_share_symbol = if sym_fast_total > 0 {
+                            sym_udp_samples as f64 / sym_fast_total as f64
+                        } else {
+                            udp_share
+                        };
+                        let effective_udp_share = if sym_fast_total >= 32 {
+                            udp_share_symbol
+                        } else {
+                            udp_share
+                        };
+                        let jitter_high =
+                            source_health.jitter_ms > fusion.jitter_threshold_ms.max(1.0);
+                        let freshness_low =
+                            source_health.freshness_score < udp_min_freshness_score();
+                        let now_recv_ns = if tick.recv_ts_local_ns > 0 {
+                            tick.recv_ts_local_ns
+                        } else {
+                            now_ns()
+                        };
+                        let ws_gap_ns = if latest_ws_recv_ns_global > 0 {
+                            now_recv_ns.saturating_sub(latest_ws_recv_ns_global)
+                        } else {
+                            i64::MAX
+                        };
+                        let ws_cap_ready = ws_gap_ns <= ws_primary_fallback_gap_ns();
+                        if ws_cap_ready {
+                            ws_primary_ready_seen = true;
+                            ws_cap_breach_started_ns = 0;
+                        } else if ws_primary_ready_seen && ws_cap_breach_started_ns == 0 {
+                            ws_cap_breach_started_ns = now_recv_ns;
+                        }
+                        let ws_breach_persisted = ws_cap_breach_started_ns > 0
+                            && now_recv_ns.saturating_sub(ws_cap_breach_started_ns)
+                                >= (fusion.fallback_arm_duration_ms as i64)
+                                    .saturating_mul(1_000_000);
+                        let fallback_active_now = fusion.mode == "websocket_primary"
+                            && now_recv_ns < ws_primary_fallback_until_ns;
+                        if should_arm_ws_primary_fallback(
+                            fusion.mode.as_str(),
+                            ws_cap_ready,
+                            ws_breach_persisted,
+                            fallback_active_now,
+                        ) {
+                            let cooldown_ns =
+                                (fusion.fallback_cooldown_sec as i64).saturating_mul(1_000_000_000);
+                            ws_primary_fallback_until_ns =
+                                now_recv_ns.saturating_add(cooldown_ns.max(0));
+                            metrics::counter!("fusion.ws_primary_fallback_arm").increment(1);
+                            stats.mark_fallback_trigger_reason("ws_gap_persisted").await;
+                        }
+
+                        let fallback_active = fusion.mode == "websocket_primary"
+                            && now_recv_ns < ws_primary_fallback_until_ns;
+                        if fallback_active {
+                            metrics::counter!("fusion.ws_primary_fallback_active").increment(1);
+                        }
+                        let fallback_state = if fallback_active {
+                            if ws_cap_ready {
+                                "cooldown"
+                            } else {
+                                "udp_fallback"
+                            }
+                        } else if ws_cap_breach_started_ns > 0 {
+                            "armed"
+                        } else {
+                            "ws_primary"
+                        };
+                        stats.set_fallback_state(fallback_state);
+
+                        let target_share = fusion.udp_share_cap.clamp(0.05, 0.95);
+                        let projected_udp_share = if fast_total > 0 {
+                            (udp_samples.saturating_add(1) as f64)
+                                / (fast_total.saturating_add(1) as f64)
+                        } else {
+                            1.0
+                        };
+                        let projected_share_violation = projected_udp_share > target_share;
+                        // In websocket_primary / active_active we hard-enforce the UDP share cap
+                        // outside explicit fallback windows. If WS is unhealthy, fallback state
+                        // should arm and take over; until then we still constrain UDP dominance.
+                        let enforce_ws_primary = should_enforce_udp_share_cap(
+                            fusion.mode.as_str(),
+                            fallback_active,
+                            projected_share_violation,
+                        );
+
+                        if enforce_ws_primary {
+                            metrics::counter!("fusion.udp_downweight_drop").increment(1);
+                            metrics::counter!("fusion.udp_share_cap_drop").increment(1);
+                            stats.mark_share_cap_drop();
+                            continue;
+                        }
+
+                        if ws_cap_ready && (jitter_high || freshness_low) {
+                            let share_ratio = (effective_udp_share / target_share).max(1.0);
+                            let base_keep_every = udp_downweight_keep_every().max(2);
+                            let dynamic_keep = share_ratio.ceil() as usize;
+                            let jitter_boost = if jitter_high { 2 } else { 1 };
+                            let freshness_boost = if freshness_low { 2 } else { 1 };
+                            let keep_every = base_keep_every
+                                .max(dynamic_keep)
+                                .max(base_keep_every.saturating_mul(jitter_boost))
+                                .max(base_keep_every.saturating_mul(freshness_boost))
+                                .clamp(2, 16);
+                            if (ingest_seq % keep_every as u64) != 0 {
+                                metrics::counter!("fusion.udp_downweight_drop").increment(1);
+                                if jitter_high {
+                                    metrics::counter!("fusion.udp_jitter_drop").increment(1);
+                                }
+                                if freshness_low {
+                                    metrics::counter!("fusion.udp_freshness_drop").increment(1);
+                                }
+                                continue;
+                            }
+                        }
+                    }
+                    if should_log_ref_tick(ingest_seq) {
+                        let tick_json =
+                            serde_json::to_string(&tick).unwrap_or_else(|_| "{}".to_string());
+                        let line = format!(
+                            "{{\"ts_ms\":{},\"source_seq\":{},\"ingest_seq\":{},\"valid\":{},\"tick\":{}}}",
+                            Utc::now().timestamp_millis(),
+                            source_seq,
+                            ingest_seq,
+                            valid,
+                            tick_json
+                        );
+                        append_jsonl_line(&dataset_path("raw", "ref_ticks.jsonl"), line);
+                    }
+                    if !valid {
+                        stats.record_issue("invalid_ref_tick").await;
+                        continue;
+                    }
+                    stats.mark_ref_tick(tick.source.as_str(), tick.recv_ts_ms);
+                    if source_key == "binance_udp" || source_key == "binance_ws" {
+                        let entry = accepted_fast_mix_by_symbol
+                            .entry(symbol_key.clone())
+                            .or_default();
+                        if source_key == "binance_udp" {
+                            entry.0 = entry.0.saturating_add(1);
+                            accepted_fast_mix_total.0 = accepted_fast_mix_total.0.saturating_add(1);
+                        } else {
+                            entry.1 = entry.1.saturating_add(1);
+                            accepted_fast_mix_total.1 = accepted_fast_mix_total.1.saturating_add(1);
+                        }
+                        let total = entry.0.saturating_add(entry.1);
+                        if total > 100_000 {
+                            entry.0 /= 2;
+                            entry.1 /= 2;
+                        }
+                        let total_global = accepted_fast_mix_total
+                            .0
+                            .saturating_add(accepted_fast_mix_total.1);
+                        if total_global > 1_000_000 {
+                            accepted_fast_mix_total.0 /= 2;
+                            accepted_fast_mix_total.1 /= 2;
+                        }
+                    }
+
+                    if is_anchor {
+                        let _ = upsert_latest_tick_slot(
+                            &shared.latest_anchor_ticks,
+                            tick.clone(),
+                            should_replace_anchor_tick,
+                        );
+                    } else if let Some(delta_ns) = upsert_latest_tick_slot(
+                        &shared.latest_fast_ticks,
+                        tick.clone(),
+                        should_replace_ref_tick,
+                    ) {
+                        metrics::histogram!("fusion.arrive_delta_ns").record(delta_ns as f64);
+                    }
+
+                    if strategy_ref_ingress_enabled {
+                        let ingress = StrategyIngressMsg {
+                            enqueued_ns: now_ns(),
+                            payload: StrategyIngress::RefTick(tick.clone()),
+                        };
+                        if strategy_ingress_drop_on_full {
+                            match strategy_tx.try_send(ingress) {
+                                Ok(()) => {}
+                                Err(mpsc::error::TrySendError::Full(_)) => {
+                                    metrics::counter!("strategy.ingress_ref_drop").increment(1);
+                                }
+                                Err(mpsc::error::TrySendError::Closed(_)) => break,
+                            }
+                        } else if strategy_tx.send(ingress).await.is_err() {
+                            break;
+                        }
+                    }
+
+                    if ref_tick_bus_enabled {
+                        publish_if_telemetry_subscribers(&bus, EngineEvent::RefTick(tick));
+                    }
+                }
+                Err(err) => {
+                    tracing::warn!(?err, "reference feed event error");
+                }
+            }
+        }
+    });
+}
+
+pub(super) fn spawn_settlement_feed(shared: Arc<EngineShared>) {
+    spawn_detached("settlement_feed_orchestrator", true, async move {
+        loop {
+            let cfg = shared.settlement_cfg.read().await.clone();
+            if !cfg.enabled || cfg.endpoint.trim().is_empty() {
+                tokio::time::sleep(Duration::from_millis(1_000)).await;
+                continue;
+            }
+
+            let req = shared
+                .http
+                .get(cfg.endpoint.clone())
+                .timeout(Duration::from_millis(cfg.timeout_ms.max(100)));
+            match req.send().await {
+                Ok(resp) => match resp.json::<serde_json::Value>().await {
+                    Ok(value) => {
+                        let mut updates = HashMap::<String, f64>::new();
+                        let maybe_object = value.as_object();
+                        if let Some(obj) = maybe_object {
+                            for symbol in &cfg.symbols {
+                                for key in settlement_symbol_keys(symbol) {
+                                    if let Some(price) = obj.get(&key).and_then(value_to_f64) {
+                                        if price.is_finite() && price > 0.0 {
+                                            updates.insert(symbol.clone(), price);
+                                            break;
+                                        }
+                                    }
+                                }
+                            }
+                        }
+                        if !updates.is_empty() {
+                            let mut map = shared.settlement_prices.write().await;
+                            for (k, v) in updates {
+                                map.insert(k, v);
+                            }
+                        }
+                    }
+                    Err(err) => {
+                        tracing::warn!(?err, "settlement feed json decode failed");
+                        metrics::counter!("settlement.feed.decode_error").increment(1);
+                    }
+                },
+                Err(err) => {
+                    tracing::warn!(?err, "settlement feed poll failed");
+                    metrics::counter!("settlement.feed.poll_error").increment(1);
+                }
+            }
+
+            tokio::time::sleep(Duration::from_millis(cfg.poll_interval_ms.max(250))).await;
+        }
+    });
+}
+
+pub(super) fn settlement_symbol_keys(symbol: &str) -> Vec<String> {
+    let mut keys = Vec::with_capacity(4);
+    let normalized = symbol.trim().to_ascii_uppercase();
+    keys.push(normalized.clone());
+    if let Some(base) = normalized.strip_suffix("USDT") {
+        keys.push(base.to_string());
+        keys.push(format!("{base}USD"));
+    }
+    keys.push(normalized.replace('_', ""));
+    keys
+}
+
+pub(super) async fn settlement_prob_yes_for_symbol(
+    shared: &Arc<EngineShared>,
+    symbol: &str,
+    p_fast_yes: f64,
+    now_ms: i64,
+) -> Option<f64> {
+    let settle_price = {
+        let anchor = shared
+            .latest_anchor_ticks
+            .get(symbol)
+            .map(|tick| tick.value().clone())
+            .filter(|tick| {
+                is_anchor_ref_source(tick.source.as_str())
+                    && now_ms.saturating_sub(ref_event_ts_ms(tick)) <= 5_000
+            })
+            .map(|tick| tick.price);
+        if let Some(v) = anchor {
+            Some(v)
+        } else {
+            shared.settlement_prices.read().await.get(symbol).copied()
+        }
+    }?;
+    if settle_price <= 0.0 {
+        return None;
+    }
+    let fast_price = shared.latest_fast_ticks.get(symbol).map(|t| t.price)?;
+    if fast_price <= 0.0 {
+        return None;
+    }
+    Some(blend_settlement_probability(
+        p_fast_yes,
+        fast_price,
+        settle_price,
+    ))
+}
+
+#[inline]
+pub(super) fn blend_settlement_probability(
+    p_fast_yes: f64,
+    fast_price: f64,
+    settle_price: f64,
+) -> f64 {
+    // When fast and settlement feeds diverge, pull probability toward 0.5.
+    // This keeps execution conservative until settlement alignment recovers.
+    let gap = ((fast_price - settle_price) / settle_price)
+        .abs()
+        .clamp(0.0, 0.03);
+    let settle_blend = (gap * 20.0).clamp(0.0, 0.25);
+    let p = (p_fast_yes.clamp(0.0, 1.0) * (1.0 - settle_blend)) + (0.5 * settle_blend);
+    p.clamp(0.0, 1.0)
+}
+
+#[derive(Debug, Default, Clone)]
+pub(super) struct SourceRuntimeStats {
+    pub(super) sample_count: u64,
+    pub(super) latency_sum_ms: f64,
+    pub(super) latency_sq_sum_ms: f64,
+    pub(super) out_of_order_count: u64,
+    pub(super) gap_count: u64,
+    pub(super) last_event_ts_ms: i64,
+    pub(super) last_recv_ts_ms: i64,
+    pub(super) deviation_ema_bps: f64,
+}
+
+pub(super) fn median_price(values: &[f64]) -> Option<f64> {
+    if values.is_empty() {
+        return None;
+    }
+    let mut sorted = values.to_vec();
+    sorted.sort_by(|a, b| a.total_cmp(b));
+    let mid = sorted.len() / 2;
+    Some(if sorted.len() % 2 == 0 {
+        (sorted[mid - 1] + sorted[mid]) * 0.5
+    } else {
+        sorted[mid]
+    })
+}
+
+pub(super) fn build_source_health_snapshot(
+    source: &str,
+    stats: &SourceRuntimeStats,
+    cfg: &SourceHealthConfig,
+    now_ms: i64,
+) -> SourceHealth {
+    let n = stats.sample_count.max(1) as f64;
+    let latency_ms = (stats.latency_sum_ms / n).max(0.0);
+    let variance = (stats.latency_sq_sum_ms / n) - (latency_ms * latency_ms);
+    let jitter_ms = variance.max(0.0).sqrt();
+    let out_of_order_rate = (stats.out_of_order_count as f64 / n).clamp(0.0, 1.0);
+    let gap_rate = (stats.gap_count as f64 / n).clamp(0.0, 1.0);
+    let price_deviation_bps = stats.deviation_ema_bps.max(0.0);
+    let freshness_age_ms = if stats.last_recv_ts_ms > 0 {
+        now_ms.saturating_sub(stats.last_recv_ts_ms).max(0) as f64
+    } else {
+        cfg.freshness_limit_ms * 4.0
+    };
+    let freshness_penalty = (freshness_age_ms / cfg.freshness_limit_ms.max(1e-6)).clamp(0.0, 2.0);
+    let freshness_score = (1.0 - freshness_penalty * 0.5).clamp(0.0, 1.0);
+
+    let jitter_penalty = (jitter_ms / cfg.jitter_limit_ms.max(1e-6)).clamp(0.0, 2.0);
+    let deviation_penalty =
+        (price_deviation_bps / cfg.deviation_limit_bps.max(1e-6)).clamp(0.0, 2.0);
+    let out_of_order_penalty = (out_of_order_rate / 0.02).clamp(0.0, 2.0);
+    let gap_penalty = (gap_rate / 0.02).clamp(0.0, 2.0);
+    let coverage = (stats.sample_count as f64 / cfg.min_samples.max(1) as f64).clamp(0.0, 1.0);
+    let raw_score = 1.0
+        - (0.30 * jitter_penalty)
+        - (0.25 * deviation_penalty)
+        - (0.18 * out_of_order_penalty)
+        - (0.12 * gap_penalty)
+        - (0.15 * freshness_penalty);
+    let score = (raw_score.clamp(0.0, 1.0) * (0.25 + 0.75 * coverage)).clamp(0.0, 1.0);
+
+    SourceHealth {
+        source: source.to_string(),
+        latency_ms,
+        jitter_ms,
+        out_of_order_rate,
+        gap_rate,
+        price_deviation_bps,
+        freshness_score,
+        score,
+        sample_count: stats.sample_count,
+        ts_ms: now_ms,
+    }
+}
+
+pub(super) fn spawn_market_feed(
+    bus: RingBus<EngineEvent>,
+    stats: Arc<ShadowStats>,
+    symbols: Vec<String>,
+    market_types: Vec<String>,
+    timeframes: Vec<String>,
+    strategy_tx: mpsc::Sender<StrategyIngressMsg>,
+) {
+    const TS_INVERSION_TOLERANCE_MS: i64 = 250;
+    const TS_BACKJUMP_RESET_MS: i64 = 5_000;
+    // If we see *no* market messages for this long, treat the WS stream as stuck and reconnect.
+    // Keep this comfortably above "normal quiet" to avoid hammering gamma discovery on reconnection.
+    // 5s is too aggressive for quiet windows and creates reconnect churn.
+    // Keep stale protection, but allow a calmer idle window to reduce needless reconnects.
+    const BOOK_IDLE_TIMEOUT_MS: u64 = 20_000;
+    const RECONNECT_BASE_MS: u64 = 250;
+    const RECONNECT_MAX_MS: u64 = 10_000;
+    spawn_detached("market_feed_orchestrator", true, async move {
+        let strategy_ingress_drop_on_full = std::env::var("POLYEDGE_STRATEGY_INGRESS_DROP_ON_FULL")
+            .ok()
+            .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+            .unwrap_or(true);
+        let strategy_book_dedupe_window_ms =
+            std::env::var("POLYEDGE_BOOK_INGRESS_DEDUPE_WINDOW_MS")
+                .ok()
+                .and_then(|v| v.parse::<i64>().ok())
+                .unwrap_or(25)
+                .clamp(0, 500);
+        let strategy_book_dedupe_bps = std::env::var("POLYEDGE_BOOK_INGRESS_DEDUPE_BPS")
+            .ok()
+            .and_then(|v| v.parse::<f64>().ok())
+            .unwrap_or(0.05)
+            .clamp(0.0, 5.0);
+        let mut reconnects: u64 = 0;
+        loop {
+            let feed = PolymarketFeed::new_with_universe(
+                Duration::from_millis(50),
+                symbols.clone(),
+                market_types.clone(),
+                timeframes.clone(),
+            );
+            let Ok(mut stream) = feed.stream_books().await else {
+                reconnects = reconnects.saturating_add(1);
+                let backoff_ms =
+                    (RECONNECT_BASE_MS.saturating_mul(reconnects.min(40))).min(RECONNECT_MAX_MS);
+                tracing::warn!(
+                    reconnects,
+                    backoff_ms,
+                    "market feed failed to start; reconnecting"
+                );
+                tokio::time::sleep(Duration::from_millis(backoff_ms)).await;
+                continue;
+            };
+            let mut ingest_seq: u64 = 0;
+            let mut last_source_ts_by_market: HashMap<String, i64> = HashMap::new();
+            let mut last_enqueued_book_by_market: HashMap<String, (i64, f64, f64, f64, f64)> =
+                HashMap::new();
+            // Only reset reconnect backoff once we observe actual book traffic (not just a successful
+            // handshake). This avoids a reconnect storm when discovery/WS is returning 200 but no
+            // updates are delivered.
+            let mut saw_any_book = false;
+
+            loop {
+                let next = tokio::time::timeout(
+                    Duration::from_millis(BOOK_IDLE_TIMEOUT_MS),
+                    stream.next(),
+                )
+                .await;
+                let item = match next {
+                    Ok(v) => v,
+                    Err(_) => {
+                        tracing::warn!(
+                            timeout_ms = BOOK_IDLE_TIMEOUT_MS,
+                            saw_any_book,
+                            reconnects,
+                            "market feed idle timeout; reconnecting"
+                        );
+                        break;
+                    }
+                };
+
+                let Some(item) = item else {
+                    tracing::warn!("market feed stream ended; reconnecting");
+                    break;
+                };
+
+                match item {
+                    Ok(book) => {
+                        if !saw_any_book {
+                            saw_any_book = true;
+                            if reconnects > 0 {
+                                tracing::info!(reconnects, "market feed reconnected");
+                            }
+                            reconnects = 0;
+                        }
+                        ingest_seq = ingest_seq.saturating_add(1);
+                        let source_ts = book.ts_ms;
+                        let source_seq = source_ts.max(0) as u64;
+                        let valid = !book.market_id.is_empty()
+                            && book.bid_yes.is_finite()
+                            && book.ask_yes.is_finite()
+                            && book.bid_no.is_finite()
+                            && book.ask_no.is_finite()
+                            && source_seq > 0;
+                        stats.mark_data_validity(valid);
+                        if let Some(prev) = last_source_ts_by_market.get(&book.market_id).copied() {
+                            if source_ts + TS_INVERSION_TOLERANCE_MS < prev {
+                                let back_jump_ms = prev.saturating_sub(source_ts);
+                                if back_jump_ms > TS_BACKJUMP_RESET_MS {
+                                    stats.record_issue("book_ts_backjump_reset").await;
+                                } else {
+                                    stats.mark_ts_inversion();
+                                }
+                            }
+                        }
+                        last_source_ts_by_market.insert(book.market_id.clone(), source_ts);
+                        // IMPORTANT: book freshness must be based on *local* receive time, not the
+                        // exchange/server-provided ts_ms (which can be skewed/backjump).
+                        let book_tick_ms = if book.recv_ts_local_ns > 0 {
+                            (book.recv_ts_local_ns / 1_000_000).max(0)
+                        } else {
+                            Utc::now().timestamp_millis()
+                        };
+                        stats.mark_book_tick(book_tick_ms);
+                        let book_json =
+                            serde_json::to_string(&book).unwrap_or_else(|_| "{}".to_string());
+                        let hash = sha256_hex(&book_json);
+                        let line = format!(
+                            "{{\"ts_ms\":{},\"source_seq\":{},\"ingest_seq\":{},\"valid\":{},\"sha256\":\"{}\",\"book\":{}}}",
+                            Utc::now().timestamp_millis(),
+                            source_seq,
+                            ingest_seq,
+                            valid,
+                            hash,
+                            book_json
+                        );
+                        append_jsonl_line(&dataset_path("raw", "book_tops.jsonl"), line);
+                        if !valid {
+                            stats.record_issue("invalid_book_top").await;
+                            continue;
+                        }
+
+                        if strategy_book_dedupe_window_ms > 0 {
+                            let book_recv_ms = if book.recv_ts_local_ns > 0 {
+                                (book.recv_ts_local_ns / 1_000_000).max(0)
+                            } else {
+                                Utc::now().timestamp_millis()
+                            };
+                            if let Some((
+                                prev_recv_ms,
+                                prev_bid_yes,
+                                prev_ask_yes,
+                                prev_bid_no,
+                                prev_ask_no,
+                            )) = last_enqueued_book_by_market.get(&book.market_id)
+                            {
+                                let within_window = (book_recv_ms - *prev_recv_ms).abs()
+                                    <= strategy_book_dedupe_window_ms;
+                                let max_diff_bps = max_book_top_diff_bps(
+                                    *prev_bid_yes,
+                                    *prev_ask_yes,
+                                    *prev_bid_no,
+                                    *prev_ask_no,
+                                    &book,
+                                );
+                                if within_window && max_diff_bps <= strategy_book_dedupe_bps {
+                                    metrics::counter!("strategy.ingress_book_dedupe_drop")
+                                        .increment(1);
+                                    continue;
+                                }
+                            }
+                            last_enqueued_book_by_market.insert(
+                                book.market_id.clone(),
+                                (
+                                    book_recv_ms,
+                                    book.bid_yes,
+                                    book.ask_yes,
+                                    book.bid_no,
+                                    book.ask_no,
+                                ),
+                            );
+                        }
+
+                        let ingress = StrategyIngressMsg {
+                            enqueued_ns: now_ns(),
+                            payload: StrategyIngress::BookTop(book.clone()),
+                        };
+                        if strategy_ingress_drop_on_full {
+                            match strategy_tx.try_send(ingress) {
+                                Ok(()) => {}
+                                Err(mpsc::error::TrySendError::Full(_)) => {
+                                    metrics::counter!("strategy.ingress_book_drop").increment(1);
+                                }
+                                Err(mpsc::error::TrySendError::Closed(_)) => break,
+                            }
+                        } else if strategy_tx.send(ingress).await.is_err() {
+                            break;
+                        }
+
+                        publish_if_telemetry_subscribers(&bus, EngineEvent::BookTop(book));
+                    }
+                    Err(err) => {
+                        tracing::warn!(?err, "market feed event error");
+                    }
+                }
+            }
+
+            reconnects = reconnects.saturating_add(1);
+            let backoff_ms =
+                (RECONNECT_BASE_MS.saturating_mul(reconnects.min(40))).min(RECONNECT_MAX_MS);
+            tokio::time::sleep(Duration::from_millis(backoff_ms)).await;
+        }
+    });
+}
diff --git a/crates/app_runner/src/fusion_engine.rs b/crates/app_runner/src/fusion_engine.rs
new file mode 100644
index 0000000..2b0a429
--- /dev/null
+++ b/crates/app_runner/src/fusion_engine.rs
@@ -0,0 +1,495 @@
+use std::collections::HashMap;
+use std::sync::OnceLock;
+use std::time::Instant;
+
+use core_types::{BookTop, RefTick};
+use dashmap::DashMap;
+
+use crate::state::FusionConfig;
+use crate::stats_utils::now_ns;
+
+#[derive(Debug, Clone, Copy, Default)]
+pub(super) struct FeedLatencySample {
+    pub(super) feed_in_ms: f64,
+    pub(super) source_latency_ms: f64,
+    pub(super) exchange_lag_ms: f64,
+    pub(super) path_lag_ms: f64,
+    pub(super) book_latency_ms: f64,
+    pub(super) local_backlog_ms: f64,
+    pub(super) ref_decode_ms: f64,
+}
+
+#[derive(Debug, Clone, Copy, Default)]
+pub(super) struct PathLagCalibState {
+    floor_ms: f64,
+    initialized: bool,
+    updated_ns: i64,
+}
+
+pub(super) static PATH_LAG_CALIB: OnceLock<DashMap<String, PathLagCalibState>> = OnceLock::new();
+
+pub(super) fn path_lag_calib_map() -> &'static DashMap<String, PathLagCalibState> {
+    PATH_LAG_CALIB.get_or_init(DashMap::new)
+}
+
+pub(super) fn calibrate_path_lag_ms(source: &str, observed_delta_ms: f64, now_ns: i64) -> f64 {
+    const FLOOR_RISE_MS_PER_SEC: f64 = 0.20;
+    const FLOOR_CLAMP_MIN_MS: f64 = -10_000.0;
+    const FLOOR_CLAMP_MAX_MS: f64 = 10_000.0;
+    let key = source.to_string();
+    let mut state = path_lag_calib_map()
+        .get(&key)
+        .map(|v| *v)
+        .unwrap_or_default();
+    if !state.initialized {
+        state.floor_ms = observed_delta_ms;
+        state.initialized = true;
+        state.updated_ns = now_ns;
+    } else {
+        let dt_sec = ((now_ns - state.updated_ns).max(0) as f64) / 1_000_000_000.0;
+        let mut floor = state.floor_ms + dt_sec * FLOOR_RISE_MS_PER_SEC;
+        if observed_delta_ms < floor {
+            floor = observed_delta_ms;
+        }
+        state.floor_ms = floor.clamp(FLOOR_CLAMP_MIN_MS, FLOOR_CLAMP_MAX_MS);
+        state.updated_ns = now_ns;
+    }
+    path_lag_calib_map().insert(key, state);
+    (observed_delta_ms - state.floor_ms).max(0.0)
+}
+
+#[cfg(test)]
+pub(super) fn reset_path_lag_calib_for_tests() {
+    if let Some(map) = PATH_LAG_CALIB.get() {
+        map.clear();
+    }
+}
+
+#[derive(Debug, Clone)]
+pub(super) struct TokenBucket {
+    pub(super) rps: f64,
+    pub(super) burst: f64,
+    pub(super) tokens: f64,
+    pub(super) last_refill: Instant,
+}
+
+impl TokenBucket {
+    pub(super) fn new(rps: f64, burst: f64) -> Self {
+        let rps = rps.max(0.1);
+        let burst = burst.max(1.0);
+        Self {
+            rps,
+            burst,
+            tokens: burst,
+            last_refill: Instant::now(),
+        }
+    }
+
+    pub(super) fn try_take(&mut self, n: f64) -> bool {
+        let now = Instant::now();
+        let dt = now.duration_since(self.last_refill).as_secs_f64();
+        self.last_refill = now;
+        self.tokens = (self.tokens + dt * self.rps).clamp(0.0, self.burst);
+        if self.tokens >= n {
+            self.tokens -= n;
+            true
+        } else {
+            false
+        }
+    }
+}
+
+pub(super) fn estimate_feed_latency(tick: &RefTick, book: &BookTop) -> FeedLatencySample {
+    let now = now_ns();
+    let now_ms = now / 1_000_000;
+    let tick_source_ms = tick.event_ts_exchange_ms.max(tick.event_ts_ms);
+    let tick_ingest_ms = (tick.recv_ts_ms - tick_source_ms).max(0) as f64;
+    let exchange_lag_ms = tick
+        .ts_first_hop_ms
+        .map(|first| (first - tick_source_ms).max(0) as f64)
+        .unwrap_or(tick_ingest_ms);
+    let path_lag_ms = tick
+        .ts_first_hop_ms
+        .map(|first| calibrate_path_lag_ms(&tick.source, (tick.recv_ts_ms - first) as f64, now))
+        .unwrap_or(f64::NAN);
+    let book_recv_ms = if book.recv_ts_local_ns > 0 {
+        (book.recv_ts_local_ns / 1_000_000).max(0)
+    } else {
+        now_ms
+    };
+    let book_ingest_ms = (book_recv_ms - book.ts_ms).max(0) as f64;
+    // IMPORTANT: `source_latency_ms` is the external *reference* (CEX) tick latency proxy.
+    // Do not mix in Polymarket book timestamps here; track book latency separately.
+    let source_latency_ms = tick_ingest_ms;
+    let ref_decode_ms = if tick.recv_ts_local_ns > 0 && tick.ingest_ts_local_ns > 0 {
+        ((tick.ingest_ts_local_ns - tick.recv_ts_local_ns).max(0) as f64) / 1_000_000.0
+    } else {
+        0.0
+    };
+
+    let latest_recv_ns = if book.recv_ts_local_ns > 0 {
+        tick.recv_ts_local_ns.max(book.recv_ts_local_ns)
+    } else {
+        tick.recv_ts_local_ns
+    };
+    let local_backlog_ms = if latest_recv_ns > 0 {
+        ((now - latest_recv_ns).max(0) as f64) / 1_000_000.0
+    } else {
+        (now_ms - tick.recv_ts_ms.max(book.ts_ms)).max(0) as f64
+    };
+
+    // IMPORTANT: `feed_in_ms` is the *local* recv->ingest latency (decode + enqueue), intended
+    // to be <5ms and independent of exchange clock skew. Use source_latency_ms/local_backlog_ms
+    // separately for "how old is this data?" debugging/guardrails.
+    let feed_in_ms = ref_decode_ms;
+    FeedLatencySample {
+        feed_in_ms,
+        source_latency_ms,
+        exchange_lag_ms,
+        path_lag_ms,
+        book_latency_ms: book_ingest_ms,
+        local_backlog_ms,
+        ref_decode_ms,
+    }
+}
+
+#[derive(Debug, Clone, Copy)]
+pub(super) struct CoalescePolicy {
+    pub(super) max_events: usize,
+    pub(super) budget_us: u64,
+}
+
+pub(super) fn compute_coalesce_policy(
+    queue_len: usize,
+    lag_p50_ms: Option<f64>,
+    strategy_max_coalesce: usize,
+    strategy_coalesce_min: usize,
+    strategy_coalesce_budget_us: u64,
+) -> CoalescePolicy {
+    // For shallow queues, process immediately to minimize tail latency.
+    if queue_len < 12 {
+        return CoalescePolicy {
+            max_events: 0,
+            budget_us: 0,
+        };
+    }
+
+    // If queue is already deep, prioritize drain speed to collapse backlog spikes quickly.
+    if queue_len >= 128 {
+        let max_events = queue_len
+            .min(strategy_max_coalesce)
+            .max(strategy_coalesce_min);
+        let budget_us = strategy_coalesce_budget_us.max(800).min(3_000);
+        return CoalescePolicy {
+            max_events,
+            budget_us,
+        };
+    }
+
+    let dynamic_cap = queue_len
+        .saturating_div(2)
+        .saturating_add(8)
+        .min(strategy_max_coalesce);
+    let max_events = dynamic_cap.max(strategy_coalesce_min);
+    let budget_us = match lag_p50_ms {
+        Some(l) if l >= 80.0 => 220_u64,
+        Some(l) if l >= 40.0 => strategy_coalesce_budget_us.min(160),
+        Some(l) if l >= 15.0 => 80_u64,
+        Some(_) => 40_u64,
+        None => strategy_coalesce_budget_us.min(120),
+    };
+
+    CoalescePolicy {
+        max_events,
+        budget_us,
+    }
+}
+
+pub(super) fn is_anchor_ref_source(source: &str) -> bool {
+    source == "chainlink_rtds"
+}
+
+#[inline]
+pub(super) fn fast_tick_allowed_in_fusion_mode(source: &str, mode: &str) -> bool {
+    match mode {
+        "udp_only" => source == "binance_udp",
+        "direct_only" => source != "binance_udp" && !is_anchor_ref_source(source),
+        "active_active" | "websocket_primary" => true,
+        // Unknown future modes: keep permissive to avoid accidental data blackout.
+        _ => true,
+    }
+}
+
+#[inline]
+pub(super) fn should_arm_ws_primary_fallback(
+    mode: &str,
+    ws_cap_ready: bool,
+    ws_breach_persisted: bool,
+    fallback_active: bool,
+) -> bool {
+    mode == "websocket_primary" && ws_breach_persisted && !ws_cap_ready && !fallback_active
+}
+
+#[inline]
+pub(super) fn should_enforce_udp_share_cap(
+    mode: &str,
+    fallback_active: bool,
+    share_high: bool,
+) -> bool {
+    matches!(mode, "active_active" | "websocket_primary") && !fallback_active && share_high
+}
+
+pub(super) fn ref_event_ts_ms(tick: &RefTick) -> i64 {
+    tick.event_ts_exchange_ms.max(tick.event_ts_ms)
+}
+
+pub(super) fn should_replace_ref_tick(current: &RefTick, next: &RefTick) -> bool {
+    let current_event = ref_event_ts_ms(current);
+    let next_event = ref_event_ts_ms(next);
+    // Guard: ignore ticks whose event timestamp is wildly in the future vs our local receive time.
+    // (This can happen under clock skew or malformed payloads and would break latency ranking.)
+    if next_event > next.recv_ts_ms + 5_000 {
+        return false;
+    }
+
+    let staleness_budget_us = fusion_staleness_budget_us_for_source(next.source.as_str());
+    if next.recv_ts_local_ns > 0
+        && current.recv_ts_local_ns > 0
+        && next.source != current.source
+        && next.recv_ts_local_ns > current.recv_ts_local_ns
+    {
+        let arrival_delta_us = (next.recv_ts_local_ns - current.recv_ts_local_ns) / 1_000;
+        if arrival_delta_us > staleness_budget_us && next_event <= current_event + 1 {
+            return false;
+        }
+    }
+
+    // Priority 1: Chainlink RTDS has <5ms latency, always prefer when timestamps are recent
+    if next.source == "chainlink_rtds" && next_event + 50 >= current_event {
+        return true;
+    }
+    if current.source == "chainlink_rtds" && current_event + 50 >= next_event {
+        return false;
+    }
+    // Goal: "fastest observable tick" for latency-sensitive triggers.
+    // Event timestamps across sources are not perfectly comparable, so we bias towards lower
+    // `recv_ts_ms - event_ts_ms` latency (i.e. faster wire path), with a small guard against
+    // extreme back-jumps in event time.
+    let current_latency_ms = (current.recv_ts_ms - current_event).max(0) as f64;
+    let next_latency_ms = (next.recv_ts_ms - next_event).max(0) as f64;
+
+    const EVENT_BACKJUMP_TOL_MS: i64 = 250;
+    const LATENCY_DOMINATE_MS: f64 = 20.0;
+    const LATENCY_TIE_EPS_MS: f64 = 5.0;
+
+    if next_event + EVENT_BACKJUMP_TOL_MS < current_event {
+        // Allow a big latency improvement to override moderate event-time skew.
+        return next_latency_ms + LATENCY_DOMINATE_MS < current_latency_ms;
+    }
+
+    if next_latency_ms + LATENCY_TIE_EPS_MS < current_latency_ms {
+        return true;
+    }
+    if current_latency_ms + LATENCY_TIE_EPS_MS < next_latency_ms {
+        return false;
+    }
+
+    // Within ~5ms latency tie: prefer the newer event time, otherwise keep first-arriving tick.
+    next_event > current_event + 1
+}
+
+// Source-specific fusion staleness budgets:
+// - UDP path (`binance_udp`) has sub-millisecond latency, so use a tighter 200us window.
+// - Other sources (direct WS, Chainlink) keep a looser 600us default.
+pub(super) fn fusion_staleness_budget_us_for_source(next_source: &str) -> i64 {
+    static BUDGET_UDP_US: OnceLock<i64> = OnceLock::new();
+    static BUDGET_DEFAULT_US: OnceLock<i64> = OnceLock::new();
+
+    // UDP path: aggressive freshness window (default 200us).
+    if next_source.contains("udp") {
+        return *BUDGET_UDP_US.get_or_init(|| {
+            std::env::var("POLYEDGE_FUSION_STALENESS_UDP_US")
+                .ok()
+                .and_then(|v| v.parse::<i64>().ok())
+                .unwrap_or(200)
+                .clamp(50, 2_000)
+        });
+    }
+
+    // Other sources: default 600us window.
+    *BUDGET_DEFAULT_US.get_or_init(|| {
+        std::env::var("POLYEDGE_FUSION_STALENESS_BUDGET_US")
+            .ok()
+            .and_then(|v| v.parse::<i64>().ok())
+            .unwrap_or(600)
+            .clamp(50, 5_000)
+    })
+}
+
+pub(super) fn udp_min_freshness_score() -> f64 {
+    static UDP_MIN_FRESHNESS_SCORE: OnceLock<f64> = OnceLock::new();
+    *UDP_MIN_FRESHNESS_SCORE.get_or_init(|| {
+        std::env::var("POLYEDGE_UDP_MIN_FRESHNESS_SCORE")
+            .ok()
+            .and_then(|v| v.parse::<f64>().ok())
+            .unwrap_or(0.55)
+            .clamp(0.0, 1.0)
+    })
+}
+
+pub(super) fn ws_primary_fallback_gap_ns() -> i64 {
+    3_000 * 1_000_000
+}
+
+pub(super) fn udp_downweight_keep_every() -> usize {
+    static UDP_KEEP_EVERY: OnceLock<usize> = OnceLock::new();
+    *UDP_KEEP_EVERY.get_or_init(|| {
+        std::env::var("POLYEDGE_UDP_DOWNWEIGHT_KEEP_EVERY")
+            .ok()
+            .and_then(|v| v.parse::<usize>().ok())
+            .unwrap_or(3)
+            .clamp(2, 32)
+    })
+}
+
+#[inline]
+pub(super) fn should_log_ref_tick(ingest_seq: u64) -> bool {
+    static SAMPLE_EVERY: OnceLock<u64> = OnceLock::new();
+    let sample_every = *SAMPLE_EVERY.get_or_init(|| {
+        std::env::var("POLYEDGE_REF_TICK_LOG_SAMPLE_EVERY")
+            .ok()
+            .and_then(|v| v.parse::<u64>().ok())
+            .unwrap_or(32)
+            .clamp(1, 1024)
+    });
+    ingest_seq % sample_every == 0
+}
+
+pub(super) fn is_ref_tick_duplicate(
+    current_source_ts_ms: i64,
+    current_price: f64,
+    prev_source_ts_ms: i64,
+    prev_price: f64,
+    cfg: &FusionConfig,
+) -> bool {
+    if (current_source_ts_ms - prev_source_ts_ms).abs() > cfg.dedupe_window_ms {
+        return false;
+    }
+    if !current_price.is_finite() || !prev_price.is_finite() {
+        return false;
+    }
+    let denom = prev_price.abs().max(1e-9);
+    let rel_bps = ((current_price - prev_price).abs() / denom) * 10_000.0;
+    rel_bps <= cfg.dedupe_price_bps
+}
+
+pub(super) fn max_book_top_diff_bps(
+    prev_bid_yes: f64,
+    prev_ask_yes: f64,
+    prev_bid_no: f64,
+    prev_ask_no: f64,
+    next: &BookTop,
+) -> f64 {
+    fn diff_bps(a: f64, b: f64) -> f64 {
+        if !a.is_finite() || !b.is_finite() {
+            return f64::INFINITY;
+        }
+        let denom = a.abs().max(1e-9);
+        ((a - b).abs() / denom) * 10_000.0
+    }
+
+    diff_bps(prev_bid_yes, next.bid_yes)
+        .max(diff_bps(prev_ask_yes, next.ask_yes))
+        .max(diff_bps(prev_bid_no, next.bid_no))
+        .max(diff_bps(prev_ask_no, next.ask_no))
+}
+
+pub(super) fn should_replace_anchor_tick(current: &RefTick, next: &RefTick) -> bool {
+    let current_event = ref_event_ts_ms(current);
+    let next_event = ref_event_ts_ms(next);
+    if next_event + 50 < current_event {
+        return false;
+    }
+    if next_event > current_event + 1 {
+        return true;
+    }
+    next.recv_ts_local_ns > current.recv_ts_local_ns + 1_000_000
+}
+
+pub(super) fn insert_latest_tick(latest_ticks: &mut HashMap<String, RefTick>, tick: RefTick) {
+    match latest_ticks.get(tick.symbol.as_str()) {
+        Some(current) => {
+            if should_replace_ref_tick(current, &tick) {
+                latest_ticks.insert(tick.symbol.clone(), tick);
+            }
+        }
+        None => {
+            latest_ticks.insert(tick.symbol.clone(), tick);
+        }
+    }
+}
+
+pub(super) fn insert_latest_anchor_tick(
+    latest_ticks: &mut HashMap<String, RefTick>,
+    tick: RefTick,
+) {
+    match latest_ticks.get(tick.symbol.as_str()) {
+        Some(current) => {
+            if should_replace_anchor_tick(current, &tick) {
+                latest_ticks.insert(tick.symbol.clone(), tick);
+            }
+        }
+        None => {
+            latest_ticks.insert(tick.symbol.clone(), tick);
+        }
+    }
+}
+
+pub(super) fn upsert_latest_tick_slot(
+    latest_ticks: &DashMap<String, RefTick>,
+    tick: RefTick,
+    should_replace: fn(&RefTick, &RefTick) -> bool,
+) -> Option<i64> {
+    use dashmap::mapref::entry::Entry;
+    match latest_ticks.entry(tick.symbol.clone()) {
+        Entry::Occupied(mut entry) => {
+            let current = entry.get();
+            if !should_replace(current, &tick) {
+                return None;
+            }
+            let delta_ns = if current.source != tick.source
+                && current.recv_ts_local_ns > 0
+                && tick.recv_ts_local_ns > 0
+            {
+                Some((tick.recv_ts_local_ns - current.recv_ts_local_ns).unsigned_abs() as i64)
+            } else {
+                None
+            };
+            entry.insert(tick);
+            delta_ns
+        }
+        Entry::Vacant(entry) => {
+            entry.insert(tick);
+            None
+        }
+    }
+}
+
+pub(super) fn insert_latest_ref_tick(
+    latest_fast_ticks: &mut HashMap<String, RefTick>,
+    latest_anchor_ticks: &mut HashMap<String, RefTick>,
+    tick: RefTick,
+) {
+    if is_anchor_ref_source(tick.source.as_str()) {
+        insert_latest_anchor_tick(latest_anchor_ticks, tick);
+    } else {
+        insert_latest_tick(latest_fast_ticks, tick);
+    }
+}
+
+pub(super) fn pick_latest_tick<'a>(
+    latest_ticks: &'a HashMap<String, RefTick>,
+    symbol: &str,
+) -> Option<&'a RefTick> {
+    latest_ticks.get(symbol)
+}
diff --git a/crates/app_runner/src/gate_eval.rs b/crates/app_runner/src/gate_eval.rs
index 87cf104..460c817 100644
--- a/crates/app_runner/src/gate_eval.rs
+++ b/crates/app_runner/src/gate_eval.rs
@@ -1,4 +1,4 @@
-use super::*;
+use crate::state::ShadowLiveReport;
 
 pub(super) fn compute_gate_fail_reasons(
     live: &ShadowLiveReport,
@@ -11,6 +11,18 @@ pub(super) fn compute_gate_fail_reasons(
             live.window_outcomes, min_outcomes
         ));
     }
+    if live.latency.ack_only_n < min_outcomes as u64 {
+        failed.push(format!(
+            "ack_only_unmeasured_or_insufficient_samples {} < {}",
+            live.latency.ack_only_n, min_outcomes
+        ));
+    }
+    if live.latency.capturable_window_n < min_outcomes as u64 {
+        failed.push(format!(
+            "capturable_window_unmeasured_or_insufficient_samples {} < {}",
+            live.latency.capturable_window_n, min_outcomes
+        ));
+    }
     if live.fillability_10ms < 0.60 {
         failed.push(format!(
             "fillability_10ms {:.4} < 0.6000",
@@ -92,6 +104,13 @@ pub(super) fn compute_gate_fail_reasons(
             live.ref_freshness_ms
         ));
     }
+    if live.probability_total >= min_outcomes as u64 && live.settlement_source_degraded_ratio > 0.50
+    {
+        failed.push(format!(
+            "settlement_source_degraded_ratio {:.4} > 0.50",
+            live.settlement_source_degraded_ratio
+        ));
+    }
     if live.net_markout_10s_usdc_p50 <= 0.0 {
         failed.push(format!(
             "net_markout_10s_usdc_p50 {:.6} <= 0",
diff --git a/crates/app_runner/src/main.rs b/crates/app_runner/src/main.rs
index 8a1a0c6..1205941 100644
--- a/crates/app_runner/src/main.rs
+++ b/crates/app_runner/src/main.rs
@@ -1,1484 +1,38 @@
-use std::collections::{HashMap, VecDeque};
-use std::fs::{self, OpenOptions};
-use std::io::Write;
-use std::net::SocketAddr;
-use std::path::{Path, PathBuf};
-use std::sync::atomic::{AtomicBool, AtomicI64, AtomicU64, Ordering};
-use std::sync::{Arc, OnceLock, RwLock as StdRwLock};
-use std::time::{Duration, Instant};
+use std::future::Future;
+use std::panic::AssertUnwindSafe;
 
 use anyhow::Result;
-use axum::extract::State;
-use axum::http::StatusCode;
-use axum::response::IntoResponse;
-use axum::routing::{get, post};
-use axum::{Json, Router};
-use chrono::Utc;
-use core_types::{
-    new_id, BookTop, ControlCommand, EdgeAttribution, EngineEvent, EnginePnLBreakdown,
-    ExecutionStyle, ExecutionVenue, FairValueModel, InventoryState, MarketFeed, MarketHealth,
-    OrderAck, OrderIntentV2, OrderSide, OrderTimeInForce, QuoteEval, QuoteIntent, QuotePolicy,
-    RefPriceFeed, RefTick, RiskContext, RiskManager, ShadowOutcome, ShadowShot, ToxicDecision,
-    ToxicFeatures, ToxicRegime,
-};
-use execution_clob::{ClobExecution, ExecutionMode};
-use fair_value::{BasisMrConfig, BasisMrFairValue};
-use feed_polymarket::PolymarketFeed;
-use feed_reference::MultiSourceRefFeed;
-use futures::StreamExt;
+use core_types::EngineEvent;
+use futures::FutureExt;
 use infra_bus::RingBus;
-use market_discovery::{DiscoveryConfig, MarketDiscovery};
-use observability::{init_metrics, init_tracing};
-use paper_executor::ShadowExecutor;
-use portfolio::PortfolioBook;
-use reqwest::Client;
-use risk_engine::{DefaultRiskManager, RiskLimits};
-use serde::{Deserialize, Serialize};
-use sha2::{Digest, Sha256};
-use strategy_maker::{MakerConfig, MakerQuotePolicy};
-use tokio::sync::{mpsc, RwLock};
 
+#[global_allocator]
+static GLOBAL: mimalloc::MiMalloc = mimalloc::MiMalloc;
+
+mod bootstrap;
+mod config_loader;
 mod control_api;
 mod engine_core;
+mod engine_loop;
+mod execution_eval;
+mod feed_runtime;
+mod fusion_engine;
 mod gate_eval;
 mod orchestration;
+mod paper_runtime;
+mod paper_sqlite;
+mod report_io;
+mod seat_persist;
+mod seat_runtime;
+mod seat_types;
+mod state;
 mod stats_utils;
-use engine_core::{
-    classify_execution_error_reason, classify_execution_style, is_policy_block_reason,
-    is_quote_reject_reason, normalize_reject_code,
-};
-use stats_utils::{
-    freshness_ms, now_ns, percentile, percentile_deque, policy_block_ratio, push_capped,
-    quote_block_ratio, robust_filter_iqr, value_to_f64,
-};
-
-#[derive(Clone)]
-struct AppState {
-    paused: Arc<RwLock<bool>>,
-    bus: RingBus<EngineEvent>,
-    portfolio: Arc<PortfolioBook>,
-    execution: Arc<ClobExecution>,
-    _shadow: Arc<ShadowExecutor>,
-    prometheus: metrics_exporter_prometheus::PrometheusHandle,
-    strategy_cfg: Arc<RwLock<MakerConfig>>,
-    fair_value_cfg: Arc<StdRwLock<BasisMrConfig>>,
-    toxicity_cfg: Arc<RwLock<ToxicityConfig>>,
-    allocator_cfg: Arc<RwLock<AllocatorConfig>>,
-    risk_limits: Arc<StdRwLock<RiskLimits>>,
-    tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
-    shadow_stats: Arc<ShadowStats>,
-    perf_profile: Arc<RwLock<PerfProfile>>,
-}
-
-#[derive(Debug, Clone)]
-struct FeeRateEntry {
-    fee_bps: f64,
-    fetched_at: Instant,
-}
-
-#[derive(Debug, Clone)]
-struct ScoringState {
-    scoring_true: u64,
-    scoring_total: u64,
-    rebate_bps_est: f64,
-    fetched_at: Instant,
-}
-
-#[derive(Clone)]
-struct EngineShared {
-    latest_books: Arc<RwLock<HashMap<String, BookTop>>>,
-    market_to_symbol: Arc<RwLock<HashMap<String, String>>>,
-    token_to_symbol: Arc<RwLock<HashMap<String, String>>>,
-    fee_cache: Arc<RwLock<HashMap<String, FeeRateEntry>>>,
-    fee_refresh_inflight: Arc<RwLock<HashMap<String, Instant>>>,
-    scoring_cache: Arc<RwLock<HashMap<String, ScoringState>>>,
-    scoring_refresh_inflight: Arc<RwLock<HashMap<String, Instant>>>,
-    http: Client,
-    clob_endpoint: String,
-    strategy_cfg: Arc<RwLock<MakerConfig>>,
-    fair_value_cfg: Arc<StdRwLock<BasisMrConfig>>,
-    toxicity_cfg: Arc<RwLock<ToxicityConfig>>,
-    risk_manager: Arc<DefaultRiskManager>,
-    universe_symbols: Arc<Vec<String>>,
-    universe_market_types: Arc<Vec<String>>,
-    universe_timeframes: Arc<Vec<String>>,
-    rate_limit_rps: f64,
-    scoring_rebate_factor: f64,
-    tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
-    shadow_stats: Arc<ShadowStats>,
-}
-
-#[derive(Serialize)]
-struct HealthResp {
-    status: &'static str,
-    paused: bool,
-}
-
-#[derive(Debug, Deserialize)]
-struct StrategyReloadReq {
-    min_edge_bps: Option<f64>,
-    ttl_ms: Option<u64>,
-    inventory_skew: Option<f64>,
-    base_quote_size: Option<f64>,
-    max_spread: Option<f64>,
-    basis_k_revert: Option<f64>,
-    basis_z_cap: Option<f64>,
-    basis_min_confidence: Option<f64>,
-    taker_trigger_bps: Option<f64>,
-    taker_max_slippage_bps: Option<f64>,
-    stale_tick_filter_ms: Option<f64>,
-    market_tier_profile: Option<String>,
-    capital_fraction_kelly: Option<f64>,
-    variance_penalty_lambda: Option<f64>,
-    min_eval_notional_usdc: Option<f64>,
-    min_expected_edge_usdc: Option<f64>,
-}
-
-#[derive(Debug, Serialize)]
-struct StrategyReloadResp {
-    maker: MakerConfig,
-    fair_value: BasisMrConfig,
-}
-
-#[derive(Debug, Deserialize)]
-struct RiskReloadReq {
-    max_market_notional: Option<f64>,
-    max_asset_notional: Option<f64>,
-    max_open_orders: Option<usize>,
-    daily_drawdown_cap_pct: Option<f64>,
-    max_loss_streak: Option<u32>,
-    cooldown_sec: Option<u64>,
-}
-
-#[derive(Debug, Deserialize)]
-struct TakerReloadReq {
-    trigger_bps: Option<f64>,
-    max_slippage_bps: Option<f64>,
-    stale_tick_filter_ms: Option<f64>,
-    market_tier_profile: Option<String>,
-}
-
-#[derive(Debug, Serialize)]
-struct TakerReloadResp {
-    trigger_bps: f64,
-    max_slippage_bps: f64,
-    stale_tick_filter_ms: f64,
-    market_tier_profile: String,
-}
-
-#[derive(Debug, Deserialize)]
-struct AllocatorReloadReq {
-    capital_fraction_kelly: Option<f64>,
-    variance_penalty_lambda: Option<f64>,
-    active_top_n_markets: Option<usize>,
-    taker_weight: Option<f64>,
-    maker_weight: Option<f64>,
-    arb_weight: Option<f64>,
-}
-
-#[derive(Debug, Clone, Serialize, Deserialize)]
-struct AllocatorConfig {
-    capital_fraction_kelly: f64,
-    variance_penalty_lambda: f64,
-    active_top_n_markets: usize,
-    taker_weight: f64,
-    maker_weight: f64,
-    arb_weight: f64,
-}
-
-impl Default for AllocatorConfig {
-    fn default() -> Self {
-        Self {
-            capital_fraction_kelly: 0.35,
-            variance_penalty_lambda: 0.25,
-            active_top_n_markets: 8,
-            taker_weight: 0.7,
-            maker_weight: 0.2,
-            arb_weight: 0.1,
-        }
-    }
-}
-
-#[derive(Debug, Serialize)]
-struct AllocatorReloadResp {
-    allocator: AllocatorConfig,
-}
-
-#[derive(Debug, Serialize)]
-struct RiskReloadResp {
-    risk: RiskLimits,
-}
-
-#[derive(Debug, Deserialize)]
-struct ToxicityReloadReq {
-    safe_threshold: Option<f64>,
-    caution_threshold: Option<f64>,
-    cooldown_min_sec: Option<u64>,
-    cooldown_max_sec: Option<u64>,
-    min_market_score: Option<f64>,
-    active_top_n_markets: Option<usize>,
-    markout_1s_caution_bps: Option<f64>,
-    markout_5s_caution_bps: Option<f64>,
-    markout_10s_caution_bps: Option<f64>,
-    markout_1s_danger_bps: Option<f64>,
-    markout_5s_danger_bps: Option<f64>,
-    markout_10s_danger_bps: Option<f64>,
-}
-
-#[derive(Debug, Deserialize)]
-struct PerfProfileReloadReq {
-    tail_guard: Option<f64>,
-    io_flush_batch: Option<usize>,
-    io_queue_capacity: Option<usize>,
-    json_mode: Option<String>,
-    io_drop_on_full: Option<bool>,
-}
-
-#[derive(Debug, Clone, Serialize, Deserialize)]
-struct ExecutionConfig {
-    mode: String,
-    rate_limit_rps: f64,
-    http_timeout_ms: u64,
-    clob_endpoint: String,
-}
-
-impl Default for ExecutionConfig {
-    fn default() -> Self {
-        Self {
-            mode: "paper".to_string(),
-            rate_limit_rps: 15.0,
-            http_timeout_ms: 3000,
-            clob_endpoint: "https://clob.polymarket.com".to_string(),
-        }
-    }
-}
-
-#[derive(Debug, Clone, Serialize, Deserialize)]
-struct PerfProfile {
-    tail_guard: f64,
-    io_flush_batch: usize,
-    io_queue_capacity: usize,
-    json_mode: String,
-    io_drop_on_full: bool,
-}
-
-impl Default for PerfProfile {
-    fn default() -> Self {
-        Self {
-            tail_guard: 0.99,
-            io_flush_batch: 64,
-            io_queue_capacity: 16_384,
-            json_mode: "typed".to_string(),
-            io_drop_on_full: true,
-        }
-    }
-}
-
-#[derive(Debug, Clone, Serialize, Deserialize)]
-struct ToxicityConfig {
-    w1: f64,
-    w2: f64,
-    w3: f64,
-    w4: f64,
-    w5: f64,
-    w6: f64,
-    safe_threshold: f64,
-    caution_threshold: f64,
-    k_spread: f64,
-    cooldown_min_sec: u64,
-    cooldown_max_sec: u64,
-    min_market_score: f64,
-    active_top_n_markets: usize,
-    markout_1s_caution_bps: f64,
-    markout_5s_caution_bps: f64,
-    markout_10s_caution_bps: f64,
-    markout_1s_danger_bps: f64,
-    markout_5s_danger_bps: f64,
-    markout_10s_danger_bps: f64,
-}
-
-impl Default for ToxicityConfig {
-    fn default() -> Self {
-        Self {
-            w1: 0.30,
-            w2: 0.25,
-            w3: 0.20,
-            w4: 0.10,
-            w5: 0.10,
-            w6: 0.05,
-            safe_threshold: 0.35,
-            caution_threshold: 0.65,
-            k_spread: 1.5,
-            cooldown_min_sec: 30,
-            cooldown_max_sec: 120,
-            min_market_score: 70.0,
-            active_top_n_markets: 8,
-            markout_1s_caution_bps: -4.0,
-            markout_5s_caution_bps: -6.0,
-            markout_10s_caution_bps: -8.0,
-            markout_1s_danger_bps: -10.0,
-            markout_5s_danger_bps: -14.0,
-            markout_10s_danger_bps: -18.0,
-        }
-    }
-}
-
-#[derive(Debug, Clone)]
-struct MarketToxicState {
-    symbol: String,
-    markout_1s: VecDeque<f64>,
-    markout_5s: VecDeque<f64>,
-    markout_10s: VecDeque<f64>,
-    attempted: u64,
-    no_quote: u64,
-    symbol_missing: u64,
-    last_tox_score: f64,
-    last_regime: ToxicRegime,
-    cooldown_until_ms: i64,
-}
-
-impl Default for MarketToxicState {
-    fn default() -> Self {
-        Self {
-            symbol: String::new(),
-            markout_1s: VecDeque::new(),
-            markout_5s: VecDeque::new(),
-            markout_10s: VecDeque::new(),
-            attempted: 0,
-            no_quote: 0,
-            symbol_missing: 0,
-            last_tox_score: 0.0,
-            last_regime: ToxicRegime::Safe,
-            cooldown_until_ms: 0,
-        }
-    }
-}
-
-#[derive(Debug, Serialize, Clone)]
-struct ToxicityMarketRow {
-    market_rank: usize,
-    market_id: String,
-    symbol: String,
-    tox_score: f64,
-    regime: ToxicRegime,
-    market_score: f64,
-    markout_10s_bps: f64,
-    no_quote_rate: f64,
-    symbol_missing_rate: f64,
-    pending_exposure: f64,
-    active_for_quoting: bool,
-}
-
-#[derive(Debug, Serialize)]
-struct ToxicityLiveReport {
-    ts_ms: i64,
-    average_tox_score: f64,
-    safe_count: usize,
-    caution_count: usize,
-    danger_count: usize,
-    rows: Vec<ToxicityMarketRow>,
-}
-
-#[derive(Debug, Serialize)]
-struct ToxicityFinalReport {
-    pass: bool,
-    failed_reasons: Vec<String>,
-    live: ToxicityLiveReport,
-}
-
-#[derive(Debug, Serialize)]
-struct GateEvaluation {
-    window_id: u64,
-    gate_ready: bool,
-    min_outcomes: usize,
-    pass: bool,
-    data_valid_ratio: f64,
-    seq_gap_rate: f64,
-    ts_inversion_rate: f64,
-    stale_tick_drop_ratio: f64,
-    fillability_10ms: f64,
-    net_edge_p50_bps: f64,
-    net_edge_p10_bps: f64,
-    net_markout_10s_usdc_p50: f64,
-    roi_notional_10s_bps_p50: f64,
-    pnl_10s_p50_bps_raw: f64,
-    pnl_10s_p50_bps_robust: f64,
-    pnl_10s_sample_count: usize,
-    pnl_10s_outlier_ratio: f64,
-    eligible_count: u64,
-    executed_count: u64,
-    executed_over_eligible: f64,
-    ev_net_usdc_p50: f64,
-    ev_net_usdc_p10: f64,
-    ev_positive_ratio: f64,
-    quote_block_ratio: f64,
-    policy_block_ratio: f64,
-    strategy_uptime_pct: f64,
-    tick_to_ack_p99_ms: f64,
-    decision_queue_wait_p99_ms: f64,
-    decision_compute_p99_ms: f64,
-    source_latency_p99_ms: f64,
-    local_backlog_p99_ms: f64,
-    failed_reasons: Vec<String>,
-}
-
-#[derive(Debug, Serialize, Clone, Default)]
-struct LatencyBreakdown {
-    feed_in_p50_ms: f64,
-    feed_in_p90_ms: f64,
-    feed_in_p99_ms: f64,
-    signal_p50_us: f64,
-    signal_p90_us: f64,
-    signal_p99_us: f64,
-    quote_p50_us: f64,
-    quote_p90_us: f64,
-    quote_p99_us: f64,
-    risk_p50_us: f64,
-    risk_p90_us: f64,
-    risk_p99_us: f64,
-    decision_queue_wait_p50_ms: f64,
-    decision_queue_wait_p90_ms: f64,
-    decision_queue_wait_p99_ms: f64,
-    decision_compute_p50_ms: f64,
-    decision_compute_p90_ms: f64,
-    decision_compute_p99_ms: f64,
-    tick_to_decision_p50_ms: f64,
-    tick_to_decision_p90_ms: f64,
-    tick_to_decision_p99_ms: f64,
-    ack_only_p50_ms: f64,
-    ack_only_p90_ms: f64,
-    ack_only_p99_ms: f64,
-    tick_to_ack_p50_ms: f64,
-    tick_to_ack_p90_ms: f64,
-    tick_to_ack_p99_ms: f64,
-    parse_p99_us: f64,
-    io_queue_p99_ms: f64,
-    bus_lag_p99_ms: f64,
-    shadow_fill_p50_ms: f64,
-    shadow_fill_p90_ms: f64,
-    shadow_fill_p99_ms: f64,
-    source_latency_p50_ms: f64,
-    source_latency_p90_ms: f64,
-    source_latency_p99_ms: f64,
-    local_backlog_p50_ms: f64,
-    local_backlog_p90_ms: f64,
-    local_backlog_p99_ms: f64,
-}
-
-#[derive(Debug, Serialize)]
-struct ShadowLiveReport {
-    window_id: u64,
-    window_shots: usize,
-    window_outcomes: usize,
-    gate_ready: bool,
-    gate_fail_reasons: Vec<String>,
-    observe_only: bool,
-    started_at_ms: i64,
-    elapsed_sec: u64,
-    total_shots: usize,
-    total_outcomes: usize,
-    data_valid_ratio: f64,
-    seq_gap_rate: f64,
-    ts_inversion_rate: f64,
-    stale_tick_drop_ratio: f64,
-    quote_attempted: u64,
-    quote_blocked: u64,
-    policy_blocked: u64,
-    fillability_5ms: f64,
-    fillability_10ms: f64,
-    fillability_25ms: f64,
-    survival_5ms: f64,
-    survival_10ms: f64,
-    survival_25ms: f64,
-    // Survival probe is an "orderless" latency-arb competitiveness metric:
-    // at T0 we observe a crossable top-of-book price, then check at +Î” whether
-    // it is still crossable. This intentionally does not depend on order acks.
-    survival_probe_5ms: f64,
-    survival_probe_10ms: f64,
-    survival_probe_25ms: f64,
-    survival_probe_5ms_n: u64,
-    survival_probe_10ms_n: u64,
-    survival_probe_25ms_n: u64,
-    net_edge_p50_bps: f64,
-    net_edge_p10_bps: f64,
-    pnl_1s_p50_bps: f64,
-    pnl_5s_p50_bps: f64,
-    pnl_10s_p50_bps: f64,
-    pnl_10s_p50_bps_raw: f64,
-    pnl_10s_p50_bps_robust: f64,
-    net_markout_10s_usdc_p50: f64,
-    roi_notional_10s_bps_p50: f64,
-    pnl_10s_sample_count: usize,
-    pnl_10s_outlier_ratio: f64,
-    eligible_count: u64,
-    executed_count: u64,
-    executed_over_eligible: f64,
-    ev_net_usdc_p50: f64,
-    ev_net_usdc_p10: f64,
-    ev_positive_ratio: f64,
-    quote_block_ratio: f64,
-    policy_block_ratio: f64,
-    queue_depth_p99: f64,
-    event_backlog_p99: f64,
-    tick_to_decision_p50_ms: f64,
-    tick_to_decision_p90_ms: f64,
-    tick_to_decision_p99_ms: f64,
-    decision_queue_wait_p99_ms: f64,
-    decision_compute_p99_ms: f64,
-    source_latency_p99_ms: f64,
-    local_backlog_p99_ms: f64,
-    ack_only_p50_ms: f64,
-    ack_only_p90_ms: f64,
-    ack_only_p99_ms: f64,
-    strategy_uptime_pct: f64,
-    tick_to_ack_p99_ms: f64,
-    ref_ticks_total: u64,
-    book_ticks_total: u64,
-    ref_freshness_ms: i64,
-    book_freshness_ms: i64,
-    book_top_lag_p50_ms: f64,
-    book_top_lag_p90_ms: f64,
-    book_top_lag_p99_ms: f64,
-    book_top_lag_by_symbol_p50_ms: HashMap<String, f64>,
-    survival_10ms_by_symbol: HashMap<String, f64>,
-    survival_probe_10ms_by_symbol: HashMap<String, f64>,
-    blocked_reason_counts: HashMap<String, u64>,
-    latency: LatencyBreakdown,
-    market_scorecard: Vec<MarketScoreRow>,
-}
-
-#[derive(Debug, Serialize)]
-struct ShadowFinalReport {
-    live: ShadowLiveReport,
-    gate: GateEvaluation,
-}
-
-#[derive(Debug, Serialize, Clone)]
-struct EnginePnlRow {
-    engine: String,
-    samples: usize,
-    total_usdc: f64,
-    p50_usdc: f64,
-    p10_usdc: f64,
-    positive_ratio: f64,
-}
-
-#[derive(Debug, Serialize, Clone)]
-struct EnginePnlReport {
-    window_id: u64,
-    breakdown: EnginePnLBreakdown,
-    rows: Vec<EnginePnlRow>,
-}
-
-#[derive(Debug, Serialize, Clone)]
-struct MarketScoreRow {
-    market_id: String,
-    symbol: String,
-    shots: usize,
-    outcomes: usize,
-    fillability_10ms: f64,
-    net_edge_p50_bps: f64,
-    net_edge_p10_bps: f64,
-    pnl_10s_p50_bps: f64,
-    net_markout_10s_usdc_p50: f64,
-    roi_notional_10s_bps_p50: f64,
-}
-
-#[derive(Debug, Clone, Copy, Default)]
-struct SurvivalProbeCounters {
-    n_5: u64,
-    s_5: u64,
-    n_10: u64,
-    s_10: u64,
-    n_25: u64,
-    s_25: u64,
-}
-
-impl SurvivalProbeCounters {
-    fn record(&mut self, delay_ms: u64, survived: bool) {
-        let (n, s) = match delay_ms {
-            5 => (&mut self.n_5, &mut self.s_5),
-            10 => (&mut self.n_10, &mut self.s_10),
-            25 => (&mut self.n_25, &mut self.s_25),
-            _ => return,
-        };
-        *n = n.saturating_add(1);
-        if survived {
-            *s = s.saturating_add(1);
-        }
-    }
-
-    fn ratio(&self, delay_ms: u64) -> f64 {
-        let (n, s) = match delay_ms {
-            5 => (self.n_5, self.s_5),
-            10 => (self.n_10, self.s_10),
-            25 => (self.n_25, self.s_25),
-            _ => (0, 0),
-        };
-        if n == 0 {
-            0.0
-        } else {
-            s as f64 / n as f64
-        }
-    }
-
-    fn n(&self, delay_ms: u64) -> u64 {
-        match delay_ms {
-            5 => self.n_5,
-            10 => self.n_10,
-            25 => self.n_25,
-            _ => 0,
-        }
-    }
-}
-
-struct ShadowStats {
-    window_id: AtomicU64,
-    started_at: RwLock<Instant>,
-    started_at_ms: AtomicI64,
-    quote_attempted: AtomicU64,
-    quote_blocked: AtomicU64,
-    policy_blocked: AtomicU64,
-    seen_count: AtomicU64,
-    candidate_count: AtomicU64,
-    quoted_count: AtomicU64,
-    eligible_count: AtomicU64,
-    executed_count: AtomicU64,
-    filled_count: AtomicU64,
-    blocked_reasons: RwLock<HashMap<String, u64>>,
-    ref_ticks_total: AtomicU64,
-    book_ticks_total: AtomicU64,
-    last_ref_tick_ms: AtomicI64,
-    last_book_tick_ms: AtomicI64,
-    shots: RwLock<Vec<ShadowShot>>,
-    outcomes: RwLock<Vec<ShadowOutcome>>,
-    decision_queue_wait_ms: RwLock<Vec<f64>>,
-    decision_compute_ms: RwLock<Vec<f64>>,
-    tick_to_decision_ms: RwLock<Vec<f64>>,
-    ack_only_ms: RwLock<Vec<f64>>,
-    tick_to_ack_ms: RwLock<Vec<f64>>,
-    feed_in_ms: RwLock<Vec<f64>>,
-    source_latency_ms: RwLock<Vec<f64>>,
-    local_backlog_ms: RwLock<Vec<f64>>,
-    book_top_lag_ms: RwLock<Vec<f64>>,
-    book_top_lag_by_symbol_ms: RwLock<HashMap<String, Vec<f64>>>,
-    survival_probe_overall: RwLock<SurvivalProbeCounters>,
-    survival_probe_by_symbol: RwLock<HashMap<String, SurvivalProbeCounters>>,
-    signal_us: RwLock<Vec<f64>>,
-    quote_us: RwLock<Vec<f64>>,
-    risk_us: RwLock<Vec<f64>>,
-    shadow_fill_ms: RwLock<Vec<f64>>,
-    queue_depth: RwLock<Vec<f64>>,
-    event_backlog: RwLock<Vec<f64>>,
-    parse_us: RwLock<Vec<f64>>,
-    io_queue_depth: RwLock<Vec<f64>>,
-    data_total: AtomicU64,
-    data_invalid: AtomicU64,
-    seq_gap: AtomicU64,
-    ts_inversion: AtomicU64,
-    stale_tick_dropped: AtomicU64,
-    loss_streak: AtomicU64,
-    observe_only: AtomicBool,
-    paused: AtomicBool,
-    paused_since_ms: AtomicU64,
-    paused_total_ms: AtomicU64,
-}
-
-impl ShadowStats {
-    const SHADOW_CAP: usize = 200_000;
-    const SAMPLE_CAP: usize = 65_536;
-    const GATE_MIN_OUTCOMES: usize = 30;
-
-    fn new() -> Self {
-        Self {
-            window_id: AtomicU64::new(0),
-            started_at: RwLock::new(Instant::now()),
-            started_at_ms: AtomicI64::new(Utc::now().timestamp_millis()),
-            quote_attempted: AtomicU64::new(0),
-            quote_blocked: AtomicU64::new(0),
-            policy_blocked: AtomicU64::new(0),
-            seen_count: AtomicU64::new(0),
-            candidate_count: AtomicU64::new(0),
-            quoted_count: AtomicU64::new(0),
-            eligible_count: AtomicU64::new(0),
-            executed_count: AtomicU64::new(0),
-            filled_count: AtomicU64::new(0),
-            blocked_reasons: RwLock::new(HashMap::new()),
-            ref_ticks_total: AtomicU64::new(0),
-            book_ticks_total: AtomicU64::new(0),
-            last_ref_tick_ms: AtomicI64::new(0),
-            last_book_tick_ms: AtomicI64::new(0),
-            shots: RwLock::new(Vec::new()),
-            outcomes: RwLock::new(Vec::new()),
-            decision_queue_wait_ms: RwLock::new(Vec::new()),
-            decision_compute_ms: RwLock::new(Vec::new()),
-            tick_to_decision_ms: RwLock::new(Vec::new()),
-            ack_only_ms: RwLock::new(Vec::new()),
-            tick_to_ack_ms: RwLock::new(Vec::new()),
-            feed_in_ms: RwLock::new(Vec::new()),
-            source_latency_ms: RwLock::new(Vec::new()),
-            local_backlog_ms: RwLock::new(Vec::new()),
-            book_top_lag_ms: RwLock::new(Vec::new()),
-            book_top_lag_by_symbol_ms: RwLock::new(HashMap::new()),
-            survival_probe_overall: RwLock::new(SurvivalProbeCounters::default()),
-            survival_probe_by_symbol: RwLock::new(HashMap::new()),
-            signal_us: RwLock::new(Vec::new()),
-            quote_us: RwLock::new(Vec::new()),
-            risk_us: RwLock::new(Vec::new()),
-            shadow_fill_ms: RwLock::new(Vec::new()),
-            queue_depth: RwLock::new(Vec::new()),
-            event_backlog: RwLock::new(Vec::new()),
-            parse_us: RwLock::new(Vec::new()),
-            io_queue_depth: RwLock::new(Vec::new()),
-            data_total: AtomicU64::new(0),
-            data_invalid: AtomicU64::new(0),
-            seq_gap: AtomicU64::new(0),
-            ts_inversion: AtomicU64::new(0),
-            stale_tick_dropped: AtomicU64::new(0),
-            loss_streak: AtomicU64::new(0),
-            observe_only: AtomicBool::new(false),
-            paused: AtomicBool::new(false),
-            paused_since_ms: AtomicU64::new(0),
-            paused_total_ms: AtomicU64::new(0),
-        }
-    }
-
-    async fn reset(&self) -> u64 {
-        let window_id = self.window_id.fetch_add(1, Ordering::Relaxed) + 1;
-        *self.started_at.write().await = Instant::now();
-        self.started_at_ms
-            .store(Utc::now().timestamp_millis(), Ordering::Relaxed);
-        self.quote_attempted.store(0, Ordering::Relaxed);
-        self.quote_blocked.store(0, Ordering::Relaxed);
-        self.policy_blocked.store(0, Ordering::Relaxed);
-        self.seen_count.store(0, Ordering::Relaxed);
-        self.candidate_count.store(0, Ordering::Relaxed);
-        self.quoted_count.store(0, Ordering::Relaxed);
-        self.eligible_count.store(0, Ordering::Relaxed);
-        self.executed_count.store(0, Ordering::Relaxed);
-        self.filled_count.store(0, Ordering::Relaxed);
-        self.ref_ticks_total.store(0, Ordering::Relaxed);
-        self.book_ticks_total.store(0, Ordering::Relaxed);
-        self.last_ref_tick_ms.store(0, Ordering::Relaxed);
-        self.last_book_tick_ms.store(0, Ordering::Relaxed);
-        self.blocked_reasons.write().await.clear();
-        self.shots.write().await.clear();
-        self.outcomes.write().await.clear();
-        self.decision_queue_wait_ms.write().await.clear();
-        self.decision_compute_ms.write().await.clear();
-        self.tick_to_decision_ms.write().await.clear();
-        self.ack_only_ms.write().await.clear();
-        self.tick_to_ack_ms.write().await.clear();
-        self.feed_in_ms.write().await.clear();
-        self.source_latency_ms.write().await.clear();
-        self.local_backlog_ms.write().await.clear();
-        self.book_top_lag_ms.write().await.clear();
-        self.book_top_lag_by_symbol_ms.write().await.clear();
-        *self.survival_probe_overall.write().await = SurvivalProbeCounters::default();
-        self.survival_probe_by_symbol.write().await.clear();
-        self.signal_us.write().await.clear();
-        self.quote_us.write().await.clear();
-        self.risk_us.write().await.clear();
-        self.shadow_fill_ms.write().await.clear();
-        self.queue_depth.write().await.clear();
-        self.event_backlog.write().await.clear();
-        self.parse_us.write().await.clear();
-        self.io_queue_depth.write().await.clear();
-        self.data_total.store(0, Ordering::Relaxed);
-        self.data_invalid.store(0, Ordering::Relaxed);
-        self.seq_gap.store(0, Ordering::Relaxed);
-        self.ts_inversion.store(0, Ordering::Relaxed);
-        self.stale_tick_dropped.store(0, Ordering::Relaxed);
-        self.loss_streak.store(0, Ordering::Relaxed);
-        self.observe_only.store(false, Ordering::Relaxed);
-        self.paused.store(false, Ordering::Relaxed);
-        self.paused_since_ms.store(0, Ordering::Relaxed);
-        self.paused_total_ms.store(0, Ordering::Relaxed);
-        window_id
-    }
-
-    async fn push_shot(&self, shot: ShadowShot) {
-        let ingest_seq = next_normalized_ingest_seq();
-        let source_seq = shot.t0_ns.max(0) as u64;
-        append_jsonl(
-            &dataset_path("normalized", "shadow_shots.jsonl"),
-            &serde_json::json!({
-                "ts_ms": Utc::now().timestamp_millis(),
-                "source_seq": source_seq,
-                "ingest_seq": ingest_seq,
-                "shot": shot
-            }),
-        );
-        let mut shots = self.shots.write().await;
-        push_capped(&mut shots, shot, Self::SHADOW_CAP);
-    }
-
-    async fn push_outcome(&self, outcome: ShadowOutcome) {
-        // Loss-streak only considers primary delay (10ms) *fillable* outcomes, so "no fills"
-        // does not trip risk controls.
-        const PRIMARY_DELAY_MS: u64 = 10;
-        if outcome.delay_ms == PRIMARY_DELAY_MS && outcome.fillable {
-            if outcome.net_markout_10s_usdc.unwrap_or(0.0) < 0.0 {
-                self.loss_streak.fetch_add(1, Ordering::Relaxed);
-            } else {
-                self.loss_streak.store(0, Ordering::Relaxed);
-            }
-        }
-        let ingest_seq = next_normalized_ingest_seq();
-        let source_seq = outcome.ts_ns.max(0) as u64;
-        append_jsonl(
-            &dataset_path("normalized", "shadow_outcomes.jsonl"),
-            &serde_json::json!({
-                "ts_ms": Utc::now().timestamp_millis(),
-                "source_seq": source_seq,
-                "ingest_seq": ingest_seq,
-                "outcome": outcome
-            }),
-        );
-        let mut outcomes = self.outcomes.write().await;
-        push_capped(&mut outcomes, outcome, Self::SHADOW_CAP);
-    }
-
-    fn loss_streak(&self) -> u32 {
-        self.loss_streak.load(Ordering::Relaxed).min(u32::MAX as u64) as u32
-    }
-
-    async fn window_outcomes_len(&self) -> usize {
-        self.outcomes.read().await.len()
-    }
-
-    async fn push_tick_to_decision_ms(&self, ms: f64) {
-        let mut v = self.tick_to_decision_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_decision_queue_wait_ms(&self, ms: f64) {
-        let mut v = self.decision_queue_wait_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_decision_compute_ms(&self, ms: f64) {
-        let mut v = self.decision_compute_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_ack_only_ms(&self, ms: f64) {
-        let mut v = self.ack_only_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_tick_to_ack_ms(&self, ms: f64) {
-        let mut v = self.tick_to_ack_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_feed_in_ms(&self, ms: f64) {
-        let mut v = self.feed_in_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_source_latency_ms(&self, ms: f64) {
-        let mut v = self.source_latency_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
+mod strategy_policy;
+mod strategy_runtime;
+mod toxicity_report;
+mod toxicity_runtime;
 
-    async fn push_local_backlog_ms(&self, ms: f64) {
-        let mut v = self.local_backlog_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_book_top_lag_ms(&self, symbol: &str, ms: f64) {
-        let mut v = self.book_top_lag_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-        drop(v);
-
-        let mut by_symbol = self.book_top_lag_by_symbol_ms.write().await;
-        let entry = by_symbol.entry(symbol.to_string()).or_default();
-        push_capped(entry, ms, 4_096);
-    }
-
-    async fn record_survival_probe(&self, symbol: &str, delay_ms: u64, survived: bool) {
-        {
-            let mut c = self.survival_probe_overall.write().await;
-            c.record(delay_ms, survived);
-        }
-        let mut by_symbol = self.survival_probe_by_symbol.write().await;
-        let entry = by_symbol.entry(symbol.to_string()).or_default();
-        entry.record(delay_ms, survived);
-    }
-
-    async fn push_signal_us(&self, us: f64) {
-        let mut v = self.signal_us.write().await;
-        push_capped(&mut v, us, Self::SAMPLE_CAP);
-    }
-
-    async fn push_quote_us(&self, us: f64) {
-        let mut v = self.quote_us.write().await;
-        push_capped(&mut v, us, Self::SAMPLE_CAP);
-    }
-
-    async fn push_risk_us(&self, us: f64) {
-        let mut v = self.risk_us.write().await;
-        push_capped(&mut v, us, Self::SAMPLE_CAP);
-    }
-
-    async fn push_shadow_fill_ms(&self, ms: f64) {
-        let mut v = self.shadow_fill_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_queue_depth(&self, depth: f64) {
-        let mut v = self.queue_depth.write().await;
-        push_capped(&mut v, depth, Self::SAMPLE_CAP);
-    }
-
-    async fn push_event_backlog(&self, depth: f64) {
-        let mut v = self.event_backlog.write().await;
-        push_capped(&mut v, depth, Self::SAMPLE_CAP);
-    }
-
-    async fn push_parse_us(&self, us: f64) {
-        let mut v = self.parse_us.write().await;
-        push_capped(&mut v, us, Self::SAMPLE_CAP);
-    }
-
-    async fn push_io_queue_depth(&self, depth: f64) {
-        let mut v = self.io_queue_depth.write().await;
-        push_capped(&mut v, depth, Self::SAMPLE_CAP);
-    }
-
-    fn mark_attempted(&self) {
-        self.quote_attempted.fetch_add(1, Ordering::Relaxed);
-    }
-
-    fn mark_seen(&self) {
-        self.seen_count.fetch_add(1, Ordering::Relaxed);
-    }
-
-    fn mark_candidate(&self) {
-        self.candidate_count.fetch_add(1, Ordering::Relaxed);
-    }
-
-    fn mark_quoted(&self, n: u64) {
-        self.quoted_count.fetch_add(n, Ordering::Relaxed);
-    }
-
-    fn mark_eligible(&self) {
-        self.eligible_count.fetch_add(1, Ordering::Relaxed);
-    }
-
-    fn mark_executed(&self) {
-        self.executed_count.fetch_add(1, Ordering::Relaxed);
-    }
-
-    fn mark_filled(&self, n: u64) {
-        self.filled_count.fetch_add(n, Ordering::Relaxed);
-    }
-
-    fn mark_blocked(&self) {
-        self.quote_blocked.fetch_add(1, Ordering::Relaxed);
-    }
-
-    fn mark_policy_blocked(&self) {
-        self.policy_blocked.fetch_add(1, Ordering::Relaxed);
-    }
-
-    async fn mark_blocked_with_reason(&self, reason: &str) {
-        if is_quote_reject_reason(reason) {
-            self.mark_blocked();
-        }
-        if is_policy_block_reason(reason) {
-            self.mark_policy_blocked();
-        }
-        let mut reasons = self.blocked_reasons.write().await;
-        *reasons.entry(reason.to_string()).or_insert(0) += 1;
-    }
-
-    async fn record_issue(&self, reason: &str) {
-        let mut reasons = self.blocked_reasons.write().await;
-        *reasons.entry(reason.to_string()).or_insert(0) += 1;
-    }
-
-    fn mark_ref_tick(&self, ts_ms: i64) {
-        self.ref_ticks_total.fetch_add(1, Ordering::Relaxed);
-        self.last_ref_tick_ms.store(ts_ms, Ordering::Relaxed);
-    }
-
-    fn mark_book_tick(&self, ts_ms: i64) {
-        self.book_ticks_total.fetch_add(1, Ordering::Relaxed);
-        self.last_book_tick_ms.store(ts_ms, Ordering::Relaxed);
-    }
-
-    fn mark_data_validity(&self, valid: bool) {
-        self.data_total.fetch_add(1, Ordering::Relaxed);
-        if !valid {
-            self.data_invalid.fetch_add(1, Ordering::Relaxed);
-        }
-    }
-
-    fn mark_ts_inversion(&self) {
-        self.ts_inversion.fetch_add(1, Ordering::Relaxed);
-    }
-
-    fn mark_stale_tick_dropped(&self) {
-        self.stale_tick_dropped.fetch_add(1, Ordering::Relaxed);
-    }
-
-    fn observe_only(&self) -> bool {
-        self.observe_only.load(Ordering::Relaxed)
-    }
-
-    fn set_observe_only(&self, v: bool) {
-        self.observe_only.store(v, Ordering::Relaxed);
-    }
-
-    fn set_paused(&self, v: bool) {
-        let now_ms = Utc::now().timestamp_millis().max(0) as u64;
-        let was = self.paused.swap(v, Ordering::Relaxed);
-        if was == v {
-            return;
-        }
-        if v {
-            self.paused_since_ms.store(now_ms, Ordering::Relaxed);
-            return;
-        }
-        let since = self.paused_since_ms.swap(0, Ordering::Relaxed);
-        if since > 0 {
-            self.paused_total_ms
-                .fetch_add(now_ms.saturating_sub(since), Ordering::Relaxed);
-        }
-    }
-
-    fn uptime_pct(&self, elapsed: Duration) -> f64 {
-        let elapsed_ms = elapsed.as_millis() as u64;
-        if elapsed_ms == 0 {
-            return 100.0;
-        }
-        let now_ms = Utc::now().timestamp_millis().max(0) as u64;
-        let base_paused = self.paused_total_ms.load(Ordering::Relaxed);
-        let paused_extra = if self.paused.load(Ordering::Relaxed) {
-            let since = self.paused_since_ms.load(Ordering::Relaxed);
-            if since > 0 {
-                now_ms.saturating_sub(since)
-            } else {
-                0
-            }
-        } else {
-            0
-        };
-        let paused_ms = base_paused.saturating_add(paused_extra).min(elapsed_ms);
-        let uptime_ms = elapsed_ms.saturating_sub(paused_ms);
-        ((uptime_ms as f64) * 100.0 / elapsed_ms as f64).clamp(0.0, 100.0)
-    }
-}
-
-impl ShadowStats {
-    async fn build_live_report(&self) -> ShadowLiveReport {
-        const PRIMARY_DELAY_MS: u64 = 10;
-        let shots = self.shots.read().await.clone();
-        let outcomes = self.outcomes.read().await.clone();
-        let decision_queue_wait_ms = self.decision_queue_wait_ms.read().await.clone();
-        let decision_compute_ms = self.decision_compute_ms.read().await.clone();
-        let tick_to_decision_ms = self.tick_to_decision_ms.read().await.clone();
-        let ack_only_ms = self.ack_only_ms.read().await.clone();
-        let tick_to_ack_ms = self.tick_to_ack_ms.read().await.clone();
-        let feed_in_ms = self.feed_in_ms.read().await.clone();
-        let source_latency_ms = self.source_latency_ms.read().await.clone();
-        let local_backlog_ms = self.local_backlog_ms.read().await.clone();
-        let book_top_lag_ms = self.book_top_lag_ms.read().await.clone();
-        let book_top_lag_by_symbol_ms = self.book_top_lag_by_symbol_ms.read().await.clone();
-        let signal_us = self.signal_us.read().await.clone();
-        let quote_us = self.quote_us.read().await.clone();
-        let risk_us = self.risk_us.read().await.clone();
-        let shadow_fill_ms = self.shadow_fill_ms.read().await.clone();
-        let queue_depth = self.queue_depth.read().await.clone();
-        let event_backlog = self.event_backlog.read().await.clone();
-        let parse_us = self.parse_us.read().await.clone();
-        let io_queue_depth = self.io_queue_depth.read().await.clone();
-        let blocked_reason_counts = self.blocked_reasons.read().await.clone();
-        let survival_probe_overall = *self.survival_probe_overall.read().await;
-        let survival_probe_by_symbol = self.survival_probe_by_symbol.read().await.clone();
-
-        let fillability_5 = fillability_ratio(&outcomes, 5);
-        let fillability_10 = fillability_ratio(&outcomes, 10);
-        let fillability_25 = fillability_ratio(&outcomes, 25);
-        let survival_5 = survival_ratio(&outcomes, 5);
-        let survival_10 = survival_ratio(&outcomes, 10);
-        let survival_25 = survival_ratio(&outcomes, 25);
-        let survival_probe_5 = survival_probe_overall.ratio(5);
-        let survival_probe_10 = survival_probe_overall.ratio(10);
-        let survival_probe_25 = survival_probe_overall.ratio(25);
-        let survival_probe_5_n = survival_probe_overall.n(5);
-        let survival_probe_10_n = survival_probe_overall.n(10);
-        let survival_probe_25_n = survival_probe_overall.n(25);
-
-        let shots_primary = shots
-            .iter()
-            .filter(|s| s.delay_ms == PRIMARY_DELAY_MS)
-            .collect::<Vec<_>>();
-        let outcomes_primary = outcomes
-            .iter()
-            .filter(|o| o.delay_ms == PRIMARY_DELAY_MS)
-            .collect::<Vec<_>>();
-        let outcomes_primary_valid = outcomes_primary
-            .iter()
-            .filter(|o| !o.is_stale_tick)
-            .collect::<Vec<_>>();
-        let net_edges = shots_primary
-            .iter()
-            .map(|s| s.edge_net_bps)
-            .collect::<Vec<_>>();
-        let net_edge_p50 = percentile(&net_edges, 0.50).unwrap_or(0.0);
-        let net_edge_p10 = percentile(&net_edges, 0.10).unwrap_or(0.0);
-        let pnl_1s = outcomes_primary_valid
-            .iter()
-            .filter_map(|o| o.net_markout_1s_bps.or(o.pnl_1s_bps))
-            .collect::<Vec<_>>();
-        let pnl_5s = outcomes_primary_valid
-            .iter()
-            .filter_map(|o| o.net_markout_5s_bps.or(o.pnl_5s_bps))
-            .collect::<Vec<_>>();
-        let pnl_10s = outcomes_primary_valid
-            .iter()
-            .filter_map(|o| o.net_markout_10s_bps.or(o.pnl_10s_bps))
-            .collect::<Vec<_>>();
-        let net_markout_10s_usdc = outcomes_primary_valid
-            .iter()
-            .filter_map(|o| o.net_markout_10s_usdc)
-            .collect::<Vec<_>>();
-        let roi_notional_10s_bps = outcomes_primary_valid
-            .iter()
-            .filter_map(|o| o.roi_notional_10s_bps)
-            .collect::<Vec<_>>();
-        let pnl_1s_p50 = percentile(&pnl_1s, 0.50).unwrap_or(0.0);
-        let pnl_5s_p50 = percentile(&pnl_5s, 0.50).unwrap_or(0.0);
-        let pnl_10s_p50_raw = percentile(&pnl_10s, 0.50).unwrap_or(0.0);
-        let net_markout_10s_usdc_p50 = percentile(&net_markout_10s_usdc, 0.50).unwrap_or(0.0);
-        let roi_notional_10s_bps_p50 = percentile(&roi_notional_10s_bps, 0.50).unwrap_or(0.0);
-        let ev_net_usdc_p50 = percentile(&net_markout_10s_usdc, 0.50).unwrap_or(0.0);
-        let ev_net_usdc_p10 = percentile(&net_markout_10s_usdc, 0.10).unwrap_or(0.0);
-        let ev_positive_ratio = if net_markout_10s_usdc.is_empty() {
-            0.0
-        } else {
-            net_markout_10s_usdc.iter().filter(|v| **v > 0.0).count() as f64
-                / net_markout_10s_usdc.len() as f64
-        };
-        let (pnl_10s_filtered, pnl_10s_outlier_ratio) = robust_filter_iqr(&pnl_10s);
-        let pnl_10s_p50_robust = percentile(&pnl_10s_filtered, 0.50).unwrap_or(pnl_10s_p50_raw);
-        let pnl_10s_sample_count = pnl_10s.len();
-
-        let attempted = self.quote_attempted.load(Ordering::Relaxed);
-        let blocked = self.quote_blocked.load(Ordering::Relaxed);
-        let policy_blocked = self.policy_blocked.load(Ordering::Relaxed);
-        let eligible_count = self.eligible_count.load(Ordering::Relaxed);
-        let executed_count = self.executed_count.load(Ordering::Relaxed);
-        let executed_over_eligible = if eligible_count == 0 {
-            0.0
-        } else {
-            executed_count as f64 / eligible_count as f64
-        };
-        let quote_block_ratio = quote_block_ratio(attempted, blocked);
-        let policy_ratio = policy_block_ratio(attempted, policy_blocked);
-
-        let elapsed = self.started_at.read().await.elapsed();
-        let uptime_pct = self.uptime_pct(elapsed);
-        let tick_to_ack_p99 = percentile(&tick_to_ack_ms, 0.99).unwrap_or(0.0);
-        let scorecard = build_market_scorecard(&shots, &outcomes);
-        let ref_ticks_total = self.ref_ticks_total.load(Ordering::Relaxed);
-        let book_ticks_total = self.book_ticks_total.load(Ordering::Relaxed);
-        let now_ms = Utc::now().timestamp_millis();
-        let last_ref_tick_ms = self.last_ref_tick_ms.load(Ordering::Relaxed);
-        let last_book_tick_ms = self.last_book_tick_ms.load(Ordering::Relaxed);
-        let ref_freshness_ms = freshness_ms(now_ms, last_ref_tick_ms);
-        let book_freshness_ms = freshness_ms(now_ms, last_book_tick_ms);
-        let data_total = self.data_total.load(Ordering::Relaxed);
-        let data_invalid = self.data_invalid.load(Ordering::Relaxed);
-        let seq_gap = self.seq_gap.load(Ordering::Relaxed);
-        let ts_inversion = self.ts_inversion.load(Ordering::Relaxed);
-        let stale_tick_dropped = self.stale_tick_dropped.load(Ordering::Relaxed);
-        let data_valid_ratio = if data_total == 0 {
-            1.0
-        } else {
-            1.0 - (data_invalid as f64 / data_total as f64)
-        };
-        let seq_gap_rate = if data_total == 0 {
-            0.0
-        } else {
-            seq_gap as f64 / data_total as f64
-        };
-        let ts_inversion_rate = if data_total == 0 {
-            0.0
-        } else {
-            ts_inversion as f64 / data_total as f64
-        };
-        let stale_tick_drop_ratio = if data_total == 0 {
-            0.0
-        } else {
-            stale_tick_dropped as f64 / data_total as f64
-        };
-
-        let book_top_lag_p50_ms = percentile(&book_top_lag_ms, 0.50).unwrap_or(0.0);
-        let book_top_lag_p90_ms = percentile(&book_top_lag_ms, 0.90).unwrap_or(0.0);
-        let book_top_lag_p99_ms = percentile(&book_top_lag_ms, 0.99).unwrap_or(0.0);
-        let mut book_top_lag_by_symbol_p50_ms = HashMap::new();
-        for (sym, samples) in book_top_lag_by_symbol_ms {
-            book_top_lag_by_symbol_p50_ms.insert(sym, percentile(&samples, 0.50).unwrap_or(0.0));
-        }
-
-        let mut survival_10ms_by_symbol = HashMap::new();
-        let mut survival_counts: HashMap<String, (u64, u64)> = HashMap::new();
-        for o in &outcomes_primary_valid {
-            let o = *o;
-            let e = survival_counts.entry(o.symbol.clone()).or_insert((0, 0));
-            e.0 = e.0.saturating_add(1);
-            if o.survived {
-                e.1 = e.1.saturating_add(1);
-            }
-        }
-        for (sym, (n, s)) in survival_counts {
-            survival_10ms_by_symbol.insert(sym, if n == 0 { 0.0 } else { s as f64 / n as f64 });
-        }
-        let mut survival_probe_10ms_by_symbol = HashMap::new();
-        for (sym, c) in survival_probe_by_symbol {
-            survival_probe_10ms_by_symbol.insert(sym, c.ratio(10));
-        }
-
-        let latency = LatencyBreakdown {
-            feed_in_p50_ms: percentile(&feed_in_ms, 0.50).unwrap_or(0.0),
-            feed_in_p90_ms: percentile(&feed_in_ms, 0.90).unwrap_or(0.0),
-            feed_in_p99_ms: percentile(&feed_in_ms, 0.99).unwrap_or(0.0),
-            signal_p50_us: percentile(&signal_us, 0.50).unwrap_or(0.0),
-            signal_p90_us: percentile(&signal_us, 0.90).unwrap_or(0.0),
-            signal_p99_us: percentile(&signal_us, 0.99).unwrap_or(0.0),
-            quote_p50_us: percentile(&quote_us, 0.50).unwrap_or(0.0),
-            quote_p90_us: percentile(&quote_us, 0.90).unwrap_or(0.0),
-            quote_p99_us: percentile(&quote_us, 0.99).unwrap_or(0.0),
-            risk_p50_us: percentile(&risk_us, 0.50).unwrap_or(0.0),
-            risk_p90_us: percentile(&risk_us, 0.90).unwrap_or(0.0),
-            risk_p99_us: percentile(&risk_us, 0.99).unwrap_or(0.0),
-            decision_queue_wait_p50_ms: percentile(&decision_queue_wait_ms, 0.50).unwrap_or(0.0),
-            decision_queue_wait_p90_ms: percentile(&decision_queue_wait_ms, 0.90).unwrap_or(0.0),
-            decision_queue_wait_p99_ms: percentile(&decision_queue_wait_ms, 0.99).unwrap_or(0.0),
-            decision_compute_p50_ms: percentile(&decision_compute_ms, 0.50).unwrap_or(0.0),
-            decision_compute_p90_ms: percentile(&decision_compute_ms, 0.90).unwrap_or(0.0),
-            decision_compute_p99_ms: percentile(&decision_compute_ms, 0.99).unwrap_or(0.0),
-            tick_to_decision_p50_ms: percentile(&tick_to_decision_ms, 0.50).unwrap_or(0.0),
-            tick_to_decision_p90_ms: percentile(&tick_to_decision_ms, 0.90).unwrap_or(0.0),
-            tick_to_decision_p99_ms: percentile(&tick_to_decision_ms, 0.99).unwrap_or(0.0),
-            ack_only_p50_ms: percentile(&ack_only_ms, 0.50).unwrap_or(0.0),
-            ack_only_p90_ms: percentile(&ack_only_ms, 0.90).unwrap_or(0.0),
-            ack_only_p99_ms: percentile(&ack_only_ms, 0.99).unwrap_or(0.0),
-            tick_to_ack_p50_ms: percentile(&tick_to_ack_ms, 0.50).unwrap_or(0.0),
-            tick_to_ack_p90_ms: percentile(&tick_to_ack_ms, 0.90).unwrap_or(0.0),
-            tick_to_ack_p99_ms: tick_to_ack_p99,
-            parse_p99_us: percentile(&parse_us, 0.99).unwrap_or(0.0),
-            io_queue_p99_ms: percentile(&io_queue_depth, 0.99).unwrap_or(0.0),
-            bus_lag_p99_ms: percentile(&event_backlog, 0.99).unwrap_or(0.0),
-            shadow_fill_p50_ms: percentile(&shadow_fill_ms, 0.50).unwrap_or(0.0),
-            shadow_fill_p90_ms: percentile(&shadow_fill_ms, 0.90).unwrap_or(0.0),
-            shadow_fill_p99_ms: percentile(&shadow_fill_ms, 0.99).unwrap_or(0.0),
-            source_latency_p50_ms: percentile(&source_latency_ms, 0.50).unwrap_or(0.0),
-            source_latency_p90_ms: percentile(&source_latency_ms, 0.90).unwrap_or(0.0),
-            source_latency_p99_ms: percentile(&source_latency_ms, 0.99).unwrap_or(0.0),
-            local_backlog_p50_ms: percentile(&local_backlog_ms, 0.50).unwrap_or(0.0),
-            local_backlog_p90_ms: percentile(&local_backlog_ms, 0.90).unwrap_or(0.0),
-            local_backlog_p99_ms: percentile(&local_backlog_ms, 0.99).unwrap_or(0.0),
-        };
-
-        let mut live = ShadowLiveReport {
-            window_id: self.window_id.load(Ordering::Relaxed),
-            window_shots: shots.len(),
-            window_outcomes: outcomes.len(),
-            gate_ready: outcomes.len() >= Self::GATE_MIN_OUTCOMES,
-            gate_fail_reasons: Vec::new(),
-            observe_only: self.observe_only(),
-            started_at_ms: self.started_at_ms.load(Ordering::Relaxed),
-            elapsed_sec: elapsed.as_secs(),
-            total_shots: shots.len(),
-            total_outcomes: outcomes.len(),
-            data_valid_ratio,
-            seq_gap_rate,
-            ts_inversion_rate,
-            stale_tick_drop_ratio,
-            quote_attempted: attempted,
-            quote_blocked: blocked,
-            policy_blocked,
-            fillability_5ms: fillability_5,
-            fillability_10ms: fillability_10,
-            fillability_25ms: fillability_25,
-            survival_5ms: survival_5,
-            survival_10ms: survival_10,
-            survival_25ms: survival_25,
-            survival_probe_5ms: survival_probe_5,
-            survival_probe_10ms: survival_probe_10,
-            survival_probe_25ms: survival_probe_25,
-            survival_probe_5ms_n: survival_probe_5_n,
-            survival_probe_10ms_n: survival_probe_10_n,
-            survival_probe_25ms_n: survival_probe_25_n,
-            net_edge_p50_bps: net_edge_p50,
-            net_edge_p10_bps: net_edge_p10,
-            pnl_1s_p50_bps: pnl_1s_p50,
-            pnl_5s_p50_bps: pnl_5s_p50,
-            pnl_10s_p50_bps: pnl_10s_p50_raw,
-            pnl_10s_p50_bps_raw: pnl_10s_p50_raw,
-            pnl_10s_p50_bps_robust: pnl_10s_p50_robust,
-            net_markout_10s_usdc_p50,
-            roi_notional_10s_bps_p50,
-            pnl_10s_sample_count,
-            pnl_10s_outlier_ratio,
-            eligible_count,
-            executed_count,
-            executed_over_eligible,
-            ev_net_usdc_p50,
-            ev_net_usdc_p10,
-            ev_positive_ratio,
-            quote_block_ratio,
-            policy_block_ratio: policy_ratio,
-            queue_depth_p99: percentile(&queue_depth, 0.99).unwrap_or(0.0),
-            event_backlog_p99: percentile(&event_backlog, 0.99).unwrap_or(0.0),
-            tick_to_decision_p50_ms: latency.tick_to_decision_p50_ms,
-            tick_to_decision_p90_ms: latency.tick_to_decision_p90_ms,
-            tick_to_decision_p99_ms: latency.tick_to_decision_p99_ms,
-            decision_queue_wait_p99_ms: latency.decision_queue_wait_p99_ms,
-            decision_compute_p99_ms: latency.decision_compute_p99_ms,
-            source_latency_p99_ms: latency.source_latency_p99_ms,
-            local_backlog_p99_ms: latency.local_backlog_p99_ms,
-            ack_only_p50_ms: latency.ack_only_p50_ms,
-            ack_only_p90_ms: latency.ack_only_p90_ms,
-            ack_only_p99_ms: latency.ack_only_p99_ms,
-            strategy_uptime_pct: uptime_pct,
-            tick_to_ack_p99_ms: tick_to_ack_p99,
-            ref_ticks_total,
-            book_ticks_total,
-            ref_freshness_ms,
-            book_freshness_ms,
-            book_top_lag_p50_ms,
-            book_top_lag_p90_ms,
-            book_top_lag_p99_ms,
-            book_top_lag_by_symbol_p50_ms,
-            survival_10ms_by_symbol,
-            survival_probe_10ms_by_symbol,
-            blocked_reason_counts,
-            latency,
-            market_scorecard: scorecard,
-        };
-        live.gate_fail_reasons =
-            gate_eval::compute_gate_fail_reasons(&live, Self::GATE_MIN_OUTCOMES);
-        live.gate_ready = live.window_outcomes >= Self::GATE_MIN_OUTCOMES;
-        live
-    }
-
-    async fn build_final_report(&self) -> ShadowFinalReport {
-        let live = self.build_live_report().await;
-        let failed = live.gate_fail_reasons.clone();
-
-        let gate = GateEvaluation {
-            window_id: live.window_id,
-            gate_ready: live.gate_ready,
-            min_outcomes: Self::GATE_MIN_OUTCOMES,
-            pass: failed.is_empty(),
-            data_valid_ratio: live.data_valid_ratio,
-            seq_gap_rate: live.seq_gap_rate,
-            ts_inversion_rate: live.ts_inversion_rate,
-            stale_tick_drop_ratio: live.stale_tick_drop_ratio,
-            fillability_10ms: live.fillability_10ms,
-            net_edge_p50_bps: live.net_edge_p50_bps,
-            net_edge_p10_bps: live.net_edge_p10_bps,
-            net_markout_10s_usdc_p50: live.net_markout_10s_usdc_p50,
-            roi_notional_10s_bps_p50: live.roi_notional_10s_bps_p50,
-            pnl_10s_p50_bps_raw: live.pnl_10s_p50_bps_raw,
-            pnl_10s_p50_bps_robust: live.pnl_10s_p50_bps_robust,
-            pnl_10s_sample_count: live.pnl_10s_sample_count,
-            pnl_10s_outlier_ratio: live.pnl_10s_outlier_ratio,
-            eligible_count: live.eligible_count,
-            executed_count: live.executed_count,
-            executed_over_eligible: live.executed_over_eligible,
-            ev_net_usdc_p50: live.ev_net_usdc_p50,
-            ev_net_usdc_p10: live.ev_net_usdc_p10,
-            ev_positive_ratio: live.ev_positive_ratio,
-            quote_block_ratio: live.quote_block_ratio,
-            policy_block_ratio: live.policy_block_ratio,
-            strategy_uptime_pct: live.strategy_uptime_pct,
-            tick_to_ack_p99_ms: live.tick_to_ack_p99_ms,
-            decision_queue_wait_p99_ms: live.decision_queue_wait_p99_ms,
-            decision_compute_p99_ms: live.decision_compute_p99_ms,
-            source_latency_p99_ms: live.latency.source_latency_p99_ms,
-            local_backlog_p99_ms: live.latency.local_backlog_p99_ms,
-            failed_reasons: failed,
-        };
-        ShadowFinalReport { live, gate }
-    }
-
-    async fn build_engine_pnl_report(&self) -> EnginePnlReport {
-        const PRIMARY_DELAY_MS: u64 = 10;
-        let shots = self.shots.read().await.clone();
-        let outcomes = self.outcomes.read().await.clone();
-        let mut style_by_shot = HashMap::<String, ExecutionStyle>::new();
-        for shot in shots.iter().filter(|s| s.delay_ms == PRIMARY_DELAY_MS) {
-            style_by_shot.insert(shot.shot_id.clone(), shot.execution_style.clone());
-        }
-
-        let mut maker = Vec::<f64>::new();
-        let mut taker = Vec::<f64>::new();
-        let mut arb = Vec::<f64>::new();
-
-        for outcome in outcomes
-            .iter()
-            .filter(|o| o.delay_ms == PRIMARY_DELAY_MS && !o.is_stale_tick)
-        {
-            let Some(markout) = outcome.net_markout_10s_usdc else {
-                continue;
-            };
-            let style = style_by_shot
-                .get(&outcome.shot_id)
-                .cloned()
-                .unwrap_or_else(|| outcome.execution_style.clone());
-            match style {
-                ExecutionStyle::Maker => maker.push(markout),
-                ExecutionStyle::Taker => taker.push(markout),
-                ExecutionStyle::Arb => arb.push(markout),
-            }
-        }
-
-        let maker_total = maker.iter().sum::<f64>();
-        let taker_total = taker.iter().sum::<f64>();
-        let arb_total = arb.iter().sum::<f64>();
-
-        EnginePnlReport {
-            window_id: self.window_id.load(Ordering::Relaxed),
-            breakdown: EnginePnLBreakdown {
-                maker_usdc: maker_total,
-                taker_usdc: taker_total,
-                arb_usdc: arb_total,
-            },
-            rows: vec![
-                build_engine_pnl_row("maker", &maker),
-                build_engine_pnl_row("taker", &taker),
-                build_engine_pnl_row("arb", &arb),
-            ],
-        }
-    }
-}
-
-fn build_engine_pnl_row(engine: &str, values: &[f64]) -> EnginePnlRow {
-    let samples = values.len();
-    let total_usdc = values.iter().sum::<f64>();
-    let p50_usdc = percentile(values, 0.50).unwrap_or(0.0);
-    let p10_usdc = percentile(values, 0.10).unwrap_or(0.0);
-    let positive_ratio = if values.is_empty() {
-        0.0
-    } else {
-        values.iter().filter(|v| **v > 0.0).count() as f64 / values.len() as f64
-    };
-    EnginePnlRow {
-        engine: engine.to_string(),
-        samples,
-        total_usdc,
-        p50_usdc,
-        p10_usdc,
-        positive_ratio,
-    }
-}
+use bootstrap::{async_main, install_rustls_provider};
 
 fn main() -> Result<()> {
     install_rustls_provider();
@@ -1488,3747 +42,43 @@ fn main() -> Result<()> {
     runtime.block_on(async_main())
 }
 
-async fn async_main() -> Result<()> {
-    init_tracing("app_runner");
-    let prometheus = init_metrics();
-    ensure_dataset_dirs();
-
-    let execution_cfg = load_execution_config();
-    let universe_cfg = load_universe_config();
-    let bus = RingBus::new(16_384);
-    let portfolio = Arc::new(PortfolioBook::default());
-    let exec_mode = if execution_cfg.mode.eq_ignore_ascii_case("live") {
-        ExecutionMode::Live
-    } else {
-        ExecutionMode::Paper
-    };
-    let execution = Arc::new(ClobExecution::new_with_timeout(
-        exec_mode,
-        execution_cfg.clob_endpoint.clone(),
-        Duration::from_millis(execution_cfg.http_timeout_ms),
-    ));
-    let shadow = Arc::new(ShadowExecutor::default());
-    let strategy_cfg = Arc::new(RwLock::new(load_strategy_config()));
-    let fair_value_cfg = Arc::new(StdRwLock::new(load_fair_value_config()));
-    let toxicity_cfg = Arc::new(RwLock::new(ToxicityConfig::default()));
-    let risk_limits = Arc::new(StdRwLock::new(load_risk_limits_config()));
-    let perf_profile = Arc::new(RwLock::new(load_perf_profile_config()));
-    let allocator_cfg = {
-        let strategy = strategy_cfg.read().await.clone();
-        let tox = toxicity_cfg.read().await.clone();
-        Arc::new(RwLock::new(AllocatorConfig {
-            capital_fraction_kelly: strategy.capital_fraction_kelly,
-            variance_penalty_lambda: strategy.variance_penalty_lambda,
-            active_top_n_markets: tox.active_top_n_markets,
-            ..AllocatorConfig::default()
-        }))
-    };
-    let tox_state = Arc::new(RwLock::new(HashMap::new()));
-    let shadow_stats = Arc::new(ShadowStats::new());
-    let paused = Arc::new(RwLock::new(false));
-    let universe_symbols = Arc::new(universe_cfg.assets.clone());
-    let universe_market_types = Arc::new(universe_cfg.market_types.clone());
-    let universe_timeframes = Arc::new(universe_cfg.timeframes.clone());
-    init_jsonl_writer(perf_profile.clone()).await;
-
-    let state = AppState {
-        paused: paused.clone(),
-        bus: bus.clone(),
-        portfolio: portfolio.clone(),
-        execution: execution.clone(),
-        _shadow: shadow.clone(),
-        prometheus,
-        strategy_cfg: strategy_cfg.clone(),
-        fair_value_cfg: fair_value_cfg.clone(),
-        toxicity_cfg: toxicity_cfg.clone(),
-        allocator_cfg: allocator_cfg.clone(),
-        risk_limits: risk_limits.clone(),
-        tox_state: tox_state.clone(),
-        shadow_stats: shadow_stats.clone(),
-        perf_profile: perf_profile.clone(),
-    };
-
-    let scoring_rebate_factor = std::env::var("POLYEDGE_SCORING_REBATE_FACTOR")
-        .ok()
-        .and_then(|v| v.parse::<f64>().ok())
-        // Worst-case by default: assume no rebate unless we have hard evidence.
-        .unwrap_or(0.0)
-        .clamp(0.0, 1.0);
-
-    let risk_manager = Arc::new(DefaultRiskManager::new(risk_limits.clone()));
-    let shared = Arc::new(EngineShared {
-        latest_books: Arc::new(RwLock::new(HashMap::new())),
-        market_to_symbol: Arc::new(RwLock::new(HashMap::new())),
-        token_to_symbol: Arc::new(RwLock::new(HashMap::new())),
-        fee_cache: Arc::new(RwLock::new(HashMap::new())),
-        fee_refresh_inflight: Arc::new(RwLock::new(HashMap::new())),
-        scoring_cache: Arc::new(RwLock::new(HashMap::new())),
-        scoring_refresh_inflight: Arc::new(RwLock::new(HashMap::new())),
-        http: Client::new(),
-        clob_endpoint: execution_cfg.clob_endpoint.clone(),
-        strategy_cfg,
-        fair_value_cfg,
-        toxicity_cfg,
-        risk_manager,
-        universe_symbols: universe_symbols.clone(),
-        universe_market_types: universe_market_types.clone(),
-        universe_timeframes: universe_timeframes.clone(),
-        rate_limit_rps: execution_cfg.rate_limit_rps.max(0.1),
-        scoring_rebate_factor,
-        tox_state,
-        shadow_stats,
-    });
-
-    spawn_reference_feed(
-        bus.clone(),
-        shared.shadow_stats.clone(),
-        (*universe_symbols).clone(),
-    );
-    spawn_market_feed(
-        bus.clone(),
-        shared.shadow_stats.clone(),
-        (*universe_symbols).clone(),
-        (*universe_market_types).clone(),
-        (*universe_timeframes).clone(),
-    );
-    spawn_strategy_engine(
-        bus.clone(),
-        portfolio,
-        execution.clone(),
-        shadow,
-        paused.clone(),
-        shared.clone(),
-    );
-    orchestration::spawn_periodic_report_persistor(
-        shared.shadow_stats.clone(),
-        shared.tox_state.clone(),
-        execution.clone(),
-        shared.toxicity_cfg.clone(),
-    );
-    orchestration::spawn_data_reconcile_task(
-        bus.clone(),
-        paused.clone(),
-        shared.shadow_stats.clone(),
-    );
-
-    let app = control_api::build_router(state);
-
-    let addr: SocketAddr = "0.0.0.0:8080".parse()?;
-    tracing::info!(%addr, "control api started");
-    axum::serve(tokio::net::TcpListener::bind(addr).await?, app).await?;
-    Ok(())
-}
-
-fn install_rustls_provider() {
-    let _ = rustls::crypto::aws_lc_rs::default_provider().install_default();
+#[inline]
+fn publish_if_telemetry_subscribers(bus: &RingBus<EngineEvent>, event: EngineEvent) {
+    if bus.receiver_count() > 1 {
+        let _ = bus.publish(event);
+    }
 }
 
-fn spawn_reference_feed(bus: RingBus<EngineEvent>, stats: Arc<ShadowStats>, symbols: Vec<String>) {
-    const TS_INVERSION_TOLERANCE_MS: i64 = 250;
+fn spawn_detached<F>(task_name: &'static str, report_normal_exit: bool, fut: F)
+where
+    F: Future<Output = ()> + Send + 'static,
+{
     tokio::spawn(async move {
-        let feed = MultiSourceRefFeed::new(Duration::from_millis(50));
-        if symbols.is_empty() {
-            tracing::warn!("reference feed symbols empty; using fallback BTCUSDT");
-        }
-        let symbols = if symbols.is_empty() {
-            vec!["BTCUSDT".to_string()]
-        } else {
-            symbols
-        };
-        let Ok(mut stream) = feed.stream_ticks(symbols).await else {
-            tracing::error!("reference feed failed to start");
-            return;
-        };
-        let mut ingest_seq: u64 = 0;
-        let mut last_source_ts_by_stream: HashMap<String, i64> = HashMap::new();
-
-        while let Some(item) = stream.next().await {
-            match item {
-                Ok(tick) => {
-                    ingest_seq = ingest_seq.saturating_add(1);
-                    let source_ts = tick.event_ts_exchange_ms.max(tick.event_ts_ms);
-                    let source_seq = source_ts.max(0) as u64;
-                    let valid = !tick.symbol.is_empty()
-                        && tick.price.is_finite()
-                        && tick.price > 0.0
-                        && source_seq > 0;
-                    stats.mark_data_validity(valid);
-                    let stream_key = format!("{}:{}", tick.source, tick.symbol);
-                    if let Some(prev) = last_source_ts_by_stream.get(&stream_key).copied() {
-                        if source_ts + TS_INVERSION_TOLERANCE_MS < prev {
-                            stats.mark_ts_inversion();
-                        }
-                    }
-                    last_source_ts_by_stream.insert(stream_key, source_ts);
-                    stats.mark_ref_tick(tick.recv_ts_ms);
-                    // Hot-path logging: avoid dynamic JSON trees + extra stringify passes.
-                    // Build a single JSONL line and hand it to the async writer.
-                    let tick_json =
-                        serde_json::to_string(&tick).unwrap_or_else(|_| "{}".to_string());
-                    let hash = sha256_hex(&tick_json);
-                    let line = format!(
-                        "{{\"ts_ms\":{},\"source_seq\":{},\"ingest_seq\":{},\"valid\":{},\"sha256\":\"{}\",\"tick\":{}}}",
-                        Utc::now().timestamp_millis(),
-                        source_seq,
-                        ingest_seq,
-                        valid,
-                        hash,
-                        tick_json
-                    );
-                    append_jsonl_line(&dataset_path("raw", "ref_ticks.jsonl"), line);
-                    if !valid {
-                        stats.record_issue("invalid_ref_tick").await;
-                        continue;
-                    }
-                    let _ = bus.publish(EngineEvent::RefTick(tick));
-                }
-                Err(err) => {
-                    tracing::warn!(?err, "reference feed event error");
+        match AssertUnwindSafe(fut).catch_unwind().await {
+            Ok(()) => {
+                if report_normal_exit {
+                    tracing::warn!(task = task_name, "detached task exited");
                 }
             }
-        }
-    });
-}
-
-fn spawn_market_feed(
-    bus: RingBus<EngineEvent>,
-    stats: Arc<ShadowStats>,
-    symbols: Vec<String>,
-    market_types: Vec<String>,
-    timeframes: Vec<String>,
-) {
-    const TS_INVERSION_TOLERANCE_MS: i64 = 250;
-    tokio::spawn(async move {
-        let feed = PolymarketFeed::new_with_universe(
-            Duration::from_millis(50),
-            symbols,
-            market_types,
-            timeframes,
-        );
-        let Ok(mut stream) = feed.stream_books().await else {
-            tracing::error!("market feed failed to start");
-            return;
-        };
-        let mut ingest_seq: u64 = 0;
-        let mut last_source_ts_by_market: HashMap<String, i64> = HashMap::new();
-
-        while let Some(item) = stream.next().await {
-            match item {
-                Ok(book) => {
-                    ingest_seq = ingest_seq.saturating_add(1);
-                    let source_ts = book.ts_ms;
-                    let source_seq = source_ts.max(0) as u64;
-                    let valid = !book.market_id.is_empty()
-                        && book.bid_yes.is_finite()
-                        && book.ask_yes.is_finite()
-                        && book.bid_no.is_finite()
-                        && book.ask_no.is_finite()
-                        && source_seq > 0;
-                    stats.mark_data_validity(valid);
-                    if let Some(prev) = last_source_ts_by_market.get(&book.market_id).copied() {
-                        if source_ts + TS_INVERSION_TOLERANCE_MS < prev {
-                            stats.mark_ts_inversion();
-                        }
-                    }
-                    last_source_ts_by_market.insert(book.market_id.clone(), source_ts);
-                    stats.mark_book_tick(book.ts_ms);
-                    let book_json =
-                        serde_json::to_string(&book).unwrap_or_else(|_| "{}".to_string());
-                    let hash = sha256_hex(&book_json);
-                    let line = format!(
-                        "{{\"ts_ms\":{},\"source_seq\":{},\"ingest_seq\":{},\"valid\":{},\"sha256\":\"{}\",\"book\":{}}}",
-                        Utc::now().timestamp_millis(),
-                        source_seq,
-                        ingest_seq,
-                        valid,
-                        hash,
-                        book_json
-                    );
-                    append_jsonl_line(&dataset_path("raw", "book_tops.jsonl"), line);
-                    if !valid {
-                        stats.record_issue("invalid_book_top").await;
-                        continue;
-                    }
-                    let _ = bus.publish(EngineEvent::BookTop(book));
-                }
-                Err(err) => {
-                    tracing::warn!(?err, "market feed event error");
-                }
+            Err(payload) => {
+                let panic_msg = if let Some(msg) = payload.downcast_ref::<&str>() {
+                    (*msg).to_string()
+                } else if let Some(msg) = payload.downcast_ref::<String>() {
+                    msg.clone()
+                } else {
+                    "unknown panic payload".to_string()
+                };
+                tracing::error!(task = task_name, panic = %panic_msg, "detached task panicked");
+                metrics::counter!("runtime.detached_task_panic").increment(1);
             }
         }
     });
 }
 
-fn spawn_strategy_engine(
-    bus: RingBus<EngineEvent>,
-    portfolio: Arc<PortfolioBook>,
-    execution: Arc<ClobExecution>,
-    shadow: Arc<ShadowExecutor>,
-    paused: Arc<RwLock<bool>>,
-    shared: Arc<EngineShared>,
-) {
-    tokio::spawn(async move {
-        let fair = BasisMrFairValue::new(shared.fair_value_cfg.clone());
-        // Separate fast reference ticks (exchange WS) from anchor ticks (Chainlink RTDS).
-        // Fast ticks drive stale filtering + fair value evaluation; anchor ticks are tracked for
-        // auditing/diagnostics so the trigger stays latency-sensitive.
-        let mut latest_fast_ticks: HashMap<String, RefTick> = HashMap::new();
-        let mut latest_anchor_ticks: HashMap<String, RefTick> = HashMap::new();
-        let mut market_inventory: HashMap<String, InventoryState> = HashMap::new();
-        let mut market_rate_budget: HashMap<String, TokenBucket> = HashMap::new();
-        let mut untracked_issue_cooldown: HashMap<String, Instant> = HashMap::new();
-        let mut book_lag_sample_at: HashMap<String, Instant> = HashMap::new();
-        let mut global_rate_budget = TokenBucket::new(
-            shared.rate_limit_rps,
-            (shared.rate_limit_rps * 2.0).max(1.0),
-        );
-        let mut rx = bus.subscribe();
-        let mut last_discovery_refresh = Instant::now() - Duration::from_secs(3600);
-        let mut last_symbol_retry_refresh = Instant::now() - Duration::from_secs(3600);
-        refresh_market_symbol_map(&shared).await;
-
-        loop {
-            if last_discovery_refresh.elapsed() >= Duration::from_secs(300) {
-                refresh_market_symbol_map(&shared).await;
-                last_discovery_refresh = Instant::now();
-            }
-
-            let recv = rx.recv().await;
-            let Ok(event) = recv else {
-                continue;
-            };
-            let dispatch_start = Instant::now();
-
-            match event {
-                EngineEvent::RefTick(tick) => {
-                    let parse_us = dispatch_start.elapsed().as_secs_f64() * 1_000_000.0;
-                    shared.shadow_stats.push_parse_us(parse_us).await;
-                    insert_latest_ref_tick(&mut latest_fast_ticks, &mut latest_anchor_ticks, tick);
-                }
-                EngineEvent::BookTop(mut book) => {
-                    let parse_us = dispatch_start.elapsed().as_secs_f64() * 1_000_000.0;
-                    shared.shadow_stats.push_parse_us(parse_us).await;
-                    // Coalesce bursty queue traffic to the freshest observable state.
-                    // This trims local backlog and avoids spending cycles on superseded snapshots.
-                    let mut coalesced = 0_u64;
-                    let dynamic_cap = rx.len().saturating_add(64).min(4_096);
-                    let max_coalesced = dynamic_cap.max(256);
-                    while coalesced < max_coalesced as u64 {
-                        match rx.try_recv() {
-                            Ok(EngineEvent::BookTop(next_book)) => {
-                                book = next_book;
-                                coalesced += 1;
-                            }
-                            Ok(EngineEvent::RefTick(next_tick)) => {
-                                insert_latest_ref_tick(
-                                    &mut latest_fast_ticks,
-                                    &mut latest_anchor_ticks,
-                                    next_tick,
-                                );
-                                coalesced += 1;
-                            }
-                            Ok(_) => {
-                                // This subscriber doesn't consume other event kinds.
-                                // Drain them here to keep queue pressure bounded.
-                                coalesced += 1;
-                            }
-                            Err(tokio::sync::broadcast::error::TryRecvError::Empty) => break,
-                            Err(tokio::sync::broadcast::error::TryRecvError::Lagged(_)) => {
-                                shared.shadow_stats.record_issue("bus_lagged").await;
-                                break;
-                            }
-                            Err(tokio::sync::broadcast::error::TryRecvError::Closed) => break,
-                        }
-                    }
-                    if coalesced > 0 {
-                        metrics::counter!("runtime.coalesced_events").increment(coalesced);
-                    }
-
-                    let backlog_depth = rx.len() as f64;
-                    shared.shadow_stats.push_event_backlog(backlog_depth).await;
-                    metrics::histogram!("runtime.event_backlog_depth").record(backlog_depth);
-                    let queue_depth = execution.open_orders_count() as f64;
-                    shared.shadow_stats.push_queue_depth(queue_depth).await;
-                    metrics::histogram!("runtime.open_order_depth").record(queue_depth);
-                    let io_depth = current_jsonl_queue_depth() as f64;
-                    shared.shadow_stats.push_io_queue_depth(io_depth).await;
-                    metrics::histogram!("runtime.jsonl_queue_depth").record(io_depth);
-                    shared
-                        .latest_books
-                        .write()
-                        .await
-                        .insert(book.market_id.clone(), book.clone());
-
-                    let fills = shadow.on_book(&book);
-                    shared.shadow_stats.mark_filled(fills.len() as u64);
-                    for fill in fills {
-                        portfolio.apply_fill(&fill);
-                        let _ = bus.publish(EngineEvent::Fill(fill.clone()));
-                        let ingest_seq = next_normalized_ingest_seq();
-                        append_jsonl(
-                            &dataset_path("normalized", "fills.jsonl"),
-                            &serde_json::json!({
-                                "ts_ms": Utc::now().timestamp_millis(),
-                                "source_seq": Utc::now().timestamp_millis().max(0) as u64,
-                                "ingest_seq": ingest_seq,
-                                "fill": fill
-                            }),
-                        );
-                    }
-
-                    if *paused.read().await {
-                        shared.shadow_stats.record_issue("paused").await;
-                        continue;
-                    }
-                    if shared.shadow_stats.observe_only() {
-                        shared.shadow_stats.record_issue("observe_only").await;
-                        continue;
-                    }
-
-                    let symbol = pick_market_symbol(&shared, &book).await;
-                    let Some(symbol) = symbol else {
-                        if market_is_tracked(&shared, &book).await {
-                            {
-                                let mut states = shared.tox_state.write().await;
-                                let st = states.entry(book.market_id.clone()).or_default();
-                                st.symbol_missing = st.symbol_missing.saturating_add(1);
-                            }
-                            shared.shadow_stats.record_issue("symbol_missing").await;
-                        } else {
-                            let now = Instant::now();
-                            let should_record = untracked_issue_cooldown
-                                .get(&book.market_id)
-                                .map(|last| last.elapsed() >= Duration::from_secs(60))
-                                .unwrap_or(true);
-                            if should_record {
-                                shared.shadow_stats.record_issue("market_untracked").await;
-                                untracked_issue_cooldown.insert(book.market_id.clone(), now);
-                            }
-                        }
-                        if last_symbol_retry_refresh.elapsed() >= Duration::from_secs(15) {
-                            refresh_market_symbol_map(&shared).await;
-                            last_symbol_retry_refresh = Instant::now();
-                        }
-                        continue;
-                    };
-                    let tick_fast = pick_latest_tick(&latest_fast_ticks, &symbol);
-                    let Some(tick_fast) = tick_fast else {
-                        shared.shadow_stats.record_issue("tick_missing").await;
-                        continue;
-                    };
-                    let tick_anchor = pick_latest_tick(&latest_anchor_ticks, &symbol);
-                    if let Some(anchor) = tick_anchor {
-                        let now_ms = Utc::now().timestamp_millis();
-                        let age_ms = now_ms - ref_event_ts_ms(anchor);
-                        if age_ms > 5_000 {
-                            shared.shadow_stats.record_issue("anchor_stale").await;
-                        }
-                    } else {
-                        shared.shadow_stats.record_issue("anchor_missing").await;
-                    }
-                    // For latency-sensitive trading, evaluate fair value on the fastest observable
-                    // reference tick. The Chainlink anchor is tracked for correctness auditing and
-                    // can be used for future calibration, but should not slow down the trigger.
-                    let eval_tick = tick_fast;
-                    shared.shadow_stats.mark_seen();
-
-                    // Positive value means: our fast reference tick arrived earlier than the
-                    // Polymarket book update (i.e. the exploitable lag window).
-                    //
-                    // Guardrail: if the tick is already old, this is not a meaningful "lag window"
-                    // measurement and would inflate p50/p99. We only sample when the tick is fresh.
-                    let tick_age_ms = freshness_ms(Utc::now().timestamp_millis(), tick_fast.recv_ts_ms);
-                    let book_top_lag_ms = if tick_age_ms <= 1_500
-                        && tick_fast.recv_ts_local_ns > 0
-                        && book.recv_ts_local_ns > 0
-                    {
-                        ((book.recv_ts_local_ns - tick_fast.recv_ts_local_ns).max(0) as f64)
-                            / 1_000_000.0
-                    } else {
-                        0.0
-                    };
-                    let should_sample_book_lag = book_lag_sample_at
-                        .get(&symbol)
-                        .map(|t| t.elapsed() >= Duration::from_millis(200))
-                        .unwrap_or(true);
-                    if should_sample_book_lag {
-                        book_lag_sample_at.insert(symbol.clone(), Instant::now());
-                        shared
-                            .shadow_stats
-                            .push_book_top_lag_ms(&symbol, book_top_lag_ms)
-                            .await;
-                    }
-
-                    let latency_sample = estimate_feed_latency(tick_fast, &book);
-                    let feed_in_ms = latency_sample.feed_in_ms;
-                    let stale_tick_filter_ms =
-                        shared.strategy_cfg.read().await.stale_tick_filter_ms;
-                    if feed_in_ms > stale_tick_filter_ms {
-                        shared.shadow_stats.mark_stale_tick_dropped();
-                        shared.shadow_stats.record_issue("stale_tick_dropped").await;
-                        continue;
-                    }
-                    shared.shadow_stats.push_feed_in_ms(feed_in_ms).await;
-                    shared
-                        .shadow_stats
-                        .push_source_latency_ms(latency_sample.source_latency_ms)
-                        .await;
-                    shared
-                        .shadow_stats
-                        .push_local_backlog_ms(latency_sample.local_backlog_ms)
-                        .await;
-                    shared
-                        .shadow_stats
-                        .push_decision_queue_wait_ms(latency_sample.local_backlog_ms)
-                        .await;
-                    metrics::histogram!("latency.feed_in_ms").record(feed_in_ms);
-                    metrics::histogram!("latency.source_latency_ms")
-                        .record(latency_sample.source_latency_ms);
-                    metrics::histogram!("latency.local_backlog_ms")
-                        .record(latency_sample.local_backlog_ms);
-                    let signal_start = Instant::now();
-                    let signal = fair.evaluate(eval_tick, &book);
-                    if signal.edge_bps_bid > 0.0 || signal.edge_bps_ask > 0.0 {
-                        shared.shadow_stats.mark_candidate();
-                    }
-                    let signal_us = signal_start.elapsed().as_secs_f64() * 1_000_000.0;
-                    shared.shadow_stats.push_signal_us(signal_us).await;
-                    metrics::histogram!("latency.signal_us").record(signal_us);
-                    let _ = bus.publish(EngineEvent::Signal(signal.clone()));
-                    if should_sample_book_lag && book_top_lag_ms >= 5.0 {
-                        // "Orderless" survival probe: measure whether an observed top-of-book
-                        // price survives for +Î” ms, independent of order placement.
-                        let mid_yes = (book.bid_yes + book.ask_yes) * 0.5;
-                        let probe_side = if signal.fair_yes >= mid_yes {
-                            OrderSide::BuyYes
-                        } else {
-                            OrderSide::BuyNo
-                        };
-                        let probe_px = aggressive_price_for_side(&book, &probe_side);
-                        if probe_px > 0.0 {
-                            for delay_ms in [5_u64, 10_u64, 25_u64] {
-                                spawn_survival_probe_task(
-                                    shared.clone(),
-                                    book.market_id.clone(),
-                                    symbol.clone(),
-                                    probe_side.clone(),
-                                    probe_px,
-                                    delay_ms,
-                                );
-                            }
-                        }
-                    }
-
-                    let cfg = shared.strategy_cfg.read().await.clone();
-                    let tox_cfg = shared.toxicity_cfg.read().await.clone();
-                    let quote_start = Instant::now();
-                    let inventory = market_inventory
-                        .entry(book.market_id.clone())
-                        .or_insert_with(|| inventory_for_market(&portfolio, &book.market_id))
-                        .clone();
-                    let pending_market_exposure =
-                        execution.open_order_notional_for_market(&book.market_id);
-                    let pending_total_exposure = execution.open_order_notional_total();
-
-                    let (
-                        tox_features,
-                        tox_decision,
-                        market_score,
-                        pending_exposure,
-                        no_quote_rate,
-                        symbol_missing_rate,
-                        markout_samples,
-                        markout_10s_p50,
-                        markout_10s_p25,
-                        active_by_rank,
-                    ) = {
-                        let mut states = shared.tox_state.write().await;
-                        let (
-                            features,
-                            decision,
-                            score,
-                            pending_exposure,
-                            no_quote_rate,
-                            symbol_missing_rate,
-                            markout_samples,
-                            markout_10s_p50,
-                            markout_10s_p25,
-                        ) = {
-                            let st = states.entry(book.market_id.clone()).or_default();
-                            st.attempted = st.attempted.saturating_add(1);
-                            st.symbol = symbol.clone();
-
-                            let features = build_toxic_features(
-                                &book,
-                                &symbol,
-                                feed_in_ms,
-                                signal.fair_yes,
-                                st,
-                            );
-                            let mut decision = evaluate_toxicity(&features, &tox_cfg);
-                            let score_scale = (tox_cfg.k_spread / 1.5).clamp(0.25, 4.0);
-                            decision.tox_score = (decision.tox_score * score_scale).clamp(0.0, 1.0);
-                            decision.regime = if decision.tox_score >= tox_cfg.caution_threshold {
-                                ToxicRegime::Danger
-                            } else if decision.tox_score >= tox_cfg.safe_threshold {
-                                ToxicRegime::Caution
-                            } else {
-                                ToxicRegime::Safe
-                            };
-                            let now_ms = Utc::now().timestamp_millis();
-
-                            if now_ms < st.cooldown_until_ms {
-                                decision.regime = ToxicRegime::Danger;
-                                decision.reason_codes.push("cooldown_active".to_string());
-                            }
-                            if matches!(decision.regime, ToxicRegime::Danger) {
-                                let cool = cooldown_secs_for_score(decision.tox_score, &tox_cfg);
-                                st.cooldown_until_ms =
-                                    st.cooldown_until_ms.max(now_ms + (cool as i64) * 1_000);
-                            }
-                            let markout_samples = st
-                                .markout_1s
-                                .len()
-                                .max(st.markout_5s.len())
-                                .max(st.markout_10s.len());
-                            if markout_samples < 20 {
-                                decision.tox_score =
-                                    decision.tox_score.min(tox_cfg.safe_threshold * 0.8);
-                                decision.regime = ToxicRegime::Safe;
-                                decision
-                                    .reason_codes
-                                    .push("warmup_samples_lt_20".to_string());
-                            }
-                            st.last_tox_score = decision.tox_score;
-                            st.last_regime = decision.regime.clone();
-                            let score =
-                                compute_market_score(st, decision.tox_score, markout_samples);
-                            let markout_10s_p50 =
-                                percentile_deque(&st.markout_10s, 0.50).unwrap_or(0.0);
-                            let markout_10s_p25 =
-                                percentile_deque(&st.markout_10s, 0.25).unwrap_or(0.0);
-                            let pending_exposure = pending_market_exposure;
-                            let attempted = st.attempted.max(1);
-                            let no_quote_rate = st.no_quote as f64 / attempted as f64;
-                            let symbol_missing_rate = st.symbol_missing as f64 / attempted as f64;
-                            (
-                                features,
-                                decision,
-                                score,
-                                pending_exposure,
-                                no_quote_rate,
-                                symbol_missing_rate,
-                                markout_samples,
-                                markout_10s_p50,
-                                markout_10s_p25,
-                            )
-                        };
-                        let active_by_rank = is_market_in_top_n(
-                            &states,
-                            &book.market_id,
-                            tox_cfg.active_top_n_markets,
-                        );
-                        (
-                            features,
-                            decision,
-                            score,
-                            pending_exposure,
-                            no_quote_rate,
-                            symbol_missing_rate,
-                            markout_samples,
-                            markout_10s_p50,
-                            markout_10s_p25,
-                            active_by_rank,
-                        )
-                    };
-                    let spread_yes = (book.ask_yes - book.bid_yes).max(0.0);
-                    let window_outcomes = shared.shadow_stats.window_outcomes_len().await;
-                    let effective_min_edge_bps = adaptive_min_edge_bps(
-                        cfg.min_edge_bps,
-                        tox_decision.tox_score,
-                        markout_samples,
-                        no_quote_rate,
-                        markout_10s_p50,
-                        markout_10s_p25,
-                        window_outcomes,
-                        ShadowStats::GATE_MIN_OUTCOMES,
-                    );
-                    let effective_max_spread = adaptive_max_spread(
-                        cfg.max_spread,
-                        tox_decision.tox_score,
-                        markout_samples,
-                    );
-                    if should_observe_only_symbol(
-                        &symbol,
-                        &cfg,
-                        &tox_decision,
-                        feed_in_ms,
-                        spread_yes,
-                        book_top_lag_ms,
-                    ) {
-                        shared
-                            .shadow_stats
-                            .mark_blocked_with_reason("symbol_quality_guard")
-                            .await;
-                        continue;
-                    }
-                    let queue_fill_proxy =
-                        estimate_queue_fill_proxy(tox_decision.tox_score, spread_yes, feed_in_ms);
-
-                    if spread_yes > effective_max_spread {
-                        {
-                            let mut states = shared.tox_state.write().await;
-                            let st = states.entry(book.market_id.clone()).or_default();
-                            st.no_quote = st.no_quote.saturating_add(1);
-                        }
-                        shared
-                            .shadow_stats
-                            .mark_blocked_with_reason("no_quote_spread")
-                            .await;
-                        continue;
-                    }
-                    if signal.confidence <= 0.0 {
-                        {
-                            let mut states = shared.tox_state.write().await;
-                            let st = states.entry(book.market_id.clone()).or_default();
-                            st.no_quote = st.no_quote.saturating_add(1);
-                        }
-                        shared
-                            .shadow_stats
-                            .mark_blocked_with_reason("no_quote_confidence")
-                            .await;
-                        continue;
-                    }
-
-                    let _ = bus.publish(EngineEvent::ToxicFeatures(tox_features.clone()));
-                    let _ = bus.publish(EngineEvent::ToxicDecision(tox_decision.clone()));
-                    let ingest_seq_features = next_normalized_ingest_seq();
-                    append_jsonl(
-                        &dataset_path("normalized", "tox_features.jsonl"),
-                        &serde_json::json!({
-                            "ts_ms": Utc::now().timestamp_millis(),
-                            "source_seq": book.ts_ms.max(0) as u64,
-                            "ingest_seq": ingest_seq_features,
-                            "features": tox_features
-                        }),
-                    );
-                    let ingest_seq_decisions = next_normalized_ingest_seq();
-                    append_jsonl(
-                        &dataset_path("normalized", "tox_decisions.jsonl"),
-                        &serde_json::json!({
-                            "ts_ms": Utc::now().timestamp_millis(),
-                            "source_seq": book.ts_ms.max(0) as u64,
-                            "ingest_seq": ingest_seq_decisions,
-                            "decision": tox_decision
-                        }),
-                    );
-                    let market_health = MarketHealth {
-                        market_id: book.market_id.clone(),
-                        symbol: symbol.clone(),
-                        symbol_missing_rate,
-                        no_quote_rate,
-                        pending_exposure,
-                        queue_fill_proxy,
-                        ts_ns: now_ns(),
-                    };
-                    let ingest_seq_health = next_normalized_ingest_seq();
-                    append_jsonl(
-                        &dataset_path("normalized", "market_health.jsonl"),
-                        &serde_json::json!({
-                            "ts_ms": Utc::now().timestamp_millis(),
-                            "source_seq": book.ts_ms.max(0) as u64,
-                            "ingest_seq": ingest_seq_health,
-                            "health": market_health
-                        }),
-                    );
-
-                    if market_score < tox_cfg.min_market_score {
-                        shared
-                            .shadow_stats
-                            .mark_blocked_with_reason("market_score_low")
-                            .await;
-                        continue;
-                    }
-                    if !active_by_rank {
-                        shared
-                            .shadow_stats
-                            .mark_blocked_with_reason("market_rank_blocked")
-                            .await;
-                        continue;
-                    }
-
-                    let mut effective_cfg = cfg.clone();
-                    effective_cfg.min_edge_bps = effective_min_edge_bps;
-                    let policy = MakerQuotePolicy::new(effective_cfg);
-                    let mut intents =
-                        policy.build_quotes_with_toxicity(&signal, &inventory, &tox_decision);
-                    if !intents.is_empty() {
-                        let markout_dispersion = (markout_10s_p50 - markout_10s_p25).abs();
-                        let var_penalty = (cfg.variance_penalty_lambda
-                            * (markout_dispersion / 200.0).clamp(0.0, 1.0))
-                        .clamp(0.0, 0.90);
-                        let kelly_scale =
-                            (cfg.capital_fraction_kelly * signal.confidence * (1.0 - var_penalty))
-                                .clamp(0.05, 1.0);
-                        for intent in &mut intents {
-                            intent.size = (intent.size * kelly_scale).max(0.01);
-                        }
-                    }
-                    if !intents.is_empty() {
-                        shared.shadow_stats.mark_quoted(intents.len() as u64);
-                    }
-                    let quote_us = quote_start.elapsed().as_secs_f64() * 1_000_000.0;
-                    shared.shadow_stats.push_quote_us(quote_us).await;
-                    metrics::histogram!("latency.quote_us").record(quote_us);
-
-                    if intents.is_empty() {
-                        {
-                            let mut states = shared.tox_state.write().await;
-                            let st = states.entry(book.market_id.clone()).or_default();
-                            st.no_quote = st.no_quote.saturating_add(1);
-                        }
-                        let edge_blocked = signal.edge_bps_bid < effective_min_edge_bps
-                            && signal.edge_bps_ask < effective_min_edge_bps;
-                        if edge_blocked {
-                            shared
-                                .shadow_stats
-                                .mark_blocked_with_reason("no_quote_edge")
-                                .await;
-                        } else {
-                            shared
-                                .shadow_stats
-                                .mark_blocked_with_reason("no_quote_policy")
-                                .await;
-                        }
-                        continue;
-                    }
-
-                    let fee_bps = get_fee_rate_bps_cached(&shared, &book.market_id).await;
-                    let drawdown = portfolio.snapshot().max_drawdown_pct;
-
-                    for mut intent in intents.drain(..) {
-                        let intent_decision_start = Instant::now();
-                        shared.shadow_stats.mark_attempted();
-
-                        let risk_start = Instant::now();
-                        let proposed_notional_usdc =
-                            (intent.price.max(0.0) * intent.size.max(0.0)).max(0.0);
-                        let ctx = RiskContext {
-                            market_id: intent.market_id.clone(),
-                            symbol: symbol.clone(),
-                            order_count: execution.open_orders_count(),
-                            proposed_size: intent.size,
-                            proposed_notional_usdc,
-                            market_notional: inventory.exposure_notional + pending_market_exposure,
-                            asset_notional: inventory.exposure_notional + pending_total_exposure,
-                            drawdown_pct: drawdown,
-                            loss_streak: shared.shadow_stats.loss_streak(),
-                            now_ms: Utc::now().timestamp_millis(),
-                        };
-                        let decision = shared.risk_manager.evaluate(&ctx);
-                        let risk_us = risk_start.elapsed().as_secs_f64() * 1_000_000.0;
-                        shared.shadow_stats.push_risk_us(risk_us).await;
-                        metrics::histogram!("latency.risk_us").record(risk_us);
-
-                        if !decision.allow {
-                            shared
-                                .shadow_stats
-                                .mark_blocked_with_reason(&format!("risk:{}", decision.reason))
-                                .await;
-                            metrics::counter!("strategy.blocked").increment(1);
-                            continue;
-                        }
-                        if decision.capped_size <= 0.0 {
-                            shared
-                                .shadow_stats
-                                .mark_blocked_with_reason("risk_capped_zero")
-                                .await;
-                            metrics::counter!("strategy.blocked").increment(1);
-                            continue;
-                        }
-                        intent.size = intent.size.min(decision.capped_size);
-
-                        let edge_gross = edge_for_intent(signal.fair_yes, &intent);
-                        let rebate_est_bps =
-                            get_rebate_bps_cached(&shared, &book.market_id, fee_bps).await;
-                        let edge_net = edge_gross - fee_bps + rebate_est_bps;
-                        if edge_net < effective_min_edge_bps {
-                            shared
-                                .shadow_stats
-                                .mark_blocked_with_reason("edge_below_threshold")
-                                .await;
-                            continue;
-                        }
-                        let intended_notional_usdc =
-                            (intent.price.max(0.0) * intent.size.max(0.0)).max(0.0);
-                        if intended_notional_usdc < cfg.min_eval_notional_usdc {
-                            shared
-                                .shadow_stats
-                                .mark_blocked_with_reason("tiny_notional")
-                                .await;
-                            continue;
-                        }
-                        let edge_net_usdc = (edge_net / 10_000.0) * intended_notional_usdc;
-                        if edge_net_usdc < cfg.min_expected_edge_usdc {
-                            shared
-                                .shadow_stats
-                                .mark_blocked_with_reason("edge_notional_too_small")
-                                .await;
-                            continue;
-                        }
-
-                        let mut force_taker = false;
-                        if should_force_taker(
-                            &cfg,
-                            &tox_decision,
-                            edge_net,
-                            signal.confidence,
-                            markout_samples,
-                            no_quote_rate,
-                            window_outcomes,
-                            ShadowStats::GATE_MIN_OUTCOMES,
-                            &symbol,
-                        ) {
-                            let aggressive_price = aggressive_price_for_side(&book, &intent.side);
-                            let passive_price = intent.price.max(1e-6);
-                            let price_move_bps = ((aggressive_price - intent.price).abs()
-                                / passive_price)
-                                * 10_000.0;
-                            let taker_slippage_budget = adaptive_taker_slippage_bps(
-                                cfg.taker_max_slippage_bps,
-                                &cfg.market_tier_profile,
-                                &symbol,
-                                markout_samples,
-                                no_quote_rate,
-                                window_outcomes,
-                                ShadowStats::GATE_MIN_OUTCOMES,
-                            );
-                            if price_move_bps <= taker_slippage_budget {
-                                intent.price = aggressive_price;
-                                intent.ttl_ms = intent.ttl_ms.min(150);
-                                force_taker = true;
-                            } else {
-                                shared
-                                    .shadow_stats
-                                    .mark_blocked_with_reason("taker_slippage_budget")
-                                    .await;
-                                continue;
-                            }
-                        }
-                        let per_market_rps = (shared.rate_limit_rps / 8.0).max(0.5);
-                        let market_bucket = market_rate_budget
-                            .entry(book.market_id.clone())
-                            .or_insert_with(|| {
-                                TokenBucket::new(per_market_rps, (per_market_rps * 2.0).max(1.0))
-                            });
-                        if !global_rate_budget.try_take(1.0) {
-                            shared
-                                .shadow_stats
-                                .mark_blocked_with_reason("rate_budget_global")
-                                .await;
-                            continue;
-                        }
-                        if !market_bucket.try_take(1.0) {
-                            shared
-                                .shadow_stats
-                                .mark_blocked_with_reason("rate_budget_market")
-                                .await;
-                            continue;
-                        }
-                        shared.shadow_stats.mark_eligible();
-
-                        let decision_compute_ms =
-                            intent_decision_start.elapsed().as_secs_f64() * 1_000.0;
-                        let tick_to_decision_ms =
-                            latency_sample.local_backlog_ms + decision_compute_ms;
-                        let place_start = Instant::now();
-                        let execution_style = if force_taker {
-                            ExecutionStyle::Taker
-                        } else {
-                            classify_execution_style(&book, &intent)
-                        };
-                        let tif = match execution_style {
-                            ExecutionStyle::Maker => OrderTimeInForce::PostOnly,
-                            ExecutionStyle::Taker | ExecutionStyle::Arb => OrderTimeInForce::Fak,
-                        };
-                        let v2_intent = OrderIntentV2 {
-                            market_id: intent.market_id.clone(),
-                            side: intent.side.clone(),
-                            price: intent.price,
-                            size: intent.size,
-                            ttl_ms: intent.ttl_ms,
-                            style: execution_style.clone(),
-                            tif,
-                            max_slippage_bps: cfg.taker_max_slippage_bps,
-                            fee_rate_bps: fee_bps,
-                            expected_edge_net_bps: edge_net,
-                            hold_to_resolution: false,
-                        };
-                        match execution.place_order_v2(v2_intent).await {
-                            Ok(ack_v2) if ack_v2.accepted => {
-                                let accepted_size = ack_v2.accepted_size.max(0.0).min(intent.size);
-                                if accepted_size <= 0.0 {
-                                    shared
-                                        .shadow_stats
-                                        .mark_blocked_with_reason("exchange_reject_zero_size")
-                                        .await;
-                                    continue;
-                                }
-                                intent.size = accepted_size;
-                                shared.shadow_stats.mark_executed();
-                                if execution.is_live() && execution_style == ExecutionStyle::Maker {
-                                    maybe_spawn_scoring_refresh(
-                                        &shared,
-                                        &book.market_id,
-                                        &ack_v2.order_id,
-                                        fee_bps,
-                                        Instant::now(),
-                                        Duration::from_secs(2),
-                                    )
-                                    .await;
-                                }
-                                let ack_only_ms = if ack_v2.exchange_latency_ms > 0.0 {
-                                    ack_v2.exchange_latency_ms
-                                } else {
-                                    place_start.elapsed().as_secs_f64() * 1_000.0
-                                };
-                                let tick_to_ack_ms = tick_to_decision_ms + ack_only_ms;
-                                shared
-                                    .shadow_stats
-                                    .push_decision_compute_ms(decision_compute_ms)
-                                    .await;
-                                shared
-                                    .shadow_stats
-                                    .push_tick_to_decision_ms(tick_to_decision_ms)
-                                    .await;
-                                shared.shadow_stats.push_ack_only_ms(ack_only_ms).await;
-                                shared
-                                    .shadow_stats
-                                    .push_tick_to_ack_ms(tick_to_ack_ms)
-                                    .await;
-                                metrics::histogram!("latency.tick_to_decision_ms")
-                                    .record(tick_to_decision_ms);
-                                metrics::histogram!("latency.decision_compute_ms")
-                                    .record(decision_compute_ms);
-                                metrics::histogram!("latency.decision_queue_wait_ms")
-                                    .record(latency_sample.local_backlog_ms);
-                                metrics::histogram!("latency.ack_only_ms").record(ack_only_ms);
-                                metrics::histogram!("latency.tick_to_ack_ms")
-                                    .record(tick_to_ack_ms);
-
-                                let ack = OrderAck {
-                                    order_id: ack_v2.order_id,
-                                    market_id: ack_v2.market_id,
-                                    accepted: true,
-                                    ts_ms: ack_v2.ts_ms,
-                                };
-                                let _ = bus.publish(EngineEvent::OrderAck(ack.clone()));
-                                shadow.register_order(&ack, intent.clone());
-
-                                for delay_ms in [5_u64, 10_u64, 25_u64] {
-                                    let shot = ShadowShot {
-                                        shot_id: new_id(),
-                                        market_id: intent.market_id.clone(),
-                                        symbol: symbol.clone(),
-                                        side: intent.side.clone(),
-                                        execution_style: execution_style.clone(),
-                                        // Use taker top-of-book only for "opportunity survival" probing.
-                                        // Keep intended_price as maker entry for markout/PnL attribution.
-                                        survival_probe_price: aggressive_price_for_side(
-                                            &book,
-                                            &intent.side,
-                                        ),
-                                        intended_price: intent.price,
-                                        size: intent.size,
-                                        edge_gross_bps: edge_gross,
-                                        edge_net_bps: edge_net,
-                                        fee_paid_bps: fee_bps,
-                                        rebate_est_bps,
-                                        delay_ms,
-                                        t0_ns: now_ns(),
-                                        min_edge_bps: effective_min_edge_bps,
-                                        tox_score: tox_decision.tox_score,
-                                        ttl_ms: intent.ttl_ms,
-                                    };
-                                    shared.shadow_stats.push_shot(shot.clone()).await;
-                                    let _ = bus.publish(EngineEvent::ShadowShot(shot.clone()));
-                                    spawn_shadow_outcome_task(shared.clone(), bus.clone(), shot);
-                                }
-                            }
-                            Ok(ack_v2) => {
-                                let reject_code = ack_v2
-                                    .reject_code
-                                    .as_deref()
-                                    .map(normalize_reject_code)
-                                    .unwrap_or_else(|| "unknown".to_string());
-                                shared
-                                    .shadow_stats
-                                    .mark_blocked_with_reason(&format!(
-                                        "exchange_reject_{reject_code}"
-                                    ))
-                                    .await;
-                                metrics::counter!("execution.place_rejected").increment(1);
-                            }
-                            Err(err) => {
-                                let reason = classify_execution_error_reason(&err);
-                                shared.shadow_stats.mark_blocked_with_reason(reason).await;
-                                tracing::warn!(?err, "place_order failed");
-                                metrics::counter!("execution.place_error").increment(1);
-                            }
-                        }
-                    }
-
-                    market_inventory.insert(
-                        book.market_id.clone(),
-                        inventory_for_market(&portfolio, &book.market_id),
-                    );
-                }
-                EngineEvent::Control(ControlCommand::Pause) => {
-                    *paused.write().await = true;
-                    shared.shadow_stats.set_paused(true);
-                }
-                EngineEvent::Control(ControlCommand::Resume) => {
-                    *paused.write().await = false;
-                    shared.shadow_stats.set_paused(false);
-                }
-                EngineEvent::Control(ControlCommand::Flatten) => {
-                    if let Err(err) = execution.flatten_all().await {
-                        tracing::warn!(?err, "flatten from control event failed");
-                    }
-                }
-                _ => {}
-            }
-        }
-    });
-}
-
-fn spawn_shadow_outcome_task(
-    shared: Arc<EngineShared>,
-    bus: RingBus<EngineEvent>,
-    shot: ShadowShot,
-) {
-    tokio::spawn(async move {
-        tokio::time::sleep(Duration::from_millis(shot.delay_ms)).await;
-
-        let book = shared
-            .latest_books
-            .read()
-            .await
-            .get(&shot.market_id)
-            .cloned();
-        let latency_ms = ((now_ns() - shot.t0_ns).max(0) as f64) / 1_000_000.0;
-        shared.shadow_stats.push_shadow_fill_ms(latency_ms).await;
-        metrics::histogram!("latency.shadow_fill_ms").record(latency_ms);
-
-        let (
-            survived,
-            fillable,
-            slippage_bps,
-            queue_fill_prob,
-            attribution,
-            pnl_1s_bps,
-            pnl_5s_bps,
-            pnl_10s_bps,
-        ) = if let Some(book) = book {
-            let survived = evaluate_survival(&shot, &book);
-            let (fillable, slippage_bps, queue_fill_prob) =
-                evaluate_fillable(&shot, &book, latency_ms);
-            if fillable {
-                let p1 = pnl_after_horizon(&shared, &shot, Duration::from_secs(1)).await;
-                let p5 = pnl_after_horizon(&shared, &shot, Duration::from_secs(5)).await;
-                let p10 = pnl_after_horizon(&shared, &shot, Duration::from_secs(10)).await;
-                let attribution = classify_filled_outcome(shot.edge_net_bps, p10, slippage_bps);
-                (
-                    survived,
-                    true,
-                    slippage_bps,
-                    queue_fill_prob,
-                    attribution,
-                    p1,
-                    p5,
-                    p10,
-                )
-            } else {
-                let attribution = classify_unfilled_outcome(
-                    &book,
-                    latency_ms,
-                    shot.delay_ms,
-                    survived,
-                    queue_fill_prob,
-                );
-                (
-                    survived,
-                    false,
-                    slippage_bps,
-                    queue_fill_prob,
-                    attribution,
-                    None,
-                    None,
-                    None,
-                )
-            }
-        } else {
-            (
-                false,
-                false,
-                None,
-                0.0,
-                EdgeAttribution::SignalLag,
-                None,
-                None,
-                None,
-            )
-        };
-        let net_markout_1s_bps = net_markout(pnl_1s_bps, &shot);
-        let net_markout_5s_bps = net_markout(pnl_5s_bps, &shot);
-        let net_markout_10s_bps = net_markout(pnl_10s_bps, &shot);
-        let entry_notional_usdc = estimate_entry_notional_usdc(&shot);
-        let net_markout_10s_usdc = bps_to_usdc(net_markout_10s_bps, entry_notional_usdc);
-        let roi_notional_10s_bps = roi_bps_from_usdc(net_markout_10s_usdc, entry_notional_usdc);
-
-        let outcome = ShadowOutcome {
-            shot_id: shot.shot_id.clone(),
-            market_id: shot.market_id.clone(),
-            symbol: shot.symbol.clone(),
-            side: shot.side.clone(),
-            delay_ms: shot.delay_ms,
-            survived,
-            fillable,
-            execution_style: shot.execution_style.clone(),
-            slippage_bps,
-            pnl_1s_bps,
-            pnl_5s_bps,
-            pnl_10s_bps,
-            net_markout_1s_bps,
-            net_markout_5s_bps,
-            net_markout_10s_bps,
-            entry_notional_usdc,
-            net_markout_10s_usdc,
-            roi_notional_10s_bps,
-            queue_fill_prob,
-            is_stale_tick: false,
-            is_outlier: false,
-            robust_weight: 1.0,
-            attribution,
-            ts_ns: now_ns(),
-        };
-        shared.shadow_stats.push_outcome(outcome.clone()).await;
-        update_toxic_state_from_outcome(&shared, &outcome).await;
-        if shot.delay_ms == 10 {
-            let eval = QuoteEval {
-                market_id: shot.market_id.clone(),
-                symbol: shot.symbol.clone(),
-                survival_10ms: if outcome.survived { 1.0 } else { 0.0 },
-                maker_markout_10s_bps: outcome.net_markout_10s_bps.unwrap_or(0.0),
-                adverse_flag: outcome.net_markout_10s_bps.unwrap_or(0.0) < 0.0,
-                ts_ns: now_ns(),
-            };
-            let ingest_seq = next_normalized_ingest_seq();
-            append_jsonl(
-                &dataset_path("normalized", "quote_eval.jsonl"),
-                &serde_json::json!({
-                    "ts_ms": Utc::now().timestamp_millis(),
-                    "source_seq": shot.t0_ns.max(0) as u64,
-                    "ingest_seq": ingest_seq,
-                    "eval": eval
-                }),
-            );
-            let _ = bus.publish(EngineEvent::QuoteEval(eval));
-        }
-        let _ = bus.publish(EngineEvent::ShadowOutcome(outcome));
-    });
-}
-
-fn spawn_survival_probe_task(
-    shared: Arc<EngineShared>,
-    market_id: String,
-    symbol: String,
-    side: OrderSide,
-    probe_px: f64,
-    delay_ms: u64,
-) {
-    tokio::spawn(async move {
-        tokio::time::sleep(Duration::from_millis(delay_ms)).await;
-        let book = shared.latest_books.read().await.get(&market_id).cloned();
-        let survived = match book {
-            Some(ref b) => is_crossable(&side, probe_px, b),
-            None => false,
-        };
-        shared
-            .shadow_stats
-            .record_survival_probe(&symbol, delay_ms, survived)
-            .await;
-    });
-}
-
-async fn refresh_market_symbol_map(shared: &EngineShared) {
-    let discovery = MarketDiscovery::new(DiscoveryConfig {
-        symbols: (*shared.universe_symbols).clone(),
-        market_types: (*shared.universe_market_types).clone(),
-        timeframes: (*shared.universe_timeframes).clone(),
-        ..DiscoveryConfig::default()
-    });
-    match discovery.discover().await {
-        Ok(markets) => {
-            let mut market_map = HashMap::new();
-            let mut token_map = HashMap::new();
-            for m in markets {
-                market_map.insert(m.market_id.clone(), m.symbol.clone());
-                if let Some(t) = m.token_id_yes {
-                    token_map.insert(t, m.symbol.clone());
-                }
-                if let Some(t) = m.token_id_no {
-                    token_map.insert(t, m.symbol.clone());
-                }
-            }
-            {
-                let mut map = shared.market_to_symbol.write().await;
-                *map = market_map;
-            }
-            {
-                let mut map = shared.token_to_symbol.write().await;
-                *map = token_map;
-            }
-        }
-        Err(err) => {
-            tracing::warn!(?err, "market discovery refresh failed");
-        }
-    }
-}
-
-async fn pick_market_symbol(shared: &EngineShared, book: &BookTop) -> Option<String> {
-    if let Some(v) = shared
-        .market_to_symbol
-        .read()
-        .await
-        .get(&book.market_id)
-        .cloned()
-    {
-        return Some(v);
-    }
-    let token_map = shared.token_to_symbol.read().await;
-    token_map
-        .get(&book.token_id_yes)
-        .cloned()
-        .or_else(|| token_map.get(&book.token_id_no).cloned())
-}
-
-async fn market_is_tracked(shared: &EngineShared, book: &BookTop) -> bool {
-    if shared
-        .market_to_symbol
-        .read()
-        .await
-        .contains_key(&book.market_id)
-    {
-        return true;
-    }
-    let token_map = shared.token_to_symbol.read().await;
-    token_map.contains_key(&book.token_id_yes) || token_map.contains_key(&book.token_id_no)
-}
-
-fn inventory_for_market(portfolio: &PortfolioBook, market_id: &str) -> InventoryState {
-    let positions = portfolio.positions();
-    if let Some(pos) = positions.get(market_id) {
-        InventoryState {
-            market_id: market_id.to_string(),
-            net_yes: pos.yes,
-            net_no: pos.no,
-            exposure_notional: pos.yes.abs() + pos.no.abs(),
-        }
-    } else {
-        InventoryState {
-            market_id: market_id.to_string(),
-            net_yes: 0.0,
-            net_no: 0.0,
-            exposure_notional: 0.0,
-        }
-    }
-}
-fn build_toxic_features(
-    book: &BookTop,
-    symbol: &str,
-    stale_ms: f64,
-    fair_yes: f64,
-    state: &MarketToxicState,
-) -> ToxicFeatures {
-    let mid_yes = ((book.bid_yes + book.ask_yes) * 0.5).max(0.0001);
-    let spread_bps = ((book.ask_yes - book.bid_yes).max(0.0) / mid_yes) * 10_000.0;
-    let microprice_drift = fair_yes - mid_yes;
-    let imbalance_den = (book.bid_yes + book.ask_yes + book.bid_no + book.ask_no).abs();
-    let imbalance = if imbalance_den <= 1e-12 {
-        0.0
-    } else {
-        ((book.bid_yes + book.ask_no) - (book.ask_yes + book.bid_no)) / imbalance_den
-    };
-    let attempted = state.attempted.max(1);
-    let cancel_burst = (state.no_quote as f64 / attempted as f64).clamp(0.0, 1.0);
-
-    ToxicFeatures {
-        market_id: book.market_id.clone(),
-        symbol: symbol.to_string(),
-        markout_1s: percentile_deque(&state.markout_1s, 0.50).unwrap_or(0.0),
-        markout_5s: percentile_deque(&state.markout_5s, 0.50).unwrap_or(0.0),
-        markout_10s: percentile_deque(&state.markout_10s, 0.50).unwrap_or(0.0),
-        spread_bps,
-        microprice_drift,
-        stale_ms,
-        imbalance,
-        cancel_burst,
-        ts_ns: now_ns(),
-    }
-}
-
-fn evaluate_toxicity(features: &ToxicFeatures, cfg: &ToxicityConfig) -> ToxicDecision {
-    let neg_markout_1s = (-features.markout_1s).max(0.0) / 20.0;
-    let neg_markout_5s = (-features.markout_5s).max(0.0) / 20.0;
-    let neg_markout_10s = (-features.markout_10s).max(0.0) / 20.0;
-    let spread_z = features.spread_bps / 50.0;
-    let microprice_drift_z = (features.microprice_drift.abs() * 10_000.0) / 20.0;
-    let stale_z = features.stale_ms / 1_500.0;
-    let raw = cfg.w1 * neg_markout_1s
-        + cfg.w2 * neg_markout_5s
-        + cfg.w3 * neg_markout_10s
-        + cfg.w4 * spread_z
-        + cfg.w5 * microprice_drift_z
-        + cfg.w6 * stale_z;
-    let markout_1s_danger = features.markout_1s <= cfg.markout_1s_danger_bps;
-    let markout_5s_danger = features.markout_5s <= cfg.markout_5s_danger_bps;
-    let markout_10s_danger = features.markout_10s <= cfg.markout_10s_danger_bps;
-    let markout_1s_caution = features.markout_1s <= cfg.markout_1s_caution_bps;
-    let markout_5s_caution = features.markout_5s <= cfg.markout_5s_caution_bps;
-    let markout_10s_caution = features.markout_10s <= cfg.markout_10s_caution_bps;
-
-    let mut horizon_boost = 0.0;
-    if markout_1s_danger {
-        horizon_boost += 0.30;
-    } else if markout_1s_caution {
-        horizon_boost += 0.15;
-    }
-    if markout_5s_danger {
-        horizon_boost += 0.25;
-    } else if markout_5s_caution {
-        horizon_boost += 0.12;
-    }
-    if markout_10s_danger {
-        horizon_boost += 0.20;
-    } else if markout_10s_caution {
-        horizon_boost += 0.10;
-    }
-    let tox_score = (sigmoid(raw) + horizon_boost).clamp(0.0, 1.0);
-
-    let mut reasons = Vec::new();
-    if markout_1s_danger {
-        reasons.push("markout_1s_danger".to_string());
-    } else if markout_1s_caution {
-        reasons.push("markout_1s_caution".to_string());
-    } else if features.markout_1s < 0.0 {
-        reasons.push("markout_1s_negative".to_string());
-    }
-    if markout_5s_danger {
-        reasons.push("markout_5s_danger".to_string());
-    } else if markout_5s_caution {
-        reasons.push("markout_5s_caution".to_string());
-    } else if features.markout_5s < 0.0 {
-        reasons.push("markout_5s_negative".to_string());
-    }
-    if markout_10s_danger {
-        reasons.push("markout_10s_danger".to_string());
-    } else if markout_10s_caution {
-        reasons.push("markout_10s_caution".to_string());
-    } else if features.markout_10s < 0.0 {
-        reasons.push("markout_10s_negative".to_string());
-    }
-    if features.spread_bps > 60.0 {
-        reasons.push("spread_wide".to_string());
-    }
-    if features.stale_ms > 1_500.0 {
-        reasons.push("stale_feed".to_string());
-    }
-    if reasons.is_empty() {
-        reasons.push("normal".to_string());
-    }
-
-    let regime = if markout_1s_danger || markout_5s_danger || markout_10s_danger {
-        ToxicRegime::Danger
-    } else if markout_1s_caution || markout_5s_caution || markout_10s_caution {
-        ToxicRegime::Caution
-    } else if tox_score >= cfg.caution_threshold {
-        ToxicRegime::Danger
-    } else if tox_score >= cfg.safe_threshold {
-        ToxicRegime::Caution
-    } else {
-        ToxicRegime::Safe
-    };
-
-    ToxicDecision {
-        market_id: features.market_id.clone(),
-        symbol: features.symbol.clone(),
-        tox_score,
-        regime,
-        reason_codes: reasons,
-        ts_ns: now_ns(),
-    }
-}
-
-fn compute_market_score(state: &MarketToxicState, tox_score: f64, markout_samples: usize) -> f64 {
-    let attempted = state.attempted.max(1);
-    let no_quote_rate = state.no_quote as f64 / attempted as f64;
-    let symbol_missing_rate = state.symbol_missing as f64 / attempted as f64;
-    let markout_10s = percentile_deque(&state.markout_10s, 0.50).unwrap_or(0.0);
-    if markout_samples < 20 {
-        let warmup_score = 80.0 - no_quote_rate * 6.0 - symbol_missing_rate * 6.0;
-        return warmup_score.clamp(45.0, 100.0);
-    }
-    let score = 70.0 + (markout_10s * 1.5).clamp(-30.0, 30.0)
-        - no_quote_rate * 25.0
-        - symbol_missing_rate * 30.0
-        - tox_score * 20.0;
-    score.clamp(0.0, 100.0)
-}
-
-fn adaptive_min_edge_bps(
-    base_min_edge_bps: f64,
-    tox_score: f64,
-    markout_samples: usize,
-    no_quote_rate: f64,
-    markout_10s_p50: f64,
-    markout_10s_p25: f64,
-    window_outcomes: usize,
-    gate_min_outcomes: usize,
-) -> f64 {
-    if window_outcomes < gate_min_outcomes {
-        let progress = (window_outcomes as f64 / gate_min_outcomes.max(1) as f64).clamp(0.0, 1.0);
-        let warmup_floor = (base_min_edge_bps * 0.15).max(0.5);
-        let warmup_target = (base_min_edge_bps * 0.50).max(warmup_floor);
-        let mut warmup_edge = warmup_floor + (warmup_target - warmup_floor) * progress;
-        if no_quote_rate > 0.85 {
-            warmup_edge *= 0.80;
-        }
-        return warmup_edge.clamp(0.25, base_min_edge_bps.max(0.25));
-    }
-
-    if markout_samples < 20 {
-        return (base_min_edge_bps * 0.5).max(1.0);
-    }
-    let mut out = base_min_edge_bps * (1.0 + tox_score * 0.6);
-    if markout_10s_p50 < 0.0 {
-        out += (-markout_10s_p50) * 0.50;
-    }
-    if markout_10s_p25 < 0.0 {
-        out += (-markout_10s_p25) * 0.35;
-    }
-    if no_quote_rate > 0.95 {
-        out *= 0.9;
-    }
-    out.clamp(1.0, base_min_edge_bps * 2.5)
-}
-
-fn adaptive_max_spread(base_max_spread: f64, tox_score: f64, markout_samples: usize) -> f64 {
-    if markout_samples < 20 {
-        return (base_max_spread * 1.2).clamp(0.003, 0.08);
-    }
-    (base_max_spread * (1.0 - tox_score * 0.35)).clamp(0.002, base_max_spread)
-}
-
-fn should_force_taker(
-    cfg: &MakerConfig,
-    tox: &ToxicDecision,
-    edge_net_bps: f64,
-    confidence: f64,
-    markout_samples: usize,
-    no_quote_rate: f64,
-    window_outcomes: usize,
-    gate_min_outcomes: usize,
-    symbol: &str,
-) -> bool {
-    let profile = cfg.market_tier_profile.to_ascii_lowercase();
-    let aggressive_profile =
-        profile.contains("taker") || profile.contains("aggressive") || profile.contains("latency");
-
-    let warmup_factor = if window_outcomes < gate_min_outcomes {
-        let progress = (window_outcomes as f64 / gate_min_outcomes.max(1) as f64).clamp(0.0, 1.0);
-        // Lower trigger during warmup so the funnel can collect enough comparable samples.
-        (0.70 + 0.30 * progress).clamp(0.60, 1.0)
-    } else {
-        1.0
-    };
-    let no_quote_factor = if no_quote_rate > 0.90 { 0.85 } else { 1.0 };
-    let mut trigger_bps = cfg.taker_trigger_bps.max(0.0) * warmup_factor * no_quote_factor;
-    if symbol.eq_ignore_ascii_case("SOLUSDT")
-        && (profile.contains("sol_guard") || !aggressive_profile)
-    {
-        trigger_bps *= 1.25;
-    }
-
-    if edge_net_bps < trigger_bps {
-        return false;
-    }
-    if matches!(tox.regime, ToxicRegime::Danger) {
-        return false;
-    }
-
-    if matches!(tox.regime, ToxicRegime::Caution) && !aggressive_profile {
-        return false;
-    }
-
-    let min_conf = if markout_samples < 20 || window_outcomes < gate_min_outcomes {
-        0.45
-    } else {
-        0.55
-    };
-    if confidence < min_conf && !aggressive_profile {
-        return false;
-    }
-
-    true
-}
-
-fn adaptive_taker_slippage_bps(
-    base_slippage_bps: f64,
-    market_tier_profile: &str,
-    symbol: &str,
-    markout_samples: usize,
-    no_quote_rate: f64,
-    window_outcomes: usize,
-    gate_min_outcomes: usize,
-) -> f64 {
-    let mut out = base_slippage_bps.max(1.0);
-    let profile = market_tier_profile.to_ascii_lowercase();
-    let aggressive = profile.contains("aggressive") || profile.contains("latency");
-
-    if window_outcomes < gate_min_outcomes || markout_samples < 20 {
-        out *= if no_quote_rate > 0.85 { 1.40 } else { 1.20 };
-    }
-    if aggressive {
-        out *= 1.10;
-    }
-    if symbol.eq_ignore_ascii_case("SOLUSDT") && (profile.contains("sol_guard") || !aggressive) {
-        out *= 0.80;
-    }
-
-    out.clamp(5.0, 60.0)
-}
-
-fn should_observe_only_symbol(
-    symbol: &str,
-    cfg: &MakerConfig,
-    tox: &ToxicDecision,
-    feed_in_ms: f64,
-    spread_yes: f64,
-    book_top_lag_ms: f64,
-) -> bool {
-    if !symbol.eq_ignore_ascii_case("SOLUSDT") {
-        return false;
-    }
-    let profile = cfg.market_tier_profile.to_ascii_lowercase();
-    if !(profile.contains("sol_guard") || profile.contains("balanced")) {
-        return false;
-    }
-
-    // Keep SOL observe-only unless the local "ref lead vs book" lag is within a tight bound.
-    // This avoids letting one slow/volatile venue degrade the overall engine quality.
-    book_top_lag_ms > 130.0
-        || matches!(tox.regime, ToxicRegime::Danger)
-        || feed_in_ms > 250.0
-        || spread_yes > 0.020
-}
-
-fn estimate_queue_fill_proxy(tox_score: f64, spread_yes: f64, feed_in_ms: f64) -> f64 {
-    let spread_pen = (spread_yes / 0.03).clamp(0.0, 1.0);
-    let latency_pen = (feed_in_ms / 800.0).clamp(0.0, 1.0);
-    (1.0 - (tox_score * 0.45 + spread_pen * 0.35 + latency_pen * 0.20)).clamp(0.0, 1.0)
-}
-
-fn estimate_queue_fill_prob(shot: &ShadowShot, book: &BookTop, latency_ms: f64) -> f64 {
-    let spread = match shot.side {
-        OrderSide::BuyYes | OrderSide::SellYes => (book.ask_yes - book.bid_yes).max(0.0),
-        OrderSide::BuyNo | OrderSide::SellNo => (book.ask_no - book.bid_no).max(0.0),
-    };
-    let spread_pen = (spread / 0.03).clamp(0.0, 1.0);
-    let delay_pen = (shot.delay_ms as f64 / 25.0).clamp(0.0, 1.0);
-    let latency_pen = (latency_ms / 100.0).clamp(0.0, 1.0);
-    (1.0 - (shot.tox_score * 0.35 + spread_pen * 0.30 + delay_pen * 0.20 + latency_pen * 0.15))
-        .clamp(0.0, 1.0)
-}
-
-fn is_market_in_top_n(
-    states: &HashMap<String, MarketToxicState>,
-    market_id: &str,
-    top_n: usize,
-) -> bool {
-    if top_n == 0 {
-        return true;
-    }
-    let mut ranked = states
-        .iter()
-        .map(|(id, st)| {
-            let samples = st
-                .markout_1s
-                .len()
-                .max(st.markout_5s.len())
-                .max(st.markout_10s.len());
-            (
-                id.clone(),
-                compute_market_score(st, st.last_tox_score, samples),
-            )
-        })
-        .collect::<Vec<_>>();
-    if ranked.is_empty() {
-        return true;
-    }
-    ranked.sort_by(|a, b| b.1.total_cmp(&a.1));
-    ranked
-        .into_iter()
-        .take(top_n.max(1))
-        .any(|(id, _)| id == market_id)
-}
-
-fn cooldown_secs_for_score(tox_score: f64, cfg: &ToxicityConfig) -> u64 {
-    let t = tox_score.clamp(0.0, 1.0);
-    ((cfg.cooldown_min_sec as f64)
-        + ((cfg.cooldown_max_sec as f64) - (cfg.cooldown_min_sec as f64)) * t)
-        .round() as u64
-}
-
-fn net_markout(markout_bps: Option<f64>, shot: &ShadowShot) -> Option<f64> {
-    markout_bps.map(|v| v - shot.fee_paid_bps + shot.rebate_est_bps)
-}
-
-fn estimate_entry_notional_usdc(shot: &ShadowShot) -> f64 {
-    (shot.intended_price.max(0.0) * shot.size.max(0.0)).max(0.0)
-}
-
-fn bps_to_usdc(bps: Option<f64>, notional_usdc: f64) -> Option<f64> {
-    if notional_usdc <= 0.0 {
-        return None;
-    }
-    bps.map(|v| (v / 10_000.0) * notional_usdc)
-}
-
-fn roi_bps_from_usdc(markout_usdc: Option<f64>, notional_usdc: f64) -> Option<f64> {
-    if notional_usdc <= 0.0 {
-        return None;
-    }
-    markout_usdc.map(|v| (v / notional_usdc) * 10_000.0)
-}
-
-async fn update_toxic_state_from_outcome(shared: &EngineShared, outcome: &ShadowOutcome) {
-    if !outcome.fillable || outcome.delay_ms != 10 {
-        return;
-    }
-    let mut states = shared.tox_state.write().await;
-    let st = states.entry(outcome.market_id.clone()).or_default();
-    if let Some(v) = outcome.net_markout_1s_bps.or(outcome.pnl_1s_bps) {
-        push_rolling(&mut st.markout_1s, v, 2048);
-    }
-    if let Some(v) = outcome.net_markout_5s_bps.or(outcome.pnl_5s_bps) {
-        push_rolling(&mut st.markout_5s, v, 2048);
-    }
-    if let Some(v) = outcome.net_markout_10s_bps.or(outcome.pnl_10s_bps) {
-        push_rolling(&mut st.markout_10s, v, 2048);
-    }
-}
-
-fn push_rolling(dst: &mut VecDeque<f64>, value: f64, cap: usize) {
-    dst.push_back(value);
-    while dst.len() > cap {
-        dst.pop_front();
-    }
-}
-
-fn sigmoid(x: f64) -> f64 {
-    if x >= 0.0 {
-        1.0 / (1.0 + (-x).exp())
-    } else {
-        let ex = x.exp();
-        ex / (1.0 + ex)
-    }
-}
-
-#[derive(Debug, Clone, Copy, Default)]
-struct FeedLatencySample {
-    feed_in_ms: f64,
-    source_latency_ms: f64,
-    local_backlog_ms: f64,
-}
-
-#[derive(Debug, Clone)]
-struct TokenBucket {
-    rps: f64,
-    burst: f64,
-    tokens: f64,
-    last_refill: Instant,
-}
-
-impl TokenBucket {
-    fn new(rps: f64, burst: f64) -> Self {
-        let rps = rps.max(0.1);
-        let burst = burst.max(1.0);
-        Self {
-            rps,
-            burst,
-            tokens: burst,
-            last_refill: Instant::now(),
-        }
-    }
-
-    fn try_take(&mut self, n: f64) -> bool {
-        let now = Instant::now();
-        let dt = now.duration_since(self.last_refill).as_secs_f64();
-        self.last_refill = now;
-        self.tokens = (self.tokens + dt * self.rps).clamp(0.0, self.burst);
-        if self.tokens >= n {
-            self.tokens -= n;
-            true
-        } else {
-            false
-        }
-    }
-}
-
-fn estimate_feed_latency(tick: &RefTick, book: &BookTop) -> FeedLatencySample {
-    let now = now_ns();
-    let now_ms = now / 1_000_000;
-    let tick_source_ms = tick.event_ts_exchange_ms.max(tick.event_ts_ms);
-    let tick_ingest_ms = (tick.recv_ts_ms - tick_source_ms).max(0) as f64;
-    let book_recv_ms = if book.recv_ts_local_ns > 0 {
-        (book.recv_ts_local_ns / 1_000_000).max(0)
-    } else {
-        now_ms
-    };
-    let book_ingest_ms = (book_recv_ms - book.ts_ms).max(0) as f64;
-    let source_latency_ms = tick_ingest_ms.max(book_ingest_ms);
-
-    let latest_recv_ns = if book.recv_ts_local_ns > 0 {
-        tick.recv_ts_local_ns.max(book.recv_ts_local_ns)
-    } else {
-        tick.recv_ts_local_ns
-    };
-    let local_backlog_ms = if latest_recv_ns > 0 {
-        ((now - latest_recv_ns).max(0) as f64) / 1_000_000.0
-    } else {
-        (now_ms - tick.recv_ts_ms.max(book.ts_ms)).max(0) as f64
-    };
-
-    let feed_in_ms = source_latency_ms + local_backlog_ms;
-    FeedLatencySample {
-        feed_in_ms,
-        source_latency_ms,
-        local_backlog_ms,
-    }
-}
-
-fn is_anchor_ref_source(source: &str) -> bool {
-    source == "chainlink_rtds"
-}
-
-fn ref_event_ts_ms(tick: &RefTick) -> i64 {
-    tick.event_ts_exchange_ms.max(tick.event_ts_ms)
-}
-
-fn should_replace_ref_tick(current: &RefTick, next: &RefTick) -> bool {
-    let current_event = ref_event_ts_ms(current);
-    let next_event = ref_event_ts_ms(next);
-    if next_event + 50 < current_event {
-        return false;
-    }
-    if next_event > current_event + 1 {
-        return true;
-    }
-    // If the event timestamps are effectively equal, keep the first-arriving tick for speed.
-    // (The later-arriving copy is usually strictly worse for latency-arb triggers.)
-    false
-}
-
-fn should_replace_anchor_tick(current: &RefTick, next: &RefTick) -> bool {
-    let current_event = ref_event_ts_ms(current);
-    let next_event = ref_event_ts_ms(next);
-    if next_event + 50 < current_event {
-        return false;
-    }
-    if next_event > current_event + 1 {
-        return true;
-    }
-    next.recv_ts_local_ns > current.recv_ts_local_ns + 1_000_000
-}
-
-fn insert_latest_tick(latest_ticks: &mut HashMap<String, RefTick>, tick: RefTick) {
-    match latest_ticks.get(tick.symbol.as_str()) {
-        Some(current) => {
-            if should_replace_ref_tick(current, &tick) {
-                latest_ticks.insert(tick.symbol.clone(), tick);
-            }
-        }
-        None => {
-            latest_ticks.insert(tick.symbol.clone(), tick);
-        }
-    }
-}
-
-fn insert_latest_anchor_tick(latest_ticks: &mut HashMap<String, RefTick>, tick: RefTick) {
-    match latest_ticks.get(tick.symbol.as_str()) {
-        Some(current) => {
-            if should_replace_anchor_tick(current, &tick) {
-                latest_ticks.insert(tick.symbol.clone(), tick);
-            }
-        }
-        None => {
-            latest_ticks.insert(tick.symbol.clone(), tick);
-        }
-    }
-}
-
-fn insert_latest_ref_tick(
-    latest_fast_ticks: &mut HashMap<String, RefTick>,
-    latest_anchor_ticks: &mut HashMap<String, RefTick>,
-    tick: RefTick,
-) {
-    if is_anchor_ref_source(tick.source.as_str()) {
-        insert_latest_anchor_tick(latest_anchor_ticks, tick);
-    } else {
-        insert_latest_tick(latest_fast_ticks, tick);
-    }
-}
-
-fn pick_latest_tick<'a>(
-    latest_ticks: &'a HashMap<String, RefTick>,
-    symbol: &str,
-) -> Option<&'a RefTick> {
-    latest_ticks
-        .get(symbol)
-        .or_else(|| latest_ticks.values().max_by_key(|t| t.recv_ts_ms))
-}
-
-async fn get_fee_rate_bps_cached(shared: &EngineShared, market_id: &str) -> f64 {
-    const DEFAULT_FEE_BPS: f64 = 2.0;
-    const TTL: Duration = Duration::from_secs(60);
-    const REFRESH_BACKOFF: Duration = Duration::from_secs(3);
-
-    let now = Instant::now();
-    let (cached_fee, needs_refresh) =
-        if let Some(entry) = shared.fee_cache.read().await.get(market_id).cloned() {
-            (
-                entry.fee_bps,
-                now.duration_since(entry.fetched_at) >= TTL || entry.fee_bps <= 0.0,
-            )
-        } else {
-            (DEFAULT_FEE_BPS, true)
-        };
-
-    if needs_refresh {
-        maybe_spawn_fee_refresh(shared, market_id, now, REFRESH_BACKOFF).await;
-    }
-
-    cached_fee
-}
-
-async fn get_rebate_bps_cached(shared: &EngineShared, market_id: &str, fee_bps: f64) -> f64 {
-    const TTL: Duration = Duration::from_secs(120);
-    let now = Instant::now();
-    let maybe = shared.scoring_cache.read().await.get(market_id).cloned();
-    match maybe {
-        Some(entry) if now.duration_since(entry.fetched_at) <= TTL => {
-            entry.rebate_bps_est.clamp(0.0, fee_bps.max(0.0))
-        }
-        _ => 0.0,
-    }
-}
-
-async fn maybe_spawn_fee_refresh(
-    shared: &EngineShared,
-    market_id: &str,
-    now: Instant,
-    refresh_backoff: Duration,
-) {
-    {
-        let inflight = shared.fee_refresh_inflight.read().await;
-        if let Some(last_attempt) = inflight.get(market_id) {
-            if now.duration_since(*last_attempt) < refresh_backoff {
-                return;
-            }
-        }
-    }
-
-    {
-        let mut inflight = shared.fee_refresh_inflight.write().await;
-        if let Some(last_attempt) = inflight.get(market_id) {
-            if now.duration_since(*last_attempt) < refresh_backoff {
-                return;
-            }
-        }
-        inflight.insert(market_id.to_string(), now);
-    }
-
-    let market = market_id.to_string();
-    let http = shared.http.clone();
-    let clob_endpoint = shared.clob_endpoint.clone();
-    let fee_cache = shared.fee_cache.clone();
-    let inflight = shared.fee_refresh_inflight.clone();
-    tokio::spawn(async move {
-        if let Some(fee_bps) = fetch_fee_rate_bps(&http, &clob_endpoint, &market).await {
-            fee_cache.write().await.insert(
-                market.clone(),
-                FeeRateEntry {
-                    fee_bps,
-                    fetched_at: Instant::now(),
-                },
-            );
-        }
-        inflight.write().await.remove(&market);
-    });
-}
-
-async fn maybe_spawn_scoring_refresh(
-    shared: &EngineShared,
-    market_id: &str,
-    order_id: &str,
-    fee_bps: f64,
-    now: Instant,
-    refresh_backoff: Duration,
-) {
-    if market_id.is_empty() || order_id.is_empty() {
-        return;
-    }
-    {
-        let inflight = shared.scoring_refresh_inflight.read().await;
-        if let Some(last_attempt) = inflight.get(market_id) {
-            if now.duration_since(*last_attempt) < refresh_backoff {
-                return;
-            }
-        }
-    }
-    {
-        let mut inflight = shared.scoring_refresh_inflight.write().await;
-        if let Some(last_attempt) = inflight.get(market_id) {
-            if now.duration_since(*last_attempt) < refresh_backoff {
-                return;
-            }
-        }
-        inflight.insert(market_id.to_string(), now);
-    }
-
-    let market = market_id.to_string();
-    let order = order_id.to_string();
-    let http = shared.http.clone();
-    let clob_endpoint = shared.clob_endpoint.clone();
-    let scoring_cache = shared.scoring_cache.clone();
-    let inflight = shared.scoring_refresh_inflight.clone();
-    let rebate_factor = shared.scoring_rebate_factor;
-    tokio::spawn(async move {
-        if let Some((scoring_ok, raw)) = fetch_order_scoring(&http, &clob_endpoint, &order).await {
-            let mut cache = scoring_cache.write().await;
-            let mut entry = cache.get(&market).cloned().unwrap_or(ScoringState {
-                scoring_true: 0,
-                scoring_total: 0,
-                rebate_bps_est: 0.0,
-                fetched_at: Instant::now(),
-            });
-            entry.scoring_total = entry.scoring_total.saturating_add(1);
-            if scoring_ok {
-                entry.scoring_true = entry.scoring_true.saturating_add(1);
-            }
-            let hit_ratio = if entry.scoring_total == 0 {
-                0.0
-            } else {
-                (entry.scoring_true as f64 / entry.scoring_total as f64).clamp(0.0, 1.0)
-            };
-            // Conservative estimate: maker rebates are a fraction of taker fees and depend on
-            // scoring + market share. Default rebate_factor is 0.0 unless explicitly configured.
-            // Cap the pool fraction at 20% of fee_bps as a hard upper bound.
-            entry.rebate_bps_est = (fee_bps.max(0.0) * 0.20 * hit_ratio * rebate_factor)
-                .clamp(0.0, fee_bps.max(0.0));
-            entry.fetched_at = Instant::now();
-            let log_row = serde_json::json!({
-                "ts_ms": Utc::now().timestamp_millis(),
-                "market_id": market,
-                "order_id": order,
-                "scoring_ok": scoring_ok,
-                "scoring_true": entry.scoring_true,
-                "scoring_total": entry.scoring_total,
-                "hit_ratio": hit_ratio,
-                "rebate_bps_est": entry.rebate_bps_est,
-                "raw": raw
-            });
-            cache.insert(market.clone(), entry);
-            append_jsonl(
-                &dataset_path("normalized", "scoring_feedback.jsonl"),
-                &log_row,
-            );
-        }
-        inflight.write().await.remove(&market);
-    });
-}
-
-async fn fetch_fee_rate_bps(http: &Client, clob_endpoint: &str, market_id: &str) -> Option<f64> {
-    let base = clob_endpoint.trim_end_matches('/');
-    let endpoints = [
-        format!("{base}/fee-rate?market_id={market_id}"),
-        format!("{base}/fee-rate?market={market_id}"),
-        format!("{base}/fee-rate?token_id={market_id}"),
-    ];
-
-    for url in endpoints {
-        let Ok(resp) = http.get(&url).send().await else {
-            continue;
-        };
-        let Ok(resp) = resp.error_for_status() else {
-            continue;
-        };
-        let Ok(v) = resp.json::<serde_json::Value>().await else {
-            continue;
-        };
-        let candidate = v
-            .get("fee_rate_bps")
-            .and_then(value_to_f64)
-            .or_else(|| v.get("feeRateBps").and_then(value_to_f64))
-            .or_else(|| v.get("makerFeeRateBps").and_then(value_to_f64))
-            .or_else(|| v.get("maker_fee_rate_bps").and_then(value_to_f64));
-        if candidate.is_some() {
-            return candidate;
-        }
-    }
-    None
-}
-
-async fn fetch_order_scoring(
-    http: &Client,
-    clob_endpoint: &str,
-    order_id: &str,
-) -> Option<(bool, serde_json::Value)> {
-    let base = clob_endpoint.trim_end_matches('/');
-    let endpoints = [
-        format!("{base}/order-scoring?order_id={order_id}"),
-        format!("{base}/order-scoring?orderId={order_id}"),
-        format!("{base}/orders-scoring?order_id={order_id}"),
-    ];
-    for url in endpoints {
-        let Ok(resp) = http.get(&url).send().await else {
-            continue;
-        };
-        let Ok(resp) = resp.error_for_status() else {
-            continue;
-        };
-        let Ok(value) = resp.json::<serde_json::Value>().await else {
-            continue;
-        };
-        let scoring = value
-            .get("scoring")
-            .and_then(|v| v.as_bool())
-            .or_else(|| value.get("is_scoring").and_then(|v| v.as_bool()))
-            .or_else(|| value.get("isScoring").and_then(|v| v.as_bool()))
-            .or_else(|| value.get("eligible").and_then(|v| v.as_bool()))
-            .or_else(|| value.as_bool())
-            .unwrap_or(false);
-        return Some((scoring, value));
-    }
-    None
-}
-
-async fn pnl_after_horizon(
-    shared: &EngineShared,
-    shot: &ShadowShot,
-    horizon: Duration,
-) -> Option<f64> {
-    tokio::time::sleep(horizon).await;
-    let book = shared
-        .latest_books
-        .read()
-        .await
-        .get(&shot.market_id)
-        .cloned()?;
-    let mark = mid_for_side(&book, &shot.side);
-    if shot.intended_price <= 0.0 {
-        return None;
-    }
-    let pnl = match shot.side {
-        OrderSide::BuyYes | OrderSide::BuyNo => {
-            ((mark - shot.intended_price) / shot.intended_price) * 10_000.0
-        }
-        OrderSide::SellYes | OrderSide::SellNo => {
-            ((shot.intended_price - mark) / shot.intended_price) * 10_000.0
-        }
-    };
-    Some(pnl)
-}
-
-fn evaluate_survival(shot: &ShadowShot, book: &BookTop) -> bool {
-    let probe_px = if shot.survival_probe_price > 0.0 {
-        shot.survival_probe_price
-    } else {
-        shot.intended_price
-    };
-    is_crossable(&shot.side, probe_px, book)
-}
-
-fn is_crossable(side: &OrderSide, probe_px: f64, book: &BookTop) -> bool {
-    if probe_px <= 0.0 {
-        return false;
-    }
-    match side {
-        OrderSide::BuyYes => probe_px >= book.ask_yes,
-        OrderSide::SellYes => probe_px <= book.bid_yes,
-        OrderSide::BuyNo => probe_px >= book.ask_no,
-        OrderSide::SellNo => probe_px <= book.bid_no,
-    }
-}
-
-fn evaluate_fillable(
-    shot: &ShadowShot,
-    book: &BookTop,
-    latency_ms: f64,
-) -> (bool, Option<f64>, f64) {
-    let probe_px = if shot.survival_probe_price > 0.0 {
-        shot.survival_probe_price
-    } else {
-        shot.intended_price
-    };
-    let (crossable, fill_px) = match shot.side {
-        OrderSide::BuyYes => (probe_px >= book.ask_yes, book.ask_yes),
-        OrderSide::SellYes => (probe_px <= book.bid_yes, book.bid_yes),
-        OrderSide::BuyNo => (probe_px >= book.ask_no, book.ask_no),
-        OrderSide::SellNo => (probe_px <= book.bid_no, book.bid_no),
-    };
-    if !crossable || probe_px <= 0.0 {
-        return (false, None, 0.0);
-    }
-    let queue_fill_prob = estimate_queue_fill_prob(shot, book, latency_ms);
-    if queue_fill_prob < 0.55 {
-        return (false, None, queue_fill_prob);
-    }
-    let mut slippage = match shot.side {
-        OrderSide::BuyYes | OrderSide::BuyNo => ((fill_px - probe_px) / probe_px) * 10_000.0,
-        OrderSide::SellYes | OrderSide::SellNo => ((probe_px - fill_px) / probe_px) * 10_000.0,
-    };
-    slippage += (1.0 - queue_fill_prob) * 8.0;
-    (true, Some(slippage), queue_fill_prob)
-}
-
-fn classify_unfilled_outcome(
-    book: &BookTop,
-    latency_ms: f64,
-    delay_ms: u64,
-    survived: bool,
-    queue_fill_prob: f64,
-) -> EdgeAttribution {
-    let spread = (book.ask_yes - book.bid_yes).max(0.0);
-    if delay_ms >= 400 {
-        return EdgeAttribution::StaleQuote;
-    }
-    if !survived {
-        return EdgeAttribution::BookMoved;
-    }
-    if book.ask_yes <= 0.0 || book.bid_yes <= 0.0 {
-        return EdgeAttribution::LiquidityThin;
-    }
-    if spread > 0.05 {
-        return EdgeAttribution::SpreadTooWide;
-    }
-    if queue_fill_prob < 0.55 {
-        return EdgeAttribution::LatencyTail;
-    }
-    if latency_ms > 100.0 {
-        return EdgeAttribution::LatencyTail;
-    }
-    EdgeAttribution::BookMoved
-}
-
-fn classify_filled_outcome(
-    edge_net_bps: f64,
-    pnl_10s_bps: Option<f64>,
-    slippage_bps: Option<f64>,
-) -> EdgeAttribution {
-    if edge_net_bps < 0.0 {
-        return EdgeAttribution::FeeOverrun;
-    }
-    if slippage_bps.unwrap_or(0.0) > edge_net_bps.abs() {
-        return EdgeAttribution::SignalLag;
-    }
-    if pnl_10s_bps.unwrap_or(0.0) < 0.0 {
-        return EdgeAttribution::AdverseSelection;
-    }
-    EdgeAttribution::Unknown
-}
-
-fn mid_for_side(book: &BookTop, side: &OrderSide) -> f64 {
-    match side {
-        OrderSide::BuyYes | OrderSide::SellYes => (book.bid_yes + book.ask_yes) * 0.5,
-        OrderSide::BuyNo | OrderSide::SellNo => (book.bid_no + book.ask_no) * 0.5,
-    }
-}
-
-fn aggressive_price_for_side(book: &BookTop, side: &OrderSide) -> f64 {
-    match side {
-        OrderSide::BuyYes => book.ask_yes,
-        OrderSide::SellYes => book.bid_yes,
-        OrderSide::BuyNo => book.ask_no,
-        OrderSide::SellNo => book.bid_no,
-    }
-}
-
-fn edge_for_intent(fair_yes: f64, intent: &QuoteIntent) -> f64 {
-    let px = intent.price.max(1e-6);
-    match intent.side {
-        // Expected edge vs. intended entry price in bps of entry.
-        OrderSide::BuyYes | OrderSide::BuyNo => ((fair_yes - px) / px) * 10_000.0,
-        OrderSide::SellYes | OrderSide::SellNo => ((px - fair_yes) / px) * 10_000.0,
-    }
-}
-
-async fn build_toxicity_live_report(
-    tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
-    shadow_stats: Arc<ShadowStats>,
-    execution: Arc<ClobExecution>,
-    toxicity_cfg: Arc<RwLock<ToxicityConfig>>,
-) -> ToxicityLiveReport {
-    let cfg = toxicity_cfg.read().await.clone();
-    let states = tox_state.read().await.clone();
-    let shots = shadow_stats.shots.read().await.clone();
-    let outcomes = shadow_stats.outcomes.read().await.clone();
-
-    let mut rows = Vec::<ToxicityMarketRow>::new();
-    let mut safe = 0usize;
-    let mut caution = 0usize;
-    let mut danger = 0usize;
-    let mut tox_sum = 0.0;
-
-    for (market_id, st) in states {
-        let symbol = if !st.symbol.is_empty() {
-            st.symbol.clone()
-        } else {
-            shots
-                .iter()
-                .find(|s| s.market_id == market_id)
-                .map(|s| s.symbol.clone())
-                .or_else(|| {
-                    outcomes
-                        .iter()
-                        .find(|o| o.market_id == market_id)
-                        .map(|o| o.symbol.clone())
-                })
-                .unwrap_or_else(|| "UNKNOWN".to_string())
-        };
-        let attempted = st.attempted.max(1);
-        let no_quote_rate = st.no_quote as f64 / attempted as f64;
-        let symbol_missing_rate = st.symbol_missing as f64 / attempted as f64;
-        let markout_10s_bps = percentile_deque(&st.markout_10s, 0.50).unwrap_or(0.0);
-        let markout_samples = st
-            .markout_1s
-            .len()
-            .max(st.markout_5s.len())
-            .max(st.markout_10s.len());
-        let market_score = compute_market_score(&st, st.last_tox_score, markout_samples);
-        let pending_exposure = execution.open_order_notional_for_market(&market_id);
-
-        tox_sum += st.last_tox_score;
-        match st.last_regime {
-            ToxicRegime::Safe => safe += 1,
-            ToxicRegime::Caution => caution += 1,
-            ToxicRegime::Danger => danger += 1,
-        }
-
-        rows.push(ToxicityMarketRow {
-            market_rank: 0,
-            market_id,
-            symbol,
-            tox_score: st.last_tox_score,
-            regime: st.last_regime,
-            market_score,
-            markout_10s_bps,
-            no_quote_rate,
-            symbol_missing_rate,
-            pending_exposure,
-            active_for_quoting: false,
-        });
-    }
-
-    rows.sort_by(|a, b| b.market_score.total_cmp(&a.market_score));
-    let top_n = cfg.active_top_n_markets;
-    for (idx, row) in rows.iter_mut().enumerate() {
-        row.market_rank = idx + 1;
-        row.active_for_quoting = top_n == 0 || (idx < top_n);
-    }
-    let avg = if rows.is_empty() {
-        0.0
-    } else {
-        tox_sum / (rows.len() as f64)
-    };
-
-    ToxicityLiveReport {
-        ts_ms: Utc::now().timestamp_millis(),
-        average_tox_score: avg,
-        safe_count: safe,
-        caution_count: caution,
-        danger_count: danger,
-        rows,
-    }
-}
-
-fn load_fair_value_config() -> BasisMrConfig {
-    let path = Path::new("configs/strategy.toml");
-    let Ok(raw) = fs::read_to_string(path) else {
-        return BasisMrConfig::default();
-    };
-
-    let mut cfg = BasisMrConfig::default();
-    let mut in_section = false;
-    for line in raw.lines() {
-        let line = line.trim();
-        if line.is_empty() || line.starts_with('#') {
-            continue;
-        }
-        if line.starts_with('[') && line.ends_with(']') {
-            in_section = line == "[fair_value.basis_mr]";
-            continue;
-        }
-        if !in_section {
-            continue;
-        }
-        let Some((k, v)) = line.split_once('=') else {
-            continue;
-        };
-        let key = k.trim();
-        let val = v.trim().trim_matches('"');
-        match key {
-            "enabled" => {
-                if let Ok(parsed) = val.parse::<bool>() {
-                    cfg.enabled = parsed;
-                }
-            }
-            "alpha_mean" => {
-                if let Ok(parsed) = val.parse::<f64>() {
-                    cfg.alpha_mean = parsed.clamp(0.0, 1.0);
-                }
-            }
-            "alpha_var" => {
-                if let Ok(parsed) = val.parse::<f64>() {
-                    cfg.alpha_var = parsed.clamp(0.0, 1.0);
-                }
-            }
-            "alpha_ret" => {
-                if let Ok(parsed) = val.parse::<f64>() {
-                    cfg.alpha_ret = parsed.clamp(0.0, 1.0);
-                }
-            }
-            "alpha_vol" => {
-                if let Ok(parsed) = val.parse::<f64>() {
-                    cfg.alpha_vol = parsed.clamp(0.0, 1.0);
-                }
-            }
-            "k_revert" => {
-                if let Ok(parsed) = val.parse::<f64>() {
-                    cfg.k_revert = parsed.clamp(0.0, 5.0);
-                }
-            }
-            "z_cap" => {
-                if let Ok(parsed) = val.parse::<f64>() {
-                    cfg.z_cap = parsed.clamp(0.5, 8.0);
-                }
-            }
-            "min_confidence" => {
-                if let Ok(parsed) = val.parse::<f64>() {
-                    cfg.min_confidence = parsed.clamp(0.0, 1.0);
-                }
-            }
-            "warmup_ticks" => {
-                if let Ok(parsed) = val.parse::<usize>() {
-                    cfg.warmup_ticks = parsed.max(1);
-                }
-            }
-            _ => {}
-        }
-    }
-    cfg
-}
-
-#[derive(Debug, Clone, Serialize, Deserialize)]
-struct UniverseConfig {
-    assets: Vec<String>,
-    market_types: Vec<String>,
-    timeframes: Vec<String>,
-    tier_whitelist: Vec<String>,
-    tier_blacklist: Vec<String>,
-}
-
-impl Default for UniverseConfig {
-    fn default() -> Self {
-        Self {
-            assets: vec![
-                "BTCUSDT".to_string(),
-                "ETHUSDT".to_string(),
-                "SOLUSDT".to_string(),
-                "XRPUSDT".to_string(),
-            ],
-            market_types: vec![
-                "updown".to_string(),
-                "above_below".to_string(),
-                "range".to_string(),
-            ],
-            timeframes: vec![
-                "5m".to_string(),
-                "15m".to_string(),
-                "1h".to_string(),
-                "1d".to_string(),
-            ],
-            tier_whitelist: Vec::new(),
-            tier_blacklist: Vec::new(),
-        }
-    }
-}
-
-fn parse_toml_array_of_strings(val: &str) -> Vec<String> {
-    let trimmed = val.trim();
-    if !(trimmed.starts_with('[') && trimmed.ends_with(']')) {
-        return Vec::new();
-    }
-    let inner = &trimmed[1..trimmed.len() - 1];
-    inner
-        .split(',')
-        .map(|s| s.trim().trim_matches('"').trim_matches('\'').to_string())
-        .filter(|s| !s.is_empty())
-        .collect::<Vec<_>>()
-}
-
-fn parse_toml_array_for_key(raw: &str, key: &str) -> Option<Vec<String>> {
-    let mut collecting = false;
-    let mut buf = String::new();
-
-    for line in raw.lines() {
-        let trimmed = line.trim();
-        if trimmed.is_empty() || trimmed.starts_with('#') {
-            continue;
-        }
-
-        if !collecting {
-            let Some((k, v)) = trimmed.split_once('=') else {
-                continue;
-            };
-            if k.trim() != key {
-                continue;
-            }
-            let value = v.trim();
-            buf.push_str(value);
-            collecting = !(value.starts_with('[') && value.ends_with(']'));
-            if !collecting {
-                break;
-            }
-            continue;
-        }
-
-        // Keep concatenating multiline array items until closing ']'.
-        buf.push_str(trimmed);
-        if trimmed.ends_with(']') {
-            break;
-        }
-    }
-
-    if buf.is_empty() {
-        return None;
-    }
-    let parsed = parse_toml_array_of_strings(&buf);
-    if parsed.is_empty() {
-        None
-    } else {
-        Some(parsed)
-    }
-}
-
-fn load_strategy_config() -> MakerConfig {
-    let path = Path::new("configs/strategy.toml");
-    let Ok(raw) = fs::read_to_string(path) else {
-        return MakerConfig::default();
-    };
-    let mut cfg = MakerConfig::default();
-    let mut in_maker = false;
-    let mut in_taker = false;
-    let mut in_online = false;
-    for line in raw.lines() {
-        let line = line.trim();
-        if line.is_empty() || line.starts_with('#') {
-            continue;
-        }
-        if line.starts_with('[') && line.ends_with(']') {
-            in_maker = line == "[maker]";
-            in_taker = line == "[taker]";
-            in_online = line == "[online_calibration]";
-            continue;
-        }
-        let Some((k, v)) = line.split_once('=') else {
-            continue;
-        };
-        let key = k.trim();
-        let val = v.trim().trim_matches('"');
-        if in_maker {
-            match key {
-                "base_quote_size" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.base_quote_size = parsed.max(0.01);
-                    }
-                }
-                "min_edge_bps" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.min_edge_bps = parsed.max(0.0);
-                    }
-                }
-                "inventory_skew" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.inventory_skew = parsed.clamp(0.0, 1.0);
-                    }
-                }
-                "max_spread" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.max_spread = parsed.max(0.0001);
-                    }
-                }
-                "ttl_ms" => {
-                    if let Ok(parsed) = val.parse::<u64>() {
-                        cfg.ttl_ms = parsed.max(50);
-                    }
-                }
-                _ => {}
-            }
-        } else if in_taker {
-            match key {
-                "trigger_bps" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.taker_trigger_bps = parsed.max(0.0);
-                    }
-                }
-                "max_slippage_bps" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.taker_max_slippage_bps = parsed.max(0.0);
-                    }
-                }
-                "stale_tick_filter_ms" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.stale_tick_filter_ms = parsed.clamp(50.0, 5_000.0);
-                    }
-                }
-                "market_tier_profile" => {
-                    cfg.market_tier_profile = val.to_string();
-                }
-                _ => {}
-            }
-        } else if in_online {
-            match key {
-                "capital_fraction_kelly" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.capital_fraction_kelly = parsed.clamp(0.01, 1.0);
-                    }
-                }
-                "variance_penalty_lambda" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.variance_penalty_lambda = parsed.clamp(0.0, 5.0);
-                    }
-                }
-                "min_eval_notional_usdc" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.min_eval_notional_usdc = parsed.max(0.0);
-                    }
-                }
-                "min_expected_edge_usdc" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.min_expected_edge_usdc = parsed.max(0.0);
-                    }
-                }
-                _ => {}
-            }
-        }
-    }
-    cfg
-}
-
-fn load_risk_limits_config() -> RiskLimits {
-    let path = Path::new("configs/risk.toml");
-    let Ok(raw) = fs::read_to_string(path) else {
-        let mut defaults = RiskLimits::default();
-        defaults.max_drawdown_pct = 0.015;
-        return defaults;
-    };
-    let mut cfg = RiskLimits::default();
-    cfg.max_drawdown_pct = 0.015;
-    let mut in_max = false;
-    for line in raw.lines() {
-        let line = line.trim();
-        if line.is_empty() || line.starts_with('#') {
-            continue;
-        }
-        if line.starts_with('[') && line.ends_with(']') {
-            in_max = line == "[max]";
-            continue;
-        }
-        let Some((k, v)) = line.split_once('=') else {
-            continue;
-        };
-        let key = k.trim();
-        let val = v.trim().trim_matches('"');
-        if in_max {
-            match key {
-                "market_notional" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.max_market_notional = parsed.max(0.0);
-                    }
-                }
-                "asset_notional" => {
-                    if let Ok(parsed) = val.parse::<f64>() {
-                        cfg.max_asset_notional = parsed.max(0.0);
-                    }
-                }
-                "open_orders" => {
-                    if let Ok(parsed) = val.parse::<usize>() {
-                        cfg.max_open_orders = parsed.max(1);
-                    }
-                }
-                "max_loss_streak" => {
-                    if let Ok(parsed) = val.parse::<u32>() {
-                        cfg.max_loss_streak = parsed.max(1);
-                    }
-                }
-                "cooldown_sec" => {
-                    if let Ok(parsed) = val.parse::<u64>() {
-                        cfg.cooldown_sec = parsed.max(1);
-                    }
-                }
-                _ => {}
-            }
-        }
-        if key == "drawdown_stop_pct" {
-            if let Ok(parsed) = val.parse::<f64>() {
-                cfg.max_drawdown_pct = parsed.clamp(0.001, 1.0);
-            }
-        } else if key == "max_loss_streak" {
-            if let Ok(parsed) = val.parse::<u32>() {
-                cfg.max_loss_streak = parsed.max(1);
-            }
-        } else if key == "cooldown_sec" {
-            if let Ok(parsed) = val.parse::<u64>() {
-                cfg.cooldown_sec = parsed.max(1);
-            }
-        }
-    }
-    cfg
-}
-
-fn load_execution_config() -> ExecutionConfig {
-    let path = Path::new("configs/execution.toml");
-    let Ok(raw) = fs::read_to_string(path) else {
-        return ExecutionConfig::default();
-    };
-    let mut cfg = ExecutionConfig::default();
-    let mut in_execution = false;
-    for line in raw.lines() {
-        let line = line.trim();
-        if line.is_empty() || line.starts_with('#') {
-            continue;
-        }
-        if line.starts_with('[') && line.ends_with(']') {
-            in_execution = line == "[execution]";
-            continue;
-        }
-        if !in_execution {
-            continue;
-        }
-        let Some((k, v)) = line.split_once('=') else {
-            continue;
-        };
-        let key = k.trim();
-        let val = v.trim().trim_matches('"');
-        match key {
-            "mode" => cfg.mode = val.to_string(),
-            "rate_limit_rps" => {
-                if let Ok(parsed) = val.parse::<f64>() {
-                    cfg.rate_limit_rps = parsed.max(0.1);
-                }
-            }
-            "http_timeout_ms" => {
-                if let Ok(parsed) = val.parse::<u64>() {
-                    cfg.http_timeout_ms = parsed.max(100);
-                }
-            }
-            "clob_endpoint" => cfg.clob_endpoint = val.to_string(),
-            _ => {}
-        }
-    }
-    cfg
-}
-
-fn load_universe_config() -> UniverseConfig {
-    let path = Path::new("configs/universe.toml");
-    let Ok(raw) = fs::read_to_string(path) else {
-        return UniverseConfig::default();
-    };
-    let mut cfg = UniverseConfig::default();
-    if let Some(parsed) = parse_toml_array_for_key(&raw, "assets") {
-        cfg.assets = parsed;
-    }
-    if let Some(parsed) = parse_toml_array_for_key(&raw, "market_types") {
-        cfg.market_types = parsed;
-    }
-    if let Some(parsed) = parse_toml_array_for_key(&raw, "timeframes") {
-        cfg.timeframes = parsed;
-    }
-    if let Some(parsed) = parse_toml_array_for_key(&raw, "tier_whitelist") {
-        cfg.tier_whitelist = parsed;
-    }
-    if let Some(parsed) = parse_toml_array_for_key(&raw, "tier_blacklist") {
-        cfg.tier_blacklist = parsed;
-    }
-    cfg
-}
-
-fn load_perf_profile_config() -> PerfProfile {
-    let path = Path::new("configs/latency.toml");
-    let Ok(raw) = fs::read_to_string(path) else {
-        return PerfProfile::default();
-    };
-
-    let mut cfg = PerfProfile::default();
-    let mut in_runtime = false;
-    for line in raw.lines() {
-        let line = line.trim();
-        if line.is_empty() || line.starts_with('#') {
-            continue;
-        }
-        if line.starts_with('[') && line.ends_with(']') {
-            in_runtime = line == "[runtime]";
-            continue;
-        }
-        if !in_runtime {
-            continue;
-        }
-        let Some((k, v)) = line.split_once('=') else {
-            continue;
-        };
-        let key = k.trim();
-        let val = v.trim().trim_matches('"');
-        match key {
-            "tail_guard" => {
-                if let Ok(parsed) = val.parse::<f64>() {
-                    cfg.tail_guard = parsed.clamp(0.50, 0.9999);
-                }
-            }
-            "io_flush_batch" => {
-                if let Ok(parsed) = val.parse::<usize>() {
-                    cfg.io_flush_batch = parsed.clamp(1, 4096);
-                }
-            }
-            "io_queue_capacity" => {
-                if let Ok(parsed) = val.parse::<usize>() {
-                    cfg.io_queue_capacity = parsed.clamp(256, 262_144);
-                }
-            }
-            "json_mode" => {
-                cfg.json_mode = val.to_string();
-            }
-            "io_drop_on_full" => {
-                if let Ok(parsed) = val.parse::<bool>() {
-                    cfg.io_drop_on_full = parsed;
-                }
-            }
-            _ => {}
-        }
-    }
-    cfg
-}
-
-fn ensure_dataset_dirs() {
-    for bucket in ["raw", "normalized", "reports"] {
-        let path = dataset_dir(bucket);
-        let _ = fs::create_dir_all(path);
-    }
-}
-
-fn dataset_date() -> String {
-    Utc::now().format("%Y-%m-%d").to_string()
-}
-
-fn dataset_dir(kind: &str) -> PathBuf {
-    PathBuf::from("datasets").join(kind).join(dataset_date())
-}
-
-fn dataset_path(kind: &str, filename: &str) -> PathBuf {
-    dataset_dir(kind).join(filename)
-}
-
-fn sha256_hex(input: &str) -> String {
-    let mut hasher = Sha256::new();
-    hasher.update(input.as_bytes());
-    format!("{:x}", hasher.finalize())
-}
-
-fn count_jsonl_lines(path: &Path) -> i64 {
-    let Ok(raw) = fs::read_to_string(path) else {
-        return 0;
-    };
-    raw.lines().filter(|l| !l.trim().is_empty()).count() as i64
-}
-
-#[derive(Debug)]
-struct JsonlWriteReq {
-    path: PathBuf,
-    line: String,
-}
-
-static JSONL_WRITER: OnceLock<mpsc::Sender<JsonlWriteReq>> = OnceLock::new();
-static JSONL_QUEUE_DEPTH: AtomicU64 = AtomicU64::new(0);
-static JSONL_QUEUE_CAP: AtomicU64 = AtomicU64::new(0);
-static JSONL_DROP_ON_FULL: AtomicBool = AtomicBool::new(true);
-static NORMALIZED_INGEST_SEQ: AtomicU64 = AtomicU64::new(0);
-
-fn next_normalized_ingest_seq() -> u64 {
-    NORMALIZED_INGEST_SEQ.fetch_add(1, Ordering::Relaxed) + 1
-}
-
-async fn init_jsonl_writer(perf_profile: Arc<RwLock<PerfProfile>>) {
-    if JSONL_WRITER.get().is_some() {
-        return;
-    }
-    let cfg = perf_profile.read().await.clone();
-    let (tx, mut rx) = mpsc::channel::<JsonlWriteReq>(cfg.io_queue_capacity.max(256));
-    JSONL_QUEUE_CAP.store(cfg.io_queue_capacity.max(256) as u64, Ordering::Relaxed);
-    JSONL_DROP_ON_FULL.store(cfg.io_drop_on_full, Ordering::Relaxed);
-    if JSONL_WRITER.set(tx.clone()).is_err() {
-        return;
-    }
-    tokio::spawn(async move {
-        let mut batch = Vec::<JsonlWriteReq>::new();
-        let mut ticker = tokio::time::interval(Duration::from_millis(200));
-        loop {
-            tokio::select! {
-                maybe_req = rx.recv() => {
-                    match maybe_req {
-                        Some(req) => {
-                            batch.push(req);
-                            let flush_batch = perf_profile.read().await.io_flush_batch.max(1);
-                            if batch.len() >= flush_batch {
-                                let to_flush = std::mem::take(&mut batch);
-                                let _ = tokio::task::spawn_blocking(move || flush_jsonl_batch_sync(to_flush)).await;
-                            }
-                        }
-                        None => {
-                            if !batch.is_empty() {
-                                let to_flush = std::mem::take(&mut batch);
-                                let _ = tokio::task::spawn_blocking(move || flush_jsonl_batch_sync(to_flush)).await;
-                            }
-                            break;
-                        }
-                    }
-                }
-                _ = ticker.tick() => {
-                    if !batch.is_empty() {
-                        let to_flush = std::mem::take(&mut batch);
-                        let _ = tokio::task::spawn_blocking(move || flush_jsonl_batch_sync(to_flush)).await;
-                    }
-                }
-            }
-            let cap = JSONL_QUEUE_CAP.load(Ordering::Relaxed) as usize;
-            JSONL_QUEUE_DEPTH.store(cap.saturating_sub(tx.capacity()) as u64, Ordering::Relaxed);
-        }
-    });
-}
-
-fn flush_jsonl_batch_sync(batch: Vec<JsonlWriteReq>) {
-    let mut grouped = HashMap::<PathBuf, Vec<String>>::new();
-    for req in batch {
-        grouped.entry(req.path).or_default().push(req.line);
-    }
-    for (path, lines) in grouped {
-        if let Some(parent) = path.parent() {
-            let _ = fs::create_dir_all(parent);
-        }
-        if let Ok(mut file) = OpenOptions::new().create(true).append(true).open(&path) {
-            for line in lines {
-                let _ = writeln!(file, "{line}");
-            }
-        }
-    }
-}
-
-fn current_jsonl_queue_depth() -> u64 {
-    JSONL_QUEUE_DEPTH.load(Ordering::Relaxed)
-}
-
-fn append_jsonl_sync(path: &Path, line: &str) {
-    if let Some(parent) = path.parent() {
-        let _ = fs::create_dir_all(parent);
-    }
-    if let Ok(mut file) = OpenOptions::new().create(true).append(true).open(path) {
-        let _ = writeln!(file, "{line}");
-    }
-}
-
-fn append_jsonl_line(path: &Path, line: String) {
-    if let Some(tx) = JSONL_WRITER.get() {
-        let req = JsonlWriteReq {
-            path: path.to_path_buf(),
-            line,
-        };
-        match tx.try_send(req) {
-            Ok(_) => {
-                let cap = JSONL_QUEUE_CAP.load(Ordering::Relaxed) as usize;
-                JSONL_QUEUE_DEPTH.store(cap.saturating_sub(tx.capacity()) as u64, Ordering::Relaxed);
-                return;
-            }
-            Err(tokio::sync::mpsc::error::TrySendError::Full(req)) => {
-                metrics::counter!("io.jsonl.queue_full").increment(1);
-                if JSONL_DROP_ON_FULL.load(Ordering::Relaxed) {
-                    metrics::counter!("io.jsonl.dropped").increment(1);
-                    return;
-                }
-                append_jsonl_sync(&req.path, &req.line);
-                return;
-            }
-            Err(tokio::sync::mpsc::error::TrySendError::Closed(req)) => {
-                metrics::counter!("io.jsonl.queue_closed").increment(1);
-                if JSONL_DROP_ON_FULL.load(Ordering::Relaxed) {
-                    metrics::counter!("io.jsonl.dropped").increment(1);
-                    return;
-                }
-                append_jsonl_sync(&req.path, &req.line);
-                return;
-            }
-        }
-    }
-    append_jsonl_sync(path, &line);
-}
-
-fn append_jsonl(path: &Path, value: &serde_json::Value) {
-    append_jsonl_line(path, value.to_string());
-}
-
-fn persist_live_report_files(live: &ShadowLiveReport) {
-    let reports_dir = dataset_dir("reports");
-    let _ = fs::create_dir_all(&reports_dir);
-
-    let live_json_path = reports_dir.join("shadow_live_latest.json");
-    if let Ok(raw) = serde_json::to_string_pretty(live) {
-        let _ = fs::write(live_json_path, raw);
-    }
-}
-
-fn persist_engine_pnl_report(report: &EnginePnlReport) {
-    let reports_dir = dataset_dir("reports");
-    let _ = fs::create_dir_all(&reports_dir);
-
-    let json_path = reports_dir.join("engine_pnl_breakdown_latest.json");
-    if let Ok(raw) = serde_json::to_string_pretty(report) {
-        let _ = fs::write(json_path, raw);
-    }
-
-    let csv_path = reports_dir.join("engine_pnl_breakdown.csv");
-    let mut rows = String::new();
-    rows.push_str("window_id,engine,samples,total_usdc,p50_usdc,p10_usdc,positive_ratio\n");
-    for row in &report.rows {
-        rows.push_str(&format!(
-            "{},{},{},{:.6},{:.6},{:.6},{:.6}\n",
-            report.window_id,
-            row.engine,
-            row.samples,
-            row.total_usdc,
-            row.p50_usdc,
-            row.p10_usdc,
-            row.positive_ratio
-        ));
-    }
-    let _ = fs::write(csv_path, rows);
-}
-
-fn persist_final_report_files(report: &ShadowFinalReport) {
-    let reports_dir = dataset_dir("reports");
-    let _ = fs::create_dir_all(&reports_dir);
-
-    let md_path = reports_dir.join("report_shadow_12h.md");
-    let gate_label = if report.gate.pass { "PASS" } else { "FAIL" };
-    let mut md = String::new();
-    md.push_str("# Shadow 12h Report\n\n");
-    md.push_str(&format!("- gate: {gate_label}\n"));
-    md.push_str(&format!(
-        "- fillability@10ms: {:.4}\n",
-        report.gate.fillability_10ms
-    ));
-    md.push_str(&format!(
-        "- net_edge_p50_bps: {:.4}\n",
-        report.gate.net_edge_p50_bps
-    ));
-    md.push_str(&format!(
-        "- net_edge_p10_bps: {:.4}\n",
-        report.gate.net_edge_p10_bps
-    ));
-    md.push_str(&format!(
-        "- net_markout_10s_usdc_p50: {:.6}\n",
-        report.gate.net_markout_10s_usdc_p50
-    ));
-    md.push_str(&format!(
-        "- roi_notional_10s_bps_p50: {:.6}\n",
-        report.gate.roi_notional_10s_bps_p50
-    ));
-    md.push_str(&format!(
-        "- ev_net_usdc_p50: {:.6}\n",
-        report.gate.ev_net_usdc_p50
-    ));
-    md.push_str(&format!(
-        "- ev_net_usdc_p10: {:.6}\n",
-        report.gate.ev_net_usdc_p10
-    ));
-    md.push_str(&format!(
-        "- ev_positive_ratio: {:.4}\n",
-        report.gate.ev_positive_ratio
-    ));
-    md.push_str(&format!(
-        "- executed_over_eligible: {:.4}\n",
-        report.gate.executed_over_eligible
-    ));
-    md.push_str(&format!(
-        "- eligible_count: {}\n",
-        report.gate.eligible_count
-    ));
-    md.push_str(&format!(
-        "- executed_count: {}\n",
-        report.gate.executed_count
-    ));
-    md.push_str(&format!(
-        "- pnl_10s_p50_bps_raw: {:.4}\n",
-        report.gate.pnl_10s_p50_bps_raw
-    ));
-    md.push_str(&format!(
-        "- pnl_10s_p50_bps_robust: {:.4}\n",
-        report.gate.pnl_10s_p50_bps_robust
-    ));
-    md.push_str(&format!(
-        "- pnl_10s_sample_count: {}\n",
-        report.gate.pnl_10s_sample_count
-    ));
-    md.push_str(&format!(
-        "- pnl_10s_outlier_ratio: {:.4}\n",
-        report.gate.pnl_10s_outlier_ratio
-    ));
-    md.push_str(&format!(
-        "- quote_block_ratio: {:.4}\n",
-        report.gate.quote_block_ratio
-    ));
-    md.push_str(&format!(
-        "- policy_block_ratio: {:.4}\n",
-        report.gate.policy_block_ratio
-    ));
-    md.push_str(&format!(
-        "- strategy_uptime_pct: {:.2}\n",
-        report.gate.strategy_uptime_pct
-    ));
-    md.push_str(&format!(
-        "- data_valid_ratio: {:.5}\n",
-        report.gate.data_valid_ratio
-    ));
-    md.push_str(&format!(
-        "- seq_gap_rate: {:.5}\n",
-        report.gate.seq_gap_rate
-    ));
-    md.push_str(&format!(
-        "- ts_inversion_rate: {:.5}\n",
-        report.gate.ts_inversion_rate
-    ));
-    md.push_str(&format!(
-        "- stale_tick_drop_ratio: {:.5}\n",
-        report.gate.stale_tick_drop_ratio
-    ));
-    md.push_str(&format!(
-        "- tick_to_ack_p99_ms: {:.4}\n\n",
-        report.gate.tick_to_ack_p99_ms
-    ));
-    md.push_str(&format!(
-        "- tick_to_decision_p99_ms: {:.4}\n",
-        report.live.tick_to_decision_p99_ms
-    ));
-    md.push_str(&format!(
-        "- ack_only_p99_ms: {:.4}\n",
-        report.live.ack_only_p99_ms
-    ));
-    md.push_str(&format!(
-        "- decision_queue_wait_p99_ms: {:.4}\n",
-        report.gate.decision_queue_wait_p99_ms
-    ));
-    md.push_str(&format!(
-        "- decision_compute_p99_ms: {:.4}\n",
-        report.gate.decision_compute_p99_ms
-    ));
-    md.push_str(&format!(
-        "- source_latency_p99_ms: {:.4}\n",
-        report.gate.source_latency_p99_ms
-    ));
-    md.push_str(&format!(
-        "- local_backlog_p99_ms: {:.4}\n",
-        report.gate.local_backlog_p99_ms
-    ));
-    md.push_str(&format!(
-        "- queue_depth_p99: {:.4}\n",
-        report.live.queue_depth_p99
-    ));
-    md.push_str(&format!(
-        "- event_backlog_p99: {:.4}\n\n",
-        report.live.event_backlog_p99
-    ));
-    md.push_str(&format!(
-        "- quote_attempted: {}\n- quote_blocked: {}\n- policy_blocked: {}\n- ref_ticks_total: {}\n- book_ticks_total: {}\n- ref_freshness_ms: {}\n- book_freshness_ms: {}\n\n",
-        report.live.quote_attempted,
-        report.live.quote_blocked,
-        report.live.policy_blocked,
-        report.live.ref_ticks_total,
-        report.live.book_ticks_total,
-        report.live.ref_freshness_ms,
-        report.live.book_freshness_ms
-    ));
-    if report.gate.failed_reasons.is_empty() {
-        md.push_str("## Failed Reasons\n- none\n");
-    } else {
-        md.push_str("## Failed Reasons\n");
-        for reason in &report.gate.failed_reasons {
-            md.push_str(&format!("- {reason}\n"));
-        }
-    }
-    if report.live.blocked_reason_counts.is_empty() {
-        md.push_str("\n## Blocked Reasons\n- none\n");
-    } else {
-        md.push_str("\n## Blocked Reasons\n");
-        let mut rows = report.live.blocked_reason_counts.iter().collect::<Vec<_>>();
-        rows.sort_by(|a, b| b.1.cmp(a.1));
-        for (reason, count) in rows {
-            md.push_str(&format!("- {}: {}\n", reason, count));
-        }
-    }
-    let _ = fs::write(md_path, md);
-
-    let latency_csv = reports_dir.join("latency_breakdown_12h.csv");
-    let mut latency_rows = String::new();
-    latency_rows.push_str("stage,p50,p90,p99,unit\n");
-    latency_rows.push_str(&format!(
-        "feed_in,{:.6},{:.6},{:.6},ms\n",
-        report.live.latency.feed_in_p50_ms,
-        report.live.latency.feed_in_p90_ms,
-        report.live.latency.feed_in_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "signal,{:.6},{:.6},{:.6},us\n",
-        report.live.latency.signal_p50_us,
-        report.live.latency.signal_p90_us,
-        report.live.latency.signal_p99_us
-    ));
-    latency_rows.push_str(&format!(
-        "quote,{:.6},{:.6},{:.6},us\n",
-        report.live.latency.quote_p50_us,
-        report.live.latency.quote_p90_us,
-        report.live.latency.quote_p99_us
-    ));
-    latency_rows.push_str(&format!(
-        "risk,{:.6},{:.6},{:.6},us\n",
-        report.live.latency.risk_p50_us,
-        report.live.latency.risk_p90_us,
-        report.live.latency.risk_p99_us
-    ));
-    latency_rows.push_str(&format!(
-        "decision_queue_wait,{:.6},{:.6},{:.6},ms\n",
-        report.live.latency.decision_queue_wait_p50_ms,
-        report.live.latency.decision_queue_wait_p90_ms,
-        report.live.latency.decision_queue_wait_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "decision_compute,{:.6},{:.6},{:.6},ms\n",
-        report.live.latency.decision_compute_p50_ms,
-        report.live.latency.decision_compute_p90_ms,
-        report.live.latency.decision_compute_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "tick_to_decision,{:.6},{:.6},{:.6},ms\n",
-        report.live.latency.tick_to_decision_p50_ms,
-        report.live.latency.tick_to_decision_p90_ms,
-        report.live.latency.tick_to_decision_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "ack_only,{:.6},{:.6},{:.6},ms\n",
-        report.live.latency.ack_only_p50_ms,
-        report.live.latency.ack_only_p90_ms,
-        report.live.latency.ack_only_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "tick_to_ack,{:.6},{:.6},{:.6},ms\n",
-        report.live.latency.tick_to_ack_p50_ms,
-        report.live.latency.tick_to_ack_p90_ms,
-        report.live.latency.tick_to_ack_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "parse,{:.6},{:.6},{:.6},us\n",
-        0.0, 0.0, report.live.latency.parse_p99_us
-    ));
-    latency_rows.push_str(&format!(
-        "io_queue,{:.6},{:.6},{:.6},count\n",
-        0.0, 0.0, report.live.latency.io_queue_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "bus_lag,{:.6},{:.6},{:.6},count\n",
-        0.0, 0.0, report.live.latency.bus_lag_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "shadow_fill,{:.6},{:.6},{:.6},ms\n",
-        report.live.latency.shadow_fill_p50_ms,
-        report.live.latency.shadow_fill_p90_ms,
-        report.live.latency.shadow_fill_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "source_latency,{:.6},{:.6},{:.6},ms\n",
-        report.live.latency.source_latency_p50_ms,
-        report.live.latency.source_latency_p90_ms,
-        report.live.latency.source_latency_p99_ms
-    ));
-    latency_rows.push_str(&format!(
-        "local_backlog,{:.6},{:.6},{:.6},ms\n",
-        report.live.latency.local_backlog_p50_ms,
-        report.live.latency.local_backlog_p90_ms,
-        report.live.latency.local_backlog_p99_ms
-    ));
-    let _ = fs::write(latency_csv, latency_rows);
-
-    let score_path = reports_dir.join("market_scorecard.csv");
-    let mut score_rows = String::new();
-    score_rows.push_str("market_id,symbol,shots,outcomes,fillability_10ms,net_edge_p50_bps,net_edge_p10_bps,pnl_10s_p50_bps,net_markout_10s_usdc_p50,roi_notional_10s_bps_p50\n");
-    for row in &report.live.market_scorecard {
-        score_rows.push_str(&format!(
-            "{},{},{},{},{:.6},{:.6},{:.6},{:.6},{:.6},{:.6}\n",
-            row.market_id,
-            row.symbol,
-            row.shots,
-            row.outcomes,
-            row.fillability_10ms,
-            row.net_edge_p50_bps,
-            row.net_edge_p10_bps,
-            row.pnl_10s_p50_bps,
-            row.net_markout_10s_usdc_p50,
-            row.roi_notional_10s_bps_p50
-        ));
-    }
-    let _ = fs::write(score_path, score_rows);
-
-    let fixlist_path = reports_dir.join("next_fixlist.md");
-    let mut fixlist = String::new();
-    fixlist.push_str("# Next Fixlist\n\n");
-    if report.gate.failed_reasons.is_empty() {
-        fixlist.push_str("- Gate passed. Keep conservative limits and continue monitoring.\n");
-    } else {
-        for reason in &report.gate.failed_reasons {
-            fixlist.push_str(&format!("- {reason}\n"));
-        }
-    }
-    let _ = fs::write(fixlist_path, fixlist);
-
-    let truth_manifest_path = reports_dir.join("truth_manifest.json");
-    let truth_manifest = serde_json::json!({
-        "generated_at_utc": Utc::now().to_rfc3339(),
-        "metrics_contract_version": "2026-02-14.v1",
-        "window": {
-            "window_id": report.live.window_id,
-            "window_shots": report.live.window_shots,
-            "window_outcomes": report.live.window_outcomes,
-            "gate_ready": report.live.gate_ready,
-        },
-        "data_chain": {
-            "raw_fields": ["sha256", "source_seq", "ingest_seq", "event_ts_exchange_ms", "recv_ts_local_ns"],
-            "normalized_fields": ["source_seq", "ingest_seq", "market_id", "symbol", "delay_ms", "fillable", "net_markout_10s_usdc"],
-            "invalid_excluded_from_gate": true
-        },
-        "formulas": {
-            "quote_block_ratio": "quote_blocked / (quote_attempted + quote_blocked)",
-            "policy_block_ratio": "policy_blocked / (quote_attempted + policy_blocked)",
-            "policy_blocked_scope": "risk:* and risk_capped_zero only",
-            "executed_over_eligible": "executed_count / eligible_count",
-            "ev_net_usdc_p50": "p50(net_markout_10s_usdc)",
-            "ev_positive_ratio": "count(net_markout_10s_usdc > 0) / count(valid outcomes)"
-        },
-        "hard_gates": {
-            "data_valid_ratio_min": 0.999,
-            "seq_gap_rate_max": 0.001,
-            "ts_inversion_rate_max": 0.0005,
-            "tick_to_ack_p99_ms_max": 450.0,
-            "decision_compute_p99_ms_max": 2.0,
-            "feed_in_p99_ms_max": 800.0,
-            "executed_over_eligible_min": 0.60,
-            "quote_block_ratio_max": 0.10,
-            "policy_block_ratio_max": 0.10,
-            "ev_net_usdc_p50_min": 0.0,
-            "roi_notional_10s_bps_p50_min": 0.0
-        }
-    });
-    if let Ok(raw) = serde_json::to_string_pretty(&truth_manifest) {
-        let _ = fs::write(truth_manifest_path, raw);
-    }
-}
-
-fn persist_toxicity_report_files(report: &ToxicityLiveReport) {
-    let reports_dir = dataset_dir("reports");
-    let _ = fs::create_dir_all(&reports_dir);
-
-    let live_json_path = reports_dir.join("toxicity_live_latest.json");
-    if let Ok(raw) = serde_json::to_string_pretty(report) {
-        let _ = fs::write(live_json_path, raw);
-    }
-
-    let csv_path = reports_dir.join("toxicity_scorecard.csv");
-    let mut rows = String::new();
-    rows.push_str("market_rank,active_for_quoting,market_id,symbol,tox_score,regime,market_score,markout_10s_bps,no_quote_rate,symbol_missing_rate,pending_exposure\n");
-    for row in &report.rows {
-        rows.push_str(&format!(
-            "{},{},{},{},{:.6},{:?},{:.6},{:.6},{:.6},{:.6},{:.6}\n",
-            row.market_rank,
-            row.active_for_quoting,
-            row.market_id,
-            row.symbol,
-            row.tox_score,
-            row.regime,
-            row.market_score,
-            row.markout_10s_bps,
-            row.no_quote_rate,
-            row.symbol_missing_rate,
-            row.pending_exposure
-        ));
-    }
-    let _ = fs::write(csv_path, rows);
-}
-
-fn fillability_ratio(outcomes: &[ShadowOutcome], delay_ms: u64) -> f64 {
-    let scoped = outcomes
-        .iter()
-        .filter(|o| o.delay_ms == delay_ms)
-        .collect::<Vec<_>>();
-    if scoped.is_empty() {
-        return 0.0;
-    }
-    let filled = scoped.iter().filter(|o| o.fillable).count();
-    filled as f64 / scoped.len() as f64
-}
-
-fn survival_ratio(outcomes: &[ShadowOutcome], delay_ms: u64) -> f64 {
-    let scoped = outcomes
-        .iter()
-        .filter(|o| o.delay_ms == delay_ms)
-        .collect::<Vec<_>>();
-    if scoped.is_empty() {
-        return 0.0;
-    }
-    let survived = scoped.iter().filter(|o| o.survived).count();
-    survived as f64 / scoped.len() as f64
-}
-
-fn build_market_scorecard(shots: &[ShadowShot], outcomes: &[ShadowOutcome]) -> Vec<MarketScoreRow> {
-    const PRIMARY_DELAY_MS: u64 = 10;
-    let mut keys: HashMap<(String, String), ()> = HashMap::new();
-    for shot in shots {
-        keys.insert((shot.market_id.clone(), shot.symbol.clone()), ());
-    }
-    for outcome in outcomes {
-        keys.insert((outcome.market_id.clone(), outcome.symbol.clone()), ());
-    }
-
-    let mut rows = Vec::new();
-    for (market_id, symbol) in keys.into_keys() {
-        let market_shots = shots
-            .iter()
-            .filter(|s| s.market_id == market_id && s.symbol == symbol)
-            .cloned()
-            .collect::<Vec<_>>();
-        let market_outcomes = outcomes
-            .iter()
-            .filter(|o| o.market_id == market_id && o.symbol == symbol)
-            .cloned()
-            .collect::<Vec<_>>();
-        let market_shots_primary = market_shots
-            .iter()
-            .filter(|s| s.delay_ms == PRIMARY_DELAY_MS)
-            .collect::<Vec<_>>();
-        let market_outcomes_primary = market_outcomes
-            .iter()
-            .filter(|o| o.delay_ms == PRIMARY_DELAY_MS)
-            .collect::<Vec<_>>();
-
-        let net_edges = market_shots_primary
-            .iter()
-            .map(|s| s.edge_net_bps)
-            .collect::<Vec<_>>();
-        let pnl_10s = market_outcomes_primary
-            .iter()
-            .filter_map(|o| o.net_markout_10s_bps.or(o.pnl_10s_bps))
-            .collect::<Vec<_>>();
-        let net_markout_10s_usdc = market_outcomes_primary
-            .iter()
-            .filter_map(|o| o.net_markout_10s_usdc)
-            .collect::<Vec<_>>();
-        let roi_notional_10s_bps = market_outcomes_primary
-            .iter()
-            .filter_map(|o| o.roi_notional_10s_bps)
-            .collect::<Vec<_>>();
-
-        rows.push(MarketScoreRow {
-            market_id,
-            symbol,
-            shots: market_shots_primary.len(),
-            outcomes: market_outcomes_primary.len(),
-            fillability_10ms: fillability_ratio(&market_outcomes, 10),
-            net_edge_p50_bps: percentile(&net_edges, 0.50).unwrap_or(0.0),
-            net_edge_p10_bps: percentile(&net_edges, 0.10).unwrap_or(0.0),
-            pnl_10s_p50_bps: percentile(&pnl_10s, 0.50).unwrap_or(0.0),
-            net_markout_10s_usdc_p50: percentile(&net_markout_10s_usdc, 0.50).unwrap_or(0.0),
-            roi_notional_10s_bps_p50: percentile(&roi_notional_10s_bps, 0.50).unwrap_or(0.0),
-        });
-    }
-
-    rows.sort_by(|a, b| {
-        b.net_markout_10s_usdc_p50
-            .total_cmp(&a.net_markout_10s_usdc_p50)
-    });
-    rows
-}
+pub(crate) use engine_loop::{
+    spawn_predator_exit_lifecycle, spawn_shadow_outcome_task, spawn_strategy_engine,
+    PredatorExecResult,
+};
 
 #[cfg(test)]
-mod tests {
-    use super::*;
-    use core_types::QuoteIntent;
-
-    #[test]
-    fn robust_filter_marks_outliers() {
-        let values = vec![1.0, 1.1, 1.2, 1.3, 99.0];
-        let (filtered, outlier_ratio) = robust_filter_iqr(&values);
-        assert!(filtered.len() < values.len());
-        assert!(outlier_ratio > 0.0);
-    }
-
-    #[test]
-    fn robust_filter_small_sample_passthrough() {
-        let values = vec![1.0, 2.0, 3.0, 4.0];
-        let (filtered, outlier_ratio) = robust_filter_iqr(&values);
-        assert_eq!(filtered, values);
-        assert_eq!(outlier_ratio, 0.0);
-    }
-
-    #[test]
-    fn percentile_basic_behavior() {
-        let values = vec![1.0, 5.0, 3.0, 2.0, 4.0];
-        assert_eq!(percentile(&values, 0.50), Some(3.0));
-        assert_eq!(percentile(&values, 0.0), Some(1.0));
-        assert_eq!(percentile(&values, 1.0), Some(5.0));
-    }
-
-    #[test]
-    fn classify_execution_style_for_yes_side() {
-        let book = BookTop {
-            market_id: "m".to_string(),
-            token_id_yes: "yes".to_string(),
-            token_id_no: "no".to_string(),
-            bid_yes: 0.49,
-            ask_yes: 0.51,
-            bid_no: 0.49,
-            ask_no: 0.51,
-            ts_ms: 1,
-            recv_ts_local_ns: 1_000_000,
-        };
-        let maker = QuoteIntent {
-            market_id: "m".to_string(),
-            side: OrderSide::BuyYes,
-            price: 0.50,
-            size: 1.0,
-            ttl_ms: 300,
-        };
-        let taker = QuoteIntent {
-            price: 0.51,
-            ..maker.clone()
-        };
-        assert_eq!(
-            classify_execution_style(&book, &maker),
-            ExecutionStyle::Maker
-        );
-        assert_eq!(
-            classify_execution_style(&book, &taker),
-            ExecutionStyle::Taker
-        );
-    }
-
-    #[test]
-    fn normalize_reject_code_sanitizes_non_alnum() {
-        let normalized = normalize_reject_code("HTTP 429/Too Many Requests");
-        assert_eq!(normalized, "http_429_too_many_requests");
-    }
-
-    #[test]
-    fn estimate_feed_latency_separates_source_and_backlog() {
-        let now = now_ns();
-        let now_ms = now / 1_000_000;
-        let tick = RefTick {
-            source: "binance_ws".to_string(),
-            symbol: "BTCUSDT".to_string(),
-            event_ts_ms: now_ms - 300,
-            recv_ts_ms: now_ms - 200,
-            event_ts_exchange_ms: now_ms - 300,
-            recv_ts_local_ns: now - 200_000_000,
-            price: 70_000.0,
-        };
-        let book = BookTop {
-            market_id: "m".to_string(),
-            token_id_yes: "yes".to_string(),
-            token_id_no: "no".to_string(),
-            bid_yes: 0.49,
-            ask_yes: 0.51,
-            bid_no: 0.49,
-            ask_no: 0.51,
-            ts_ms: now_ms - 40,
-            recv_ts_local_ns: now - 20_000_000,
-        };
-
-        let sample = estimate_feed_latency(&tick, &book);
-        assert!(sample.source_latency_ms >= 95.0);
-        assert!(sample.source_latency_ms <= 110.0);
-        assert!(sample.local_backlog_ms >= 10.0);
-        assert!(sample.local_backlog_ms <= 40.0);
-        assert!(sample.feed_in_ms >= sample.source_latency_ms);
-        assert!(
-            (sample.feed_in_ms - (sample.source_latency_ms + sample.local_backlog_ms)).abs() < 3.0
-        );
-    }
-
-    #[test]
-    fn should_force_taker_respects_profile_and_regime() {
-        let mut cfg = MakerConfig::default();
-        cfg.taker_trigger_bps = 10.0;
-        cfg.market_tier_profile = "balanced".to_string();
-
-        let safe = ToxicDecision {
-            market_id: "m".to_string(),
-            symbol: "BTCUSDT".to_string(),
-            tox_score: 0.1,
-            regime: ToxicRegime::Safe,
-            reason_codes: vec![],
-            ts_ns: 1,
-        };
-        assert!(should_force_taker(
-            &cfg, &safe, 12.0, 0.8, 30, 0.1, 40, 30, "BTCUSDT"
-        ));
-        assert!(!should_force_taker(
-            &cfg, &safe, 8.0, 0.8, 30, 0.1, 40, 30, "BTCUSDT"
-        ));
-        assert!(!should_force_taker(
-            &cfg, &safe, 12.0, 0.4, 30, 0.1, 40, 30, "BTCUSDT"
-        ));
-
-        let caution = ToxicDecision {
-            regime: ToxicRegime::Caution,
-            ..safe.clone()
-        };
-        assert!(!should_force_taker(
-            &cfg, &caution, 12.0, 0.8, 30, 0.1, 40, 30, "BTCUSDT"
-        ));
-        cfg.market_tier_profile = "latency_aggressive".to_string();
-        assert!(should_force_taker(
-            &cfg, &caution, 12.0, 0.8, 30, 0.1, 40, 30, "BTCUSDT"
-        ));
-    }
-
-    #[test]
-    fn adaptive_min_edge_bps_warmup_relaxes_threshold() {
-        let relaxed = adaptive_min_edge_bps(5.0, 0.3, 0, 0.95, 0.0, 0.0, 0, 30);
-        assert!(relaxed <= 1.0);
-        let progressed = adaptive_min_edge_bps(5.0, 0.3, 0, 0.20, 0.0, 0.0, 25, 30);
-        assert!(progressed >= relaxed);
-    }
-
-    #[test]
-    fn sol_guard_observe_only_for_high_latency_or_spread() {
-        let mut cfg = MakerConfig::default();
-        cfg.market_tier_profile = "balanced_sol_guard".to_string();
-        let tox = ToxicDecision {
-            market_id: "m".to_string(),
-            symbol: "SOLUSDT".to_string(),
-            tox_score: 0.2,
-            regime: ToxicRegime::Safe,
-            reason_codes: vec![],
-            ts_ns: 1,
-        };
-        assert!(should_observe_only_symbol(
-            "SOLUSDT", &cfg, &tox, 120.0, 0.01, 180.0
-        ));
-        assert!(should_observe_only_symbol(
-            "SOLUSDT", &cfg, &tox, 260.0, 0.01, 80.0
-        ));
-        assert!(should_observe_only_symbol(
-            "SOLUSDT", &cfg, &tox, 120.0, 0.03, 80.0
-        ));
-        assert!(!should_observe_only_symbol(
-            "SOLUSDT", &cfg, &tox, 120.0, 0.01, 80.0
-        ));
-        assert!(!should_observe_only_symbol(
-            "BTCUSDT", &cfg, &tox, 260.0, 0.03, 999.0
-        ));
-    }
-
-    #[test]
-    fn quote_block_ratio_matches_contract_and_is_bounded() {
-        assert_eq!(quote_block_ratio(0, 0), 0.0);
-        assert_eq!(quote_block_ratio(10, 0), 0.0);
-        assert_eq!(quote_block_ratio(0, 10), 1.0);
-
-        let r = quote_block_ratio(10, 2);
-        assert!(r > 0.0 && r < 1.0);
-    }
-
-    #[test]
-    fn policy_block_ratio_matches_contract_and_is_bounded() {
-        assert_eq!(policy_block_ratio(0, 0), 0.0);
-        assert_eq!(policy_block_ratio(10, 0), 0.0);
-        assert_eq!(policy_block_ratio(0, 10), 1.0);
-
-        let r = policy_block_ratio(10, 2);
-        assert!(r > 0.0 && r < 1.0);
-    }
-
-    #[test]
-    fn uptime_pct_is_bounded() {
-        let stats = ShadowStats::new();
-        let u = stats.uptime_pct(Duration::from_secs(1));
-        assert!((0.0..=100.0).contains(&u));
-    }
-
-    #[test]
-    fn parse_toml_array_for_key_handles_multiline_arrays() {
-        let raw = r#"
-assets = [
-  "BTCUSDT",
-  "ETHUSDT",
-  "XRPUSDT",
-]
-market_types = ["updown", "range"]
-timeframes = ["5m", "15m", "1h", "1d"]
-"#;
-        let assets = parse_toml_array_for_key(raw, "assets").unwrap_or_default();
-        assert_eq!(
-            assets,
-            vec![
-                "BTCUSDT".to_string(),
-                "ETHUSDT".to_string(),
-                "XRPUSDT".to_string()
-            ]
-        );
-        let market_types = parse_toml_array_for_key(raw, "market_types").unwrap_or_default();
-        assert_eq!(
-            market_types,
-            vec!["updown".to_string(), "range".to_string()]
-        );
-        let timeframes = parse_toml_array_for_key(raw, "timeframes").unwrap_or_default();
-        assert_eq!(
-            timeframes,
-            vec![
-                "5m".to_string(),
-                "15m".to_string(),
-                "1h".to_string(),
-                "1d".to_string()
-            ]
-        );
-    }
-
-    #[test]
-    fn parse_toml_array_for_key_returns_none_for_missing_or_empty() {
-        let raw = "foo = 1\nassets = []\n";
-        assert!(parse_toml_array_for_key(raw, "missing").is_none());
-        assert!(parse_toml_array_for_key(raw, "assets").is_none());
-    }
-}
+mod tests;
diff --git a/crates/app_runner/src/orchestration.rs b/crates/app_runner/src/orchestration.rs
index 34ba575..b156dce 100644
--- a/crates/app_runner/src/orchestration.rs
+++ b/crates/app_runner/src/orchestration.rs
@@ -1,12 +1,97 @@
-use super::*;
+use std::collections::HashMap;
+use std::fs;
+use std::io::{Read, Seek};
+use std::path::PathBuf;
+use std::sync::Arc;
+use std::time::{Duration, Instant};
+
+use chrono::Utc;
+use core_types::{ControlCommand, EngineEvent};
+use execution_clob::ClobExecution;
+use infra_bus::RingBus;
+use tokio::sync::RwLock;
+
+use crate::report_io::{
+    append_jsonl, dataset_path, persist_engine_pnl_report, persist_final_report_files,
+    persist_live_report_files, persist_toxicity_report_files,
+};
+use crate::state::{MarketToxicState, ShadowStats, ToxicityConfig};
+use crate::toxicity_report::build_toxicity_live_report;
+use crate::spawn_detached;
+
+#[derive(Debug, Clone, Default)]
+struct JsonlTailCounter {
+    /// Current file path being tracked (bucketed by date).
+    path: PathBuf,
+    /// Byte offset we have already scanned up to.
+    offset: u64,
+    /// Cumulative line count observed since the current baseline/rotation.
+    lines: i64,
+}
+
+impl JsonlTailCounter {
+    fn tick(mut self, path: PathBuf) -> Self {
+        // If the date rolled over (or path otherwise changed), reset baseline.
+        if self.path != path {
+            self.path = path;
+            self.offset = 0;
+            self.lines = 0;
+        }
+
+        let Ok(meta) = fs::metadata(&self.path) else {
+            return self;
+        };
+        let len = meta.len();
+
+        // Baseline: do not scan historical data on startup. We only care about deltas while the
+        // current process is running to detect drops/gaps in the JSONL writer.
+        if self.offset == 0 {
+            self.offset = len;
+            return self;
+        }
+
+        // Handle truncation/rotation.
+        if len < self.offset {
+            self.offset = len;
+            self.lines = 0;
+            return self;
+        }
+
+        let Ok(mut file) = std::fs::File::open(&self.path) else {
+            return self;
+        };
+        if file.seek(std::io::SeekFrom::Start(self.offset)).is_err() {
+            return self;
+        }
+
+        let mut buf = [0_u8; 64 * 1024];
+        let mut added: i64 = 0;
+        loop {
+            let Ok(n) = file.read(&mut buf) else {
+                break;
+            };
+            if n == 0 {
+                break;
+            }
+            for &b in &buf[..n] {
+                if b == b'\n' {
+                    added = added.saturating_add(1);
+                }
+            }
+        }
+        self.lines = self.lines.saturating_add(added);
+        self.offset = len;
+        self
+    }
+}
 
 pub(super) fn spawn_periodic_report_persistor(
     stats: Arc<ShadowStats>,
     tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
     execution: Arc<ClobExecution>,
-    toxicity_cfg: Arc<RwLock<ToxicityConfig>>,
+    toxicity_cfg: Arc<RwLock<Arc<ToxicityConfig>>>,
 ) {
-    tokio::spawn(async move {
+    spawn_detached("periodic_report_persistor", false, async move {
         let mut last_final = Instant::now() - Duration::from_secs(600);
         loop {
             let live = stats.build_live_report().await;
@@ -38,30 +123,81 @@ pub(super) fn spawn_data_reconcile_task(
     paused: Arc<RwLock<bool>>,
     stats: Arc<ShadowStats>,
 ) {
-    tokio::spawn(async move {
+    spawn_detached("data_reconcile_task", false, async move {
         let mut interval = tokio::time::interval(Duration::from_secs(600));
+        // The raw JSONL files are bucketed by date, while `ShadowStats` counters are reset on
+        // `/control/reset_shadow` (window reset). Comparing absolute totals would therefore
+        // generate false "gap" alarms after any reset. Track deltas between intervals and
+        // automatically re-baseline on resets/rotations.
+        let mut last_window_id: u64 = 0;
+        let mut last_ref_lines: i64 = 0;
+        let mut last_book_lines: i64 = 0;
+        let mut last_ref_expected: i64 = 0;
+        let mut last_book_expected: i64 = 0;
+        let mut ref_tail = JsonlTailCounter::default();
+        let mut book_tail = JsonlTailCounter::default();
         loop {
             interval.tick().await;
             let live = stats.build_live_report().await;
-            let ref_lines = count_jsonl_lines(&dataset_path("raw", "ref_ticks.jsonl"));
-            let book_lines = count_jsonl_lines(&dataset_path("raw", "book_tops.jsonl"));
+            let ref_path = dataset_path("raw", "ref_ticks.jsonl");
+            let book_path = dataset_path("raw", "book_tops.jsonl");
+            // Counting lines in multi-GB JSONL files must never allocate the whole file.
+            // We do a tail-based, incremental newline count in a blocking thread.
+            let (next_ref_tail, next_book_tail) = {
+                // We avoid moving the live state into the blocking closure so we can keep the
+                // current values on failure (panic/cancel).
+                let ref_state = ref_tail.clone();
+                let book_state = book_tail.clone();
+                match tokio::task::spawn_blocking(move || {
+                    (ref_state.tick(ref_path), book_state.tick(book_path))
+                })
+                .await
+                {
+                    Ok(v) => v,
+                    Err(_) => (ref_tail.clone(), book_tail.clone()),
+                }
+            };
+            ref_tail = next_ref_tail;
+            book_tail = next_book_tail;
+            let ref_lines = ref_tail.lines;
+            let book_lines = book_tail.lines;
             let ref_expected = live.ref_ticks_total as i64;
             let book_expected = live.book_ticks_total as i64;
-            let ref_gap_ratio = if ref_expected <= 0 {
-                0.0
-            } else {
-                ((ref_lines - ref_expected).abs() as f64) / (ref_expected as f64)
-            };
-            let book_gap_ratio = if book_expected <= 0 {
-                0.0
+            let baseline_reset = last_window_id == 0
+                || live.window_id != last_window_id
+                || ref_lines < last_ref_lines
+                || book_lines < last_book_lines
+                || ref_expected < last_ref_expected
+                || book_expected < last_book_expected;
+
+            let (ref_gap_ratio, book_gap_ratio) = if baseline_reset {
+                (0.0, 0.0)
             } else {
-                ((book_lines - book_expected).abs() as f64) / (book_expected as f64)
+                let ref_lines_delta = ref_lines - last_ref_lines;
+                let book_lines_delta = book_lines - last_book_lines;
+                let ref_expected_delta = ref_expected - last_ref_expected;
+                let book_expected_delta = book_expected - last_book_expected;
+                let ref_gap = if ref_expected_delta <= 0 {
+                    0.0
+                } else {
+                    ((ref_lines_delta - ref_expected_delta).abs() as f64)
+                        / (ref_expected_delta as f64)
+                };
+                let book_gap = if book_expected_delta <= 0 {
+                    0.0
+                } else {
+                    ((book_lines_delta - book_expected_delta).abs() as f64)
+                        / (book_expected_delta as f64)
+                };
+                (ref_gap, book_gap)
             };
-            let reconcile_fail = ref_gap_ratio > 0.05
-                || book_gap_ratio > 0.05
-                || live.data_valid_ratio < 0.999
-                || live.seq_gap_rate > 0.001
-                || live.ts_inversion_rate > 0.0005;
+
+            let reconcile_fail = !baseline_reset
+                && (ref_gap_ratio > 0.05
+                    || book_gap_ratio > 0.05
+                    || live.data_valid_ratio < 0.999
+                    || live.seq_gap_rate > 0.001
+                    || live.ts_inversion_rate > 0.0005);
 
             if reconcile_fail {
                 stats.set_observe_only(true);
@@ -86,9 +222,16 @@ pub(super) fn spawn_data_reconcile_task(
                     "ref_gap_ratio": ref_gap_ratio,
                     "book_gap_ratio": book_gap_ratio,
                     "reconcile_fail": reconcile_fail,
+                    "baseline_reset": baseline_reset,
                     "observe_only": stats.observe_only()
                 }),
             );
+
+            last_window_id = live.window_id;
+            last_ref_lines = ref_lines;
+            last_book_lines = book_lines;
+            last_ref_expected = ref_expected;
+            last_book_expected = book_expected;
         }
     });
 }
diff --git a/crates/app_runner/src/paper_runtime.rs b/crates/app_runner/src/paper_runtime.rs
new file mode 100644
index 0000000..366902d
--- /dev/null
+++ b/crates/app_runner/src/paper_runtime.rs
@@ -0,0 +1,997 @@
+use std::collections::{BTreeMap, HashMap, VecDeque};
+use std::path::PathBuf;
+use std::sync::Arc;
+use std::sync::OnceLock;
+
+use chrono::{TimeZone, Utc};
+use core_types::{
+    BookTop, Direction, ExecutionStyle, FillEvent, OrderAck, OrderSide, PaperAction, PaperDailySummary,
+    PaperFill, PaperIntent, PaperLiveReport, PaperTradeRecord, Stage,
+};
+use tokio::sync::RwLock;
+
+use crate::paper_sqlite::PaperSqliteWriter;
+use crate::report_io::{append_jsonl, dataset_path};
+use crate::seat_runtime::SeatRuntimeHandle;
+use crate::seat_types::SeatDecisionRecord;
+use crate::stats_utils::percentile;
+
+const HISTORY_CAP: usize = 20_000;
+
+static GLOBAL_PAPER_RUNTIME: OnceLock<Arc<PaperRuntimeHandle>> = OnceLock::new();
+
+#[derive(Debug, Clone)]
+pub(crate) struct PaperIntentCtx {
+    pub(crate) market_id: String,
+    pub(crate) symbol: String,
+    pub(crate) timeframe: String,
+    pub(crate) stage: Stage,
+    pub(crate) direction: Direction,
+    pub(crate) velocity_bps_per_sec: f64,
+    pub(crate) edge_bps: f64,
+    pub(crate) prob_fast: f64,
+    pub(crate) prob_settle: f64,
+    pub(crate) confidence: f64,
+    pub(crate) action: PaperAction,
+    pub(crate) intent: ExecutionStyle,
+    pub(crate) requested_size_usdc: f64,
+    pub(crate) requested_size_contracts: f64,
+    pub(crate) entry_price: f64,
+}
+
+#[derive(Debug, Clone)]
+struct PaperLot {
+    market_id: String,
+    symbol: String,
+    timeframe: String,
+    side: OrderSide,
+    stage: Stage,
+    direction: Direction,
+    velocity_bps_per_sec: f64,
+    edge_bps: f64,
+    prob_fast: f64,
+    prob_settle: f64,
+    confidence: f64,
+    intent: ExecutionStyle,
+    requested_size_usdc: f64,
+    entry_price: f64,
+    remaining_size: f64,
+    entry_fee_per_contract: f64,
+    opened_ts_ms: i64,
+    seat_layer: Option<String>,
+    tuned_params_before: Option<serde_json::Value>,
+    tuned_params_after: Option<serde_json::Value>,
+    rollback_triggered: Option<String>,
+    shadow_pnl_comparison: Option<f64>,
+}
+
+#[derive(Debug, Clone)]
+struct PaperDailyAgg {
+    starting_bankroll: f64,
+    ending_bankroll: f64,
+    trades: u64,
+    wins: u64,
+    fee_total_usdc: f64,
+    pnl_total_usdc: f64,
+    durations_ms: Vec<f64>,
+}
+
+#[derive(Default)]
+struct PaperRuntimeState {
+    bankroll: f64,
+    peak_bankroll: f64,
+    max_drawdown_pct: f64,
+    trades: u64,
+    wins: u64,
+    losses: u64,
+    fee_total_usdc: f64,
+    pnl_total_usdc: f64,
+    intents: HashMap<String, PaperIntent>,
+    open_lots: HashMap<String, VecDeque<PaperLot>>,
+    chainlink_aux_by_market: HashMap<String, f64>,
+    records: VecDeque<PaperTradeRecord>,
+    daily: BTreeMap<String, PaperDailyAgg>,
+}
+
+#[derive(Clone)]
+pub(crate) struct PaperRuntimeHandle {
+    enabled: bool,
+    run_id: String,
+    initial_capital: f64,
+    seat: Arc<SeatRuntimeHandle>,
+    sqlite: PaperSqliteWriter,
+    state: Arc<RwLock<PaperRuntimeState>>,
+}
+
+impl PaperRuntimeHandle {
+    pub(crate) fn new(
+        enabled: bool,
+        run_id: String,
+        initial_capital: f64,
+        sqlite_enabled: bool,
+        seat: Arc<SeatRuntimeHandle>,
+    ) -> Arc<Self> {
+        let sqlite_path = dataset_path("reports", "paper_summary.sqlite");
+        let sqlite = PaperSqliteWriter::spawn(sqlite_path, sqlite_enabled && enabled);
+        let mut state = PaperRuntimeState::default();
+        state.bankroll = initial_capital;
+        state.peak_bankroll = initial_capital;
+        Arc::new(Self {
+            enabled,
+            run_id,
+            initial_capital,
+            seat,
+            sqlite,
+            state: Arc::new(RwLock::new(state)),
+        })
+    }
+
+    pub(crate) async fn register_order_intent(&self, ack: &OrderAck, ctx: PaperIntentCtx) {
+        if !self.enabled {
+            return;
+        }
+        let seat_status = self.seat.status().await;
+        let last_decision = self.seat.history(1).into_iter().next();
+        let (tuned_before, tuned_after, rollback_triggered, shadow_pnl_comparison) =
+            extract_last_decision(last_decision.as_ref());
+
+        let intent = PaperIntent {
+            ts_ms: ack.ts_ms,
+            order_id: ack.order_id.clone(),
+            market_id: ctx.market_id,
+            symbol: ctx.symbol,
+            timeframe: ctx.timeframe,
+            stage: ctx.stage,
+            direction: ctx.direction,
+            velocity_bps_per_sec: ctx.velocity_bps_per_sec,
+            edge_bps: ctx.edge_bps,
+            prob_fast: ctx.prob_fast,
+            prob_settle: ctx.prob_settle,
+            confidence: ctx.confidence,
+            action: ctx.action,
+            intent: ctx.intent,
+            requested_size_usdc: ctx.requested_size_usdc,
+            requested_size_contracts: ctx.requested_size_contracts,
+            entry_price: ctx.entry_price,
+            seat_layer: Some(enum_text(&seat_status.current_layer)),
+            tuned_params_before: tuned_before,
+            tuned_params_after: tuned_after,
+            rollback_triggered,
+            shadow_pnl_comparison,
+        };
+        let mut s = self.state.write().await;
+        s.intents.insert(ack.order_id.clone(), intent);
+    }
+
+    pub(crate) async fn on_fill(&self, fill: &FillEvent) {
+        if !self.enabled {
+            return;
+        }
+        let mut s = self.state.write().await;
+        let ts_ms = fill.ts_ms.max(Utc::now().timestamp_millis());
+        let mut intent = s.intents.remove(fill.order_id.as_str()).unwrap_or_else(|| {
+            fallback_intent(fill, ts_ms, self.seat.history(1).into_iter().next().as_ref())
+        });
+        intent.requested_size_contracts = intent.requested_size_contracts.max(fill.size);
+        intent.requested_size_usdc = intent
+            .requested_size_usdc
+            .max(fill.price * intent.requested_size_contracts);
+        let mid = fill.mid_price.unwrap_or(fill.price).max(1e-9);
+        let slippage_bps = fill
+            .slippage_bps
+            .unwrap_or_else(|| ((fill.price - mid) / mid) * 10_000.0);
+        let _paper_fill = PaperFill {
+            ts_ms,
+            order_id: fill.order_id.clone(),
+            market_id: fill.market_id.clone(),
+            side: fill.side.clone(),
+            style: fill.style.clone(),
+            requested_size_usdc: intent.requested_size_usdc,
+            executed_size_usdc: fill.price * fill.size,
+            entry_price: intent.entry_price,
+            fill_price: fill.price,
+            mid_price: mid,
+            slippage_bps,
+            fee_usdc: fill.fee,
+        };
+
+        match fill.side {
+            OrderSide::BuyYes | OrderSide::BuyNo => {
+                self.open_lot_locked(&mut s, fill, intent, ts_ms);
+            }
+            OrderSide::SellYes | OrderSide::SellNo => {
+                self.close_lot_locked(&mut s, fill, intent, ts_ms, slippage_bps);
+            }
+        }
+        self.persist_reports_locked(&mut s);
+    }
+
+    pub(crate) async fn on_book(&self, book: &BookTop, chainlink_settlement_price: Option<f64>) {
+        if !self.enabled {
+            return;
+        }
+        let mut s = self.state.write().await;
+        let now_ms = book.ts_ms.max(Utc::now().timestamp_millis());
+        if let Some(price) = chainlink_settlement_price {
+            if price.is_finite() && price > 0.0 {
+                s.chainlink_aux_by_market.insert(book.market_id.clone(), price);
+            }
+        }
+        let mid_yes = (book.bid_yes + book.ask_yes) * 0.5;
+        let mid_no = (book.bid_no + book.ask_no) * 0.5;
+        self.force_settle_expired_locked(&mut s, &book.market_id, now_ms, mid_yes, mid_no);
+        self.persist_reports_locked(&mut s);
+    }
+
+    pub(crate) async fn reset(&self) {
+        let mut s = self.state.write().await;
+        *s = PaperRuntimeState {
+            bankroll: self.initial_capital,
+            peak_bankroll: self.initial_capital,
+            ..PaperRuntimeState::default()
+        };
+        self.sqlite.reset();
+        self.persist_reports_locked(&mut s);
+    }
+
+    pub(crate) async fn live_report(&self) -> PaperLiveReport {
+        let s = self.state.read().await;
+        build_live_report(&s, &self.run_id, self.initial_capital)
+    }
+
+    pub(crate) async fn history(&self, limit: usize) -> Vec<PaperTradeRecord> {
+        let s = self.state.read().await;
+        s.records.iter().rev().take(limit).cloned().collect()
+    }
+
+    pub(crate) async fn daily(&self) -> Vec<PaperDailySummary> {
+        let s = self.state.read().await;
+        build_daily_summaries(&s)
+    }
+
+    pub(crate) async fn summary_json(&self) -> serde_json::Value {
+        let s = self.state.read().await;
+        let live = build_live_report(&s, &self.run_id, self.initial_capital);
+        let analytics = build_analytics(&s.records);
+        serde_json::json!({
+            "ts_ms": Utc::now().timestamp_millis(),
+            "run_id": self.run_id,
+            "initial_capital": self.initial_capital,
+            "bankroll": live.bankroll,
+            "roi_pct": live.roi_pct,
+            "win_rate": live.win_rate,
+            "trades": live.trades,
+            "fee_total_usdc": live.fee_total_usdc,
+            "pnl_total_usdc": live.pnl_total_usdc,
+            "fee_ratio": live.fee_ratio,
+            "avg_trade_duration_ms": live.avg_trade_duration_ms,
+            "median_trade_duration_ms": live.median_trade_duration_ms,
+            "open_positions_count": live.open_positions_count,
+            "stage_distribution": analytics.stage_distribution,
+            "action_distribution": analytics.action_distribution,
+            "timeframe_distribution": analytics.timeframe_distribution,
+            "seat": {
+                "layer_distribution": analytics.seat_layer_distribution,
+                "rollback_count": analytics.seat_rollback_count,
+                "shadow_pnl_mean": analytics.shadow_pnl_mean,
+            },
+            "slippage": {
+                "avg_abs_slippage_bps": analytics.avg_abs_slippage_bps,
+                "avg_taker_abs_slippage_bps": analytics.avg_taker_abs_slippage_bps,
+                "worst_abs_slippage_bps": analytics.worst_abs_slippage_bps,
+            },
+            "reversal": {
+                "count": analytics.reversal_count,
+                "losing_count": analytics.reversal_losing_count,
+                "loss_rate": analytics.reversal_loss_rate,
+            }
+        })
+    }
+
+    fn open_lot_locked(
+        &self,
+        s: &mut PaperRuntimeState,
+        fill: &FillEvent,
+        mut intent: PaperIntent,
+        ts_ms: i64,
+    ) {
+        let key = lot_key(fill.market_id.as_str(), &fill.side);
+        let has_existing = s.open_lots.get(&key).map(|v| !v.is_empty()).unwrap_or(false);
+        if matches!(intent.action, PaperAction::Enter | PaperAction::Add) {
+            intent.action = if has_existing {
+                PaperAction::Add
+            } else {
+                PaperAction::Enter
+            };
+        }
+        let lot = PaperLot {
+            market_id: fill.market_id.clone(),
+            symbol: intent.symbol.clone(),
+            timeframe: intent.timeframe.clone(),
+            side: fill.side.clone(),
+            stage: intent.stage.clone(),
+            direction: intent.direction.clone(),
+            velocity_bps_per_sec: intent.velocity_bps_per_sec,
+            edge_bps: intent.edge_bps,
+            prob_fast: intent.prob_fast,
+            prob_settle: intent.prob_settle,
+            confidence: intent.confidence,
+            intent: fill.style.clone(),
+            requested_size_usdc: intent.requested_size_usdc,
+            entry_price: fill.price,
+            remaining_size: fill.size.max(0.0),
+            entry_fee_per_contract: if fill.size > 0.0 { fill.fee / fill.size } else { 0.0 },
+            opened_ts_ms: ts_ms,
+            seat_layer: intent.seat_layer,
+            tuned_params_before: intent.tuned_params_before,
+            tuned_params_after: intent.tuned_params_after,
+            rollback_triggered: intent.rollback_triggered,
+            shadow_pnl_comparison: intent.shadow_pnl_comparison,
+        };
+        s.fee_total_usdc += fill.fee;
+        s.open_lots.entry(key).or_default().push_back(lot);
+    }
+
+    fn close_lot_locked(
+        &self,
+        s: &mut PaperRuntimeState,
+        fill: &FillEvent,
+        intent: PaperIntent,
+        ts_ms: i64,
+        slippage_bps: f64,
+    ) {
+        let close_target_side = match fill.side {
+            OrderSide::SellYes => OrderSide::BuyYes,
+            OrderSide::SellNo => OrderSide::BuyNo,
+            _ => return,
+        };
+        let key = lot_key(fill.market_id.as_str(), &close_target_side);
+        let Some(mut lots) = s.open_lots.remove(&key) else {
+            return;
+        };
+
+        let mut remaining = fill.size.max(0.0);
+        if remaining <= 0.0 {
+            if !lots.is_empty() {
+                s.open_lots.insert(key, lots);
+            }
+            return;
+        }
+        let exit_fee_per_contract = if fill.size > 0.0 { fill.fee / fill.size } else { 0.0 };
+        while remaining > 1e-12 {
+            let Some(front) = lots.front_mut() else {
+                break;
+            };
+            let close_size = front.remaining_size.min(remaining);
+            if close_size <= 1e-12 {
+                break;
+            }
+            let entry_fee = front.entry_fee_per_contract * close_size;
+            let exit_fee = exit_fee_per_contract * close_size;
+            let pnl = (fill.price - front.entry_price) * close_size - entry_fee - exit_fee;
+            let bankroll_before = s.bankroll;
+            s.bankroll += pnl;
+            s.peak_bankroll = s.peak_bankroll.max(s.bankroll);
+            if s.peak_bankroll > 0.0 {
+                let dd = (s.peak_bankroll - s.bankroll) / s.peak_bankroll;
+                s.max_drawdown_pct = s.max_drawdown_pct.max(dd.max(0.0));
+            }
+            s.trades = s.trades.saturating_add(1);
+            if pnl >= 0.0 {
+                s.wins = s.wins.saturating_add(1);
+            } else {
+                s.losses = s.losses.saturating_add(1);
+            }
+            s.fee_total_usdc += exit_fee;
+            s.pnl_total_usdc += pnl;
+            let close_action = match intent.action {
+                PaperAction::ReversalExit | PaperAction::LateHeavy | PaperAction::DoubleSide => {
+                    intent.action.clone()
+                }
+                _ => {
+                    if matches!(front.stage, Stage::Late) {
+                        PaperAction::LateHeavy
+                    } else {
+                        PaperAction::ReversalExit
+                    }
+                }
+            };
+            let chainlink_settlement_price = s
+                .chainlink_aux_by_market
+                .get(&front.market_id)
+                .copied()
+                .filter(|v| v.is_finite() && *v > 0.0);
+            let record = PaperTradeRecord {
+                ts_ms,
+                paper_mode: "shadow".to_string(),
+                market_id: front.market_id.clone(),
+                symbol: front.symbol.clone(),
+                timeframe: front.timeframe.clone(),
+                stage: front.stage.clone(),
+                direction: front.direction.clone(),
+                velocity_bps_per_sec: front.velocity_bps_per_sec,
+                edge_bps: front.edge_bps,
+                prob_fast: front.prob_fast,
+                prob_settle: front.prob_settle,
+                confidence: front.confidence,
+                action: close_action,
+                intent: fill.style.clone(),
+                requested_size_usdc: front.requested_size_usdc,
+                executed_size_usdc: fill.price * close_size,
+                entry_price: front.entry_price,
+                fill_price: fill.price,
+                slippage_bps,
+                fee_usdc: entry_fee + exit_fee,
+                realized_pnl_usdc: pnl,
+                bankroll_before,
+                bankroll_after: s.bankroll,
+                settlement_price: fill.price,
+                chainlink_settlement_price,
+                settlement_source: "exit_fill".to_string(),
+                forced_settlement: false,
+                trade_duration_ms: ts_ms.saturating_sub(front.opened_ts_ms),
+                seat_layer: front.seat_layer.clone(),
+                tuned_params_before: front.tuned_params_before.clone(),
+                tuned_params_after: front.tuned_params_after.clone(),
+                rollback_triggered: front.rollback_triggered.clone(),
+                shadow_pnl_comparison: front.shadow_pnl_comparison,
+            };
+            self.push_record_locked(s, record);
+            front.remaining_size -= close_size;
+            if front.remaining_size <= 1e-12 {
+                lots.pop_front();
+            }
+            remaining -= close_size;
+        }
+        if !lots.is_empty() {
+            s.open_lots.insert(key, lots);
+        }
+    }
+
+    fn force_settle_expired_locked(
+        &self,
+        s: &mut PaperRuntimeState,
+        market_id: &str,
+        now_ms: i64,
+        mid_yes: f64,
+        mid_no: f64,
+    ) {
+        let mut keys = Vec::new();
+        keys.push(lot_key(market_id, &OrderSide::BuyYes));
+        keys.push(lot_key(market_id, &OrderSide::BuyNo));
+        for key in keys {
+            let Some(lots) = s.open_lots.get_mut(&key) else {
+                continue;
+            };
+            let chainlink_settlement_price = s
+                .chainlink_aux_by_market
+                .get(market_id)
+                .copied()
+                .filter(|v| v.is_finite() && *v > 0.0);
+            let mut settled = Vec::new();
+            while let Some(front) = lots.front() {
+                if !is_expired(front.opened_ts_ms, now_ms, front.timeframe.as_str()) {
+                    break;
+                }
+                settled.push(front.clone());
+                lots.pop_front();
+            }
+            for lot in settled {
+                let close_price = match lot.side {
+                    OrderSide::BuyYes | OrderSide::SellYes => mid_yes.max(0.0),
+                    OrderSide::BuyNo | OrderSide::SellNo => mid_no.max(0.0),
+                };
+                let entry_fee = lot.entry_fee_per_contract * lot.remaining_size;
+                let pnl = (close_price - lot.entry_price) * lot.remaining_size - entry_fee;
+                let bankroll_before = s.bankroll;
+                s.bankroll += pnl;
+                s.peak_bankroll = s.peak_bankroll.max(s.bankroll);
+                if s.peak_bankroll > 0.0 {
+                    let dd = (s.peak_bankroll - s.bankroll) / s.peak_bankroll;
+                    s.max_drawdown_pct = s.max_drawdown_pct.max(dd.max(0.0));
+                }
+                s.trades = s.trades.saturating_add(1);
+                if pnl >= 0.0 {
+                    s.wins = s.wins.saturating_add(1);
+                } else {
+                    s.losses = s.losses.saturating_add(1);
+                }
+                s.pnl_total_usdc += pnl;
+                let record = PaperTradeRecord {
+                    ts_ms: now_ms,
+                    paper_mode: "shadow".to_string(),
+                    market_id: lot.market_id.clone(),
+                    symbol: lot.symbol.clone(),
+                    timeframe: lot.timeframe.clone(),
+                    stage: lot.stage.clone(),
+                    direction: lot.direction.clone(),
+                    velocity_bps_per_sec: lot.velocity_bps_per_sec,
+                    edge_bps: lot.edge_bps,
+                    prob_fast: lot.prob_fast,
+                    prob_settle: lot.prob_settle,
+                    confidence: lot.confidence,
+                    action: PaperAction::LateHeavy,
+                    intent: lot.intent.clone(),
+                    requested_size_usdc: lot.requested_size_usdc,
+                    executed_size_usdc: close_price * lot.remaining_size,
+                    entry_price: lot.entry_price,
+                    fill_price: close_price,
+                    slippage_bps: 0.0,
+                    fee_usdc: entry_fee,
+                    realized_pnl_usdc: pnl,
+                    bankroll_before,
+                    bankroll_after: s.bankroll,
+                    settlement_price: close_price,
+                    chainlink_settlement_price,
+                    settlement_source: "pm_mid".to_string(),
+                    forced_settlement: true,
+                    trade_duration_ms: now_ms.saturating_sub(lot.opened_ts_ms),
+                    seat_layer: lot.seat_layer.clone(),
+                    tuned_params_before: lot.tuned_params_before.clone(),
+                    tuned_params_after: lot.tuned_params_after.clone(),
+                    rollback_triggered: lot.rollback_triggered.clone(),
+                    shadow_pnl_comparison: lot.shadow_pnl_comparison,
+                };
+                self.push_record_locked(s, record);
+            }
+        }
+    }
+
+    fn push_record_locked(&self, s: &mut PaperRuntimeState, record: PaperTradeRecord) {
+        update_daily(s, &record);
+        append_jsonl(
+            &dataset_path("normalized", "paper_records.jsonl"),
+            &serde_json::json!(record),
+        );
+        self.sqlite.push_trade(&record);
+        s.records.push_back(record);
+        if s.records.len() > HISTORY_CAP {
+            let _ = s.records.pop_front();
+        }
+    }
+
+    fn persist_reports_locked(&self, s: &mut PaperRuntimeState) {
+        let live = build_live_report(s, &self.run_id, self.initial_capital);
+        let analytics = build_analytics(&s.records);
+        let summary = serde_json::json!({
+            "run_id": self.run_id,
+            "ts_ms": live.ts_ms,
+            "initial_capital": self.initial_capital,
+            "bankroll": live.bankroll,
+            "roi_pct": live.roi_pct,
+            "trades": live.trades,
+            "wins": live.wins,
+            "losses": live.losses,
+            "win_rate": live.win_rate,
+            "max_drawdown_pct": live.max_drawdown_pct,
+            "fee_total_usdc": live.fee_total_usdc,
+            "pnl_total_usdc": live.pnl_total_usdc,
+            "fee_ratio": live.fee_ratio,
+            "avg_trade_duration_ms": live.avg_trade_duration_ms,
+            "median_trade_duration_ms": live.median_trade_duration_ms,
+            "open_positions_count": live.open_positions_count,
+            "stage_distribution": analytics.stage_distribution,
+            "action_distribution": analytics.action_distribution,
+            "timeframe_distribution": analytics.timeframe_distribution,
+            "seat": {
+                "layer_distribution": analytics.seat_layer_distribution,
+                "rollback_count": analytics.seat_rollback_count,
+                "shadow_pnl_mean": analytics.shadow_pnl_mean,
+            },
+            "slippage": {
+                "avg_abs_slippage_bps": analytics.avg_abs_slippage_bps,
+                "avg_taker_abs_slippage_bps": analytics.avg_taker_abs_slippage_bps,
+                "worst_abs_slippage_bps": analytics.worst_abs_slippage_bps,
+            },
+            "reversal": {
+                "count": analytics.reversal_count,
+                "losing_count": analytics.reversal_losing_count,
+                "loss_rate": analytics.reversal_loss_rate,
+            }
+        });
+        let diagnosis = serde_json::json!({
+            "ts_ms": live.ts_ms,
+            "alerts": build_diagnosis_alerts(&live, &analytics),
+            "root_causes": build_root_causes(&live, &analytics),
+            "slippage": {
+                "avg_abs_slippage_bps": analytics.avg_abs_slippage_bps,
+                "avg_taker_abs_slippage_bps": analytics.avg_taker_abs_slippage_bps,
+                "worst_abs_slippage_bps": analytics.worst_abs_slippage_bps,
+            },
+            "reversal": {
+                "count": analytics.reversal_count,
+                "losing_count": analytics.reversal_losing_count,
+                "loss_rate": analytics.reversal_loss_rate,
+            },
+            "seat": {
+                "layer_distribution": analytics.seat_layer_distribution,
+                "rollback_count": analytics.seat_rollback_count,
+                "shadow_pnl_mean": analytics.shadow_pnl_mean,
+            },
+            "stage_distribution": analytics.stage_distribution,
+            "action_distribution": analytics.action_distribution,
+        });
+        let daily = build_daily_summaries(s);
+        write_json_file(dataset_path("reports", "paper_live_latest.json"), &live);
+        write_json_file(dataset_path("reports", "paper_summary_latest.json"), &summary);
+        write_json_file(dataset_path("reports", "paper_diagnosis_latest.json"), &diagnosis);
+        write_daily_csv(dataset_path("reports", "daily_compound_summary.csv"), &daily);
+        for day in &daily {
+            self.sqlite.push_daily(day);
+        }
+        self.sqlite.push_summary(&live);
+    }
+}
+
+pub(crate) fn set_global_paper_runtime(handle: Arc<PaperRuntimeHandle>) {
+    let _ = GLOBAL_PAPER_RUNTIME.set(handle);
+}
+
+pub(crate) fn global_paper_runtime() -> Option<Arc<PaperRuntimeHandle>> {
+    GLOBAL_PAPER_RUNTIME.get().cloned()
+}
+
+fn fallback_intent(fill: &FillEvent, ts_ms: i64, decision: Option<&SeatDecisionRecord>) -> PaperIntent {
+    let (tuned_before, tuned_after, rollback_triggered, shadow_pnl_comparison) =
+        extract_last_decision(decision);
+    PaperIntent {
+        ts_ms,
+        order_id: fill.order_id.clone(),
+        market_id: fill.market_id.clone(),
+        symbol: fill.market_id.clone(),
+        timeframe: "unknown".to_string(),
+        stage: Stage::Early,
+        direction: match fill.side {
+            OrderSide::BuyYes | OrderSide::SellNo => Direction::Up,
+            OrderSide::BuyNo | OrderSide::SellYes => Direction::Down,
+        },
+        velocity_bps_per_sec: 0.0,
+        edge_bps: 0.0,
+        prob_fast: 0.5,
+        prob_settle: 0.5,
+        confidence: 0.0,
+        action: PaperAction::Enter,
+        intent: fill.style.clone(),
+        requested_size_usdc: fill.price * fill.size,
+        requested_size_contracts: fill.size,
+        entry_price: fill.price,
+        seat_layer: None,
+        tuned_params_before: tuned_before,
+        tuned_params_after: tuned_after,
+        rollback_triggered,
+        shadow_pnl_comparison,
+    }
+}
+
+fn extract_last_decision(
+    decision: Option<&SeatDecisionRecord>,
+) -> (
+    Option<serde_json::Value>,
+    Option<serde_json::Value>,
+    Option<String>,
+    Option<f64>,
+) {
+    let Some(d) = decision else {
+        return (None, None, None, None);
+    };
+    let before = serde_json::to_value(&d.previous).ok();
+    let after = serde_json::to_value(&d.candidate).ok();
+    let rollback_triggered = if d.rollback {
+        Some(d.decision.clone())
+    } else {
+        None
+    };
+    let shadow_pnl = d
+        .notes
+        .iter()
+        .find_map(|v| v.strip_prefix("shadow_ev_usdc_p50="))
+        .and_then(|v| v.parse::<f64>().ok());
+    (before, after, rollback_triggered, shadow_pnl)
+}
+
+fn update_daily(s: &mut PaperRuntimeState, record: &PaperTradeRecord) {
+    let day = Utc
+        .timestamp_millis_opt(record.ts_ms)
+        .single()
+        .unwrap_or_else(Utc::now)
+        .format("%Y-%m-%d")
+        .to_string();
+    let entry = s.daily.entry(day).or_insert_with(|| PaperDailyAgg {
+        starting_bankroll: record.bankroll_before,
+        ending_bankroll: record.bankroll_after,
+        trades: 0,
+        wins: 0,
+        fee_total_usdc: 0.0,
+        pnl_total_usdc: 0.0,
+        durations_ms: Vec::new(),
+    });
+    entry.trades = entry.trades.saturating_add(1);
+    if record.realized_pnl_usdc >= 0.0 {
+        entry.wins = entry.wins.saturating_add(1);
+    }
+    entry.ending_bankroll = record.bankroll_after;
+    entry.fee_total_usdc += record.fee_usdc;
+    entry.pnl_total_usdc += record.realized_pnl_usdc;
+    entry
+        .durations_ms
+        .push(record.trade_duration_ms.max(0) as f64);
+}
+
+fn build_live_report(s: &PaperRuntimeState, run_id: &str, initial_capital: f64) -> PaperLiveReport {
+    let durations = s
+        .records
+        .iter()
+        .map(|r| r.trade_duration_ms.max(0) as f64)
+        .collect::<Vec<_>>();
+    let avg_trade_duration_ms = if durations.is_empty() {
+        0.0
+    } else {
+        durations.iter().sum::<f64>() / durations.len() as f64
+    };
+    let median_trade_duration_ms = percentile(&durations, 0.50).unwrap_or(0.0);
+    let win_rate = if s.trades == 0 {
+        0.0
+    } else {
+        s.wins as f64 / s.trades as f64
+    };
+    let roi_pct = if initial_capital.abs() < 1e-9 {
+        0.0
+    } else {
+        (s.bankroll - initial_capital) / initial_capital * 100.0
+    };
+    let fee_ratio = if s.pnl_total_usdc.abs() < 1e-9 {
+        0.0
+    } else {
+        (s.fee_total_usdc / s.pnl_total_usdc.abs()).abs()
+    };
+    let open_positions_count = s.open_lots.values().map(|v| v.len()).sum::<usize>();
+    PaperLiveReport {
+        ts_ms: Utc::now().timestamp_millis(),
+        run_id: run_id.to_string(),
+        initial_capital,
+        bankroll: s.bankroll,
+        trades: s.trades,
+        wins: s.wins,
+        losses: s.losses,
+        win_rate,
+        roi_pct,
+        max_drawdown_pct: s.max_drawdown_pct * 100.0,
+        fee_total_usdc: s.fee_total_usdc,
+        pnl_total_usdc: s.pnl_total_usdc,
+        fee_ratio,
+        avg_trade_duration_ms,
+        median_trade_duration_ms,
+        trade_count_source: "shadow_fill".to_string(),
+        open_positions_count,
+    }
+}
+
+fn build_daily_summaries(s: &PaperRuntimeState) -> Vec<PaperDailySummary> {
+    s.daily
+        .iter()
+        .map(|(day, agg)| {
+            let win_rate = if agg.trades == 0 {
+                0.0
+            } else {
+                agg.wins as f64 / agg.trades as f64
+            };
+            let daily_roi_pct = if agg.starting_bankroll.abs() < 1e-9 {
+                0.0
+            } else {
+                (agg.ending_bankroll - agg.starting_bankroll) / agg.starting_bankroll * 100.0
+            };
+            let avg_trade_duration_ms = if agg.durations_ms.is_empty() {
+                0.0
+            } else {
+                agg.durations_ms.iter().sum::<f64>() / agg.durations_ms.len() as f64
+            };
+            let median_trade_duration_ms = percentile(&agg.durations_ms, 0.50).unwrap_or(0.0);
+            PaperDailySummary {
+                utc_day: day.clone(),
+                starting_bankroll: agg.starting_bankroll,
+                ending_bankroll: agg.ending_bankroll,
+                daily_roi_pct,
+                trades: agg.trades,
+                win_rate,
+                fee_total_usdc: agg.fee_total_usdc,
+                pnl_total_usdc: agg.pnl_total_usdc,
+                avg_trade_duration_ms,
+                median_trade_duration_ms,
+            }
+        })
+        .collect()
+}
+
+#[derive(Default)]
+struct PaperAnalytics {
+    stage_distribution: BTreeMap<String, u64>,
+    action_distribution: BTreeMap<String, u64>,
+    timeframe_distribution: BTreeMap<String, u64>,
+    seat_layer_distribution: BTreeMap<String, u64>,
+    seat_rollback_count: u64,
+    shadow_pnl_mean: f64,
+    avg_abs_slippage_bps: f64,
+    avg_taker_abs_slippage_bps: f64,
+    worst_abs_slippage_bps: f64,
+    reversal_count: u64,
+    reversal_losing_count: u64,
+    reversal_loss_rate: f64,
+}
+
+fn build_analytics(records: &VecDeque<PaperTradeRecord>) -> PaperAnalytics {
+    let mut out = PaperAnalytics::default();
+    let mut abs_slippage_sum = 0.0;
+    let mut abs_slippage_cnt = 0_u64;
+    let mut taker_abs_slippage_sum = 0.0;
+    let mut taker_abs_slippage_cnt = 0_u64;
+    let mut shadow_pnl_sum = 0.0;
+    let mut shadow_pnl_cnt = 0_u64;
+
+    for r in records {
+        *out.stage_distribution.entry(enum_text(&r.stage)).or_default() += 1;
+        *out.action_distribution.entry(enum_text(&r.action)).or_default() += 1;
+        *out.timeframe_distribution.entry(r.timeframe.clone()).or_default() += 1;
+        if let Some(layer) = &r.seat_layer {
+            *out.seat_layer_distribution.entry(layer.clone()).or_default() += 1;
+        }
+        if r.rollback_triggered.is_some() {
+            out.seat_rollback_count = out.seat_rollback_count.saturating_add(1);
+        }
+        if let Some(v) = r.shadow_pnl_comparison {
+            if v.is_finite() {
+                shadow_pnl_sum += v;
+                shadow_pnl_cnt = shadow_pnl_cnt.saturating_add(1);
+            }
+        }
+
+        let abs_slippage = r.slippage_bps.abs();
+        if abs_slippage.is_finite() {
+            abs_slippage_sum += abs_slippage;
+            abs_slippage_cnt = abs_slippage_cnt.saturating_add(1);
+            out.worst_abs_slippage_bps = out.worst_abs_slippage_bps.max(abs_slippage);
+            if !matches!(r.intent, ExecutionStyle::Maker) {
+                taker_abs_slippage_sum += abs_slippage;
+                taker_abs_slippage_cnt = taker_abs_slippage_cnt.saturating_add(1);
+            }
+        }
+        if matches!(r.action, PaperAction::ReversalExit) {
+            out.reversal_count = out.reversal_count.saturating_add(1);
+            if r.realized_pnl_usdc < 0.0 {
+                out.reversal_losing_count = out.reversal_losing_count.saturating_add(1);
+            }
+        }
+    }
+
+    out.shadow_pnl_mean = if shadow_pnl_cnt == 0 {
+        0.0
+    } else {
+        shadow_pnl_sum / shadow_pnl_cnt as f64
+    };
+    out.avg_abs_slippage_bps = if abs_slippage_cnt == 0 {
+        0.0
+    } else {
+        abs_slippage_sum / abs_slippage_cnt as f64
+    };
+    out.avg_taker_abs_slippage_bps = if taker_abs_slippage_cnt == 0 {
+        0.0
+    } else {
+        taker_abs_slippage_sum / taker_abs_slippage_cnt as f64
+    };
+    out.reversal_loss_rate = if out.reversal_count == 0 {
+        0.0
+    } else {
+        out.reversal_losing_count as f64 / out.reversal_count as f64
+    };
+    out
+}
+
+fn build_diagnosis_alerts(live: &PaperLiveReport, analytics: &PaperAnalytics) -> Vec<String> {
+    let mut alerts = Vec::new();
+    if live.trades == 0 {
+        alerts.push("no_trades_recorded".to_string());
+    }
+    if live.win_rate < 0.45 && live.trades >= 20 {
+        alerts.push("low_win_rate".to_string());
+    }
+    if live.fee_ratio > 0.5 && live.trades > 0 {
+        alerts.push("fee_ratio_high".to_string());
+    }
+    if live.max_drawdown_pct > 20.0 {
+        alerts.push("drawdown_high".to_string());
+    }
+    if analytics.avg_taker_abs_slippage_bps > 15.0 && live.trades >= 10 {
+        alerts.push("taker_slippage_high".to_string());
+    }
+    if analytics.reversal_loss_rate > 0.60 && analytics.reversal_count >= 10 {
+        alerts.push("reversal_exit_underperforming".to_string());
+    }
+    if analytics.seat_rollback_count >= 2 {
+        alerts.push("seat_rollback_frequent".to_string());
+    }
+    alerts
+}
+
+fn build_root_causes(live: &PaperLiveReport, analytics: &PaperAnalytics) -> Vec<String> {
+    let mut causes = Vec::new();
+    if live.trades == 0 {
+        causes.push("entry_conditions_too_strict_or_feed_inactive".to_string());
+    }
+    if live.fee_ratio > 0.6 {
+        causes.push("fee_dominates_edge_tune_min_edge_or_taker_usage".to_string());
+    }
+    if analytics.avg_taker_abs_slippage_bps > 15.0 {
+        causes.push("taker_slippage_excessive_consider_maker_bias_or_spread_filter".to_string());
+    }
+    if analytics.reversal_loss_rate > 0.60 && analytics.reversal_count >= 10 {
+        causes.push("reversal_exit_rule_quality_low_check_velocity_and_edge_thresholds".to_string());
+    }
+    if live.max_drawdown_pct > 20.0 {
+        causes.push("risk_controls_too_loose_reduce_position_fraction_or_drawdown_limit".to_string());
+    }
+    if causes.is_empty() {
+        causes.push("no_critical_issue_detected".to_string());
+    }
+    causes
+}
+
+fn lot_key(market_id: &str, side: &OrderSide) -> String {
+    format!("{market_id}|{}", enum_text(side))
+}
+
+fn frame_ms(timeframe: &str) -> i64 {
+    match timeframe {
+        "5m" | "5min" => 5 * 60 * 1_000,
+        "15m" | "15min" => 15 * 60 * 1_000,
+        "1h" => 60 * 60 * 1_000,
+        "1d" => 24 * 60 * 60 * 1_000,
+        _ => i64::MAX,
+    }
+}
+
+fn is_expired(opened_ts_ms: i64, now_ms: i64, timeframe: &str) -> bool {
+    let fm = frame_ms(timeframe);
+    if fm == i64::MAX || opened_ts_ms <= 0 || now_ms <= 0 {
+        return false;
+    }
+    opened_ts_ms.div_euclid(fm) < now_ms.div_euclid(fm)
+}
+
+fn enum_text<T: serde::Serialize>(value: &T) -> String {
+    serde_json::to_value(value)
+        .ok()
+        .and_then(|v| v.as_str().map(ToOwned::to_owned))
+        .unwrap_or_else(|| "unknown".to_string())
+}
+
+fn write_json_file(path: PathBuf, value: &impl serde::Serialize) {
+    if let Some(parent) = path.parent() {
+        let _ = std::fs::create_dir_all(parent);
+    }
+    if let Ok(raw) = serde_json::to_vec_pretty(value) {
+        let _ = std::fs::write(path, raw);
+    }
+}
+
+fn write_daily_csv(path: PathBuf, days: &[PaperDailySummary]) {
+    if let Some(parent) = path.parent() {
+        let _ = std::fs::create_dir_all(parent);
+    }
+    let mut out = String::new();
+    out.push_str("utc_day,starting_bankroll,ending_bankroll,daily_roi_pct,trades,win_rate,fee_total_usdc,pnl_total_usdc,avg_trade_duration_ms,median_trade_duration_ms\n");
+    for d in days {
+        out.push_str(&format!(
+            "{},{:.6},{:.6},{:.6},{},{:.6},{:.6},{:.6},{:.3},{:.3}\n",
+            d.utc_day,
+            d.starting_bankroll,
+            d.ending_bankroll,
+            d.daily_roi_pct,
+            d.trades,
+            d.win_rate,
+            d.fee_total_usdc,
+            d.pnl_total_usdc,
+            d.avg_trade_duration_ms,
+            d.median_trade_duration_ms
+        ));
+    }
+    let _ = std::fs::write(path, out);
+}
diff --git a/crates/app_runner/src/paper_sqlite.rs b/crates/app_runner/src/paper_sqlite.rs
new file mode 100644
index 0000000..639b416
--- /dev/null
+++ b/crates/app_runner/src/paper_sqlite.rs
@@ -0,0 +1,316 @@
+use std::fs;
+use std::path::PathBuf;
+use std::sync::mpsc;
+use std::thread;
+
+use core_types::{PaperDailySummary, PaperLiveReport, PaperTradeRecord};
+use rusqlite::{params, Connection};
+
+#[derive(Debug)]
+enum SqliteMsg {
+    Trade(PaperTradeRecord),
+    Daily(PaperDailySummary),
+    Summary(PaperLiveReport),
+    Reset,
+}
+
+#[derive(Clone, Default)]
+pub(crate) struct PaperSqliteWriter {
+    tx: Option<mpsc::Sender<SqliteMsg>>,
+}
+
+impl PaperSqliteWriter {
+    pub(crate) fn spawn(path: PathBuf, enabled: bool) -> Self {
+        if !enabled {
+            return Self { tx: None };
+        }
+        let (tx, rx) = mpsc::channel::<SqliteMsg>();
+        thread::spawn(move || {
+            if let Err(err) = run_writer(path, rx) {
+                tracing::warn!(error = %err, "paper sqlite writer exited");
+            }
+        });
+        Self { tx: Some(tx) }
+    }
+
+    pub(crate) fn push_trade(&self, record: &PaperTradeRecord) {
+        if let Some(tx) = &self.tx {
+            let _ = tx.send(SqliteMsg::Trade(record.clone()));
+        }
+    }
+
+    pub(crate) fn push_daily(&self, daily: &PaperDailySummary) {
+        if let Some(tx) = &self.tx {
+            let _ = tx.send(SqliteMsg::Daily(daily.clone()));
+        }
+    }
+
+    pub(crate) fn push_summary(&self, report: &PaperLiveReport) {
+        if let Some(tx) = &self.tx {
+            let _ = tx.send(SqliteMsg::Summary(report.clone()));
+        }
+    }
+
+    pub(crate) fn reset(&self) {
+        if let Some(tx) = &self.tx {
+            let _ = tx.send(SqliteMsg::Reset);
+        }
+    }
+}
+
+fn run_writer(path: PathBuf, rx: mpsc::Receiver<SqliteMsg>) -> anyhow::Result<()> {
+    if let Some(parent) = path.parent() {
+        fs::create_dir_all(parent)?;
+    }
+    let conn = Connection::open(path)?;
+    init_schema(&conn)?;
+
+    while let Ok(msg) = rx.recv() {
+        match msg {
+            SqliteMsg::Trade(r) => insert_trade(&conn, &r)?,
+            SqliteMsg::Daily(d) => upsert_daily(&conn, &d)?,
+            SqliteMsg::Summary(s) => upsert_summary(&conn, &s)?,
+            SqliteMsg::Reset => reset_all(&conn)?,
+        }
+    }
+    Ok(())
+}
+
+fn init_schema(conn: &Connection) -> anyhow::Result<()> {
+    conn.execute_batch(
+        r#"
+        CREATE TABLE IF NOT EXISTS paper_records (
+            id INTEGER PRIMARY KEY AUTOINCREMENT,
+            ts_ms INTEGER NOT NULL,
+            paper_mode TEXT NOT NULL,
+            market_id TEXT NOT NULL,
+            symbol TEXT NOT NULL,
+            timeframe TEXT NOT NULL,
+            stage TEXT NOT NULL,
+            direction TEXT NOT NULL,
+            velocity_bps_per_sec REAL NOT NULL,
+            edge_bps REAL NOT NULL,
+            prob_fast REAL NOT NULL,
+            prob_settle REAL NOT NULL,
+            confidence REAL NOT NULL,
+            action TEXT NOT NULL,
+            intent TEXT NOT NULL,
+            requested_size_usdc REAL NOT NULL,
+            executed_size_usdc REAL NOT NULL,
+            entry_price REAL NOT NULL,
+            fill_price REAL NOT NULL,
+            slippage_bps REAL NOT NULL,
+            fee_usdc REAL NOT NULL,
+            realized_pnl_usdc REAL NOT NULL,
+            bankroll_before REAL NOT NULL,
+            bankroll_after REAL NOT NULL,
+            settlement_price REAL NOT NULL,
+            chainlink_settlement_price REAL NULL,
+            settlement_source TEXT NOT NULL,
+            forced_settlement INTEGER NOT NULL,
+            trade_duration_ms INTEGER NOT NULL,
+            seat_layer TEXT NULL,
+            tuned_params_before TEXT NULL,
+            tuned_params_after TEXT NULL,
+            rollback_triggered TEXT NULL,
+            shadow_pnl_comparison REAL NULL
+        );
+        CREATE INDEX IF NOT EXISTS idx_paper_records_ts ON paper_records(ts_ms);
+        CREATE INDEX IF NOT EXISTS idx_paper_records_market ON paper_records(market_id);
+
+        CREATE TABLE IF NOT EXISTS paper_daily_summary (
+            utc_day TEXT PRIMARY KEY,
+            starting_bankroll REAL NOT NULL,
+            ending_bankroll REAL NOT NULL,
+            daily_roi_pct REAL NOT NULL,
+            trades INTEGER NOT NULL,
+            win_rate REAL NOT NULL,
+            fee_total_usdc REAL NOT NULL,
+            pnl_total_usdc REAL NOT NULL,
+            avg_trade_duration_ms REAL NOT NULL,
+            median_trade_duration_ms REAL NOT NULL
+        );
+
+        CREATE TABLE IF NOT EXISTS paper_run_summary (
+            run_id TEXT PRIMARY KEY,
+            ts_ms INTEGER NOT NULL,
+            initial_capital REAL NOT NULL,
+            bankroll REAL NOT NULL,
+            trades INTEGER NOT NULL,
+            wins INTEGER NOT NULL,
+            losses INTEGER NOT NULL,
+            win_rate REAL NOT NULL,
+            roi_pct REAL NOT NULL,
+            max_drawdown_pct REAL NOT NULL,
+            fee_total_usdc REAL NOT NULL,
+            pnl_total_usdc REAL NOT NULL,
+            fee_ratio REAL NOT NULL,
+            avg_trade_duration_ms REAL NOT NULL,
+            median_trade_duration_ms REAL NOT NULL,
+            trade_count_source TEXT NOT NULL,
+            open_positions_count INTEGER NOT NULL
+        );
+        "#,
+    )?;
+    let _ = conn.execute(
+        "ALTER TABLE paper_records ADD COLUMN chainlink_settlement_price REAL NULL",
+        [],
+    );
+    Ok(())
+}
+
+fn insert_trade(conn: &Connection, r: &PaperTradeRecord) -> anyhow::Result<()> {
+    conn.execute(
+        r#"
+        INSERT INTO paper_records (
+            ts_ms, paper_mode, market_id, symbol, timeframe, stage, direction,
+            velocity_bps_per_sec, edge_bps, prob_fast, prob_settle, confidence, action, intent,
+            requested_size_usdc, executed_size_usdc, entry_price, fill_price, slippage_bps,
+            fee_usdc, realized_pnl_usdc, bankroll_before, bankroll_after, settlement_price,
+            chainlink_settlement_price, settlement_source, forced_settlement, trade_duration_ms, seat_layer,
+            tuned_params_before, tuned_params_after, rollback_triggered, shadow_pnl_comparison
+        ) VALUES (
+            ?, ?, ?, ?, ?, ?, ?,
+            ?, ?, ?, ?, ?, ?, ?,
+            ?, ?, ?, ?, ?,
+            ?, ?, ?, ?, ?,
+            ?, ?, ?, ?, ?,
+            ?, ?, ?, ?
+        )
+        "#,
+        params![
+            r.ts_ms,
+            r.paper_mode,
+            r.market_id,
+            r.symbol,
+            r.timeframe,
+            enum_text(&r.stage),
+            enum_text(&r.direction),
+            r.velocity_bps_per_sec,
+            r.edge_bps,
+            r.prob_fast,
+            r.prob_settle,
+            r.confidence,
+            enum_text(&r.action),
+            enum_text(&r.intent),
+            r.requested_size_usdc,
+            r.executed_size_usdc,
+            r.entry_price,
+            r.fill_price,
+            r.slippage_bps,
+            r.fee_usdc,
+            r.realized_pnl_usdc,
+            r.bankroll_before,
+            r.bankroll_after,
+            r.settlement_price,
+            r.chainlink_settlement_price,
+            r.settlement_source,
+            if r.forced_settlement { 1_i64 } else { 0_i64 },
+            r.trade_duration_ms,
+            r.seat_layer,
+            r.tuned_params_before.as_ref().map(|v| v.to_string()),
+            r.tuned_params_after.as_ref().map(|v| v.to_string()),
+            r.rollback_triggered,
+            r.shadow_pnl_comparison,
+        ],
+    )?;
+    Ok(())
+}
+
+fn upsert_daily(conn: &Connection, d: &PaperDailySummary) -> anyhow::Result<()> {
+    conn.execute(
+        r#"
+        INSERT INTO paper_daily_summary (
+            utc_day, starting_bankroll, ending_bankroll, daily_roi_pct,
+            trades, win_rate, fee_total_usdc, pnl_total_usdc,
+            avg_trade_duration_ms, median_trade_duration_ms
+        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
+        ON CONFLICT(utc_day) DO UPDATE SET
+            starting_bankroll=excluded.starting_bankroll,
+            ending_bankroll=excluded.ending_bankroll,
+            daily_roi_pct=excluded.daily_roi_pct,
+            trades=excluded.trades,
+            win_rate=excluded.win_rate,
+            fee_total_usdc=excluded.fee_total_usdc,
+            pnl_total_usdc=excluded.pnl_total_usdc,
+            avg_trade_duration_ms=excluded.avg_trade_duration_ms,
+            median_trade_duration_ms=excluded.median_trade_duration_ms
+        "#,
+        params![
+            d.utc_day,
+            d.starting_bankroll,
+            d.ending_bankroll,
+            d.daily_roi_pct,
+            d.trades as i64,
+            d.win_rate,
+            d.fee_total_usdc,
+            d.pnl_total_usdc,
+            d.avg_trade_duration_ms,
+            d.median_trade_duration_ms
+        ],
+    )?;
+    Ok(())
+}
+
+fn upsert_summary(conn: &Connection, s: &PaperLiveReport) -> anyhow::Result<()> {
+    conn.execute(
+        r#"
+        INSERT INTO paper_run_summary (
+            run_id, ts_ms, initial_capital, bankroll, trades, wins, losses, win_rate, roi_pct,
+            max_drawdown_pct, fee_total_usdc, pnl_total_usdc, fee_ratio,
+            avg_trade_duration_ms, median_trade_duration_ms, trade_count_source, open_positions_count
+        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
+        ON CONFLICT(run_id) DO UPDATE SET
+            ts_ms=excluded.ts_ms,
+            initial_capital=excluded.initial_capital,
+            bankroll=excluded.bankroll,
+            trades=excluded.trades,
+            wins=excluded.wins,
+            losses=excluded.losses,
+            win_rate=excluded.win_rate,
+            roi_pct=excluded.roi_pct,
+            max_drawdown_pct=excluded.max_drawdown_pct,
+            fee_total_usdc=excluded.fee_total_usdc,
+            pnl_total_usdc=excluded.pnl_total_usdc,
+            fee_ratio=excluded.fee_ratio,
+            avg_trade_duration_ms=excluded.avg_trade_duration_ms,
+            median_trade_duration_ms=excluded.median_trade_duration_ms,
+            trade_count_source=excluded.trade_count_source,
+            open_positions_count=excluded.open_positions_count
+        "#,
+        params![
+            s.run_id,
+            s.ts_ms,
+            s.initial_capital,
+            s.bankroll,
+            s.trades as i64,
+            s.wins as i64,
+            s.losses as i64,
+            s.win_rate,
+            s.roi_pct,
+            s.max_drawdown_pct,
+            s.fee_total_usdc,
+            s.pnl_total_usdc,
+            s.fee_ratio,
+            s.avg_trade_duration_ms,
+            s.median_trade_duration_ms,
+            s.trade_count_source,
+            s.open_positions_count as i64,
+        ],
+    )?;
+    Ok(())
+}
+
+fn reset_all(conn: &Connection) -> anyhow::Result<()> {
+    conn.execute("DELETE FROM paper_records", [])?;
+    conn.execute("DELETE FROM paper_daily_summary", [])?;
+    conn.execute("DELETE FROM paper_run_summary", [])?;
+    Ok(())
+}
+
+fn enum_text<T: serde::Serialize>(value: &T) -> String {
+    serde_json::to_value(value)
+        .ok()
+        .and_then(|v| v.as_str().map(ToOwned::to_owned))
+        .unwrap_or_else(|| "unknown".to_string())
+}
diff --git a/crates/app_runner/src/report_io.rs b/crates/app_runner/src/report_io.rs
new file mode 100644
index 0000000..42f1450
--- /dev/null
+++ b/crates/app_runner/src/report_io.rs
@@ -0,0 +1,775 @@
+use std::collections::HashMap;
+use std::fs::{self, OpenOptions};
+use std::io::Write;
+use std::path::{Path, PathBuf};
+use std::sync::atomic::{AtomicBool, AtomicI64, AtomicU64, Ordering};
+use std::sync::{Arc, OnceLock};
+use std::time::Duration;
+
+use chrono::Utc;
+use core_types::{ShadowOutcome, ShadowShot};
+use sha2::{Digest, Sha256};
+use tokio::sync::{mpsc, RwLock};
+
+use crate::state::{
+    EnginePnlReport, MarketScoreRow, PerfProfile, ShadowFinalReport, ShadowLiveReport,
+    ToxicityLiveReport,
+};
+use crate::stats_utils::percentile;
+use crate::spawn_detached;
+
+pub(super) fn ensure_dataset_dirs() {
+    for bucket in ["raw", "normalized", "reports"] {
+        let path = dataset_dir(bucket);
+        let _ = fs::create_dir_all(path);
+    }
+}
+
+pub(super) fn dataset_date() -> String {
+    Utc::now().format("%Y-%m-%d").to_string()
+}
+
+pub(super) fn dataset_dir(kind: &str) -> PathBuf {
+    let root = std::env::var("POLYEDGE_DATASET_ROOT")
+        .ok()
+        .filter(|v| !v.trim().is_empty())
+        .map(PathBuf::from)
+        .unwrap_or_else(|| PathBuf::from("datasets"));
+    root.join(kind).join(dataset_date())
+}
+
+pub(super) fn dataset_path(kind: &str, filename: &str) -> PathBuf {
+    dataset_dir(kind).join(filename)
+}
+
+pub(super) fn sha256_hex(input: &str) -> String {
+    let mut hasher = Sha256::new();
+    hasher.update(input.as_bytes());
+    format!("{:x}", hasher.finalize())
+}
+
+#[derive(Debug)]
+pub(super) struct JsonlWriteReq {
+    path: PathBuf,
+    line: String,
+}
+
+pub(super) static JSONL_WRITER: OnceLock<mpsc::Sender<JsonlWriteReq>> = OnceLock::new();
+pub(super) static JSONL_QUEUE_DEPTH: AtomicU64 = AtomicU64::new(0);
+pub(super) static JSONL_QUEUE_CAP: AtomicU64 = AtomicU64::new(0);
+pub(super) static JSONL_DROP_ON_FULL: AtomicBool = AtomicBool::new(true);
+pub(super) static NORMALIZED_INGEST_SEQ: AtomicU64 = AtomicU64::new(0);
+
+pub(super) fn next_normalized_ingest_seq() -> u64 {
+    NORMALIZED_INGEST_SEQ.fetch_add(1, Ordering::Relaxed) + 1
+}
+
+pub(super) async fn init_jsonl_writer(perf_profile: Arc<RwLock<PerfProfile>>) {
+    if JSONL_WRITER.get().is_some() {
+        return;
+    }
+    let cfg = perf_profile.read().await.clone();
+    let (tx, mut rx) = mpsc::channel::<JsonlWriteReq>(cfg.io_queue_capacity.max(256));
+    JSONL_QUEUE_CAP.store(cfg.io_queue_capacity.max(256) as u64, Ordering::Relaxed);
+    JSONL_DROP_ON_FULL.store(cfg.io_drop_on_full, Ordering::Relaxed);
+    if JSONL_WRITER.set(tx.clone()).is_err() {
+        return;
+    }
+    spawn_detached("jsonl_writer", true, async move {
+        let mut batch = Vec::<JsonlWriteReq>::new();
+        let mut ticker = tokio::time::interval(Duration::from_millis(200));
+        loop {
+            tokio::select! {
+                maybe_req = rx.recv() => {
+                    match maybe_req {
+                        Some(req) => {
+                            batch.push(req);
+                            let flush_batch = perf_profile.read().await.io_flush_batch.max(1);
+                            if batch.len() >= flush_batch {
+                                let to_flush = std::mem::take(&mut batch);
+                                let _ = tokio::task::spawn_blocking(move || flush_jsonl_batch_sync(to_flush)).await;
+                            }
+                        }
+                        None => {
+                            if !batch.is_empty() {
+                                let to_flush = std::mem::take(&mut batch);
+                                let _ = tokio::task::spawn_blocking(move || flush_jsonl_batch_sync(to_flush)).await;
+                            }
+                            break;
+                        }
+                    }
+                }
+                _ = ticker.tick() => {
+                    if !batch.is_empty() {
+                        let to_flush = std::mem::take(&mut batch);
+                        let _ = tokio::task::spawn_blocking(move || flush_jsonl_batch_sync(to_flush)).await;
+                    }
+                }
+            }
+            let cap = JSONL_QUEUE_CAP.load(Ordering::Relaxed) as usize;
+            JSONL_QUEUE_DEPTH.store(cap.saturating_sub(tx.capacity()) as u64, Ordering::Relaxed);
+        }
+    });
+}
+
+pub(super) fn flush_jsonl_batch_sync(batch: Vec<JsonlWriteReq>) {
+    let mut grouped = HashMap::<PathBuf, Vec<String>>::new();
+    for req in batch {
+        grouped.entry(req.path).or_default().push(req.line);
+    }
+    for (path, lines) in grouped {
+        if let Some(parent) = path.parent() {
+            let _ = fs::create_dir_all(parent);
+        }
+        if let Ok(mut file) = OpenOptions::new().create(true).append(true).open(&path) {
+            for line in lines {
+                let _ = writeln!(file, "{line}");
+            }
+        }
+    }
+}
+
+pub(super) fn current_jsonl_queue_depth() -> u64 {
+    JSONL_QUEUE_DEPTH.load(Ordering::Relaxed)
+}
+
+pub(super) fn append_jsonl_sync(path: &Path, line: &str) {
+    if let Some(parent) = path.parent() {
+        let _ = fs::create_dir_all(parent);
+    }
+    if let Ok(mut file) = OpenOptions::new().create(true).append(true).open(path) {
+        let _ = writeln!(file, "{line}");
+    }
+}
+
+pub(super) fn append_jsonl_line(path: &Path, line: String) {
+    if let Some(tx) = JSONL_WRITER.get() {
+        let req = JsonlWriteReq {
+            path: path.to_path_buf(),
+            line,
+        };
+        match tx.try_send(req) {
+            Ok(_) => {
+                let cap = JSONL_QUEUE_CAP.load(Ordering::Relaxed) as usize;
+                JSONL_QUEUE_DEPTH
+                    .store(cap.saturating_sub(tx.capacity()) as u64, Ordering::Relaxed);
+                return;
+            }
+            Err(tokio::sync::mpsc::error::TrySendError::Full(req)) => {
+                metrics::counter!("io.jsonl.queue_full").increment(1);
+                if JSONL_DROP_ON_FULL.load(Ordering::Relaxed) {
+                    metrics::counter!("io.jsonl.dropped").increment(1);
+                    return;
+                }
+                append_jsonl_sync(&req.path, &req.line);
+                return;
+            }
+            Err(tokio::sync::mpsc::error::TrySendError::Closed(req)) => {
+                metrics::counter!("io.jsonl.queue_closed").increment(1);
+                if JSONL_DROP_ON_FULL.load(Ordering::Relaxed) {
+                    metrics::counter!("io.jsonl.dropped").increment(1);
+                    return;
+                }
+                append_jsonl_sync(&req.path, &req.line);
+                return;
+            }
+        }
+    }
+    append_jsonl_sync(path, &line);
+}
+
+pub(super) fn append_jsonl(path: &Path, value: &serde_json::Value) {
+    append_jsonl_line(path, value.to_string());
+}
+
+pub(super) static LAST_LIVE_REPORT_PERSIST_MS: AtomicI64 = AtomicI64::new(0);
+
+pub(super) fn persist_live_report_files(live: &ShadowLiveReport) {
+    // Throttle file persistence. /report/shadow/live can be polled at high frequency (storm tests)
+    // and pretty-json serialization + fs::write per request is unnecessary and can destabilize the
+    // process under load.
+    let now_ms = Utc::now().timestamp_millis();
+    let last_ms = LAST_LIVE_REPORT_PERSIST_MS.load(Ordering::Relaxed);
+    if now_ms.saturating_sub(last_ms) < 1_000 {
+        return;
+    }
+    if LAST_LIVE_REPORT_PERSIST_MS
+        .compare_exchange(last_ms, now_ms, Ordering::Relaxed, Ordering::Relaxed)
+        .is_err()
+    {
+        return;
+    }
+
+    let reports_dir = dataset_dir("reports");
+    let _ = fs::create_dir_all(&reports_dir);
+
+    let live_json_path = reports_dir.join("shadow_live_latest.json");
+    if let Ok(raw) = serde_json::to_string_pretty(live) {
+        let _ = fs::write(live_json_path, raw);
+    }
+}
+
+pub(super) fn persist_engine_pnl_report(report: &EnginePnlReport) {
+    let reports_dir = dataset_dir("reports");
+    let _ = fs::create_dir_all(&reports_dir);
+
+    let json_path = reports_dir.join("engine_pnl_breakdown_latest.json");
+    if let Ok(raw) = serde_json::to_string_pretty(report) {
+        let _ = fs::write(json_path, raw);
+    }
+
+    let csv_path = reports_dir.join("engine_pnl_breakdown.csv");
+    let mut rows = String::new();
+    rows.push_str("window_id,engine,samples,total_usdc,p50_usdc,p10_usdc,positive_ratio\n");
+    for row in &report.rows {
+        rows.push_str(&format!(
+            "{},{},{},{:.6},{:.6},{:.6},{:.6}\n",
+            report.window_id,
+            row.engine,
+            row.samples,
+            row.total_usdc,
+            row.p50_usdc,
+            row.p10_usdc,
+            row.positive_ratio
+        ));
+    }
+    let _ = fs::write(csv_path, rows);
+}
+
+pub(super) fn persist_final_report_files(report: &ShadowFinalReport) {
+    let reports_dir = dataset_dir("reports");
+    let _ = fs::create_dir_all(&reports_dir);
+
+    let md_path = reports_dir.join("report_shadow_12h.md");
+    let gate_label = if report.gate.pass { "PASS" } else { "FAIL" };
+    let mut md = String::new();
+    md.push_str("# Shadow 12h Report\n\n");
+    md.push_str(&format!("- gate: {gate_label}\n"));
+    md.push_str(&format!(
+        "- fillability@10ms: {:.4}\n",
+        report.gate.fillability_10ms
+    ));
+    md.push_str(&format!(
+        "- net_edge_p50_bps: {:.4}\n",
+        report.gate.net_edge_p50_bps
+    ));
+    md.push_str(&format!(
+        "- net_edge_p10_bps: {:.4}\n",
+        report.gate.net_edge_p10_bps
+    ));
+    md.push_str(&format!(
+        "- net_markout_10s_usdc_p50: {:.6}\n",
+        report.gate.net_markout_10s_usdc_p50
+    ));
+    md.push_str(&format!(
+        "- roi_notional_10s_bps_p50: {:.6}\n",
+        report.gate.roi_notional_10s_bps_p50
+    ));
+    md.push_str(&format!(
+        "- ev_net_usdc_p50: {:.6}\n",
+        report.gate.ev_net_usdc_p50
+    ));
+    md.push_str(&format!(
+        "- ev_net_usdc_p10: {:.6}\n",
+        report.gate.ev_net_usdc_p10
+    ));
+    md.push_str(&format!(
+        "- ev_positive_ratio: {:.4}\n",
+        report.gate.ev_positive_ratio
+    ));
+    md.push_str(&format!(
+        "- executed_over_eligible: {:.4}\n",
+        report.gate.executed_over_eligible
+    ));
+    md.push_str(&format!(
+        "- eligible_count: {}\n",
+        report.gate.eligible_count
+    ));
+    md.push_str(&format!(
+        "- executed_count: {}\n",
+        report.gate.executed_count
+    ));
+    md.push_str(&format!(
+        "- pnl_10s_p50_bps_raw: {:.4}\n",
+        report.gate.pnl_10s_p50_bps_raw
+    ));
+    md.push_str(&format!(
+        "- pnl_10s_p50_bps_robust: {:.4}\n",
+        report.gate.pnl_10s_p50_bps_robust
+    ));
+    md.push_str(&format!(
+        "- pnl_10s_sample_count: {}\n",
+        report.gate.pnl_10s_sample_count
+    ));
+    md.push_str(&format!(
+        "- pnl_10s_outlier_ratio: {:.4}\n",
+        report.gate.pnl_10s_outlier_ratio
+    ));
+    md.push_str(&format!(
+        "- quote_block_ratio: {:.4}\n",
+        report.gate.quote_block_ratio
+    ));
+    md.push_str(&format!(
+        "- policy_block_ratio: {:.4}\n",
+        report.gate.policy_block_ratio
+    ));
+    md.push_str(&format!(
+        "- gate_block_ratio: {:.4}\n",
+        report.gate.gate_block_ratio
+    ));
+    md.push_str(&format!(
+        "- strategy_uptime_pct: {:.2}\n",
+        report.gate.strategy_uptime_pct
+    ));
+    md.push_str(&format!(
+        "- data_valid_ratio: {:.5}\n",
+        report.gate.data_valid_ratio
+    ));
+    md.push_str(&format!(
+        "- seq_gap_rate: {:.5}\n",
+        report.gate.seq_gap_rate
+    ));
+    md.push_str(&format!(
+        "- ts_inversion_rate: {:.5}\n",
+        report.gate.ts_inversion_rate
+    ));
+    md.push_str(&format!(
+        "- stale_tick_drop_ratio: {:.5}\n",
+        report.gate.stale_tick_drop_ratio
+    ));
+    md.push_str(&format!(
+        "- tick_to_ack_p99_ms: {:.4}\n\n",
+        report.gate.tick_to_ack_p99_ms
+    ));
+    md.push_str(&format!(
+        "- tick_to_decision_p99_ms: {:.4}\n",
+        report.live.tick_to_decision_p99_ms
+    ));
+    md.push_str(&format!(
+        "- ack_only_p99_ms: {:.4}\n",
+        report.live.ack_only_p99_ms
+    ));
+    md.push_str(&format!(
+        "- alpha_window_p99_ms: {:.4}\n",
+        report.live.alpha_window_p99_ms
+    ));
+    md.push_str(&format!(
+        "- alpha_window_hit_ratio: {:.4}\n",
+        report.live.alpha_window_hit_ratio
+    ));
+    md.push_str(&format!(
+        "- decision_queue_wait_p99_ms: {:.4}\n",
+        report.gate.decision_queue_wait_p99_ms
+    ));
+    md.push_str(&format!(
+        "- decision_compute_p99_ms: {:.4}\n",
+        report.gate.decision_compute_p99_ms
+    ));
+    md.push_str(&format!(
+        "- source_latency_p99_ms: {:.4}\n",
+        report.gate.source_latency_p99_ms
+    ));
+    md.push_str(&format!(
+        "- local_backlog_p99_ms: {:.4}\n",
+        report.gate.local_backlog_p99_ms
+    ));
+    md.push_str(&format!(
+        "- queue_depth_p99: {:.4}\n",
+        report.live.queue_depth_p99
+    ));
+    md.push_str(&format!(
+        "- event_backlog_p99: {:.4}\n\n",
+        report.live.event_backlog_p99
+    ));
+    md.push_str(&format!(
+        "- quote_attempted: {}\n- quote_blocked: {}\n- policy_blocked: {}\n- ref_ticks_total: {}\n- book_ticks_total: {}\n- ref_freshness_ms: {}\n- book_freshness_ms: {}\n\n",
+        report.live.quote_attempted,
+        report.live.quote_blocked,
+        report.live.policy_blocked,
+        report.live.ref_ticks_total,
+        report.live.book_ticks_total,
+        report.live.ref_freshness_ms,
+        report.live.book_freshness_ms
+    ));
+    if report.gate.failed_reasons.is_empty() {
+        md.push_str("## Failed Reasons\n- none\n");
+    } else {
+        md.push_str("## Failed Reasons\n");
+        for reason in &report.gate.failed_reasons {
+            md.push_str(&format!("- {reason}\n"));
+        }
+    }
+    if report.live.blocked_reason_counts.is_empty() {
+        md.push_str("\n## Blocked Reasons\n- none\n");
+    } else {
+        md.push_str("\n## Blocked Reasons\n");
+        let mut rows = report.live.blocked_reason_counts.iter().collect::<Vec<_>>();
+        rows.sort_by(|a, b| b.1.cmp(a.1));
+        for (reason, count) in rows {
+            md.push_str(&format!("- {}: {}\n", reason, count));
+        }
+    }
+    if report.live.policy_block_reason_distribution.is_empty() {
+        md.push_str("\n## Policy Block Reason Distribution\n- none\n");
+    } else {
+        md.push_str("\n## Policy Block Reason Distribution\n");
+        let mut rows = report
+            .live
+            .policy_block_reason_distribution
+            .iter()
+            .collect::<Vec<_>>();
+        rows.sort_by(|a, b| b.1.cmp(a.1));
+        for (reason, count) in rows {
+            md.push_str(&format!("- {}: {}\n", reason, count));
+        }
+    }
+    if report.live.gate_block_reason_distribution.is_empty() {
+        md.push_str("\n## Gate Block Reason Distribution\n- none\n");
+    } else {
+        md.push_str("\n## Gate Block Reason Distribution\n");
+        let mut rows = report
+            .live
+            .gate_block_reason_distribution
+            .iter()
+            .collect::<Vec<_>>();
+        rows.sort_by(|a, b| b.1.cmp(a.1));
+        for (reason, count) in rows {
+            md.push_str(&format!("- {}: {}\n", reason, count));
+        }
+    }
+    let _ = fs::write(md_path, md);
+
+    let latency_csv = reports_dir.join("latency_breakdown_12h.csv");
+    let mut latency_rows = String::new();
+    latency_rows.push_str("stage,p50,p90,p99,unit\n");
+    latency_rows.push_str(&format!(
+        "feed_in,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.feed_in_p50_ms,
+        report.live.latency.feed_in_p90_ms,
+        report.live.latency.feed_in_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "signal,{:.6},{:.6},{:.6},us\n",
+        report.live.latency.signal_p50_us,
+        report.live.latency.signal_p90_us,
+        report.live.latency.signal_p99_us
+    ));
+    latency_rows.push_str(&format!(
+        "quote,{:.6},{:.6},{:.6},us\n",
+        report.live.latency.quote_p50_us,
+        report.live.latency.quote_p90_us,
+        report.live.latency.quote_p99_us
+    ));
+    latency_rows.push_str(&format!(
+        "risk,{:.6},{:.6},{:.6},us\n",
+        report.live.latency.risk_p50_us,
+        report.live.latency.risk_p90_us,
+        report.live.latency.risk_p99_us
+    ));
+    latency_rows.push_str(&format!(
+        "decision_queue_wait,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.decision_queue_wait_p50_ms,
+        report.live.latency.decision_queue_wait_p90_ms,
+        report.live.latency.decision_queue_wait_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "decision_compute,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.decision_compute_p50_ms,
+        report.live.latency.decision_compute_p90_ms,
+        report.live.latency.decision_compute_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "tick_to_decision,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.tick_to_decision_p50_ms,
+        report.live.latency.tick_to_decision_p90_ms,
+        report.live.latency.tick_to_decision_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "ack_only,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.ack_only_p50_ms,
+        report.live.latency.ack_only_p90_ms,
+        report.live.latency.ack_only_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "tick_to_ack,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.tick_to_ack_p50_ms,
+        report.live.latency.tick_to_ack_p90_ms,
+        report.live.latency.tick_to_ack_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "alpha_window,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.alpha_window_p50_ms,
+        report.live.latency.alpha_window_p90_ms,
+        report.live.latency.alpha_window_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "parse,{:.6},{:.6},{:.6},us\n",
+        0.0, 0.0, report.live.latency.parse_p99_us
+    ));
+    latency_rows.push_str(&format!(
+        "io_queue,{:.6},{:.6},{:.6},count\n",
+        0.0, 0.0, report.live.latency.io_queue_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "bus_lag,{:.6},{:.6},{:.6},count\n",
+        0.0, 0.0, report.live.latency.bus_lag_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "shadow_fill,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.shadow_fill_p50_ms,
+        report.live.latency.shadow_fill_p90_ms,
+        report.live.latency.shadow_fill_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "source_latency,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.source_latency_p50_ms,
+        report.live.latency.source_latency_p90_ms,
+        report.live.latency.source_latency_p99_ms
+    ));
+    latency_rows.push_str(&format!(
+        "local_backlog,{:.6},{:.6},{:.6},ms\n",
+        report.live.latency.local_backlog_p50_ms,
+        report.live.latency.local_backlog_p90_ms,
+        report.live.latency.local_backlog_p99_ms
+    ));
+    let _ = fs::write(latency_csv, latency_rows);
+
+    let score_path = reports_dir.join("market_scorecard.csv");
+    let mut score_rows = String::new();
+    score_rows.push_str("market_id,symbol,shots,outcomes,fillability_10ms,net_edge_p50_bps,net_edge_p10_bps,pnl_10s_p50_bps,net_markout_10s_usdc_p50,roi_notional_10s_bps_p50\n");
+    for row in &report.live.market_scorecard {
+        score_rows.push_str(&format!(
+            "{},{},{},{},{:.6},{:.6},{:.6},{:.6},{:.6},{:.6}\n",
+            row.market_id,
+            row.symbol,
+            row.shots,
+            row.outcomes,
+            row.fillability_10ms,
+            row.net_edge_p50_bps,
+            row.net_edge_p10_bps,
+            row.pnl_10s_p50_bps,
+            row.net_markout_10s_usdc_p50,
+            row.roi_notional_10s_bps_p50
+        ));
+    }
+    let _ = fs::write(score_path, score_rows);
+
+    let fixlist_path = reports_dir.join("next_fixlist.md");
+    let mut fixlist = String::new();
+    fixlist.push_str("# Next Fixlist\n\n");
+    if report.gate.failed_reasons.is_empty() {
+        fixlist.push_str("- Gate passed. Keep conservative limits and continue monitoring.\n");
+    } else {
+        for reason in &report.gate.failed_reasons {
+            fixlist.push_str(&format!("- {reason}\n"));
+        }
+    }
+    let _ = fs::write(fixlist_path, fixlist);
+
+    let truth_manifest_path = reports_dir.join("truth_manifest.json");
+    let truth_manifest = serde_json::json!({
+        "generated_at_utc": Utc::now().to_rfc3339(),
+        "metrics_contract_version": "2026-02-14.v1",
+        "window": {
+            "window_id": report.live.window_id,
+            "window_shots": report.live.window_shots,
+            "window_outcomes": report.live.window_outcomes,
+            "gate_ready": report.live.gate_ready,
+            "gate_ready_strict": report.live.gate_ready_strict,
+            "gate_ready_effective": report.live.gate_ready_effective,
+            "last_30s_taker_fallback_count": report.live.last_30s_taker_fallback_count,
+        },
+        "data_chain": {
+            "raw_fields": ["sha256", "source_seq", "ingest_seq", "event_ts_exchange_ms", "recv_ts_local_ns"],
+            "normalized_fields": ["source_seq", "ingest_seq", "market_id", "symbol", "delay_ms", "fillable", "net_markout_10s_usdc"],
+            "invalid_excluded_from_gate": true
+        },
+        "formulas": {
+            "quote_block_ratio": "quote_blocked / (quote_attempted + quote_blocked)",
+            "policy_block_ratio": "policy_blocked / (quote_attempted + policy_blocked)",
+            "policy_blocked_scope": "risk:* and risk_capped_zero only",
+            "executed_over_eligible": "executed_count / eligible_count",
+            "ev_net_usdc_p50": "p50(net_markout_10s_usdc)",
+            "ev_positive_ratio": "count(net_markout_10s_usdc > 0) / count(valid outcomes)"
+        },
+        "hard_gates": {
+            "data_valid_ratio_min": 0.999,
+            "seq_gap_rate_max": 0.001,
+            "ts_inversion_rate_max": 0.0005,
+            "tick_to_ack_p99_ms_max": 450.0,
+            "decision_compute_p99_ms_max": 2.0,
+            "feed_in_p99_ms_max": 800.0,
+            "executed_over_eligible_min": 0.60,
+            "quote_block_ratio_max": 0.10,
+            "policy_block_ratio_max": 0.10,
+            "ev_net_usdc_p50_min": 0.0,
+            "roi_notional_10s_bps_p50_min": 0.0
+        }
+    });
+    if let Ok(raw) = serde_json::to_string_pretty(&truth_manifest) {
+        let _ = fs::write(truth_manifest_path, raw);
+    }
+}
+
+pub(super) fn persist_toxicity_report_files(report: &ToxicityLiveReport) {
+    let reports_dir = dataset_dir("reports");
+    let _ = fs::create_dir_all(&reports_dir);
+
+    let live_json_path = reports_dir.join("toxicity_live_latest.json");
+    if let Ok(raw) = serde_json::to_string_pretty(report) {
+        let _ = fs::write(live_json_path, raw);
+    }
+
+    let csv_path = reports_dir.join("toxicity_scorecard.csv");
+    let mut rows = String::new();
+    rows.push_str("market_rank,active_for_quoting,market_id,symbol,tox_score,regime,market_score,markout_10s_bps,no_quote_rate,symbol_missing_rate,pending_exposure\n");
+    for row in &report.rows {
+        rows.push_str(&format!(
+            "{},{},{},{},{:.6},{:?},{:.6},{:.6},{:.6},{:.6},{:.6}\n",
+            row.market_rank,
+            row.active_for_quoting,
+            row.market_id,
+            row.symbol,
+            row.tox_score,
+            row.regime,
+            row.market_score,
+            row.markout_10s_bps,
+            row.no_quote_rate,
+            row.symbol_missing_rate,
+            row.pending_exposure
+        ));
+    }
+    let _ = fs::write(csv_path, rows);
+}
+
+pub(super) fn fillability_ratio(outcomes: &[ShadowOutcome], delay_ms: u64) -> f64 {
+    let mut total = 0_u64;
+    let mut filled = 0_u64;
+    for o in outcomes {
+        if o.delay_ms != delay_ms {
+            continue;
+        }
+        total = total.saturating_add(1);
+        if o.fillable {
+            filled = filled.saturating_add(1);
+        }
+    }
+    if total == 0 {
+        0.0
+    } else {
+        filled as f64 / total as f64
+    }
+}
+
+pub(super) fn survival_ratio(outcomes: &[ShadowOutcome], delay_ms: u64) -> f64 {
+    let mut total = 0_u64;
+    let mut survived = 0_u64;
+    for o in outcomes {
+        if o.delay_ms != delay_ms {
+            continue;
+        }
+        total = total.saturating_add(1);
+        if o.survived {
+            survived = survived.saturating_add(1);
+        }
+    }
+    if total == 0 {
+        0.0
+    } else {
+        survived as f64 / total as f64
+    }
+}
+
+pub(super) fn build_market_scorecard(
+    shots: &[ShadowShot],
+    outcomes: &[ShadowOutcome],
+) -> Vec<MarketScoreRow> {
+    const PRIMARY_DELAY_MS: u64 = 10;
+    const MAX_ROWS: usize = 200;
+
+    #[derive(Default)]
+    struct Agg {
+        market_id: String,
+        symbol: String,
+        shots_primary: usize,
+        outcomes_primary: usize,
+        filled_10ms: u64,
+        total_10ms: u64,
+        net_edges: Vec<f64>,
+        pnl_10s: Vec<f64>,
+        net_markout_10s_usdc: Vec<f64>,
+        roi_notional_10s_bps: Vec<f64>,
+    }
+
+    // Single-pass aggregation to avoid O(N^2) cloning/filtering. This keeps /report/shadow/live
+    // stable under stress polling.
+    let mut by_key: HashMap<(String, String), Agg> = HashMap::new();
+
+    for s in shots {
+        if s.delay_ms != PRIMARY_DELAY_MS {
+            continue;
+        }
+        let key = (s.market_id.clone(), s.symbol.clone());
+        let entry = by_key.entry(key).or_insert_with(|| Agg {
+            market_id: s.market_id.clone(),
+            symbol: s.symbol.clone(),
+            ..Agg::default()
+        });
+        entry.shots_primary = entry.shots_primary.saturating_add(1);
+        entry.net_edges.push(s.edge_net_bps);
+    }
+
+    for o in outcomes {
+        if o.delay_ms != PRIMARY_DELAY_MS {
+            continue;
+        }
+        let key = (o.market_id.clone(), o.symbol.clone());
+        let entry = by_key.entry(key).or_insert_with(|| Agg {
+            market_id: o.market_id.clone(),
+            symbol: o.symbol.clone(),
+            ..Agg::default()
+        });
+        entry.outcomes_primary = entry.outcomes_primary.saturating_add(1);
+        entry.total_10ms = entry.total_10ms.saturating_add(1);
+        if o.fillable {
+            entry.filled_10ms = entry.filled_10ms.saturating_add(1);
+        }
+        if let Some(v) = o.net_markout_10s_bps.or(o.pnl_10s_bps) {
+            entry.pnl_10s.push(v);
+        }
+        if let Some(v) = o.net_markout_10s_usdc {
+            entry.net_markout_10s_usdc.push(v);
+        }
+        if let Some(v) = o.roi_notional_10s_bps {
+            entry.roi_notional_10s_bps.push(v);
+        }
+    }
+
+    let mut rows = Vec::with_capacity(by_key.len());
+    for (_, agg) in by_key {
+        let fillability_10ms = if agg.total_10ms == 0 {
+            0.0
+        } else {
+            agg.filled_10ms as f64 / agg.total_10ms as f64
+        };
+        rows.push(MarketScoreRow {
+            market_id: agg.market_id,
+            symbol: agg.symbol,
+            shots: agg.shots_primary,
+            outcomes: agg.outcomes_primary,
+            fillability_10ms,
+            net_edge_p50_bps: percentile(&agg.net_edges, 0.50).unwrap_or(0.0),
+            net_edge_p10_bps: percentile(&agg.net_edges, 0.10).unwrap_or(0.0),
+            pnl_10s_p50_bps: percentile(&agg.pnl_10s, 0.50).unwrap_or(0.0),
+            net_markout_10s_usdc_p50: percentile(&agg.net_markout_10s_usdc, 0.50).unwrap_or(0.0),
+            roi_notional_10s_bps_p50: percentile(&agg.roi_notional_10s_bps, 0.50).unwrap_or(0.0),
+        });
+    }
+
+    rows.sort_by(|a, b| {
+        b.net_markout_10s_usdc_p50
+            .total_cmp(&a.net_markout_10s_usdc_p50)
+    });
+    rows.truncate(MAX_ROWS);
+    rows
+}
diff --git a/crates/app_runner/src/seat_persist.rs b/crates/app_runner/src/seat_persist.rs
new file mode 100644
index 0000000..3842b7a
--- /dev/null
+++ b/crates/app_runner/src/seat_persist.rs
@@ -0,0 +1,335 @@
+use std::fs::{self, File, OpenOptions};
+use std::io::{BufRead, BufReader, Write};
+use std::path::{Path, PathBuf};
+
+use anyhow::{Context, Result};
+use chrono::{Datelike, TimeZone, Utc};
+use flate2::write::GzEncoder;
+use flate2::Compression;
+use serde_json::json;
+
+use crate::seat_types::{SeatDecisionRecord, SeatRuntimeState};
+
+pub(crate) fn seat_dir() -> PathBuf {
+    let root = std::env::var("POLYEDGE_DATASET_ROOT")
+        .ok()
+        .filter(|v| !v.trim().is_empty())
+        .map(PathBuf::from)
+        .unwrap_or_else(|| PathBuf::from("datasets"));
+    root.join("reports").join("seat")
+}
+
+pub(crate) fn seat_state_path() -> PathBuf {
+    seat_dir().join("seat_state.json")
+}
+
+pub(crate) fn seat_decisions_path() -> PathBuf {
+    seat_dir().join("seat_decisions.jsonl")
+}
+
+pub(crate) fn seat_reports_dir() -> PathBuf {
+    seat_dir().join("reports")
+}
+
+pub(crate) fn ensure_seat_dir() -> Result<()> {
+    fs::create_dir_all(seat_dir()).context("create seat report dir")
+}
+
+pub(crate) fn write_state_atomic(state: &SeatRuntimeState) -> Result<()> {
+    ensure_seat_dir()?;
+    let target = seat_state_path();
+    let tmp = target.with_extension("json.tmp");
+    let payload = serde_json::to_vec_pretty(state).context("serialize seat state")?;
+
+    {
+        let mut file = File::create(&tmp).context("create seat state tmp")?;
+        file.write_all(&payload).context("write seat state tmp")?;
+        file.sync_all().context("sync seat state tmp")?;
+    }
+
+    if let Err(err) = fs::rename(&tmp, &target) {
+        if target.exists() {
+            let _ = fs::remove_file(&target);
+            fs::rename(&tmp, &target).context("replace seat state file")?;
+        } else {
+            return Err(err).context("rename seat state tmp");
+        }
+    }
+    Ok(())
+}
+
+pub(crate) fn append_decision(record: &SeatDecisionRecord) -> Result<()> {
+    ensure_seat_dir()?;
+    let path = seat_decisions_path();
+    let mut file = OpenOptions::new()
+        .create(true)
+        .append(true)
+        .open(path)
+        .context("open seat decisions jsonl")?;
+    let line = serde_json::to_string(record).context("serialize seat decision")?;
+    writeln!(file, "{line}").context("append seat decision line")?;
+    Ok(())
+}
+
+pub(crate) fn load_state() -> Option<SeatRuntimeState> {
+    let path = seat_state_path();
+    let raw = fs::read_to_string(path).ok()?;
+    serde_json::from_str::<SeatRuntimeState>(&raw).ok()
+}
+
+fn last_decision_record(path: &Path) -> Option<SeatDecisionRecord> {
+    let file = File::open(path).ok()?;
+    let reader = BufReader::new(file);
+    let lines = reader.lines().map_while(Result::ok).collect::<Vec<_>>();
+    lines
+        .into_iter()
+        .rev()
+        .find_map(|line| serde_json::from_str::<SeatDecisionRecord>(&line).ok())
+}
+
+pub(crate) fn recover_state() -> SeatRuntimeState {
+    if let Some(state) = load_state() {
+        return state;
+    }
+    let path = seat_decisions_path();
+    let Some(last) = last_decision_record(&path) else {
+        return SeatRuntimeState::default();
+    };
+    let mut state = SeatRuntimeState::default();
+    state.current_layer = last.layer;
+    state.last_params = last.candidate;
+    state.last_objective = Some(last.baseline);
+    state.last_decision_ts_ms = last.ts_ms;
+    state.trade_count_source = last.trade_count_source;
+    state
+}
+
+pub(crate) fn load_history(limit: usize) -> Vec<SeatDecisionRecord> {
+    let path = seat_decisions_path();
+    let Ok(file) = File::open(path) else {
+        return Vec::new();
+    };
+    let reader = BufReader::new(file);
+    let mut out = Vec::new();
+    for line in reader.lines().map_while(Result::ok) {
+        if let Ok(record) = serde_json::from_str::<SeatDecisionRecord>(&line) {
+            out.push(record);
+        }
+    }
+    if out.len() > limit {
+        out[out.len() - limit..].to_vec()
+    } else {
+        out
+    }
+}
+
+fn month_bucket(ts_ms: i64) -> String {
+    let dt = Utc
+        .timestamp_millis_opt(ts_ms)
+        .single()
+        .unwrap_or_else(Utc::now);
+    format!("{:04}-{:02}", dt.year(), dt.month())
+}
+
+pub(crate) fn archive_old_decisions(retention_days: u32) -> Result<()> {
+    ensure_seat_dir()?;
+    let path = seat_decisions_path();
+    if !path.exists() {
+        return Ok(());
+    }
+    let cutoff_ms = Utc::now()
+        .timestamp_millis()
+        .saturating_sub((retention_days as i64) * 24 * 3_600 * 1_000);
+
+    let file = File::open(&path).context("open seat decision file for archive")?;
+    let reader = BufReader::new(file);
+    let mut keep_lines = Vec::<String>::new();
+    let mut archive_buckets = std::collections::BTreeMap::<String, Vec<String>>::new();
+
+    for line in reader.lines().map_while(Result::ok) {
+        let Ok(record) = serde_json::from_str::<SeatDecisionRecord>(&line) else {
+            continue;
+        };
+        if record.ts_ms < cutoff_ms {
+            archive_buckets
+                .entry(month_bucket(record.ts_ms))
+                .or_default()
+                .push(line);
+        } else {
+            keep_lines.push(line);
+        }
+    }
+
+    for (month, lines) in archive_buckets {
+        let gz_path = seat_dir().join(format!("seat_decisions_{month}.jsonl.gz"));
+        let gz_file = OpenOptions::new()
+            .create(true)
+            .append(true)
+            .open(gz_path)
+            .context("open monthly archive")?;
+        let mut encoder = GzEncoder::new(gz_file, Compression::default());
+        for line in lines {
+            writeln!(encoder, "{line}").context("append line to monthly archive")?;
+        }
+        encoder.finish().context("finalize monthly archive")?;
+    }
+
+    let tmp = path.with_extension("jsonl.tmp");
+    {
+        let mut out = File::create(&tmp).context("create trimmed decision temp file")?;
+        for line in keep_lines {
+            writeln!(out, "{line}").context("write trimmed decision line")?;
+        }
+        out.sync_all().context("sync trimmed decision file")?;
+    }
+    if let Err(err) = fs::rename(&tmp, &path) {
+        if path.exists() {
+            let _ = fs::remove_file(&path);
+            fs::rename(&tmp, &path).context("replace trimmed decision file")?;
+        } else {
+            return Err(err).context("rename trimmed decision file");
+        }
+    }
+    Ok(())
+}
+
+fn decision_file_slug(raw: &str) -> String {
+    let mut out = String::with_capacity(raw.len());
+    for ch in raw.chars() {
+        if ch.is_ascii_alphanumeric() || ch == '_' || ch == '-' {
+            out.push(ch);
+        } else {
+            out.push('_');
+        }
+    }
+    while out.contains("__") {
+        out = out.replace("__", "_");
+    }
+    out.trim_matches('_').to_string()
+}
+
+fn numeric_delta(prev: Option<f64>, next: Option<f64>) -> Option<f64> {
+    match (prev, next) {
+        (Some(a), Some(b)) if a.is_finite() && b.is_finite() => Some(b - a),
+        _ => None,
+    }
+}
+
+pub(crate) fn write_tune_report(record: &SeatDecisionRecord, state: &SeatRuntimeState) -> Result<()> {
+    ensure_seat_dir()?;
+    fs::create_dir_all(seat_reports_dir()).context("create seat reports dir")?;
+
+    let curve_start = record.ts_ms.saturating_sub(24 * 3_600 * 1_000);
+    let objective_curve = state
+        .objective_history
+        .iter()
+        .filter(|point| point.ts_ms >= curve_start)
+        .map(|point| json!({"ts_ms": point.ts_ms, "objective": point.objective}))
+        .collect::<Vec<_>>();
+    let volatility_curve = state
+        .volatility_history
+        .iter()
+        .filter(|point| point.ts_ms >= curve_start)
+        .map(|point| json!({"ts_ms": point.ts_ms, "volatility_proxy": point.objective}))
+        .collect::<Vec<_>>();
+
+    let param_delta = json!({
+        "position_fraction": numeric_delta(record.previous.position_fraction, record.candidate.position_fraction),
+        "early_size_scale": numeric_delta(record.previous.early_size_scale, record.candidate.early_size_scale),
+        "maturity_size_scale": numeric_delta(record.previous.maturity_size_scale, record.candidate.maturity_size_scale),
+        "late_size_scale": numeric_delta(record.previous.late_size_scale, record.candidate.late_size_scale),
+        "min_edge_net_bps": numeric_delta(record.previous.min_edge_net_bps, record.candidate.min_edge_net_bps),
+        "convergence_exit_ratio": numeric_delta(record.previous.convergence_exit_ratio, record.candidate.convergence_exit_ratio),
+        "min_velocity_bps_per_sec": numeric_delta(record.previous.min_velocity_bps_per_sec, record.candidate.min_velocity_bps_per_sec),
+        "capital_fraction_kelly": numeric_delta(record.previous.capital_fraction_kelly, record.candidate.capital_fraction_kelly),
+        "t100ms_reversal_bps": numeric_delta(record.previous.t100ms_reversal_bps, record.candidate.t100ms_reversal_bps),
+        "t300ms_reversal_bps": numeric_delta(record.previous.t300ms_reversal_bps, record.candidate.t300ms_reversal_bps),
+        "max_single_trade_loss_usdc": numeric_delta(record.previous.max_single_trade_loss_usdc, record.candidate.max_single_trade_loss_usdc),
+        "risk_max_drawdown_pct": numeric_delta(record.previous.risk_max_drawdown_pct, record.candidate.risk_max_drawdown_pct),
+        "risk_max_market_notional": numeric_delta(record.previous.risk_max_market_notional, record.candidate.risk_max_market_notional),
+        "maker_min_edge_bps": numeric_delta(record.previous.maker_min_edge_bps, record.candidate.maker_min_edge_bps),
+        "basis_k_revert": numeric_delta(record.previous.basis_k_revert, record.candidate.basis_k_revert),
+        "basis_z_cap": numeric_delta(record.previous.basis_z_cap, record.candidate.basis_z_cap),
+    });
+
+    let style_match_score = record
+        .notes
+        .iter()
+        .find_map(|note| note.strip_prefix("style_match_score="))
+        .and_then(|v| v.parse::<f64>().ok())
+        .or_else(|| {
+            record
+                .notes
+                .iter()
+                .find_map(|note| note.strip_prefix("style_objective="))
+                .and_then(|v| v.parse::<f64>().ok())
+        })
+        .unwrap_or(0.0);
+    let shadow_pnl_proxy = record
+        .notes
+        .iter()
+        .find_map(|note| note.strip_prefix("shadow_ev_usdc_p50="))
+        .and_then(|v| v.parse::<f64>().ok());
+
+    let payload = json!({
+        "ts_ms": record.ts_ms,
+        "layer": record.layer.as_str(),
+        "decision": record.decision,
+        "rollback": record.rollback,
+        "trade_count_source": record.trade_count_source,
+        "params_previous": record.previous,
+        "params_candidate": record.candidate,
+        "params_delta": param_delta,
+        "baseline": record.baseline,
+        "risk_metrics": {
+            "max_drawdown_pct_baseline": record.baseline.max_drawdown_pct,
+            "max_drawdown_pct_latest": state.last_objective.as_ref().map(|v| v.max_drawdown_pct),
+            "source_health_min_baseline": record.baseline.source_health_min,
+            "source_health_min_latest": state.last_objective.as_ref().map(|v| v.source_health_min),
+        },
+        "shadow_metrics": {
+            "shadow_ev_usdc_p50": shadow_pnl_proxy,
+            "active_shadow_until_ms": record.lock_state.active_shadow_until_ms,
+        },
+        "style_metrics": {
+            "style_match_score": style_match_score,
+            "style_memory_size": state.style_memory.len(),
+        },
+        "curves": {
+            "objective_24h": objective_curve,
+            "volatility_24h": volatility_curve,
+        },
+        "notes": record.notes,
+    });
+
+    let slug = decision_file_slug(&record.decision);
+    let json_path = seat_reports_dir().join(format!("seat_tune_{}_{}.json", record.ts_ms, slug));
+    let md_path = seat_reports_dir().join(format!("seat_tune_{}_{}.md", record.ts_ms, slug));
+    fs::write(
+        &json_path,
+        serde_json::to_vec_pretty(&payload).context("serialize seat tune report")?,
+    )
+    .context("write seat tune json report")?;
+
+    let mut md = String::new();
+    md.push_str("# SEAT Tune Report\n\n");
+    md.push_str(&format!("- ts_ms: {}\n", record.ts_ms));
+    md.push_str(&format!("- layer: {}\n", record.layer.as_str()));
+    md.push_str(&format!("- decision: {}\n", record.decision));
+    md.push_str(&format!("- rollback: {}\n", record.rollback));
+    md.push_str(&format!("- trade_count_source: {}\n", record.trade_count_source));
+    md.push_str(&format!(
+        "- baseline_ev_usdc_p50: {:.6}\n",
+        record.baseline.ev_usdc_p50
+    ));
+    md.push_str(&format!(
+        "- baseline_max_drawdown_pct: {:.6}\n",
+        record.baseline.max_drawdown_pct
+    ));
+    md.push_str(&format!("- style_match_score: {:.6}\n", style_match_score));
+    if let Some(shadow_ev) = shadow_pnl_proxy {
+        md.push_str(&format!("- shadow_ev_usdc_p50: {:.6}\n", shadow_ev));
+    }
+    fs::write(md_path, md).context("write seat tune markdown report")?;
+    Ok(())
+}
diff --git a/crates/app_runner/src/seat_runtime.rs b/crates/app_runner/src/seat_runtime.rs
new file mode 100644
index 0000000..19c8671
--- /dev/null
+++ b/crates/app_runner/src/seat_runtime.rs
@@ -0,0 +1,1613 @@
+use std::process::Stdio;
+use std::sync::atomic::{AtomicU64, Ordering};
+use std::sync::Arc;
+use std::time::Duration;
+
+use anyhow::{anyhow, Context, Result};
+use chrono::Utc;
+use reqwest::Client;
+use serde::Deserialize;
+use tokio::process::{Child, Command};
+use tokio::sync::{Mutex, RwLock};
+
+use crate::seat_persist::{
+    append_decision, archive_old_decisions, load_history, recover_state, write_state_atomic,
+    write_tune_report,
+};
+use crate::seat_types::{
+    SeatConfig, SeatDecisionRecord, SeatForceLayerReq, SeatLayer, SeatLockState,
+    SeatManualOverrideReq, SeatMonitorState, SeatObjectivePoint, SeatObjectiveSnapshot,
+    SeatOptimizerProposal, SeatParameterSet, SeatRuntimeState, SeatSmoothingState, SeatStatusReport,
+    SeatStyleMemoryEntry, SeatStyleVector,
+};
+use crate::spawn_detached;
+
+fn now_ms() -> i64 {
+    Utc::now().timestamp_millis()
+}
+
+fn env_flag_enabled(name: &str) -> bool {
+    std::env::var(name)
+        .ok()
+        .map(|v| {
+            let normalized = v.trim().to_ascii_lowercase();
+            matches!(normalized.as_str(), "1" | "true" | "yes" | "on")
+        })
+        .unwrap_or(false)
+}
+
+#[derive(Debug, Deserialize)]
+struct SourceHealthLite {
+    #[serde(default)]
+    score: f64,
+}
+
+#[derive(Debug, Deserialize)]
+struct ShadowLiveLite {
+    #[serde(default)]
+    executed_count: u64,
+    #[serde(default)]
+    ev_net_usdc_p50: f64,
+    #[serde(default)]
+    roi_notional_10s_bps_p50: f64,
+    #[serde(default)]
+    ev_positive_ratio: f64,
+    #[serde(default)]
+    pnl_10s_p50_bps_raw: f64,
+    #[serde(default)]
+    source_health: Vec<SourceHealthLite>,
+}
+
+#[derive(Debug, Deserialize, Default)]
+struct PnlLite {
+    #[serde(default)]
+    max_drawdown_pct: f64,
+}
+
+#[derive(Debug)]
+struct ChallengerProcess {
+    layer: SeatLayer,
+    started_ms: i64,
+    end_ms: i64,
+    required_cycles: u32,
+    control_base_url: String,
+    candidate: SeatParameterSet,
+    old_params: SeatParameterSet,
+    baseline: SeatObjectiveSnapshot,
+    proposal_notes: Vec<String>,
+    child: Child,
+}
+
+#[derive(Clone)]
+pub(crate) struct SeatRuntimeHandle {
+    cfg: SeatConfig,
+    http: Client,
+    state: Arc<RwLock<SeatRuntimeState>>,
+    live_fill_counter: Arc<AtomicU64>,
+    challenger: Arc<Mutex<Option<ChallengerProcess>>>,
+}
+
+impl SeatRuntimeHandle {
+    pub(crate) fn spawn(mut cfg: SeatConfig) -> Arc<Self> {
+        if let Ok(value) = std::env::var("POLYEDGE_SEAT_ENABLED") {
+            cfg.enabled = env_flag_enabled("POLYEDGE_SEAT_ENABLED") || value.eq_ignore_ascii_case("true");
+        }
+        if cfg.control_base_url.trim().is_empty() {
+            let port = std::env::var("POLYEDGE_CONTROL_PORT")
+                .ok()
+                .and_then(|v| v.parse::<u16>().ok())
+                .unwrap_or(8080);
+            cfg.control_base_url = format!("http://127.0.0.1:{port}");
+        }
+        let handle = Arc::new(Self {
+            cfg,
+            http: Client::builder()
+                .timeout(Duration::from_secs(20))
+                .build()
+                .unwrap_or_else(|_| Client::new()),
+            state: Arc::new(RwLock::new(recover_state())),
+            live_fill_counter: Arc::new(AtomicU64::new(0)),
+            challenger: Arc::new(Mutex::new(None)),
+        });
+        if handle.cfg.enabled {
+            let runner = handle.clone();
+            spawn_detached("seat_runtime", true, async move {
+                runner.run().await;
+            });
+        }
+        handle
+    }
+
+    pub(crate) fn live_fill_counter(&self) -> Arc<AtomicU64> {
+        self.live_fill_counter.clone()
+    }
+
+    pub(crate) async fn pause(&self, reason: String) -> SeatStatusReport {
+        let mut state = self.state.write().await;
+        state.paused = true;
+        state.pause_reason = Some(reason);
+        state.last_decision_ts_ms = now_ms();
+        let _ = write_state_atomic(&state);
+        drop(state);
+        self.status().await
+    }
+
+    pub(crate) async fn resume(&self) -> SeatStatusReport {
+        let mut state = self.state.write().await;
+        state.paused = false;
+        state.pause_reason = None;
+        state.last_decision_ts_ms = now_ms();
+        let _ = write_state_atomic(&state);
+        drop(state);
+        self.status().await
+    }
+
+    pub(crate) async fn force_layer(&self, req: SeatForceLayerReq) -> SeatStatusReport {
+        let mut state = self.state.write().await;
+        state.forced_layer = req.layer;
+        state.last_decision_ts_ms = now_ms();
+        let _ = write_state_atomic(&state);
+        drop(state);
+        self.status().await
+    }
+
+    pub(crate) async fn manual_override(&self, req: SeatManualOverrideReq) -> Result<SeatStatusReport> {
+        if req.params.is_empty() {
+            return Err(anyhow!("manual override params is empty"));
+        }
+        self.apply_params(&req.params, &self.cfg.control_base_url).await?;
+        let mut state = self.state.write().await;
+        state.manual_override = Some(req.params);
+        state.last_decision_ts_ms = now_ms();
+        write_state_atomic(&state)?;
+        drop(state);
+        Ok(self.status().await)
+    }
+
+    pub(crate) async fn clear_manual_override(&self) -> SeatStatusReport {
+        let mut state = self.state.write().await;
+        state.manual_override = None;
+        state.last_decision_ts_ms = now_ms();
+        let _ = write_state_atomic(&state);
+        drop(state);
+        self.status().await
+    }
+
+    pub(crate) async fn status(&self) -> SeatStatusReport {
+        let state = self.state.read().await;
+        SeatStatusReport {
+            ts_ms: now_ms(),
+            enabled: self.cfg.enabled,
+            paused: state.paused,
+            pause_reason: state.pause_reason.clone(),
+            current_layer: state.current_layer,
+            forced_layer: state.forced_layer,
+            global_pause_until_ms: state.global_pause_until_ms,
+            layer0_lock_until_ms: state.layer0_lock_until_ms,
+            active_shadow_until_ms: state.active_shadow_until_ms,
+            trade_count: state.live_fill_total.max(state.proxy_trade_total),
+            trade_count_source: state.trade_count_source.clone(),
+            started_ms: state.started_ms,
+            last_decision_ts_ms: state.last_decision_ts_ms,
+            degrade_streak: state.degrade_streak,
+            rollback_streak: state.rollback_streak,
+            smoothing_active: state.smoothing.is_some(),
+            monitor_active: state.monitor.is_some(),
+            manual_override_active: state.manual_override.is_some(),
+            last_objective: state.last_objective.clone(),
+        }
+    }
+
+    pub(crate) fn history(&self, limit: usize) -> Vec<SeatDecisionRecord> {
+        load_history(limit)
+    }
+
+    async fn run(self: Arc<Self>) {
+        let mut ticker = tokio::time::interval(Duration::from_secs(self.cfg.runtime_tick_sec.max(5)));
+        loop {
+            ticker.tick().await;
+            if let Err(err) = self.tick_once().await {
+                tracing::warn!(error = %err, "seat runtime tick failed");
+            }
+        }
+    }
+
+    async fn tick_once(&self) -> Result<()> {
+        let now = now_ms();
+        let Some((live, pnl)) = self.fetch_runtime_metrics().await? else {
+            return Ok(());
+        };
+        let objective = self.build_objective(&live, &pnl);
+        {
+            let mut state = self.state.write().await;
+            self.refresh_trade_counter(&mut state, &live);
+            self.push_history(&mut state, now, &objective);
+            state.last_objective = Some(objective.clone());
+            if now.saturating_sub(state.last_archive_ts_ms) > 86_400_000 {
+                archive_old_decisions(self.cfg.history_retention_days)?;
+                state.last_archive_ts_ms = now;
+            }
+        }
+
+        self.poll_challenger(now).await?;
+        self.process_smoothing(now).await?;
+        self.process_monitor(now, &objective).await?;
+        self.process_post_switch_degrade(now).await?;
+
+        if self.black_swan_triggered(&objective).await? {
+            self.force_layer0_lock("black_swan").await?;
+            return Ok(());
+        }
+
+        let due = {
+            let mut state = self.state.write().await;
+            let layer_pause_until = state
+                .layer_pause_until_ms
+                .get(state.current_layer.as_str())
+                .copied()
+                .unwrap_or(0);
+            if state.paused
+                || now < state.global_pause_until_ms
+                || now < state.active_shadow_until_ms
+                || now < layer_pause_until
+                || state.smoothing.is_some()
+                || state.monitor.is_some()
+            {
+                write_state_atomic(&state)?;
+                return Ok(());
+            }
+            if now.saturating_sub(state.last_activation_check_ms) >= (self.cfg.activation_check_sec as i64) * 1_000 {
+                state.last_activation_check_ms = now;
+                let target = self.target_layer(&state, now);
+                if target != state.current_layer {
+                    state.current_layer = target;
+                    let last_params = state.last_params.clone();
+                    self.record_decision_locked(
+                        &mut state,
+                        target,
+                        last_params,
+                        objective.clone(),
+                        "layer_switch".to_string(),
+                        false,
+                        Vec::new(),
+                    )?;
+                }
+            }
+            self.is_tune_due(&state, now)
+        };
+        if due {
+            let layer = self.state.read().await.current_layer;
+            self.run_tune_cycle(layer, objective, now).await?;
+        }
+        let state = self.state.read().await;
+        write_state_atomic(&state)?;
+        Ok(())
+    }
+
+    fn target_layer(&self, state: &SeatRuntimeState, now: i64) -> SeatLayer {
+        if now < state.layer0_lock_until_ms {
+            return SeatLayer::Layer0;
+        }
+        if let Some(forced) = state.forced_layer {
+            return forced;
+        }
+        let trade_count = state.live_fill_total.max(state.proxy_trade_total);
+        let uptime_sec = ((now.saturating_sub(state.started_ms)) / 1_000).max(0) as u64;
+        if trade_count < self.cfg.layer1_min_trades || uptime_sec < 48 * 3_600 {
+            SeatLayer::Layer0
+        } else if trade_count >= self.cfg.layer3_min_trades
+            || (uptime_sec >= self.cfg.layer3_min_uptime_sec && trade_count >= self.cfg.layer2_min_trades)
+        {
+            SeatLayer::Layer3
+        } else if trade_count >= self.cfg.layer2_min_trades && uptime_sec >= self.cfg.layer2_min_uptime_sec {
+            SeatLayer::Layer2
+        } else {
+            SeatLayer::Layer1
+        }
+    }
+
+    fn is_tune_due(&self, state: &SeatRuntimeState, now: i64) -> bool {
+        let key = state.current_layer.as_str().to_string();
+        let Some(last_ms) = state.last_tune_ms_by_layer.get(&key).copied() else {
+            return true;
+        };
+        let interval = match state.current_layer {
+            SeatLayer::Layer0 | SeatLayer::Layer1 => self.cfg.layer1_interval_sec,
+            SeatLayer::Layer2 => self.cfg.layer2_interval_sec,
+            SeatLayer::Layer3 => self.cfg.layer3_interval_sec,
+        };
+        now.saturating_sub(last_ms) >= (interval as i64) * 1_000
+    }
+
+    fn effective_shadow_sec(&self, layer: SeatLayer) -> u64 {
+        match layer {
+            SeatLayer::Layer2 => self.cfg.layer2_shadow_sec,
+            SeatLayer::Layer3 => self.cfg.layer3_shadow_sec.max(20 * 5 * 60),
+            SeatLayer::Layer0 | SeatLayer::Layer1 => 0,
+        }
+    }
+
+    fn required_shadow_cycles(&self, layer: SeatLayer, shadow_sec: u64) -> u32 {
+        match layer {
+            SeatLayer::Layer3 => (shadow_sec / (5 * 60)).max(20) as u32,
+            SeatLayer::Layer2 => (shadow_sec / (5 * 60)).max(1) as u32,
+            SeatLayer::Layer0 | SeatLayer::Layer1 => 0,
+        }
+    }
+
+    fn build_objective(&self, live: &ShadowLiveLite, pnl: &PnlLite) -> SeatObjectiveSnapshot {
+        let source_health_min = if live.source_health.is_empty() {
+            1.0
+        } else {
+            live.source_health.iter().map(|row| row.score).fold(1.0_f64, f64::min)
+        };
+        let objective = live.ev_net_usdc_p50
+            + live.roi_notional_10s_bps_p50 * 0.01
+            + live.ev_positive_ratio * 0.5
+            - pnl.max_drawdown_pct.max(0.0) * self.cfg.objective_drawdown_penalty;
+        SeatObjectiveSnapshot {
+            ev_usdc_p50: live.ev_net_usdc_p50,
+            max_drawdown_pct: pnl.max_drawdown_pct.max(0.0),
+            roi_notional_10s_bps_p50: live.roi_notional_10s_bps_p50,
+            win_rate: live.ev_positive_ratio,
+            source_health_min,
+            volatility_proxy: live.pnl_10s_p50_bps_raw.abs(),
+            objective,
+        }
+    }
+
+    fn refresh_trade_counter(&self, state: &mut SeatRuntimeState, live: &ShadowLiveLite) {
+        let live_seen = self.live_fill_counter.load(Ordering::Relaxed);
+        let live_delta = if live_seen >= state.live_fill_seen { live_seen - state.live_fill_seen } else { live_seen };
+        state.live_fill_total = state.live_fill_total.saturating_add(live_delta);
+        state.live_fill_seen = live_seen;
+
+        let proxy_delta = if live.executed_count >= state.proxy_trade_seen {
+            live.executed_count - state.proxy_trade_seen
+        } else {
+            live.executed_count
+        };
+        state.proxy_trade_total = state.proxy_trade_total.saturating_add(proxy_delta);
+        state.proxy_trade_seen = live.executed_count;
+        let live_expected = !env_flag_enabled("POLYEDGE_FORCE_PAPER") && env_flag_enabled("POLYEDGE_LIVE_ARMED");
+        state.trade_count_source = if live_expected && state.live_fill_total > 0 {
+            "live_fill".to_string()
+        } else {
+            "proxy".to_string()
+        };
+    }
+
+    fn push_history(&self, state: &mut SeatRuntimeState, ts_ms: i64, objective: &SeatObjectiveSnapshot) {
+        state.objective_history.push(SeatObjectivePoint { ts_ms, objective: objective.objective });
+        state.volatility_history.push(SeatObjectivePoint { ts_ms, objective: objective.volatility_proxy });
+        let keep_after = ts_ms.saturating_sub(8 * 24 * 3_600 * 1_000);
+        state.objective_history.retain(|p| p.ts_ms >= keep_after);
+        state.volatility_history.retain(|p| p.ts_ms >= keep_after);
+    }
+
+    async fn fetch_runtime_metrics(&self) -> Result<Option<(ShadowLiveLite, PnlLite)>> {
+        let live_resp = match self.http.get(format!("{}/report/shadow/live", self.cfg.control_base_url)).send().await {
+            Ok(v) => v,
+            Err(_) => return Ok(None),
+        };
+        if !live_resp.status().is_success() {
+            return Ok(None);
+        }
+        let live = live_resp.json::<ShadowLiveLite>().await.context("parse shadow live")?;
+        let pnl_resp = self
+            .http
+            .get(format!("{}/state/pnl", self.cfg.control_base_url))
+            .send()
+            .await
+            .context("get state pnl")?;
+        if !pnl_resp.status().is_success() {
+            return Ok(None);
+        }
+        let pnl = pnl_resp.json::<PnlLite>().await.context("parse state pnl")?;
+        Ok(Some((live, pnl)))
+    }
+
+    async fn black_swan_triggered(&self, objective: &SeatObjectiveSnapshot) -> Result<bool> {
+        let state = self.state.read().await;
+        let mut vols = state
+            .volatility_history
+            .iter()
+            .map(|p| p.objective)
+            .filter(|v| v.is_finite())
+            .collect::<Vec<_>>();
+        if vols.len() < 32 {
+            return Ok(objective.source_health_min < self.cfg.source_health_floor);
+        }
+        vols.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
+        let idx = ((vols.len() as f64) * 0.95).floor() as usize;
+        let p95 = vols
+            .get(idx.min(vols.len().saturating_sub(1)))
+            .copied()
+            .unwrap_or(0.0);
+        Ok(objective.volatility_proxy > p95 || objective.source_health_min < self.cfg.source_health_floor)
+    }
+
+    async fn force_layer0_lock(&self, reason: &str) -> Result<()> {
+        let now = now_ms();
+        let mut state = self.state.write().await;
+        state.current_layer = SeatLayer::Layer0;
+        state.layer0_lock_until_ms = now + (self.cfg.black_swan_lock_sec as i64) * 1_000;
+        state.active_shadow_until_ms = 0;
+        state.smoothing = None;
+        state.monitor = None;
+        let last_params = state.last_params.clone();
+        let last_objective = state.last_objective.clone().unwrap_or_default();
+        self.record_decision_locked(
+            &mut state,
+            SeatLayer::Layer0,
+            last_params,
+            last_objective,
+            format!("force_layer0:{reason}"),
+            false,
+            vec![reason.to_string()],
+        )?;
+        write_state_atomic(&state)?;
+        Ok(())
+    }
+
+    async fn run_tune_cycle(&self, layer: SeatLayer, baseline: SeatObjectiveSnapshot, now: i64) -> Result<()> {
+        let current = match self.capture_current_params().await {
+            Ok(v) => v,
+            Err(_) => self.state.read().await.last_params.clone(),
+        };
+        let (mut candidate, proposal_notes) = match layer {
+            SeatLayer::Layer0 => (self.layer0_candidate(&current, &baseline), Vec::new()),
+            SeatLayer::Layer1 | SeatLayer::Layer2 | SeatLayer::Layer3 => {
+                let proposal = self.optimizer_candidate(layer, &current, &baseline).await?;
+                let mut notes = proposal.notes.clone();
+                notes.push(format!(
+                    "mc_ev_delta_p50={:.6}",
+                    proposal.validation.mc_ev_delta_p50
+                ));
+                notes.push(format!(
+                    "mc_drawdown_p95={:.6}",
+                    proposal.validation.mc_drawdown_p95
+                ));
+                notes.push(format!(
+                    "style_match_score={:.6}",
+                    proposal.meta.style_match_score
+                ));
+                notes.push(format!("style_match_count={}", proposal.meta.style_match_count));
+                notes.push(format!("top_k_size={}", proposal.meta.top_k_size));
+                notes.push(format!(
+                    "walk_forward_windows={}",
+                    proposal.validation.walk_forward_windows
+                ));
+                notes.push(format!(
+                    "walk_forward_score={:.6}",
+                    proposal.validation.walk_forward_score
+                ));
+                notes.push(format!(
+                    "objective_uplift_estimate={:.6}",
+                    proposal.meta.objective_uplift_estimate
+                ));
+                notes.push(format!("rl_signal={:.6}", proposal.meta.rl_signal));
+                (proposal.candidate, notes)
+            }
+        };
+        {
+            let state = self.state.read().await;
+            if let Some(override_params) = &state.manual_override {
+                candidate = override_params.merge_over(&candidate);
+            }
+        }
+        candidate = candidate
+            .clamp_relative(&current, layer.step_limit_pct())
+            .merge_over(&current);
+
+        if layer == SeatLayer::Layer2 || layer == SeatLayer::Layer3 {
+            let shadow_sec = self.effective_shadow_sec(layer);
+            let started = self
+                .start_challenger(
+                    layer,
+                    current.clone(),
+                    candidate.clone(),
+                    baseline.clone(),
+                    shadow_sec,
+                    now,
+                    proposal_notes.clone(),
+                )
+                .await?;
+            if !started {
+                let mut state = self.state.write().await;
+                self.record_decision_locked(
+                    &mut state,
+                    layer,
+                    current,
+                    baseline,
+                    "shadow_skip_active".to_string(),
+                    false,
+                    vec!["active_shadow_window_in_progress".to_string()],
+                )?;
+                write_state_atomic(&state)?;
+                return Ok(());
+            }
+        } else {
+            self.begin_smoothing(layer, current, candidate, baseline, now, proposal_notes)
+                .await?;
+        }
+
+        let mut state = self.state.write().await;
+        state
+            .last_tune_ms_by_layer
+            .insert(layer.as_str().to_string(), now);
+        write_state_atomic(&state)?;
+        Ok(())
+    }
+
+    fn layer0_candidate(&self, current: &SeatParameterSet, baseline: &SeatObjectiveSnapshot) -> SeatParameterSet {
+        let mut out = current.clone();
+        let tighten = baseline.ev_usdc_p50 < 0.0 || baseline.max_drawdown_pct > 0.05;
+        if let Some(v) = current.position_fraction {
+            out.position_fraction = Some(if tighten { v * 0.97 } else { v * 1.01 });
+        }
+        if let Some(v) = current.early_size_scale {
+            out.early_size_scale = Some(if tighten { v * 0.98 } else { v * 1.02 });
+        }
+        if let Some(v) = current.maturity_size_scale {
+            out.maturity_size_scale = Some(if tighten { v * 0.99 } else { v * 1.01 });
+        }
+        if let Some(v) = current.late_size_scale {
+            out.late_size_scale = Some(if tighten { v * 0.98 } else { v * 1.02 });
+        }
+        if let Some(v) = current.min_edge_net_bps {
+            out.min_edge_net_bps = Some(if tighten { v * 1.03 } else { v * 0.99 });
+        }
+        if let Some(v) = current.convergence_exit_ratio {
+            out.convergence_exit_ratio = Some(if tighten {
+                (v * 0.99).max(0.10)
+            } else {
+                (v * 1.005).min(0.99)
+            });
+        }
+        if let Some(v) = current.min_velocity_bps_per_sec {
+            out.min_velocity_bps_per_sec = Some(if tighten { v * 1.03 } else { v * 0.99 });
+        }
+        out.clamp_relative(current, SeatLayer::Layer0.step_limit_pct())
+    }
+
+    async fn optimizer_candidate(
+        &self,
+        layer: SeatLayer,
+        current: &SeatParameterSet,
+        baseline: &SeatObjectiveSnapshot,
+    ) -> Result<SeatOptimizerProposal> {
+        let endpoint = match layer {
+            SeatLayer::Layer1 => "l1",
+            SeatLayer::Layer2 => "l2",
+            SeatLayer::Layer3 => {
+                let state = self.state.read().await;
+                if state.style_memory.len() < 8 {
+                    "l2"
+                } else {
+                    "l3"
+                }
+            }
+            SeatLayer::Layer0 => "l1",
+        };
+        let current_style = SeatStyleVector {
+            volatility_proxy: baseline.volatility_proxy,
+            source_health_min: baseline.source_health_min,
+            roi_notional_10s_bps_p50: baseline.roi_notional_10s_bps_p50,
+            win_rate: baseline.win_rate,
+        };
+        let (style_memory, objective_history, volatility_history) = {
+            let state = self.state.read().await;
+            (
+                state.style_memory.clone(),
+                state
+                    .objective_history
+                    .iter()
+                    .rev()
+                    .take(1_440)
+                    .cloned()
+                    .collect::<Vec<_>>()
+                    .into_iter()
+                    .rev()
+                    .collect::<Vec<_>>(),
+                state
+                    .volatility_history
+                    .iter()
+                    .rev()
+                    .take(1_440)
+                    .cloned()
+                    .collect::<Vec<_>>()
+                    .into_iter()
+                    .rev()
+                    .collect::<Vec<_>>(),
+            )
+        };
+        let payload = serde_json::json!({
+            "layer": layer.as_str(),
+            "current_params": current,
+            "baseline": baseline,
+            "style_memory": style_memory,
+            "current_style": current_style,
+            "objective_history": objective_history,
+            "volatility_history": volatility_history,
+        });
+        let resp = self
+            .http
+            .post(format!("{}/v1/seat/{endpoint}/optimize", self.cfg.optimizer_url))
+            .json(&payload)
+            .send()
+            .await
+            .with_context(|| format!("seat optimizer {endpoint}"))?;
+        if !resp.status().is_success() {
+            return Err(anyhow!("seat optimizer status={}", resp.status()));
+        }
+        let proposal = resp
+            .json::<SeatOptimizerProposal>()
+            .await
+            .context("parse optimizer proposal")?;
+        let required_mc = match layer {
+            SeatLayer::Layer1 => 100,
+            SeatLayer::Layer2 => 500,
+            SeatLayer::Layer3 => 1_000,
+            SeatLayer::Layer0 => 100,
+        };
+        if proposal.validation.mc_runs < required_mc || !proposal.validation.mc_pass {
+            return Err(anyhow!(
+                "optimizer validation failed mc_runs={} mc_pass={}",
+                proposal.validation.mc_runs,
+                proposal.validation.mc_pass
+            ));
+        }
+        if layer != SeatLayer::Layer1 && !proposal.validation.walk_forward_pass {
+            return Err(anyhow!("optimizer walk-forward validation failed"));
+        }
+        if layer != SeatLayer::Layer1 && !proposal.validation.shadow_pass {
+            return Err(anyhow!("optimizer shadow validation failed"));
+        }
+        Ok(proposal)
+    }
+
+    async fn begin_smoothing(
+        &self,
+        layer: SeatLayer,
+        old_params: SeatParameterSet,
+        candidate: SeatParameterSet,
+        baseline: SeatObjectiveSnapshot,
+        now: i64,
+        mut notes: Vec<String>,
+    ) -> Result<()> {
+        let mut state = self.state.write().await;
+        let pre_switch = self.mean_objective_24h_locked(&state, now).unwrap_or(baseline.objective);
+        state.pre_switch_objective_24h = Some(pre_switch);
+        state.smoothing = Some(SeatSmoothingState {
+            layer,
+            old_params: old_params.clone(),
+            target_params: candidate.clone(),
+            current_params: old_params,
+            baseline: baseline.clone(),
+            started_ms: now,
+            end_ms: now + (self.cfg.smoothing_sec as i64) * 1_000,
+            next_step_ms: now,
+        });
+        notes.push(format!("pre_switch_objective_24h={pre_switch:.6}"));
+        self.record_decision_locked(
+            &mut state,
+            layer,
+            candidate,
+            baseline,
+            "smoothing_started".to_string(),
+            false,
+            notes,
+        )?;
+        write_state_atomic(&state)?;
+        Ok(())
+    }
+
+    async fn process_smoothing(&self, now: i64) -> Result<()> {
+        let mut start_monitor = None::<(
+            SeatLayer,
+            SeatParameterSet,
+            SeatParameterSet,
+            SeatObjectiveSnapshot,
+            f64,
+        )>;
+        {
+            let mut state = self.state.write().await;
+            let Some(mut smooth) = state.smoothing.clone() else {
+                return Ok(());
+            };
+            if now < smooth.next_step_ms {
+                return Ok(());
+            }
+            if now >= smooth.end_ms {
+                self.apply_params(&smooth.target_params, &self.cfg.control_base_url)
+                    .await?;
+                start_monitor = Some((
+                    smooth.layer,
+                    smooth.old_params.clone(),
+                    smooth.target_params.clone(),
+                    smooth.baseline.clone(),
+                    state.pre_switch_objective_24h.unwrap_or(0.0),
+                ));
+                state.smoothing = None;
+            } else {
+                smooth.current_params.exp_blend_towards(&smooth.target_params, 0.7);
+                self.apply_params(&smooth.current_params, &self.cfg.control_base_url)
+                    .await?;
+                smooth.next_step_ms = smooth.next_step_ms.saturating_add(5 * 60 * 1_000);
+                state.smoothing = Some(smooth);
+            }
+            write_state_atomic(&state)?;
+        }
+        if let Some((layer, old_params, new_params, baseline, pre_switch)) = start_monitor {
+            let mut state = self.state.write().await;
+            state.monitor = Some(SeatMonitorState {
+                layer,
+                old_params,
+                new_params,
+                baseline,
+                pre_switch_objective_24h: pre_switch,
+                started_ms: now,
+                end_ms: now + (self.cfg.monitor_sec as i64) * 1_000,
+            });
+            write_state_atomic(&state)?;
+        }
+        Ok(())
+    }
+
+    async fn process_monitor(&self, now: i64, objective: &SeatObjectiveSnapshot) -> Result<()> {
+        let monitor = self.state.read().await.monitor.clone();
+        let Some(monitor) = monitor else {
+            return Ok(());
+        };
+        if now < monitor.end_ms {
+            let local_rollback = objective.ev_usdc_p50 < monitor.baseline.ev_usdc_p50
+                || objective.max_drawdown_pct > monitor.baseline.max_drawdown_pct;
+            let remote_rollback = match self
+                .http
+                .post(format!("{}/v1/seat/monitor_60m", self.cfg.optimizer_url))
+                .json(&serde_json::json!({
+                    "layer": monitor.layer.as_str(),
+                    "ev_new": objective.ev_usdc_p50,
+                    "ev_old": monitor.baseline.ev_usdc_p50,
+                    "dd_new": objective.max_drawdown_pct,
+                    "dd_old": monitor.baseline.max_drawdown_pct,
+                }))
+                .send()
+                .await
+            {
+                Ok(resp) => match resp.json::<serde_json::Value>().await {
+                    Ok(body) => body
+                        .get("rollback")
+                        .and_then(|x| x.as_bool())
+                        .unwrap_or(local_rollback),
+                    Err(_) => local_rollback,
+                },
+                Err(_) => local_rollback,
+            };
+            if local_rollback || remote_rollback {
+                self.rollback_with_pause(
+                    monitor.layer,
+                    monitor.old_params,
+                    monitor.baseline,
+                    "monitor_regression",
+                    now,
+                )
+                .await?;
+            }
+            return Ok(());
+        }
+
+        let entry = {
+            let mut state = self.state.write().await;
+            state.monitor = None;
+            state.rollback_streak = 0;
+            state.post_switch_eval_due_ms = now + 24 * 3_600 * 1_000;
+            state.post_switch_start_ms = now;
+            state.post_switch_baseline_24h = Some(monitor.pre_switch_objective_24h);
+            state.post_switch_layer = Some(monitor.layer);
+            let entry = self.update_style_memory_locked(&mut state, objective, &monitor.new_params, now);
+            self.record_decision_locked(
+                &mut state,
+                monitor.layer,
+                monitor.new_params,
+                objective.clone(),
+                "monitor_pass".to_string(),
+                false,
+                vec![
+                    format!("style_objective={:.6}", entry.objective),
+                    format!("style_id={}", entry.style_id),
+                ],
+            )?;
+            write_state_atomic(&state)?;
+            entry
+        };
+        let _ = self
+            .push_style_memory_update(monitor.layer, &entry, objective)
+            .await;
+        Ok(())
+    }
+
+    async fn process_post_switch_degrade(&self, now: i64) -> Result<()> {
+        let maybe = {
+            let state = self.state.read().await;
+            if state.post_switch_eval_due_ms == 0 || now < state.post_switch_eval_due_ms {
+                None
+            } else {
+                Some((
+                    state.post_switch_layer.unwrap_or(SeatLayer::Layer0),
+                    state.post_switch_start_ms,
+                    state.post_switch_baseline_24h.unwrap_or(0.0),
+                ))
+            }
+        };
+        let Some((layer, start_ms, baseline)) = maybe else {
+            return Ok(());
+        };
+        let post_mean = {
+            let state = self.state.read().await;
+            let values = state
+                .objective_history
+                .iter()
+                .filter(|p| p.ts_ms >= start_ms)
+                .map(|p| p.objective)
+                .collect::<Vec<_>>();
+            if values.is_empty() {
+                baseline
+            } else {
+                values.iter().sum::<f64>() / values.len() as f64
+            }
+        };
+        let mut state = self.state.write().await;
+        state.post_switch_eval_due_ms = 0;
+        state.post_switch_baseline_24h = None;
+        state.post_switch_layer = None;
+        if post_mean < baseline {
+            self.downgrade_locked(&mut state, layer, format!("{post_mean:.6}<{baseline:.6}"))?;
+        } else {
+            state.degrade_streak = 0;
+        }
+        write_state_atomic(&state)?;
+        Ok(())
+    }
+
+    async fn rollback_with_pause(
+        &self,
+        layer: SeatLayer,
+        old_params: SeatParameterSet,
+        baseline: SeatObjectiveSnapshot,
+        reason: &str,
+        now: i64,
+    ) -> Result<()> {
+        self.apply_params(&old_params, &self.cfg.control_base_url).await?;
+        let mut state = self.state.write().await;
+        state.smoothing = None;
+        state.monitor = None;
+        state
+            .layer_pause_until_ms
+            .insert(layer.as_str().to_string(), now + (self.cfg.rollback_pause_sec as i64) * 1_000);
+        state.rollback_streak = state.rollback_streak.saturating_add(1);
+        if state.rollback_streak >= 2 {
+            state.global_pause_until_ms = now + (self.cfg.global_pause_sec as i64) * 1_000;
+            state.layer0_lock_until_ms = now + (self.cfg.layer0_lock_sec as i64) * 1_000;
+            state.current_layer = SeatLayer::Layer0;
+        }
+        self.record_decision_locked(
+            &mut state,
+            layer,
+            old_params,
+            baseline,
+            format!("rollback:{reason}"),
+            true,
+            vec![reason.to_string()],
+        )?;
+        write_state_atomic(&state)?;
+        Ok(())
+    }
+
+    fn downgrade_locked(&self, state: &mut SeatRuntimeState, from_layer: SeatLayer, reason: String) -> Result<()> {
+        let next = match from_layer {
+            SeatLayer::Layer3 => SeatLayer::Layer2,
+            SeatLayer::Layer2 => SeatLayer::Layer1,
+            SeatLayer::Layer1 | SeatLayer::Layer0 => SeatLayer::Layer0,
+        };
+        state.current_layer = next;
+        state
+            .layer_pause_until_ms
+            .insert(from_layer.as_str().to_string(), now_ms() + (self.cfg.rollback_pause_sec as i64) * 1_000);
+        state.degrade_streak = state.degrade_streak.saturating_add(1);
+        if state.degrade_streak >= 2 {
+            state.current_layer = SeatLayer::Layer0;
+            state.layer0_lock_until_ms = now_ms() + (self.cfg.layer0_lock_sec as i64) * 1_000;
+            state.degrade_streak = 0;
+        }
+        let last_params = state.last_params.clone();
+        let last_objective = state.last_objective.clone().unwrap_or_default();
+        self.record_decision_locked(
+            state,
+            state.current_layer,
+            last_params,
+            last_objective,
+            format!("downgrade:{reason}"),
+            false,
+            vec![reason],
+        )?;
+        Ok(())
+    }
+
+    fn mean_objective_24h_locked(&self, state: &SeatRuntimeState, now: i64) -> Option<f64> {
+        let start = now.saturating_sub(24 * 3_600 * 1_000);
+        let values = state
+            .objective_history
+            .iter()
+            .filter(|p| p.ts_ms >= start && p.ts_ms <= now)
+            .map(|p| p.objective)
+            .collect::<Vec<_>>();
+        if values.is_empty() {
+            None
+        } else {
+            Some(values.iter().sum::<f64>() / values.len() as f64)
+        }
+    }
+
+    fn update_style_memory_locked(
+        &self,
+        state: &mut SeatRuntimeState,
+        objective: &SeatObjectiveSnapshot,
+        params: &SeatParameterSet,
+        now: i64,
+    ) -> SeatStyleMemoryEntry {
+        let vector = SeatStyleVector {
+            volatility_proxy: objective.volatility_proxy,
+            source_health_min: objective.source_health_min,
+            roi_notional_10s_bps_p50: objective.roi_notional_10s_bps_p50,
+            win_rate: objective.win_rate,
+        };
+        let style_id = self.style_id(&vector);
+        if let Some(entry) = state.style_memory.iter_mut().find(|entry| entry.style_id == style_id) {
+            entry.vector = vector;
+            entry.params = params.clone();
+            entry.objective = objective.objective;
+            entry.updated_ms = now;
+            return entry.clone();
+        }
+        if state.style_memory.len() < 8 {
+            let entry = SeatStyleMemoryEntry {
+                style_id,
+                vector,
+                params: params.clone(),
+                objective: objective.objective,
+                updated_ms: now,
+            };
+            state.style_memory.push(entry.clone());
+            return entry;
+        }
+        if let Some((idx, _)) = state
+            .style_memory
+            .iter()
+            .enumerate()
+            .min_by(|(_, a), (_, b)| a.objective.partial_cmp(&b.objective).unwrap_or(std::cmp::Ordering::Equal))
+        {
+            let entry = SeatStyleMemoryEntry {
+                style_id,
+                vector,
+                params: params.clone(),
+                objective: objective.objective,
+                updated_ms: now,
+            };
+            state.style_memory[idx] = entry.clone();
+            return entry;
+        }
+        SeatStyleMemoryEntry {
+            style_id,
+            vector,
+            params: params.clone(),
+            objective: objective.objective,
+            updated_ms: now,
+        }
+    }
+
+    fn style_id(&self, vector: &SeatStyleVector) -> String {
+        let vol = if vector.volatility_proxy > 8.0 { "hv" } else { "lv" };
+        let health = if vector.source_health_min > 0.6 { "hh" } else { "lh" };
+        let drift = if vector.roi_notional_10s_bps_p50 > 0.0 { "pr" } else { "ng" };
+        format!("{vol}_{health}_{drift}")
+    }
+
+    async fn push_style_memory_update(
+        &self,
+        layer: SeatLayer,
+        entry: &SeatStyleMemoryEntry,
+        objective: &SeatObjectiveSnapshot,
+    ) -> Result<()> {
+        let resp = self
+            .http
+            .post(format!("{}/v1/seat/style_memory/update", self.cfg.optimizer_url))
+            .json(&serde_json::json!({
+                "layer": layer.as_str(),
+                "entry": entry,
+                "reward": objective.objective,
+                "objective": objective,
+            }))
+            .send()
+            .await?;
+        if !resp.status().is_success() {
+            return Err(anyhow!("style memory update failed status={}", resp.status()));
+        }
+        Ok(())
+    }
+
+    fn record_decision_locked(
+        &self,
+        state: &mut SeatRuntimeState,
+        layer: SeatLayer,
+        candidate: SeatParameterSet,
+        baseline: SeatObjectiveSnapshot,
+        decision: String,
+        rollback: bool,
+        notes: Vec<String>,
+    ) -> Result<()> {
+        let previous = state.last_params.clone();
+        state.last_decision_ts_ms = now_ms();
+        state.decision_seq = state.decision_seq.saturating_add(1);
+        state.last_params = candidate.clone();
+        let record = SeatDecisionRecord {
+            ts_ms: state.last_decision_ts_ms,
+            layer,
+            previous,
+            candidate,
+            baseline,
+            decision,
+            rollback,
+            lock_state: SeatLockState {
+                paused: state.paused,
+                global_pause_until_ms: state.global_pause_until_ms,
+                layer0_lock_until_ms: state.layer0_lock_until_ms,
+                active_shadow_until_ms: state.active_shadow_until_ms,
+            },
+            trade_count_source: state.trade_count_source.clone(),
+            notes,
+        };
+        append_decision(&record)?;
+        write_tune_report(&record, state)?;
+        Ok(())
+    }
+
+    async fn apply_params(&self, params: &SeatParameterSet, base_url: &str) -> Result<()> {
+        if params.is_empty() {
+            return Ok(());
+        }
+        if params.position_fraction.is_some()
+            || params.early_size_scale.is_some()
+            || params.maturity_size_scale.is_some()
+            || params.late_size_scale.is_some()
+            || params.min_edge_net_bps.is_some()
+            || params.min_velocity_bps_per_sec.is_some()
+        {
+            let mut body = serde_json::Map::new();
+            if params.position_fraction.is_some() {
+                body.insert(
+                    "compounder".to_string(),
+                    serde_json::json!({"position_fraction": params.position_fraction}),
+                );
+            }
+            if params.early_size_scale.is_some()
+                || params.maturity_size_scale.is_some()
+                || params.late_size_scale.is_some()
+            {
+                body.insert(
+                    "v52_time_phase".to_string(),
+                    serde_json::json!({
+                        "early_size_scale": params.early_size_scale,
+                        "maturity_size_scale": params.maturity_size_scale,
+                        "late_size_scale": params.late_size_scale
+                    }),
+                );
+            }
+            if params.min_edge_net_bps.is_some() {
+                body.insert(
+                    "taker_sniper".to_string(),
+                    serde_json::json!({"min_edge_net_bps": params.min_edge_net_bps}),
+                );
+            }
+            if params.min_velocity_bps_per_sec.is_some() {
+                body.insert(
+                    "direction_detector".to_string(),
+                    serde_json::json!({"min_velocity_bps_per_sec": params.min_velocity_bps_per_sec}),
+                );
+            }
+            self.http
+                .post(format!("{base_url}/control/reload_predator_c"))
+                .json(&serde_json::Value::Object(body))
+                .send()
+                .await?
+                .error_for_status()?;
+        }
+        if params.convergence_exit_ratio.is_some()
+            || params.t100ms_reversal_bps.is_some()
+            || params.t300ms_reversal_bps.is_some()
+            || params.max_single_trade_loss_usdc.is_some()
+        {
+            self.http
+                .post(format!("{base_url}/control/reload_exit"))
+                .json(&serde_json::json!({
+                    "convergence_exit_ratio": params.convergence_exit_ratio,
+                    "t100ms_reversal_bps": params.t100ms_reversal_bps,
+                    "t300ms_reversal_bps": params.t300ms_reversal_bps,
+                    "max_single_trade_loss_usdc": params.max_single_trade_loss_usdc
+                }))
+                .send()
+                .await?
+                .error_for_status()?;
+        }
+        if params.capital_fraction_kelly.is_some() {
+            self.http
+                .post(format!("{base_url}/control/reload_allocator"))
+                .json(&serde_json::json!({
+                    "capital_fraction_kelly": params.capital_fraction_kelly
+                }))
+                .send()
+                .await?
+                .error_for_status()?;
+        }
+        if params.risk_max_drawdown_pct.is_some() || params.risk_max_market_notional.is_some() {
+            self.http
+                .post(format!("{base_url}/control/reload_risk"))
+                .json(&serde_json::json!({
+                    "daily_drawdown_cap_pct": params.risk_max_drawdown_pct,
+                    "max_market_notional": params.risk_max_market_notional
+                }))
+                .send()
+                .await?
+                .error_for_status()?;
+        }
+        if params.maker_min_edge_bps.is_some() || params.basis_k_revert.is_some() || params.basis_z_cap.is_some() {
+            self.http
+                .post(format!("{base_url}/control/reload_strategy"))
+                .json(&serde_json::json!({
+                    "min_edge_bps": params.maker_min_edge_bps,
+                    "basis_k_revert": params.basis_k_revert,
+                    "basis_z_cap": params.basis_z_cap
+                }))
+                .send()
+                .await?
+                .error_for_status()?;
+        }
+        Ok(())
+    }
+
+    async fn capture_current_params(&self) -> Result<SeatParameterSet> {
+        #[derive(Debug, Deserialize)]
+        struct PredatorResp {
+            predator_c: serde_json::Value,
+        }
+        #[derive(Debug, Deserialize)]
+        struct ExitResp {
+            exit: serde_json::Value,
+        }
+        #[derive(Debug, Deserialize)]
+        struct AllocatorResp {
+            allocator: serde_json::Value,
+        }
+        #[derive(Debug, Deserialize)]
+        struct RiskResp {
+            risk: serde_json::Value,
+        }
+        #[derive(Debug, Deserialize)]
+        struct StrategyResp {
+            maker: serde_json::Value,
+            fair_value: serde_json::Value,
+            v52: serde_json::Value,
+        }
+
+        let predator = self
+            .http
+            .post(format!("{}/control/reload_predator_c", self.cfg.control_base_url))
+            .json(&serde_json::json!({}))
+            .send()
+            .await?
+            .error_for_status()?
+            .json::<PredatorResp>()
+            .await?;
+        let exit = self
+            .http
+            .post(format!("{}/control/reload_exit", self.cfg.control_base_url))
+            .json(&serde_json::json!({}))
+            .send()
+            .await?
+            .error_for_status()?
+            .json::<ExitResp>()
+            .await?;
+        let allocator = self
+            .http
+            .post(format!("{}/control/reload_allocator", self.cfg.control_base_url))
+            .json(&serde_json::json!({}))
+            .send()
+            .await?
+            .error_for_status()?
+            .json::<AllocatorResp>()
+            .await?;
+        let risk = self
+            .http
+            .post(format!("{}/control/reload_risk", self.cfg.control_base_url))
+            .json(&serde_json::json!({}))
+            .send()
+            .await?
+            .error_for_status()?
+            .json::<RiskResp>()
+            .await?;
+        let strategy = self
+            .http
+            .post(format!("{}/control/reload_strategy", self.cfg.control_base_url))
+            .json(&serde_json::json!({}))
+            .send()
+            .await?
+            .error_for_status()?
+            .json::<StrategyResp>()
+            .await?;
+
+        Ok(SeatParameterSet {
+            position_fraction: predator
+                .predator_c
+                .get("compounder")
+                .and_then(|v| v.get("position_fraction"))
+                .and_then(|v| v.as_f64()),
+            early_size_scale: strategy
+                .v52
+                .get("time_phase")
+                .and_then(|v| v.get("early_size_scale"))
+                .and_then(|v| v.as_f64()),
+            maturity_size_scale: strategy
+                .v52
+                .get("time_phase")
+                .and_then(|v| v.get("maturity_size_scale"))
+                .and_then(|v| v.as_f64()),
+            late_size_scale: strategy
+                .v52
+                .get("time_phase")
+                .and_then(|v| v.get("late_size_scale"))
+                .and_then(|v| v.as_f64()),
+            min_edge_net_bps: predator
+                .predator_c
+                .get("taker_sniper")
+                .and_then(|v| v.get("min_edge_net_bps"))
+                .and_then(|v| v.as_f64()),
+            convergence_exit_ratio: exit
+                .exit
+                .get("convergence_exit_ratio")
+                .and_then(|v| v.as_f64()),
+            min_velocity_bps_per_sec: predator
+                .predator_c
+                .get("direction_detector")
+                .and_then(|v| v.get("min_velocity_bps_per_sec"))
+                .and_then(|v| v.as_f64()),
+            capital_fraction_kelly: allocator
+                .allocator
+                .get("capital_fraction_kelly")
+                .and_then(|v| v.as_f64()),
+            t100ms_reversal_bps: exit
+                .exit
+                .get("t100ms_reversal_bps")
+                .and_then(|v| v.as_f64()),
+            t300ms_reversal_bps: exit
+                .exit
+                .get("t300ms_reversal_bps")
+                .and_then(|v| v.as_f64()),
+            max_single_trade_loss_usdc: exit
+                .exit
+                .get("max_single_trade_loss_usdc")
+                .and_then(|v| v.as_f64()),
+            risk_max_drawdown_pct: risk
+                .risk
+                .get("max_drawdown_pct")
+                .and_then(|v| v.as_f64()),
+            risk_max_market_notional: risk
+                .risk
+                .get("max_market_notional")
+                .and_then(|v| v.as_f64()),
+            maker_min_edge_bps: strategy
+                .maker
+                .get("min_edge_bps")
+                .and_then(|v| v.as_f64()),
+            basis_k_revert: strategy
+                .fair_value
+                .get("k_revert")
+                .and_then(|v| v.as_f64()),
+            basis_z_cap: strategy.fair_value.get("z_cap").and_then(|v| v.as_f64()),
+        })
+    }
+
+    async fn start_challenger(
+        &self,
+        layer: SeatLayer,
+        old_params: SeatParameterSet,
+        candidate: SeatParameterSet,
+        baseline: SeatObjectiveSnapshot,
+        shadow_sec: u64,
+        now: i64,
+        mut notes: Vec<String>,
+    ) -> Result<bool> {
+        let mut guard = self.challenger.lock().await;
+        if guard.is_some() {
+            return Ok(false);
+        }
+        let required_cycles = self.required_shadow_cycles(layer, shadow_sec);
+        let port = self.find_available_port()?;
+        let root = self.build_challenger_dataset_root(now, layer);
+        let mut cmd = Command::new(std::env::current_exe().context("resolve current exe")?);
+        cmd.env("POLYEDGE_FORCE_PAPER", "true")
+            .env("POLYEDGE_SEAT_ENABLED", "false")
+            .env("POLYEDGE_LIVE_ARMED", "false")
+            .env("POLYEDGE_CONTROL_PORT", port.to_string())
+            .env("POLYEDGE_DATASET_ROOT", &root)
+            .stdin(Stdio::null())
+            .stdout(Stdio::null())
+            .stderr(Stdio::null());
+        let child = cmd.spawn().context("spawn challenger app_runner")?;
+        let base_url = format!("http://127.0.0.1:{port}");
+        self.wait_control_ready(&base_url).await?;
+        self.apply_params(&candidate, &base_url).await?;
+        let proposal_notes = notes.clone();
+        *guard = Some(ChallengerProcess {
+            layer,
+            started_ms: now,
+            end_ms: now + (shadow_sec as i64) * 1_000,
+            required_cycles,
+            control_base_url: base_url,
+            candidate: candidate.clone(),
+            old_params,
+            baseline: baseline.clone(),
+            proposal_notes,
+            child,
+        });
+        drop(guard);
+        let mut state = self.state.write().await;
+        state.active_shadow_until_ms = now + (shadow_sec as i64) * 1_000;
+        notes.push(format!("duration_sec={shadow_sec}"));
+        notes.push(format!("required_cycles={required_cycles}"));
+        self.record_decision_locked(
+            &mut state,
+            layer,
+            candidate,
+            baseline,
+            "shadow_started".to_string(),
+            false,
+            notes,
+        )?;
+        write_state_atomic(&state)?;
+        Ok(true)
+    }
+
+    async fn poll_challenger(&self, now: i64) -> Result<()> {
+        let mut guard = self.challenger.lock().await;
+        let Some(mut challenger) = guard.take() else {
+            return Ok(());
+        };
+        if now < challenger.end_ms {
+            *guard = Some(challenger);
+            return Ok(());
+        }
+        let compare = self.fetch_shadow_and_pnl_from_base(&challenger.control_base_url).await;
+        let observed_cycles = ((now.saturating_sub(challenger.started_ms)) / (5 * 60 * 1_000)) as u32;
+        let (pass, shadow_notes) = match compare {
+            Ok((live, pnl)) => {
+                let obj = self.build_objective(&live, &pnl);
+                let local_pass = obj.ev_usdc_p50 >= challenger.baseline.ev_usdc_p50 * 1.05
+                    && obj.max_drawdown_pct <= challenger.baseline.max_drawdown_pct * 1.12
+                    && observed_cycles >= challenger.required_cycles;
+                let remote_pass = match self
+                    .http
+                    .post(format!("{}/v1/seat/shadow_compare", self.cfg.optimizer_url))
+                    .json(&serde_json::json!({
+                        "layer": challenger.layer.as_str(),
+                        "ev_new": obj.ev_usdc_p50,
+                        "ev_old": challenger.baseline.ev_usdc_p50,
+                        "dd_new": obj.max_drawdown_pct,
+                        "dd_old": challenger.baseline.max_drawdown_pct,
+                        "cycles_observed": observed_cycles,
+                        "cycles_required": challenger.required_cycles,
+                    }))
+                    .send()
+                    .await
+                {
+                    Ok(resp) => match resp.json::<serde_json::Value>().await {
+                        Ok(body) => body
+                            .get("pass")
+                            .and_then(|x| x.as_bool())
+                            .unwrap_or(local_pass),
+                        Err(_) => local_pass,
+                    },
+                    Err(_) => local_pass,
+                };
+                (
+                    local_pass && remote_pass,
+                    vec![
+                        format!("shadow_ev_usdc_p50={:.6}", obj.ev_usdc_p50),
+                        format!(
+                            "shadow_max_drawdown_pct={:.6}",
+                            obj.max_drawdown_pct
+                        ),
+                    ],
+                )
+            }
+            Err(_) => (false, vec!["shadow_metrics_unavailable=true".to_string()]),
+        };
+        let _ = challenger.child.kill().await;
+        let _ = challenger.child.wait().await;
+        {
+            let mut state = self.state.write().await;
+            state.active_shadow_until_ms = 0;
+            write_state_atomic(&state)?;
+        }
+        if pass {
+            self.begin_smoothing(
+                challenger.layer,
+                challenger.old_params,
+                challenger.candidate,
+                challenger.baseline,
+                now,
+                {
+                    let mut notes = challenger.proposal_notes;
+                    notes.extend(shadow_notes);
+                    notes.extend([
+                    format!("shadow_cycles_observed={observed_cycles}"),
+                    format!("shadow_cycles_required={}", challenger.required_cycles),
+                    ]);
+                    notes
+                },
+            )
+            .await?;
+        } else {
+            let mut state = self.state.write().await;
+            let last_params = state.last_params.clone();
+            self.record_decision_locked(
+                &mut state,
+                challenger.layer,
+                last_params,
+                challenger.baseline,
+                "shadow_reject".to_string(),
+                false,
+                {
+                    let mut notes = vec!["shadow_compare_failed".to_string()];
+                    notes.extend(shadow_notes);
+                    notes.extend([
+                    format!("shadow_cycles_observed={observed_cycles}"),
+                    format!("shadow_cycles_required={}", challenger.required_cycles),
+                    ]);
+                    notes
+                },
+            )?;
+            write_state_atomic(&state)?;
+        }
+        Ok(())
+    }
+
+    async fn fetch_shadow_and_pnl_from_base(&self, base_url: &str) -> Result<(ShadowLiveLite, PnlLite)> {
+        let live = self
+            .http
+            .get(format!("{base_url}/report/shadow/live"))
+            .send()
+            .await?
+            .error_for_status()?
+            .json::<ShadowLiveLite>()
+            .await?;
+        let pnl = self
+            .http
+            .get(format!("{base_url}/state/pnl"))
+            .send()
+            .await?
+            .error_for_status()?
+            .json::<PnlLite>()
+            .await?;
+        Ok((live, pnl))
+    }
+
+    fn find_available_port(&self) -> Result<u16> {
+        let listener = std::net::TcpListener::bind("127.0.0.1:0").context("bind ephemeral port")?;
+        let port = listener.local_addr().context("ephemeral addr")?.port();
+        drop(listener);
+        Ok(port)
+    }
+
+    fn build_challenger_dataset_root(&self, now: i64, layer: SeatLayer) -> String {
+        let root = std::env::var("POLYEDGE_DATASET_ROOT")
+            .ok()
+            .filter(|v| !v.trim().is_empty())
+            .unwrap_or_else(|| "datasets".to_string());
+        let path = std::path::PathBuf::from(root)
+            .join("seat_challenger")
+            .join(format!("{}_{}", now, layer.as_str()));
+        let _ = std::fs::create_dir_all(&path);
+        path.to_string_lossy().to_string()
+    }
+
+    async fn wait_control_ready(&self, base_url: &str) -> Result<()> {
+        let health = format!("{base_url}/health");
+        let start = now_ms();
+        while now_ms().saturating_sub(start) < 30_000 {
+            let ok = self
+                .http
+                .get(&health)
+                .send()
+                .await
+                .map(|resp| resp.status().is_success())
+                .unwrap_or(false);
+            if ok {
+                return Ok(());
+            }
+            tokio::time::sleep(Duration::from_millis(500)).await;
+        }
+        Err(anyhow!("challenger control API not ready"))
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    fn test_handle() -> SeatRuntimeHandle {
+        SeatRuntimeHandle {
+            cfg: SeatConfig::default(),
+            http: Client::new(),
+            state: Arc::new(RwLock::new(SeatRuntimeState::default())),
+            live_fill_counter: Arc::new(AtomicU64::new(0)),
+            challenger: Arc::new(Mutex::new(None)),
+        }
+    }
+
+    #[test]
+    fn layer_boundaries_respect_trade_and_uptime() {
+        let handle = test_handle();
+        let mut state = SeatRuntimeState::default();
+        let t0 = state.started_ms + 50 * 3_600 * 1_000;
+        state.live_fill_total = 200;
+        assert_eq!(handle.target_layer(&state, t0), SeatLayer::Layer0);
+        state.live_fill_total = 320;
+        assert_eq!(handle.target_layer(&state, t0), SeatLayer::Layer1);
+        let t1 = state.started_ms + 73 * 3_600 * 1_000;
+        state.live_fill_total = 900;
+        assert_eq!(handle.target_layer(&state, t1), SeatLayer::Layer2);
+        state.live_fill_total = 2_100;
+        assert_eq!(handle.target_layer(&state, t1), SeatLayer::Layer3);
+    }
+
+    #[test]
+    fn smoothing_and_monitor_window_form_ninety_minutes() {
+        let smooth = SeatSmoothingState {
+            layer: SeatLayer::Layer1,
+            old_params: SeatParameterSet::default(),
+            target_params: SeatParameterSet::default(),
+            current_params: SeatParameterSet::default(),
+            baseline: SeatObjectiveSnapshot::default(),
+            started_ms: 0,
+            end_ms: 1_800_000,
+            next_step_ms: 0,
+        };
+        let monitor = SeatMonitorState {
+            layer: SeatLayer::Layer1,
+            old_params: SeatParameterSet::default(),
+            new_params: SeatParameterSet::default(),
+            baseline: SeatObjectiveSnapshot::default(),
+            pre_switch_objective_24h: 0.0,
+            started_ms: smooth.end_ms,
+            end_ms: smooth.end_ms + 3_600_000,
+        };
+        assert_eq!(monitor.end_ms, 5_400_000);
+    }
+
+    #[test]
+    fn downgrade_streak_forces_layer0_lock() {
+        let handle = test_handle();
+        let mut state = SeatRuntimeState::default();
+        state.current_layer = SeatLayer::Layer3;
+        handle
+            .downgrade_locked(&mut state, SeatLayer::Layer3, "first".to_string())
+            .expect("first downgrade");
+        assert_eq!(state.current_layer, SeatLayer::Layer2);
+        handle
+            .downgrade_locked(&mut state, SeatLayer::Layer2, "second".to_string())
+            .expect("second downgrade");
+        assert_eq!(state.current_layer, SeatLayer::Layer0);
+        assert!(state.layer0_lock_until_ms > 0);
+    }
+}
diff --git a/crates/app_runner/src/seat_types.rs b/crates/app_runner/src/seat_types.rs
new file mode 100644
index 0000000..bc89a49
--- /dev/null
+++ b/crates/app_runner/src/seat_types.rs
@@ -0,0 +1,546 @@
+use std::collections::BTreeMap;
+
+use serde::{Deserialize, Serialize};
+
+#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord, Hash)]
+#[serde(rename_all = "snake_case")]
+pub(crate) enum SeatLayer {
+    Layer0,
+    Layer1,
+    Layer2,
+    Layer3,
+}
+
+impl SeatLayer {
+    pub(crate) fn as_str(self) -> &'static str {
+        match self {
+            Self::Layer0 => "layer0",
+            Self::Layer1 => "layer1",
+            Self::Layer2 => "layer2",
+            Self::Layer3 => "layer3",
+        }
+    }
+
+    pub(crate) fn step_limit_pct(self) -> f64 {
+        match self {
+            Self::Layer0 => 0.03,
+            Self::Layer1 => 0.05,
+            Self::Layer2 | Self::Layer3 => 0.12,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SeatConfig {
+    pub(crate) enabled: bool,
+    pub(crate) control_base_url: String,
+    pub(crate) optimizer_url: String,
+    pub(crate) runtime_tick_sec: u64,
+    pub(crate) activation_check_sec: u64,
+    pub(crate) layer1_interval_sec: u64,
+    pub(crate) layer2_interval_sec: u64,
+    pub(crate) layer3_interval_sec: u64,
+    pub(crate) layer2_shadow_sec: u64,
+    pub(crate) layer3_shadow_sec: u64,
+    pub(crate) smoothing_sec: u64,
+    pub(crate) monitor_sec: u64,
+    pub(crate) rollback_pause_sec: u64,
+    pub(crate) global_pause_sec: u64,
+    pub(crate) layer0_lock_sec: u64,
+    pub(crate) layer1_min_trades: u64,
+    pub(crate) layer2_min_trades: u64,
+    pub(crate) layer2_min_uptime_sec: u64,
+    pub(crate) layer3_min_trades: u64,
+    pub(crate) layer3_min_uptime_sec: u64,
+    pub(crate) black_swan_lock_sec: u64,
+    pub(crate) source_health_floor: f64,
+    pub(crate) history_retention_days: u32,
+    pub(crate) objective_drawdown_penalty: f64,
+}
+
+impl Default for SeatConfig {
+    fn default() -> Self {
+        Self {
+            enabled: true,
+            control_base_url: "http://127.0.0.1:8080".to_string(),
+            optimizer_url: std::env::var("POLYEDGE_SEAT_OPTIMIZER_URL")
+                .unwrap_or_else(|_| "http://127.0.0.1:8091".to_string()),
+            runtime_tick_sec: 60,
+            activation_check_sec: 3_600,
+            layer1_interval_sec: 3_600,
+            layer2_interval_sec: 21_600,
+            layer3_interval_sec: 86_400,
+            layer2_shadow_sec: 2_700,
+            layer3_shadow_sec: 6_000,
+            smoothing_sec: 1_800,
+            monitor_sec: 3_600,
+            rollback_pause_sec: 86_400,
+            global_pause_sec: 172_800,
+            layer0_lock_sec: 172_800,
+            layer1_min_trades: 300,
+            layer2_min_trades: 800,
+            layer2_min_uptime_sec: 72 * 3_600,
+            layer3_min_trades: 2_000,
+            layer3_min_uptime_sec: 14 * 24 * 3_600,
+            black_swan_lock_sec: 172_800,
+            source_health_floor: 0.30,
+            history_retention_days: 180,
+            objective_drawdown_penalty: 5.0,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default, PartialEq)]
+pub(crate) struct SeatParameterSet {
+    pub(crate) position_fraction: Option<f64>,
+    pub(crate) early_size_scale: Option<f64>,
+    pub(crate) maturity_size_scale: Option<f64>,
+    pub(crate) late_size_scale: Option<f64>,
+    pub(crate) min_edge_net_bps: Option<f64>,
+    pub(crate) convergence_exit_ratio: Option<f64>,
+    pub(crate) min_velocity_bps_per_sec: Option<f64>,
+    pub(crate) capital_fraction_kelly: Option<f64>,
+    pub(crate) t100ms_reversal_bps: Option<f64>,
+    pub(crate) t300ms_reversal_bps: Option<f64>,
+    pub(crate) max_single_trade_loss_usdc: Option<f64>,
+    pub(crate) risk_max_drawdown_pct: Option<f64>,
+    pub(crate) risk_max_market_notional: Option<f64>,
+    pub(crate) maker_min_edge_bps: Option<f64>,
+    pub(crate) basis_k_revert: Option<f64>,
+    pub(crate) basis_z_cap: Option<f64>,
+}
+
+impl SeatParameterSet {
+    pub(crate) fn is_empty(&self) -> bool {
+        self == &Self::default()
+    }
+
+    pub(crate) fn merge_over(&self, base: &Self) -> Self {
+        let mut out = base.clone();
+        macro_rules! merge_field {
+            ($name:ident) => {
+                if self.$name.is_some() {
+                    out.$name = self.$name;
+                }
+            };
+        }
+        merge_field!(position_fraction);
+        merge_field!(early_size_scale);
+        merge_field!(maturity_size_scale);
+        merge_field!(late_size_scale);
+        merge_field!(min_edge_net_bps);
+        merge_field!(convergence_exit_ratio);
+        merge_field!(min_velocity_bps_per_sec);
+        merge_field!(capital_fraction_kelly);
+        merge_field!(t100ms_reversal_bps);
+        merge_field!(t300ms_reversal_bps);
+        merge_field!(max_single_trade_loss_usdc);
+        merge_field!(risk_max_drawdown_pct);
+        merge_field!(risk_max_market_notional);
+        merge_field!(maker_min_edge_bps);
+        merge_field!(basis_k_revert);
+        merge_field!(basis_z_cap);
+        out
+    }
+
+    pub(crate) fn clamp_relative(&self, current: &Self, max_step_pct: f64) -> Self {
+        fn clamp_opt(candidate: Option<f64>, current: Option<f64>, pct: f64) -> Option<f64> {
+            match (candidate, current) {
+                (Some(next), Some(cur)) if cur.is_finite() && next.is_finite() => {
+                    let step = cur.abs() * pct.max(0.0);
+                    if step > 0.0 {
+                        Some(next.clamp(cur - step, cur + step))
+                    } else {
+                        Some(next)
+                    }
+                }
+                (Some(next), _) => Some(next),
+                (None, cur) => cur,
+            }
+        }
+        Self {
+            position_fraction: clamp_opt(
+                self.position_fraction,
+                current.position_fraction,
+                max_step_pct,
+            ),
+            early_size_scale: clamp_opt(
+                self.early_size_scale,
+                current.early_size_scale,
+                max_step_pct,
+            ),
+            maturity_size_scale: clamp_opt(
+                self.maturity_size_scale,
+                current.maturity_size_scale,
+                max_step_pct,
+            ),
+            late_size_scale: clamp_opt(
+                self.late_size_scale,
+                current.late_size_scale,
+                max_step_pct,
+            ),
+            min_edge_net_bps: clamp_opt(
+                self.min_edge_net_bps,
+                current.min_edge_net_bps,
+                max_step_pct,
+            ),
+            convergence_exit_ratio: clamp_opt(
+                self.convergence_exit_ratio,
+                current.convergence_exit_ratio,
+                max_step_pct,
+            ),
+            min_velocity_bps_per_sec: clamp_opt(
+                self.min_velocity_bps_per_sec,
+                current.min_velocity_bps_per_sec,
+                max_step_pct,
+            ),
+            capital_fraction_kelly: clamp_opt(
+                self.capital_fraction_kelly,
+                current.capital_fraction_kelly,
+                max_step_pct,
+            ),
+            t100ms_reversal_bps: clamp_opt(
+                self.t100ms_reversal_bps,
+                current.t100ms_reversal_bps,
+                max_step_pct,
+            ),
+            t300ms_reversal_bps: clamp_opt(
+                self.t300ms_reversal_bps,
+                current.t300ms_reversal_bps,
+                max_step_pct,
+            ),
+            max_single_trade_loss_usdc: clamp_opt(
+                self.max_single_trade_loss_usdc,
+                current.max_single_trade_loss_usdc,
+                max_step_pct,
+            ),
+            risk_max_drawdown_pct: clamp_opt(
+                self.risk_max_drawdown_pct,
+                current.risk_max_drawdown_pct,
+                max_step_pct,
+            ),
+            risk_max_market_notional: clamp_opt(
+                self.risk_max_market_notional,
+                current.risk_max_market_notional,
+                max_step_pct,
+            ),
+            maker_min_edge_bps: clamp_opt(
+                self.maker_min_edge_bps,
+                current.maker_min_edge_bps,
+                max_step_pct,
+            ),
+            basis_k_revert: clamp_opt(self.basis_k_revert, current.basis_k_revert, max_step_pct),
+            basis_z_cap: clamp_opt(self.basis_z_cap, current.basis_z_cap, max_step_pct),
+        }
+    }
+
+    pub(crate) fn exp_blend_towards(&mut self, target: &Self, alpha: f64) {
+        fn blend(cur: Option<f64>, target: Option<f64>, alpha: f64) -> Option<f64> {
+            match (cur, target) {
+                (Some(c), Some(t)) => Some(c + (t - c) * alpha),
+                (None, Some(t)) => Some(t),
+                (Some(c), None) => Some(c),
+                (None, None) => None,
+            }
+        }
+        self.position_fraction = blend(self.position_fraction, target.position_fraction, alpha);
+        self.early_size_scale = blend(self.early_size_scale, target.early_size_scale, alpha);
+        self.maturity_size_scale =
+            blend(self.maturity_size_scale, target.maturity_size_scale, alpha);
+        self.late_size_scale = blend(self.late_size_scale, target.late_size_scale, alpha);
+        self.min_edge_net_bps = blend(self.min_edge_net_bps, target.min_edge_net_bps, alpha);
+        self.convergence_exit_ratio = blend(
+            self.convergence_exit_ratio,
+            target.convergence_exit_ratio,
+            alpha,
+        );
+        self.min_velocity_bps_per_sec = blend(
+            self.min_velocity_bps_per_sec,
+            target.min_velocity_bps_per_sec,
+            alpha,
+        );
+        self.capital_fraction_kelly = blend(
+            self.capital_fraction_kelly,
+            target.capital_fraction_kelly,
+            alpha,
+        );
+        self.t100ms_reversal_bps =
+            blend(self.t100ms_reversal_bps, target.t100ms_reversal_bps, alpha);
+        self.t300ms_reversal_bps =
+            blend(self.t300ms_reversal_bps, target.t300ms_reversal_bps, alpha);
+        self.max_single_trade_loss_usdc = blend(
+            self.max_single_trade_loss_usdc,
+            target.max_single_trade_loss_usdc,
+            alpha,
+        );
+        self.risk_max_drawdown_pct = blend(
+            self.risk_max_drawdown_pct,
+            target.risk_max_drawdown_pct,
+            alpha,
+        );
+        self.risk_max_market_notional = blend(
+            self.risk_max_market_notional,
+            target.risk_max_market_notional,
+            alpha,
+        );
+        self.maker_min_edge_bps = blend(self.maker_min_edge_bps, target.maker_min_edge_bps, alpha);
+        self.basis_k_revert = blend(self.basis_k_revert, target.basis_k_revert, alpha);
+        self.basis_z_cap = blend(self.basis_z_cap, target.basis_z_cap, alpha);
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub(crate) struct SeatObjectiveSnapshot {
+    pub(crate) ev_usdc_p50: f64,
+    pub(crate) max_drawdown_pct: f64,
+    pub(crate) roi_notional_10s_bps_p50: f64,
+    pub(crate) win_rate: f64,
+    pub(crate) source_health_min: f64,
+    pub(crate) volatility_proxy: f64,
+    pub(crate) objective: f64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub(crate) struct SeatObjectivePoint {
+    pub(crate) ts_ms: i64,
+    pub(crate) objective: f64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SeatSmoothingState {
+    pub(crate) layer: SeatLayer,
+    pub(crate) old_params: SeatParameterSet,
+    pub(crate) target_params: SeatParameterSet,
+    pub(crate) current_params: SeatParameterSet,
+    pub(crate) baseline: SeatObjectiveSnapshot,
+    pub(crate) started_ms: i64,
+    pub(crate) end_ms: i64,
+    pub(crate) next_step_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SeatMonitorState {
+    pub(crate) layer: SeatLayer,
+    pub(crate) old_params: SeatParameterSet,
+    pub(crate) new_params: SeatParameterSet,
+    pub(crate) baseline: SeatObjectiveSnapshot,
+    pub(crate) pre_switch_objective_24h: f64,
+    pub(crate) started_ms: i64,
+    pub(crate) end_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub(crate) struct SeatStyleVector {
+    pub(crate) volatility_proxy: f64,
+    pub(crate) source_health_min: f64,
+    pub(crate) roi_notional_10s_bps_p50: f64,
+    pub(crate) win_rate: f64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SeatStyleMemoryEntry {
+    pub(crate) style_id: String,
+    pub(crate) vector: SeatStyleVector,
+    pub(crate) params: SeatParameterSet,
+    pub(crate) objective: f64,
+    pub(crate) updated_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SeatRuntimeState {
+    pub(crate) version: u32,
+    pub(crate) started_ms: i64,
+    pub(crate) current_layer: SeatLayer,
+    pub(crate) forced_layer: Option<SeatLayer>,
+    pub(crate) paused: bool,
+    pub(crate) pause_reason: Option<String>,
+    pub(crate) global_pause_until_ms: i64,
+    pub(crate) layer0_lock_until_ms: i64,
+    pub(crate) layer_pause_until_ms: BTreeMap<String, i64>,
+    pub(crate) active_shadow_until_ms: i64,
+    pub(crate) smoothing: Option<SeatSmoothingState>,
+    pub(crate) monitor: Option<SeatMonitorState>,
+    pub(crate) manual_override: Option<SeatParameterSet>,
+    pub(crate) last_tune_ms_by_layer: BTreeMap<String, i64>,
+    pub(crate) last_activation_check_ms: i64,
+    pub(crate) last_decision_ts_ms: i64,
+    pub(crate) decision_seq: u64,
+    pub(crate) degrade_streak: u32,
+    pub(crate) rollback_streak: u32,
+    pub(crate) live_fill_total: u64,
+    pub(crate) live_fill_seen: u64,
+    pub(crate) proxy_trade_total: u64,
+    pub(crate) proxy_trade_seen: u64,
+    pub(crate) trade_count_source: String,
+    pub(crate) objective_history: Vec<SeatObjectivePoint>,
+    pub(crate) volatility_history: Vec<SeatObjectivePoint>,
+    pub(crate) last_objective: Option<SeatObjectiveSnapshot>,
+    pub(crate) pre_switch_objective_24h: Option<f64>,
+    pub(crate) post_switch_eval_due_ms: i64,
+    pub(crate) post_switch_start_ms: i64,
+    pub(crate) post_switch_baseline_24h: Option<f64>,
+    pub(crate) post_switch_layer: Option<SeatLayer>,
+    pub(crate) last_params: SeatParameterSet,
+    pub(crate) style_memory: Vec<SeatStyleMemoryEntry>,
+    pub(crate) last_archive_ts_ms: i64,
+}
+
+impl Default for SeatRuntimeState {
+    fn default() -> Self {
+        Self {
+            version: 1,
+            started_ms: chrono::Utc::now().timestamp_millis(),
+            current_layer: SeatLayer::Layer0,
+            forced_layer: None,
+            paused: false,
+            pause_reason: None,
+            global_pause_until_ms: 0,
+            layer0_lock_until_ms: 0,
+            layer_pause_until_ms: BTreeMap::new(),
+            active_shadow_until_ms: 0,
+            smoothing: None,
+            monitor: None,
+            manual_override: None,
+            last_tune_ms_by_layer: BTreeMap::new(),
+            last_activation_check_ms: 0,
+            last_decision_ts_ms: 0,
+            decision_seq: 0,
+            degrade_streak: 0,
+            rollback_streak: 0,
+            live_fill_total: 0,
+            live_fill_seen: 0,
+            proxy_trade_total: 0,
+            proxy_trade_seen: 0,
+            trade_count_source: "proxy".to_string(),
+            objective_history: Vec::new(),
+            volatility_history: Vec::new(),
+            last_objective: None,
+            pre_switch_objective_24h: None,
+            post_switch_eval_due_ms: 0,
+            post_switch_start_ms: 0,
+            post_switch_baseline_24h: None,
+            post_switch_layer: None,
+            last_params: SeatParameterSet::default(),
+            style_memory: Vec::new(),
+            last_archive_ts_ms: 0,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub(crate) struct SeatValidationResult {
+    pub(crate) mc_runs: u32,
+    pub(crate) mc_pass: bool,
+    pub(crate) walk_forward_pass: bool,
+    pub(crate) shadow_pass: bool,
+    #[serde(default)]
+    pub(crate) walk_forward_windows: u32,
+    #[serde(default)]
+    pub(crate) walk_forward_score: f64,
+    #[serde(default)]
+    pub(crate) mc_ev_delta_p50: f64,
+    #[serde(default)]
+    pub(crate) mc_drawdown_p95: f64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub(crate) struct SeatOptimizerMeta {
+    #[serde(default)]
+    pub(crate) style_match_score: f64,
+    #[serde(default)]
+    pub(crate) style_match_count: u32,
+    #[serde(default)]
+    pub(crate) top_k_size: u32,
+    #[serde(default)]
+    pub(crate) objective_uplift_estimate: f64,
+    #[serde(default)]
+    pub(crate) rl_signal: f64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub(crate) struct SeatOptimizerProposal {
+    pub(crate) layer: String,
+    pub(crate) candidate: SeatParameterSet,
+    pub(crate) validation: SeatValidationResult,
+    #[serde(default)]
+    pub(crate) meta: SeatOptimizerMeta,
+    pub(crate) notes: Vec<String>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub(crate) struct SeatLockState {
+    pub(crate) paused: bool,
+    pub(crate) global_pause_until_ms: i64,
+    pub(crate) layer0_lock_until_ms: i64,
+    pub(crate) active_shadow_until_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SeatDecisionRecord {
+    pub(crate) ts_ms: i64,
+    pub(crate) layer: SeatLayer,
+    #[serde(default)]
+    pub(crate) previous: SeatParameterSet,
+    pub(crate) candidate: SeatParameterSet,
+    pub(crate) baseline: SeatObjectiveSnapshot,
+    pub(crate) decision: String,
+    pub(crate) rollback: bool,
+    pub(crate) lock_state: SeatLockState,
+    pub(crate) trade_count_source: String,
+    pub(crate) notes: Vec<String>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SeatStatusReport {
+    pub(crate) ts_ms: i64,
+    pub(crate) enabled: bool,
+    pub(crate) paused: bool,
+    pub(crate) pause_reason: Option<String>,
+    pub(crate) current_layer: SeatLayer,
+    pub(crate) forced_layer: Option<SeatLayer>,
+    pub(crate) global_pause_until_ms: i64,
+    pub(crate) layer0_lock_until_ms: i64,
+    pub(crate) active_shadow_until_ms: i64,
+    pub(crate) trade_count: u64,
+    pub(crate) trade_count_source: String,
+    pub(crate) started_ms: i64,
+    pub(crate) last_decision_ts_ms: i64,
+    pub(crate) degrade_streak: u32,
+    pub(crate) rollback_streak: u32,
+    pub(crate) smoothing_active: bool,
+    pub(crate) monitor_active: bool,
+    pub(crate) manual_override_active: bool,
+    pub(crate) last_objective: Option<SeatObjectiveSnapshot>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SeatForceLayerReq {
+    pub(crate) layer: Option<SeatLayer>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub(crate) struct SeatManualOverrideReq {
+    pub(crate) params: SeatParameterSet,
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn relative_clamp_respects_pct() {
+        let current = SeatParameterSet {
+            position_fraction: Some(0.15),
+            min_edge_net_bps: Some(200.0),
+            ..SeatParameterSet::default()
+        };
+        let candidate = SeatParameterSet {
+            position_fraction: Some(0.20),
+            min_edge_net_bps: Some(260.0),
+            ..SeatParameterSet::default()
+        };
+        let clamped = candidate.clamp_relative(&current, 0.05);
+        assert_eq!(clamped.position_fraction, Some(0.1575));
+        assert_eq!(clamped.min_edge_net_bps, Some(210.0));
+    }
+}
diff --git a/crates/app_runner/src/state.rs b/crates/app_runner/src/state.rs
new file mode 100644
index 0000000..bc2e002
--- /dev/null
+++ b/crates/app_runner/src/state.rs
@@ -0,0 +1,2531 @@
+use std::collections::{HashMap, VecDeque};
+use std::sync::atomic::{AtomicBool, AtomicI64, AtomicU64, Ordering};
+use std::sync::{Arc, RwLock as StdRwLock};
+use std::time::{Duration, Instant};
+
+use chrono::Utc;
+use core_types::{
+    BookTop, CapitalUpdate, Direction, DirectionSignal, EngineEvent, EnginePnLBreakdown,
+    ExecutionStyle, ProbabilityEstimate, RefTick, Regime, ShadowOutcome, ShadowShot, Signal,
+    SourceHealth, TimeframeClass, ToxicRegime,
+};
+use dashmap::DashMap;
+use direction_detector::{DirectionConfig, DirectionDetector};
+use execution_clob::ClobExecution;
+use exit_manager::{ExitManager, ExitManagerConfig, ExitReason};
+use fair_value::BasisMrConfig;
+use infra_bus::RingBus;
+use paper_executor::ShadowExecutor;
+use portfolio::PortfolioBook;
+use probability_engine::{ProbabilityEngine, ProbabilityEngineConfig};
+use reqwest::Client;
+use risk_engine::{DefaultRiskManager, RiskLimits};
+use serde::{Deserialize, Serialize};
+use settlement_compounder::{CompounderConfig, SettlementCompounder};
+use strategy_maker::MakerConfig;
+use taker_sniper::{TakerSniper, TakerSniperConfig};
+use timeframe_router::{RouterConfig, TimeframeRouter};
+use tokio::sync::RwLock;
+
+use crate::engine_core::{is_gate_block_reason, is_policy_block_reason, is_quote_reject_reason};
+use crate::paper_runtime::PaperRuntimeHandle;
+use crate::gate_eval;
+use crate::report_io::{
+    append_jsonl, build_market_scorecard, dataset_path, fillability_ratio,
+    next_normalized_ingest_seq, survival_ratio,
+};
+use crate::seat_runtime::SeatRuntimeHandle;
+use crate::stats_utils::{
+    freshness_ms, percentile, policy_block_ratio, push_capped, quote_block_ratio, ratio_u64,
+    robust_filter_iqr,
+};
+
+#[derive(Clone)]
+pub(crate) struct AppState {
+    pub(crate) paused: Arc<RwLock<bool>>,
+    pub(crate) bus: RingBus<EngineEvent>,
+    pub(crate) portfolio: Arc<PortfolioBook>,
+    pub(crate) execution: Arc<ClobExecution>,
+    pub(crate) _shadow: Arc<ShadowExecutor>,
+    pub(crate) prometheus: metrics_exporter_prometheus::PrometheusHandle,
+    pub(crate) strategy_cfg: Arc<RwLock<Arc<MakerConfig>>>,
+    pub(crate) fair_value_cfg: Arc<StdRwLock<BasisMrConfig>>,
+    pub(crate) toxicity_cfg: Arc<RwLock<Arc<ToxicityConfig>>>,
+    pub(crate) allocator_cfg: Arc<RwLock<AllocatorConfig>>,
+    pub(crate) risk_limits: Arc<StdRwLock<RiskLimits>>,
+    pub(crate) tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
+    pub(crate) shadow_stats: Arc<ShadowStats>,
+    pub(crate) perf_profile: Arc<RwLock<PerfProfile>>,
+    pub(crate) shared: Arc<EngineShared>,
+    pub(crate) seat: Arc<SeatRuntimeHandle>,
+    pub(crate) paper: Arc<PaperRuntimeHandle>,
+}
+
+#[derive(Debug, Clone)]
+pub(crate) enum StrategyIngress {
+    RefTick(RefTick),
+    BookTop(BookTop),
+}
+
+#[derive(Debug, Clone)]
+pub(crate) struct StrategyIngressMsg {
+    pub(crate) enqueued_ns: i64,
+    pub(crate) payload: StrategyIngress,
+}
+
+#[derive(Debug, Clone)]
+pub(crate) struct FeeRateEntry {
+    pub(crate) fee_bps: f64,
+    pub(crate) fetched_at: Instant,
+}
+
+#[derive(Debug, Clone)]
+pub(crate) struct ScoringState {
+    pub(crate) rebate_bps_est: f64,
+    pub(crate) fetched_at: Instant,
+}
+
+#[derive(Debug, Clone)]
+pub(crate) struct SignalCacheEntry {
+    pub(crate) signal: Signal,
+    pub(crate) ts_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+#[serde(rename_all = "snake_case")]
+#[derive(Default)]
+pub(crate) enum PredatorCPriority {
+    MakerFirst,
+    #[default]
+    TakerFirst,
+    TakerOnly,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub(crate) struct PredatorCConfig {
+    pub(crate) enabled: bool,
+    pub(crate) priority: PredatorCPriority,
+    pub(crate) direction_detector: DirectionConfig,
+    pub(crate) probability_engine: ProbabilityEngineConfig,
+    pub(crate) taker_sniper: TakerSniperConfig,
+    pub(crate) strategy_d: PredatorDConfig,
+    pub(crate) regime: PredatorRegimeConfig,
+    pub(crate) cross_symbol: PredatorCrossSymbolConfig,
+    pub(crate) router: RouterConfig,
+    pub(crate) compounder: CompounderConfig,
+    #[serde(default)]
+    pub(crate) v52: V52Config,
+}
+
+impl Default for PredatorCConfig {
+    fn default() -> Self {
+        Self {
+            enabled: false,
+            priority: PredatorCPriority::TakerFirst,
+            direction_detector: DirectionConfig::default(),
+            probability_engine: ProbabilityEngineConfig::default(),
+            taker_sniper: TakerSniperConfig::default(),
+            strategy_d: PredatorDConfig::default(),
+            regime: PredatorRegimeConfig::default(),
+            cross_symbol: PredatorCrossSymbolConfig::default(),
+            router: RouterConfig::default(),
+            compounder: CompounderConfig::default(),
+            v52: V52Config::default(),
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub(crate) struct V52Config {
+    pub(crate) time_phase: V52TimePhaseConfig,
+    pub(crate) execution: V52ExecutionConfig,
+    pub(crate) dual_arb: V52DualArbConfig,
+    pub(crate) reversal: V52ReversalConfig,
+}
+
+impl Default for V52Config {
+    fn default() -> Self {
+        Self {
+            time_phase: V52TimePhaseConfig::default(),
+            execution: V52ExecutionConfig::default(),
+            dual_arb: V52DualArbConfig::default(),
+            reversal: V52ReversalConfig::default(),
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub(crate) struct V52TimePhaseConfig {
+    pub(crate) early_min_ratio: f64,
+    pub(crate) late_max_ratio: f64,
+    pub(crate) early_size_scale: f64,
+    pub(crate) maturity_size_scale: f64,
+    pub(crate) late_size_scale: f64,
+    pub(crate) allow_timeframes: Vec<String>,
+}
+
+impl Default for V52TimePhaseConfig {
+    fn default() -> Self {
+        Self {
+            early_min_ratio: 0.55,
+            late_max_ratio: 0.10,
+            early_size_scale: 0.80,
+            maturity_size_scale: 1.00,
+            late_size_scale: 1.25,
+            allow_timeframes: vec!["5m".to_string(), "15m".to_string()],
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub(crate) struct V52ExecutionConfig {
+    pub(crate) late_force_taker_remaining_ms: u64,
+    pub(crate) maker_wait_ms_before_force: u64,
+    pub(crate) apply_force_taker_in_maturity: bool,
+    pub(crate) apply_force_taker_in_late: bool,
+    pub(crate) alpha_window_enabled: bool,
+    pub(crate) alpha_window_move_bps: f64,
+    pub(crate) alpha_window_poll_ms: u64,
+    pub(crate) alpha_window_max_wait_ms: u64,
+    pub(crate) require_compounder_when_live: bool,
+}
+
+impl Default for V52ExecutionConfig {
+    fn default() -> Self {
+        Self {
+            late_force_taker_remaining_ms: 30_000,
+            maker_wait_ms_before_force: 800,
+            apply_force_taker_in_maturity: true,
+            apply_force_taker_in_late: true,
+            alpha_window_enabled: true,
+            alpha_window_move_bps: 3.0,
+            alpha_window_poll_ms: 10,
+            alpha_window_max_wait_ms: 1_000,
+            require_compounder_when_live: true,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub(crate) struct V52DualArbConfig {
+    pub(crate) enabled: bool,
+    pub(crate) safety_margin_bps: f64,
+    pub(crate) threshold: f64,
+    pub(crate) fee_buffer_mode: String,
+}
+
+impl Default for V52DualArbConfig {
+    fn default() -> Self {
+        Self {
+            enabled: true,
+            safety_margin_bps: 3.0,
+            threshold: 0.99,
+            fee_buffer_mode: "conservative_taker".to_string(),
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub(crate) struct V52ReversalConfig {
+    pub(crate) same_market_opposite_first: bool,
+}
+
+impl Default for V52ReversalConfig {
+    fn default() -> Self {
+        Self {
+            same_market_opposite_first: true,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub(crate) struct PredatorDConfig {
+    pub(crate) enabled: bool,
+    pub(crate) min_gap_bps: f64,
+    pub(crate) min_edge_net_bps: f64,
+    pub(crate) min_confidence: f64,
+    pub(crate) max_notional_usdc: f64,
+    pub(crate) cooldown_ms_per_market: u64,
+}
+
+impl Default for PredatorDConfig {
+    fn default() -> Self {
+        Self {
+            enabled: false,
+            min_gap_bps: 25.0,
+            min_edge_net_bps: 15.0,
+            min_confidence: 0.65,
+            max_notional_usdc: 25.0,
+            cooldown_ms_per_market: 500,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub(crate) struct PredatorRegimeConfig {
+    pub(crate) enabled: bool,
+    pub(crate) active_min_confidence: f64,
+    pub(crate) active_min_magnitude_pct: f64,
+    pub(crate) defend_tox_score: f64,
+    pub(crate) defend_on_toxic_danger: bool,
+    pub(crate) defend_min_source_health: f64,
+    pub(crate) quiet_min_edge_multiplier: f64,
+    pub(crate) quiet_chunk_scale: f64,
+}
+
+impl Default for PredatorRegimeConfig {
+    fn default() -> Self {
+        Self {
+            enabled: true,
+            active_min_confidence: 0.75,
+            active_min_magnitude_pct: 0.10,
+            defend_tox_score: 0.70,
+            defend_on_toxic_danger: true,
+            defend_min_source_health: 0.45,
+            quiet_min_edge_multiplier: 1.25,
+            quiet_chunk_scale: 0.50,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub(crate) struct PredatorCrossSymbolConfig {
+    pub(crate) enabled: bool,
+    pub(crate) leader_symbol: String,
+    pub(crate) follower_symbols: Vec<String>,
+    pub(crate) min_leader_confidence: f64,
+    pub(crate) min_leader_magnitude_pct: f64,
+    pub(crate) follower_stale_confidence_max: f64,
+    pub(crate) max_correlated_positions: usize,
+}
+
+impl Default for PredatorCrossSymbolConfig {
+    fn default() -> Self {
+        Self {
+            enabled: true,
+            leader_symbol: "BTCUSDT".to_string(),
+            follower_symbols: vec!["ETHUSDT".to_string(), "SOLUSDT".to_string()],
+            min_leader_confidence: 0.80,
+            min_leader_magnitude_pct: 0.12,
+            follower_stale_confidence_max: 0.65,
+            max_correlated_positions: 2,
+        }
+    }
+}
+
+#[derive(Clone)]
+pub(crate) struct EngineShared {
+    pub(crate) latest_books: Arc<RwLock<HashMap<String, BookTop>>>,
+    pub(crate) latest_signals: Arc<DashMap<String, SignalCacheEntry>>,
+    pub(crate) latest_fast_ticks: Arc<DashMap<String, RefTick>>,
+    pub(crate) latest_anchor_ticks: Arc<DashMap<String, RefTick>>,
+    pub(crate) market_to_symbol: Arc<RwLock<HashMap<String, String>>>,
+    pub(crate) token_to_symbol: Arc<RwLock<HashMap<String, String>>>,
+    pub(crate) market_to_timeframe: Arc<RwLock<HashMap<String, TimeframeClass>>>,
+    pub(crate) symbol_to_markets: Arc<RwLock<HashMap<String, Vec<String>>>>,
+    pub(crate) fee_cache: Arc<RwLock<HashMap<String, FeeRateEntry>>>,
+    pub(crate) fee_refresh_inflight: Arc<RwLock<HashMap<String, Instant>>>,
+    pub(crate) scoring_cache: Arc<RwLock<HashMap<String, ScoringState>>>,
+    pub(crate) http: Client,
+    pub(crate) clob_endpoint: String,
+    pub(crate) strategy_cfg: Arc<RwLock<Arc<MakerConfig>>>,
+    pub(crate) settlement_cfg: Arc<RwLock<SettlementConfig>>,
+    pub(crate) source_health_cfg: Arc<RwLock<SourceHealthConfig>>,
+    pub(crate) source_health_latest: Arc<RwLock<HashMap<String, SourceHealth>>>,
+    pub(crate) settlement_prices: Arc<RwLock<HashMap<String, f64>>>,
+    pub(crate) fusion_cfg: Arc<RwLock<FusionConfig>>,
+    pub(crate) edge_model_cfg: Arc<RwLock<EdgeModelConfig>>,
+    pub(crate) exit_cfg: Arc<RwLock<ExitConfig>>,
+    pub(crate) fair_value_cfg: Arc<StdRwLock<BasisMrConfig>>,
+    pub(crate) toxicity_cfg: Arc<RwLock<Arc<ToxicityConfig>>>,
+    pub(crate) risk_manager: Arc<DefaultRiskManager>,
+    pub(crate) risk_limits: Arc<StdRwLock<RiskLimits>>,
+    pub(crate) universe_symbols: Arc<Vec<String>>,
+    pub(crate) universe_market_types: Arc<Vec<String>>,
+    pub(crate) universe_timeframes: Arc<Vec<String>>,
+    pub(crate) rate_limit_rps: f64,
+    pub(crate) tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
+    pub(crate) shadow_stats: Arc<ShadowStats>,
+    pub(crate) predator_cfg: Arc<RwLock<PredatorCConfig>>,
+    pub(crate) predator_direction_detector: Arc<RwLock<DirectionDetector>>,
+    pub(crate) predator_latest_direction: Arc<RwLock<HashMap<String, DirectionSignal>>>,
+    pub(crate) predator_latest_probability: Arc<RwLock<HashMap<String, ProbabilityEstimate>>>,
+    pub(crate) predator_probability_engine: Arc<RwLock<ProbabilityEngine>>,
+    pub(crate) predator_taker_sniper: Arc<RwLock<TakerSniper>>,
+    pub(crate) predator_d_last_fire_ms: Arc<RwLock<HashMap<String, i64>>>,
+    pub(crate) predator_router: Arc<RwLock<TimeframeRouter>>,
+    pub(crate) predator_compounder: Arc<RwLock<SettlementCompounder>>,
+    pub(crate) predator_exit_manager: Arc<RwLock<ExitManager>>,
+    /// WSS User Channel fill broadcaster â€” None in paper mode
+    pub(crate) wss_fill_tx:
+        Option<Arc<tokio::sync::broadcast::Sender<execution_clob::wss_user_feed::WssFillEvent>>>,
+}
+
+#[derive(Serialize)]
+pub(crate) struct HealthResp {
+    pub(crate) status: &'static str,
+    pub(crate) paused: bool,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct StrategyReloadReq {
+    pub(crate) min_edge_bps: Option<f64>,
+    pub(crate) ttl_ms: Option<u64>,
+    pub(crate) inventory_skew: Option<f64>,
+    pub(crate) base_quote_size: Option<f64>,
+    pub(crate) max_spread: Option<f64>,
+    pub(crate) basis_k_revert: Option<f64>,
+    pub(crate) basis_z_cap: Option<f64>,
+    pub(crate) basis_min_confidence: Option<f64>,
+    pub(crate) taker_trigger_bps: Option<f64>,
+    pub(crate) taker_max_slippage_bps: Option<f64>,
+    pub(crate) stale_tick_filter_ms: Option<f64>,
+    pub(crate) market_tier_profile: Option<String>,
+    pub(crate) capital_fraction_kelly: Option<f64>,
+    pub(crate) variance_penalty_lambda: Option<f64>,
+    pub(crate) min_eval_notional_usdc: Option<f64>,
+    pub(crate) min_expected_edge_usdc: Option<f64>,
+    pub(crate) v52: Option<V52Config>,
+    pub(crate) v52_time_phase: Option<V52TimePhaseConfig>,
+    pub(crate) v52_execution: Option<V52ExecutionConfig>,
+    pub(crate) v52_dual_arb: Option<V52DualArbConfig>,
+    pub(crate) v52_reversal: Option<V52ReversalConfig>,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct FusionReloadReq {
+    pub(crate) enable_udp: Option<bool>,
+    pub(crate) mode: Option<String>,
+    pub(crate) udp_port: Option<u16>,
+    pub(crate) dedupe_window_ms: Option<i64>,
+    pub(crate) dedupe_price_bps: Option<f64>,
+    pub(crate) udp_share_cap: Option<f64>,
+    pub(crate) jitter_threshold_ms: Option<f64>,
+    pub(crate) fallback_arm_duration_ms: Option<u64>,
+    pub(crate) fallback_cooldown_sec: Option<u64>,
+    pub(crate) udp_local_only: Option<bool>,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct EdgeModelReloadReq {
+    pub(crate) model: Option<String>,
+    pub(crate) gate_mode: Option<String>,
+    pub(crate) version: Option<String>,
+    pub(crate) base_gate_bps: Option<f64>,
+    pub(crate) congestion_penalty_bps: Option<f64>,
+    pub(crate) latency_penalty_bps: Option<f64>,
+    pub(crate) fail_cost_bps: Option<f64>,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct ProbabilityReloadReq {
+    pub(crate) momentum_gain: Option<f64>,
+    pub(crate) lag_penalty_per_ms: Option<f64>,
+    pub(crate) confidence_floor: Option<f64>,
+    pub(crate) sigma_annual: Option<f64>,
+    pub(crate) horizon_sec: Option<f64>,
+    pub(crate) drift_annual: Option<f64>,
+    pub(crate) velocity_drift_gain: Option<f64>,
+    pub(crate) acceleration_drift_gain: Option<f64>,
+    pub(crate) fair_blend_weight: Option<f64>,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct SourceHealthReloadReq {
+    pub(crate) min_samples: Option<u64>,
+    pub(crate) gap_window_ms: Option<i64>,
+    pub(crate) jitter_limit_ms: Option<f64>,
+    pub(crate) deviation_limit_bps: Option<f64>,
+    pub(crate) freshness_limit_ms: Option<f64>,
+    pub(crate) min_score_for_trading: Option<f64>,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct ExitReloadReq {
+    pub(crate) enabled: Option<bool>,
+    pub(crate) t100ms_reversal_bps: Option<f64>,
+    pub(crate) t300ms_reversal_bps: Option<f64>,
+    pub(crate) convergence_exit_ratio: Option<f64>,
+    pub(crate) time_stop_ms: Option<u64>,
+    pub(crate) edge_decay_bps: Option<f64>,
+    pub(crate) adverse_move_bps: Option<f64>,
+    pub(crate) flatten_on_trigger: Option<bool>,
+    pub(crate) t3_take_ratio: Option<f64>,
+    pub(crate) t15_min_unrealized_usdc: Option<f64>,
+    pub(crate) t60_true_prob_floor: Option<f64>,
+    pub(crate) t300_force_exit_ms: Option<u64>,
+    pub(crate) t300_hold_prob_threshold: Option<f64>,
+    pub(crate) t300_hold_time_to_expiry_ms: Option<u64>,
+    pub(crate) max_single_trade_loss_usdc: Option<f64>,
+}
+
+#[derive(Debug, Serialize)]
+pub(crate) struct StrategyReloadResp {
+    pub(crate) maker: MakerConfig,
+    pub(crate) fair_value: BasisMrConfig,
+    pub(crate) v52: V52Config,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct RiskReloadReq {
+    pub(crate) max_market_notional: Option<f64>,
+    pub(crate) max_asset_notional: Option<f64>,
+    pub(crate) max_open_orders: Option<usize>,
+    pub(crate) daily_drawdown_cap_pct: Option<f64>,
+    pub(crate) max_loss_streak: Option<u32>,
+    pub(crate) cooldown_sec: Option<u64>,
+    pub(crate) progressive_enabled: Option<bool>,
+    pub(crate) drawdown_tier1_ratio: Option<f64>,
+    pub(crate) drawdown_tier2_ratio: Option<f64>,
+    pub(crate) tier1_size_scale: Option<f64>,
+    pub(crate) tier2_size_scale: Option<f64>,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct TakerReloadReq {
+    pub(crate) trigger_bps: Option<f64>,
+    pub(crate) max_slippage_bps: Option<f64>,
+    pub(crate) stale_tick_filter_ms: Option<f64>,
+    pub(crate) market_tier_profile: Option<String>,
+}
+
+#[derive(Debug, Serialize)]
+pub(crate) struct TakerReloadResp {
+    pub(crate) trigger_bps: f64,
+    pub(crate) max_slippage_bps: f64,
+    pub(crate) stale_tick_filter_ms: f64,
+    pub(crate) market_tier_profile: String,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct AllocatorReloadReq {
+    pub(crate) capital_fraction_kelly: Option<f64>,
+    pub(crate) variance_penalty_lambda: Option<f64>,
+    pub(crate) active_top_n_markets: Option<usize>,
+    pub(crate) taker_weight: Option<f64>,
+    pub(crate) maker_weight: Option<f64>,
+    pub(crate) arb_weight: Option<f64>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct AllocatorConfig {
+    pub(crate) capital_fraction_kelly: f64,
+    pub(crate) variance_penalty_lambda: f64,
+    pub(crate) active_top_n_markets: usize,
+    pub(crate) taker_weight: f64,
+    pub(crate) maker_weight: f64,
+    pub(crate) arb_weight: f64,
+}
+
+impl Default for AllocatorConfig {
+    fn default() -> Self {
+        Self {
+            capital_fraction_kelly: 0.35,
+            variance_penalty_lambda: 0.25,
+            active_top_n_markets: 8,
+            taker_weight: 0.7,
+            maker_weight: 0.2,
+            arb_weight: 0.1,
+        }
+    }
+}
+
+#[derive(Debug, Serialize)]
+pub(crate) struct AllocatorReloadResp {
+    pub(crate) allocator: AllocatorConfig,
+}
+
+#[derive(Debug, Serialize)]
+pub(crate) struct RiskReloadResp {
+    pub(crate) risk: RiskLimits,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct ToxicityReloadReq {
+    pub(crate) safe_threshold: Option<f64>,
+    pub(crate) caution_threshold: Option<f64>,
+    pub(crate) cooldown_min_sec: Option<u64>,
+    pub(crate) cooldown_max_sec: Option<u64>,
+    pub(crate) min_market_score: Option<f64>,
+    pub(crate) active_top_n_markets: Option<usize>,
+    pub(crate) markout_1s_caution_bps: Option<f64>,
+    pub(crate) markout_5s_caution_bps: Option<f64>,
+    pub(crate) markout_10s_caution_bps: Option<f64>,
+    pub(crate) markout_1s_danger_bps: Option<f64>,
+    pub(crate) markout_5s_danger_bps: Option<f64>,
+    pub(crate) markout_10s_danger_bps: Option<f64>,
+}
+
+#[derive(Debug, Deserialize)]
+pub(crate) struct PerfProfileReloadReq {
+    pub(crate) tail_guard: Option<f64>,
+    pub(crate) io_flush_batch: Option<usize>,
+    pub(crate) io_queue_capacity: Option<usize>,
+    pub(crate) json_mode: Option<String>,
+    pub(crate) io_drop_on_full: Option<bool>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct FusionConfig {
+    pub(crate) enable_udp: bool,
+    pub(crate) mode: String,
+    pub(crate) udp_port: u16,
+    pub(crate) dedupe_window_ms: i64,
+    pub(crate) dedupe_price_bps: f64,
+    pub(crate) udp_share_cap: f64,
+    pub(crate) jitter_threshold_ms: f64,
+    pub(crate) fallback_arm_duration_ms: u64,
+    pub(crate) fallback_cooldown_sec: u64,
+    pub(crate) udp_local_only: bool,
+}
+
+impl Default for FusionConfig {
+    fn default() -> Self {
+        Self {
+            enable_udp: true,
+            mode: "direct_only".to_string(),
+            udp_port: 6666,
+            dedupe_window_ms: 120,
+            dedupe_price_bps: 0.2,
+            udp_share_cap: 0.35,
+            jitter_threshold_ms: 25.0,
+            fallback_arm_duration_ms: 8_000,
+            fallback_cooldown_sec: 300,
+            udp_local_only: true,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct EdgeModelConfig {
+    pub(crate) model: String,
+    pub(crate) gate_mode: String,
+    pub(crate) version: String,
+    pub(crate) base_gate_bps: f64,
+    pub(crate) congestion_penalty_bps: f64,
+    pub(crate) latency_penalty_bps: f64,
+    pub(crate) fail_cost_bps: f64,
+}
+
+impl Default for EdgeModelConfig {
+    fn default() -> Self {
+        Self {
+            model: "ev_net".to_string(),
+            gate_mode: "dynamic".to_string(),
+            version: "v2-ev-net".to_string(),
+            base_gate_bps: 0.0,
+            congestion_penalty_bps: 2.0,
+            latency_penalty_bps: 2.0,
+            fail_cost_bps: 1.0,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct ExitConfig {
+    pub(crate) enabled: bool,
+    pub(crate) t100ms_reversal_bps: f64,
+    pub(crate) t300ms_reversal_bps: f64,
+    pub(crate) convergence_exit_ratio: f64,
+    pub(crate) time_stop_ms: u64,
+    pub(crate) edge_decay_bps: f64,
+    pub(crate) adverse_move_bps: f64,
+    pub(crate) flatten_on_trigger: bool,
+    pub(crate) t3_take_ratio: f64,
+    pub(crate) t15_min_unrealized_usdc: f64,
+    pub(crate) t60_true_prob_floor: f64,
+    pub(crate) t300_force_exit_ms: u64,
+    pub(crate) t300_hold_prob_threshold: f64,
+    pub(crate) t300_hold_time_to_expiry_ms: u64,
+    pub(crate) max_single_trade_loss_usdc: f64,
+}
+
+impl Default for ExitConfig {
+    fn default() -> Self {
+        Self {
+            enabled: true,
+            t100ms_reversal_bps: -3.0,
+            t300ms_reversal_bps: -2.0,
+            convergence_exit_ratio: 0.85,
+            time_stop_ms: 300_000,
+            edge_decay_bps: -2.0,
+            adverse_move_bps: -8.0,
+            flatten_on_trigger: true,
+            t3_take_ratio: 0.60,
+            t15_min_unrealized_usdc: 0.0,
+            t60_true_prob_floor: 0.70,
+            t300_force_exit_ms: 300_000,
+            t300_hold_prob_threshold: 0.95,
+            t300_hold_time_to_expiry_ms: 300_000,
+            max_single_trade_loss_usdc: 1.0,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SettlementConfig {
+    pub(crate) enabled: bool,
+    pub(crate) endpoint: String,
+    pub(crate) required_for_live: bool,
+    pub(crate) poll_interval_ms: u64,
+    pub(crate) timeout_ms: u64,
+    pub(crate) symbols: Vec<String>,
+}
+
+impl Default for SettlementConfig {
+    fn default() -> Self {
+        Self {
+            enabled: true,
+            endpoint: String::new(),
+            required_for_live: true,
+            poll_interval_ms: 1_000,
+            timeout_ms: 800,
+            symbols: vec![
+                "BTCUSDT".to_string(),
+                "ETHUSDT".to_string(),
+                "SOLUSDT".to_string(),
+                "XRPUSDT".to_string(),
+            ],
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize)]
+pub(crate) struct LiveGateStatus {
+    pub(crate) ready: bool,
+    pub(crate) reason: String,
+}
+
+pub(crate) fn settlement_live_gate_status(cfg: &SettlementConfig) -> LiveGateStatus {
+    if !cfg.required_for_live {
+        return LiveGateStatus {
+            ready: true,
+            reason: "settlement_required_for_live_disabled".to_string(),
+        };
+    }
+    if !cfg.enabled {
+        return LiveGateStatus {
+            ready: false,
+            reason: "settlement_feed_disabled".to_string(),
+        };
+    }
+    if cfg.endpoint.trim().is_empty() {
+        return LiveGateStatus {
+            ready: false,
+            reason: "settlement_endpoint_empty".to_string(),
+        };
+    }
+    LiveGateStatus {
+        ready: true,
+        reason: "ok".to_string(),
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct SourceHealthConfig {
+    pub(crate) min_samples: u64,
+    pub(crate) gap_window_ms: i64,
+    pub(crate) jitter_limit_ms: f64,
+    pub(crate) deviation_limit_bps: f64,
+    pub(crate) freshness_limit_ms: f64,
+    pub(crate) min_score_for_trading: f64,
+}
+
+impl Default for SourceHealthConfig {
+    fn default() -> Self {
+        Self {
+            min_samples: 64,
+            gap_window_ms: 2_000,
+            jitter_limit_ms: 12.0,
+            deviation_limit_bps: 30.0,
+            freshness_limit_ms: 2_000.0,
+            min_score_for_trading: 0.45,
+        }
+    }
+}
+
+pub(crate) fn to_exit_manager_config(cfg: &ExitConfig) -> ExitManagerConfig {
+    ExitManagerConfig {
+        t100ms_reversal_bps: cfg.t100ms_reversal_bps,
+        t300ms_reversal_bps: cfg.t300ms_reversal_bps,
+        convergence_exit_ratio: cfg.convergence_exit_ratio.clamp(0.0, 1.0),
+        t3_take_ratio: cfg.t3_take_ratio.clamp(0.0, 5.0),
+        t15_min_unrealized_usdc: cfg.t15_min_unrealized_usdc,
+        t60_true_prob_floor: cfg.t60_true_prob_floor.clamp(0.0, 1.0),
+        t300_force_exit_ms: cfg.t300_force_exit_ms.max(1_000),
+        t300_hold_prob_threshold: cfg.t300_hold_prob_threshold.clamp(0.0, 1.0),
+        t300_hold_time_to_expiry_ms: cfg.t300_hold_time_to_expiry_ms.max(1_000),
+        max_single_trade_loss_usdc: cfg.max_single_trade_loss_usdc.max(0.0),
+    }
+}
+
+pub(crate) fn exit_reason_label(reason: ExitReason) -> &'static str {
+    match reason {
+        ExitReason::StopLoss => "stop_loss",
+        ExitReason::Reversal100ms => "t_plus_100ms_reversal",
+        ExitReason::Reversal300ms => "t_plus_300ms_reversal",
+        // ä»·æ ¼æ”¶æ•›åˆ°å…¬å…ä»·å€¼ 85%+ï¼Œå¥—åˆ©åˆ©æ¶¦å·²åƒæ»¡
+        ExitReason::ConvergenceExit => "convergence_exit",
+        ExitReason::TakeProfit3s => "t_plus_3s",
+        ExitReason::TakeProfit15s => "t_plus_15s",
+        ExitReason::ProbGuard60s => "t_plus_60s_prob_guard",
+        ExitReason::ForceClose300s => "t_plus_300s_force",
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct ExecutionConfig {
+    pub(crate) mode: String,
+    pub(crate) rate_limit_rps: f64,
+    pub(crate) http_timeout_ms: u64,
+    pub(crate) clob_endpoint: String,
+    #[serde(default)]
+    pub(crate) order_endpoint: Option<String>,
+    #[serde(default)]
+    pub(crate) order_backup_endpoint: Option<String>,
+    #[serde(default)]
+    pub(crate) order_failover_timeout_ms: u64,
+}
+
+impl Default for ExecutionConfig {
+    fn default() -> Self {
+        Self {
+            mode: "paper".to_string(),
+            rate_limit_rps: 15.0,
+            http_timeout_ms: 3000,
+            clob_endpoint: "https://clob.polymarket.com".to_string(),
+            order_endpoint: None,
+            order_backup_endpoint: None,
+            order_failover_timeout_ms: 200,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct PerfProfile {
+    pub(crate) tail_guard: f64,
+    pub(crate) io_flush_batch: usize,
+    pub(crate) io_queue_capacity: usize,
+    pub(crate) json_mode: String,
+    pub(crate) io_drop_on_full: bool,
+}
+
+impl Default for PerfProfile {
+    fn default() -> Self {
+        Self {
+            tail_guard: 0.99,
+            io_flush_batch: 64,
+            io_queue_capacity: 16_384,
+            json_mode: "typed".to_string(),
+            io_drop_on_full: true,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub(crate) struct ToxicityConfig {
+    pub(crate) w1: f64,
+    pub(crate) w2: f64,
+    pub(crate) w3: f64,
+    pub(crate) w4: f64,
+    pub(crate) w5: f64,
+    pub(crate) w6: f64,
+    pub(crate) safe_threshold: f64,
+    pub(crate) caution_threshold: f64,
+    pub(crate) k_spread: f64,
+    pub(crate) cooldown_min_sec: u64,
+    pub(crate) cooldown_max_sec: u64,
+    pub(crate) min_market_score: f64,
+    pub(crate) active_top_n_markets: usize,
+    pub(crate) markout_1s_caution_bps: f64,
+    pub(crate) markout_5s_caution_bps: f64,
+    pub(crate) markout_10s_caution_bps: f64,
+    pub(crate) markout_1s_danger_bps: f64,
+    pub(crate) markout_5s_danger_bps: f64,
+    pub(crate) markout_10s_danger_bps: f64,
+}
+
+impl Default for ToxicityConfig {
+    fn default() -> Self {
+        Self {
+            w1: 0.30,
+            w2: 0.25,
+            w3: 0.20,
+            w4: 0.10,
+            w5: 0.10,
+            w6: 0.05,
+            safe_threshold: 0.35,
+            caution_threshold: 0.65,
+            k_spread: 1.5,
+            cooldown_min_sec: 30,
+            cooldown_max_sec: 120,
+            min_market_score: 70.0,
+            active_top_n_markets: 8,
+            markout_1s_caution_bps: -4.0,
+            markout_5s_caution_bps: -6.0,
+            markout_10s_caution_bps: -8.0,
+            markout_1s_danger_bps: -10.0,
+            markout_5s_danger_bps: -14.0,
+            markout_10s_danger_bps: -18.0,
+        }
+    }
+}
+
+#[derive(Debug, Clone)]
+pub(crate) struct MarketToxicState {
+    pub(crate) symbol: String,
+    pub(crate) markout_1s: VecDeque<f64>,
+    pub(crate) markout_5s: VecDeque<f64>,
+    pub(crate) markout_10s: VecDeque<f64>,
+    pub(crate) attempted: u64,
+    pub(crate) no_quote: u64,
+    pub(crate) symbol_missing: u64,
+    pub(crate) last_tox_score: f64,
+    pub(crate) last_regime: ToxicRegime,
+    pub(crate) market_score: f64,
+    pub(crate) cooldown_until_ms: i64,
+}
+
+impl Default for MarketToxicState {
+    fn default() -> Self {
+        Self {
+            symbol: String::new(),
+            markout_1s: VecDeque::new(),
+            markout_5s: VecDeque::new(),
+            markout_10s: VecDeque::new(),
+            attempted: 0,
+            no_quote: 0,
+            symbol_missing: 0,
+            last_tox_score: 0.0,
+            last_regime: ToxicRegime::Safe,
+            market_score: 80.0,
+            cooldown_until_ms: 0,
+        }
+    }
+}
+
+#[derive(Debug, Serialize, Clone)]
+pub(crate) struct ToxicityMarketRow {
+    pub(crate) market_rank: usize,
+    pub(crate) market_id: String,
+    pub(crate) symbol: String,
+    pub(crate) tox_score: f64,
+    pub(crate) regime: ToxicRegime,
+    pub(crate) market_score: f64,
+    pub(crate) markout_10s_bps: f64,
+    pub(crate) no_quote_rate: f64,
+    pub(crate) symbol_missing_rate: f64,
+    pub(crate) pending_exposure: f64,
+    pub(crate) active_for_quoting: bool,
+}
+
+#[derive(Debug, Serialize)]
+pub(crate) struct ToxicityLiveReport {
+    pub(crate) ts_ms: i64,
+    pub(crate) average_tox_score: f64,
+    pub(crate) safe_count: usize,
+    pub(crate) caution_count: usize,
+    pub(crate) danger_count: usize,
+    pub(crate) rows: Vec<ToxicityMarketRow>,
+}
+
+#[derive(Debug, Serialize)]
+pub(crate) struct ToxicityFinalReport {
+    pub(crate) pass: bool,
+    pub(crate) failed_reasons: Vec<String>,
+    pub(crate) live: ToxicityLiveReport,
+}
+
+#[derive(Debug, Serialize)]
+pub(crate) struct GateEvaluation {
+    pub(crate) window_id: u64,
+    pub(crate) gate_ready: bool,
+    pub(crate) min_outcomes: usize,
+    pub(crate) pass: bool,
+    pub(crate) data_valid_ratio: f64,
+    pub(crate) seq_gap_rate: f64,
+    pub(crate) ts_inversion_rate: f64,
+    pub(crate) stale_tick_drop_ratio: f64,
+    pub(crate) fillability_10ms: f64,
+    pub(crate) net_edge_p50_bps: f64,
+    pub(crate) net_edge_p10_bps: f64,
+    pub(crate) net_markout_10s_usdc_p50: f64,
+    pub(crate) roi_notional_10s_bps_p50: f64,
+    pub(crate) pnl_10s_p50_bps_raw: f64,
+    pub(crate) pnl_10s_p50_bps_robust: f64,
+    pub(crate) pnl_10s_sample_count: usize,
+    pub(crate) pnl_10s_outlier_ratio: f64,
+    pub(crate) eligible_count: u64,
+    pub(crate) executed_count: u64,
+    pub(crate) executed_over_eligible: f64,
+    pub(crate) ev_net_usdc_p50: f64,
+    pub(crate) ev_net_usdc_p10: f64,
+    pub(crate) ev_positive_ratio: f64,
+    pub(crate) quote_block_ratio: f64,
+    pub(crate) policy_block_ratio: f64,
+    pub(crate) gate_blocked: u64,
+    pub(crate) gate_block_ratio: f64,
+    pub(crate) strategy_uptime_pct: f64,
+    pub(crate) tick_to_ack_p99_ms: f64,
+    pub(crate) decision_queue_wait_p99_ms: f64,
+    pub(crate) decision_compute_p99_ms: f64,
+    pub(crate) source_latency_p99_ms: f64,
+    pub(crate) exchange_lag_p99_ms: f64,
+    pub(crate) path_lag_p99_ms: f64,
+    pub(crate) local_backlog_p99_ms: f64,
+    pub(crate) failed_reasons: Vec<String>,
+}
+
+#[derive(Debug, Serialize, Clone, Default)]
+pub(crate) struct LatencyBreakdown {
+    pub(crate) feed_in_p50_ms: f64,
+    pub(crate) feed_in_p90_ms: f64,
+    pub(crate) feed_in_p99_ms: f64,
+    pub(crate) signal_p50_us: f64,
+    pub(crate) signal_p90_us: f64,
+    pub(crate) signal_p99_us: f64,
+    pub(crate) quote_p50_us: f64,
+    pub(crate) quote_p90_us: f64,
+    pub(crate) quote_p99_us: f64,
+    pub(crate) risk_p50_us: f64,
+    pub(crate) risk_p90_us: f64,
+    pub(crate) risk_p99_us: f64,
+    pub(crate) decision_queue_wait_p50_ms: f64,
+    pub(crate) decision_queue_wait_p90_ms: f64,
+    pub(crate) decision_queue_wait_p99_ms: f64,
+    pub(crate) decision_compute_p50_ms: f64,
+    pub(crate) decision_compute_p90_ms: f64,
+    pub(crate) decision_compute_p99_ms: f64,
+    pub(crate) tick_to_decision_p50_ms: f64,
+    pub(crate) tick_to_decision_p90_ms: f64,
+    pub(crate) tick_to_decision_p99_ms: f64,
+    pub(crate) ack_only_p50_ms: f64,
+    pub(crate) ack_only_p90_ms: f64,
+    pub(crate) ack_only_p99_ms: f64,
+    pub(crate) tick_to_ack_p50_ms: f64,
+    pub(crate) tick_to_ack_p90_ms: f64,
+    pub(crate) tick_to_ack_p99_ms: f64,
+    pub(crate) parse_p99_us: f64,
+    pub(crate) io_queue_p99_ms: f64,
+    pub(crate) bus_lag_p99_ms: f64,
+    pub(crate) shadow_fill_p50_ms: f64,
+    pub(crate) shadow_fill_p90_ms: f64,
+    pub(crate) shadow_fill_p99_ms: f64,
+    pub(crate) source_latency_p50_ms: f64,
+    pub(crate) source_latency_p90_ms: f64,
+    pub(crate) source_latency_p99_ms: f64,
+    pub(crate) exchange_lag_p50_ms: f64,
+    pub(crate) exchange_lag_p90_ms: f64,
+    pub(crate) exchange_lag_p99_ms: f64,
+    pub(crate) path_lag_p50_ms: f64,
+    pub(crate) path_lag_p90_ms: f64,
+    pub(crate) path_lag_p99_ms: f64,
+    pub(crate) path_lag_coverage_ratio: f64,
+    pub(crate) book_latency_p50_ms: f64,
+    pub(crate) book_latency_p90_ms: f64,
+    pub(crate) book_latency_p99_ms: f64,
+    pub(crate) local_backlog_p50_ms: f64,
+    pub(crate) local_backlog_p90_ms: f64,
+    pub(crate) local_backlog_p99_ms: f64,
+    pub(crate) ref_decode_p50_ms: f64,
+    pub(crate) ref_decode_p90_ms: f64,
+    pub(crate) ref_decode_p99_ms: f64,
+    /// `book_top_lag_ms` distribution *for the same primary-delay executed shots* that have a
+    /// measured `ack_only_ms` (i.e. same sample set as capturable_window).
+    pub(crate) book_top_lag_at_ack_p50_ms: f64,
+    pub(crate) book_top_lag_at_ack_p90_ms: f64,
+    pub(crate) book_top_lag_at_ack_p99_ms: f64,
+    pub(crate) book_top_lag_at_ack_n: u64,
+    pub(crate) capturable_window_p50_ms: f64,
+    pub(crate) capturable_window_p75_ms: f64,
+    pub(crate) capturable_window_p90_ms: f64,
+    pub(crate) capturable_window_p99_ms: f64,
+    pub(crate) alpha_window_p50_ms: f64,
+    pub(crate) alpha_window_p90_ms: f64,
+    pub(crate) alpha_window_p99_ms: f64,
+    pub(crate) alpha_window_hit_ratio: f64,
+    pub(crate) alpha_window_n: u64,
+    /// Ratio of samples where capturable_window_ms > 0.0.
+    pub(crate) profitable_window_ratio: f64,
+    /// Number of capturable window samples included in the distribution.
+    pub(crate) capturable_window_n: u64,
+    /// Number of ack_only_ms samples (only meaningful in live execution).
+    pub(crate) ack_only_n: u64,
+    /// Number of tick_to_ack_ms samples.
+    pub(crate) tick_to_ack_n: u64,
+}
+
+#[derive(Debug, Serialize)]
+pub(crate) struct ShadowLiveReport {
+    pub(crate) window_id: u64,
+    pub(crate) window_shots: usize,
+    pub(crate) window_outcomes: usize,
+    // Backward-compatible strict gate bit used by existing risk/optimizer scripts.
+    pub(crate) gate_ready: bool,
+    // Explicit strict/effective split to avoid semantic ambiguity in external audits.
+    pub(crate) gate_ready_strict: bool,
+    pub(crate) gate_ready_effective: bool,
+    pub(crate) gate_fail_reasons: Vec<String>,
+    pub(crate) observe_only: bool,
+    pub(crate) started_at_ms: i64,
+    pub(crate) elapsed_sec: u64,
+    pub(crate) total_shots: usize,
+    pub(crate) total_outcomes: usize,
+    pub(crate) data_valid_ratio: f64,
+    pub(crate) seq_gap_rate: f64,
+    pub(crate) ts_inversion_rate: f64,
+    pub(crate) stale_tick_drop_ratio: f64,
+    pub(crate) quote_attempted: u64,
+    pub(crate) quote_blocked: u64,
+    pub(crate) policy_blocked: u64,
+    pub(crate) fillability_5ms: f64,
+    pub(crate) fillability_10ms: f64,
+    pub(crate) fillability_25ms: f64,
+    pub(crate) survival_5ms: f64,
+    pub(crate) survival_10ms: f64,
+    pub(crate) survival_25ms: f64,
+    // Survival probe is an "orderless" latency-arb competitiveness metric:
+    // at T0 we observe a crossable top-of-book price, then check at +Î” whether
+    // it is still crossable. This intentionally does not depend on order acks.
+    pub(crate) survival_probe_5ms: f64,
+    pub(crate) survival_probe_10ms: f64,
+    pub(crate) survival_probe_25ms: f64,
+    pub(crate) survival_probe_5ms_n: u64,
+    pub(crate) survival_probe_10ms_n: u64,
+    pub(crate) survival_probe_25ms_n: u64,
+    pub(crate) net_edge_p50_bps: f64,
+    pub(crate) net_edge_p10_bps: f64,
+    pub(crate) pnl_1s_p50_bps: f64,
+    pub(crate) pnl_5s_p50_bps: f64,
+    pub(crate) pnl_10s_p50_bps: f64,
+    pub(crate) pnl_10s_p50_bps_raw: f64,
+    pub(crate) pnl_10s_p50_bps_robust: f64,
+    pub(crate) net_markout_10s_usdc_p50: f64,
+    pub(crate) roi_notional_10s_bps_p50: f64,
+    pub(crate) pnl_10s_sample_count: usize,
+    pub(crate) pnl_10s_outlier_ratio: f64,
+    pub(crate) eligible_count: u64,
+    pub(crate) executed_count: u64,
+    pub(crate) executed_over_eligible: f64,
+    pub(crate) ev_net_usdc_p50: f64,
+    pub(crate) ev_net_usdc_p10: f64,
+    pub(crate) ev_positive_ratio: f64,
+    pub(crate) quote_block_ratio: f64,
+    pub(crate) policy_block_ratio: f64,
+    pub(crate) gate_blocked: u64,
+    pub(crate) gate_block_ratio: f64,
+    pub(crate) queue_depth_p99: f64,
+    pub(crate) event_backlog_p99: f64,
+    pub(crate) tick_to_decision_p50_ms: f64,
+    pub(crate) tick_to_decision_p90_ms: f64,
+    pub(crate) tick_to_decision_p99_ms: f64,
+    pub(crate) decision_queue_wait_p99_ms: f64,
+    pub(crate) decision_compute_p99_ms: f64,
+    pub(crate) source_latency_p99_ms: f64,
+    pub(crate) exchange_lag_p99_ms: f64,
+    pub(crate) path_lag_p99_ms: f64,
+    pub(crate) local_backlog_p99_ms: f64,
+    pub(crate) lag_half_life_ms: f64,
+    pub(crate) probability_total: u64,
+    pub(crate) settlement_source_degraded_ratio: f64,
+    pub(crate) settle_fast_delta_p50_bps: f64,
+    pub(crate) settle_fast_delta_p90_bps: f64,
+    pub(crate) probability_confidence_p50: f64,
+    pub(crate) ack_only_p50_ms: f64,
+    pub(crate) ack_only_p90_ms: f64,
+    pub(crate) ack_only_p99_ms: f64,
+    pub(crate) alpha_window_p50_ms: f64,
+    pub(crate) alpha_window_p90_ms: f64,
+    pub(crate) alpha_window_p99_ms: f64,
+    pub(crate) alpha_window_hit_ratio: f64,
+    pub(crate) alpha_window_n: u64,
+    pub(crate) strategy_uptime_pct: f64,
+    pub(crate) tick_to_ack_p99_ms: f64,
+    pub(crate) ref_ticks_total: u64,
+    pub(crate) book_ticks_total: u64,
+    pub(crate) ref_freshness_ms: i64,
+    pub(crate) book_freshness_ms: i64,
+    pub(crate) book_top_lag_p50_ms: f64,
+    pub(crate) book_top_lag_p90_ms: f64,
+    pub(crate) book_top_lag_p99_ms: f64,
+    pub(crate) book_top_lag_by_symbol_p50_ms: HashMap<String, f64>,
+    pub(crate) survival_10ms_by_symbol: HashMap<String, f64>,
+    pub(crate) survival_probe_10ms_by_symbol: HashMap<String, f64>,
+    pub(crate) blocked_reason_counts: HashMap<String, u64>,
+    pub(crate) policy_block_reason_distribution: HashMap<String, u64>,
+    pub(crate) gate_block_reason_distribution: HashMap<String, u64>,
+    pub(crate) source_mix_ratio: HashMap<String, f64>,
+    pub(crate) udp_share_effective: f64,
+    pub(crate) udp_local_drop_count: u64,
+    pub(crate) share_cap_drop_count: u64,
+    pub(crate) fallback_state: String,
+    pub(crate) fallback_trigger_reason_distribution: HashMap<String, u64>,
+    pub(crate) source_health: Vec<SourceHealth>,
+    pub(crate) exit_reason_top: Vec<(String, u64)>,
+    pub(crate) edge_model_version: String,
+    pub(crate) latency: LatencyBreakdown,
+    pub(crate) market_scorecard: Vec<MarketScoreRow>,
+    pub(crate) predator_c_enabled: bool,
+    pub(crate) direction_signals_up: u64,
+    pub(crate) direction_signals_down: u64,
+    pub(crate) direction_signals_neutral: u64,
+    pub(crate) taker_sniper_fired: u64,
+    pub(crate) taker_sniper_skipped: u64,
+    pub(crate) predator_regime_active: u64,
+    pub(crate) predator_regime_quiet: u64,
+    pub(crate) predator_regime_defend: u64,
+    pub(crate) predator_cross_symbol_fired: u64,
+    pub(crate) taker_sniper_skip_reasons_top: Vec<(String, u64)>,
+    pub(crate) last_30s_taker_fallback_count: u64,
+    pub(crate) router_locked_by_tf_usdc: HashMap<String, f64>,
+    pub(crate) capital_available_usdc: f64,
+    pub(crate) capital_base_quote_size: f64,
+    pub(crate) capital_halt: bool,
+}
+
+#[derive(Debug, Serialize)]
+pub(crate) struct ShadowFinalReport {
+    pub(crate) live: ShadowLiveReport,
+    pub(crate) gate: GateEvaluation,
+}
+
+#[derive(Debug, Serialize, Clone)]
+pub(crate) struct EnginePnlRow {
+    pub(crate) engine: String,
+    pub(crate) samples: usize,
+    pub(crate) total_usdc: f64,
+    pub(crate) p50_usdc: f64,
+    pub(crate) p10_usdc: f64,
+    pub(crate) positive_ratio: f64,
+}
+
+#[derive(Debug, Serialize, Clone)]
+pub(crate) struct EnginePnlReport {
+    pub(crate) window_id: u64,
+    pub(crate) breakdown: EnginePnLBreakdown,
+    pub(crate) rows: Vec<EnginePnlRow>,
+}
+
+#[derive(Debug, Serialize, Clone)]
+pub(crate) struct MarketScoreRow {
+    pub(crate) market_id: String,
+    pub(crate) symbol: String,
+    pub(crate) shots: usize,
+    pub(crate) outcomes: usize,
+    pub(crate) fillability_10ms: f64,
+    pub(crate) net_edge_p50_bps: f64,
+    pub(crate) net_edge_p10_bps: f64,
+    pub(crate) pnl_10s_p50_bps: f64,
+    pub(crate) net_markout_10s_usdc_p50: f64,
+    pub(crate) roi_notional_10s_bps_p50: f64,
+}
+
+#[derive(Debug, Clone, Copy, Default)]
+pub(crate) struct SurvivalProbeCounters {
+    pub(crate) n_5: u64,
+    pub(crate) s_5: u64,
+    pub(crate) n_10: u64,
+    pub(crate) s_10: u64,
+    pub(crate) n_25: u64,
+    pub(crate) s_25: u64,
+}
+
+impl SurvivalProbeCounters {
+    pub(crate) fn record(&mut self, delay_ms: u64, survived: bool) {
+        let (n, s) = match delay_ms {
+            5 => (&mut self.n_5, &mut self.s_5),
+            10 => (&mut self.n_10, &mut self.s_10),
+            25 => (&mut self.n_25, &mut self.s_25),
+            _ => return,
+        };
+        *n = n.saturating_add(1);
+        if survived {
+            *s = s.saturating_add(1);
+        }
+    }
+
+    pub(crate) fn ratio(&self, delay_ms: u64) -> f64 {
+        let (n, s) = match delay_ms {
+            5 => (self.n_5, self.s_5),
+            10 => (self.n_10, self.s_10),
+            25 => (self.n_25, self.s_25),
+            _ => (0, 0),
+        };
+        if n == 0 {
+            0.0
+        } else {
+            s as f64 / n as f64
+        }
+    }
+
+    pub(crate) fn n(&self, delay_ms: u64) -> u64 {
+        match delay_ms {
+            5 => self.n_5,
+            10 => self.n_10,
+            25 => self.n_25,
+            _ => 0,
+        }
+    }
+}
+
+pub(crate) struct ShadowStats {
+    pub(crate) window_id: AtomicU64,
+    pub(crate) started_at: RwLock<Instant>,
+    pub(crate) started_at_ms: AtomicI64,
+    pub(crate) quote_attempted: AtomicU64,
+    pub(crate) quote_blocked: AtomicU64,
+    pub(crate) policy_blocked: AtomicU64,
+    pub(crate) seen_count: AtomicU64,
+    pub(crate) candidate_count: AtomicU64,
+    pub(crate) quoted_count: AtomicU64,
+    pub(crate) eligible_count: AtomicU64,
+    pub(crate) executed_count: AtomicU64,
+    pub(crate) filled_count: AtomicU64,
+    pub(crate) blocked_reasons: RwLock<HashMap<String, u64>>,
+    pub(crate) exit_reasons: RwLock<HashMap<String, u64>>,
+    pub(crate) ref_ticks_total: AtomicU64,
+    pub(crate) book_ticks_total: AtomicU64,
+    pub(crate) ref_source_counts: DashMap<String, u64>,
+    pub(crate) ref_dedupe_dropped: AtomicU64,
+    pub(crate) share_cap_drop_count: AtomicU64,
+    pub(crate) udp_local_drop_count_baseline: AtomicU64,
+    pub(crate) fallback_state_code: AtomicU64,
+    pub(crate) fallback_trigger_reasons: RwLock<HashMap<String, u64>>,
+    pub(crate) last_ref_tick_ms: AtomicI64,
+    pub(crate) last_book_tick_ms: AtomicI64,
+    pub(crate) shots: RwLock<Vec<ShadowShot>>,
+    pub(crate) outcomes: RwLock<Vec<ShadowOutcome>>,
+    pub(crate) samples: RwLock<ShadowSamples>,
+    pub(crate) book_top_lag_by_symbol_ms: RwLock<HashMap<String, Vec<f64>>>,
+    pub(crate) survival_probe_overall: RwLock<SurvivalProbeCounters>,
+    pub(crate) survival_probe_by_symbol: RwLock<HashMap<String, SurvivalProbeCounters>>,
+    pub(crate) data_total: AtomicU64,
+    pub(crate) data_invalid: AtomicU64,
+    pub(crate) seq_gap: AtomicU64,
+    pub(crate) ts_inversion: AtomicU64,
+    pub(crate) stale_tick_dropped: AtomicU64,
+    pub(crate) loss_streak: AtomicU64,
+    pub(crate) observe_only: AtomicBool,
+    pub(crate) paused: AtomicBool,
+    pub(crate) paused_since_ms: AtomicU64,
+    pub(crate) paused_total_ms: AtomicU64,
+    pub(crate) predator_c_enabled: AtomicBool,
+    pub(crate) predator_dir_up: AtomicU64,
+    pub(crate) predator_dir_down: AtomicU64,
+    pub(crate) predator_dir_neutral: AtomicU64,
+    pub(crate) predator_taker_fired: AtomicU64,
+    pub(crate) predator_taker_skipped: AtomicU64,
+    pub(crate) predator_regime_active: AtomicU64,
+    pub(crate) predator_regime_quiet: AtomicU64,
+    pub(crate) predator_regime_defend: AtomicU64,
+    pub(crate) predator_cross_symbol_fired: AtomicU64,
+    pub(crate) predator_last_30s_taker_fallback_count: AtomicU64,
+    pub(crate) predator_taker_skip_reasons: RwLock<HashMap<String, u64>>,
+    pub(crate) predator_router_locked_by_tf_usdc: RwLock<HashMap<String, f64>>,
+    pub(crate) predator_capital: RwLock<CapitalUpdate>,
+    pub(crate) predator_capital_halt: AtomicBool,
+    pub(crate) probability_total: AtomicU64,
+    pub(crate) probability_degraded: AtomicU64,
+}
+
+#[derive(Debug, Clone, Default)]
+pub(crate) struct ShadowSamples {
+    pub(crate) decision_queue_wait_ms: Vec<f64>,
+    pub(crate) decision_compute_ms: Vec<f64>,
+    pub(crate) tick_to_decision_ms: Vec<f64>,
+    pub(crate) ack_only_ms: Vec<f64>,
+    pub(crate) tick_to_ack_ms: Vec<f64>,
+    pub(crate) capturable_window_ms: Vec<f64>,
+    pub(crate) alpha_window_ms: Vec<f64>,
+    pub(crate) alpha_window_hit: Vec<f64>,
+    pub(crate) feed_in_ms: Vec<f64>,
+    pub(crate) source_latency_ms: Vec<f64>,
+    pub(crate) exchange_lag_ms: Vec<f64>,
+    pub(crate) path_lag_ms: Vec<f64>,
+    pub(crate) book_latency_ms: Vec<f64>,
+    pub(crate) local_backlog_ms: Vec<f64>,
+    pub(crate) ref_decode_ms: Vec<f64>,
+    pub(crate) book_top_lag_ms: Vec<f64>,
+    pub(crate) signal_us: Vec<f64>,
+    pub(crate) quote_us: Vec<f64>,
+    pub(crate) risk_us: Vec<f64>,
+    pub(crate) shadow_fill_ms: Vec<f64>,
+    pub(crate) queue_depth: Vec<f64>,
+    pub(crate) event_backlog: Vec<f64>,
+    pub(crate) parse_us: Vec<f64>,
+    pub(crate) io_queue_depth: Vec<f64>,
+    pub(crate) settle_fast_delta_bps: Vec<f64>,
+    pub(crate) probability_confidence: Vec<f64>,
+}
+
+impl ShadowStats {
+    const SHADOW_CAP: usize = 200_000;
+    const SAMPLE_CAP: usize = 65_536;
+    pub(crate) const GATE_MIN_OUTCOMES: usize = 30;
+
+    pub(crate) fn new() -> Self {
+        Self {
+            window_id: AtomicU64::new(0),
+            started_at: RwLock::new(Instant::now()),
+            started_at_ms: AtomicI64::new(Utc::now().timestamp_millis()),
+            quote_attempted: AtomicU64::new(0),
+            quote_blocked: AtomicU64::new(0),
+            policy_blocked: AtomicU64::new(0),
+            seen_count: AtomicU64::new(0),
+            candidate_count: AtomicU64::new(0),
+            quoted_count: AtomicU64::new(0),
+            eligible_count: AtomicU64::new(0),
+            executed_count: AtomicU64::new(0),
+            filled_count: AtomicU64::new(0),
+            blocked_reasons: RwLock::new(HashMap::new()),
+            exit_reasons: RwLock::new(HashMap::new()),
+            ref_ticks_total: AtomicU64::new(0),
+            book_ticks_total: AtomicU64::new(0),
+            ref_source_counts: DashMap::new(),
+            ref_dedupe_dropped: AtomicU64::new(0),
+            share_cap_drop_count: AtomicU64::new(0),
+            udp_local_drop_count_baseline: AtomicU64::new(feed_udp::udp_local_drop_count()),
+            fallback_state_code: AtomicU64::new(0),
+            fallback_trigger_reasons: RwLock::new(HashMap::new()),
+            last_ref_tick_ms: AtomicI64::new(0),
+            last_book_tick_ms: AtomicI64::new(0),
+            shots: RwLock::new(Vec::new()),
+            outcomes: RwLock::new(Vec::new()),
+            samples: RwLock::new(ShadowSamples::default()),
+            book_top_lag_by_symbol_ms: RwLock::new(HashMap::new()),
+            survival_probe_overall: RwLock::new(SurvivalProbeCounters::default()),
+            survival_probe_by_symbol: RwLock::new(HashMap::new()),
+            data_total: AtomicU64::new(0),
+            data_invalid: AtomicU64::new(0),
+            seq_gap: AtomicU64::new(0),
+            ts_inversion: AtomicU64::new(0),
+            stale_tick_dropped: AtomicU64::new(0),
+            loss_streak: AtomicU64::new(0),
+            observe_only: AtomicBool::new(false),
+            paused: AtomicBool::new(false),
+            paused_since_ms: AtomicU64::new(0),
+            paused_total_ms: AtomicU64::new(0),
+            predator_c_enabled: AtomicBool::new(false),
+            predator_dir_up: AtomicU64::new(0),
+            predator_dir_down: AtomicU64::new(0),
+            predator_dir_neutral: AtomicU64::new(0),
+            predator_taker_fired: AtomicU64::new(0),
+            predator_taker_skipped: AtomicU64::new(0),
+            predator_regime_active: AtomicU64::new(0),
+            predator_regime_quiet: AtomicU64::new(0),
+            predator_regime_defend: AtomicU64::new(0),
+            predator_cross_symbol_fired: AtomicU64::new(0),
+            predator_last_30s_taker_fallback_count: AtomicU64::new(0),
+            predator_taker_skip_reasons: RwLock::new(HashMap::new()),
+            predator_router_locked_by_tf_usdc: RwLock::new(HashMap::new()),
+            predator_capital: RwLock::new(CapitalUpdate {
+                available_usdc: 0.0,
+                base_quote_size: 0.0,
+                ts_ms: 0,
+            }),
+            predator_capital_halt: AtomicBool::new(false),
+            probability_total: AtomicU64::new(0),
+            probability_degraded: AtomicU64::new(0),
+        }
+    }
+
+    pub(crate) async fn reset(&self) -> u64 {
+        let window_id = self.window_id.fetch_add(1, Ordering::Relaxed) + 1;
+        *self.started_at.write().await = Instant::now();
+        self.started_at_ms
+            .store(Utc::now().timestamp_millis(), Ordering::Relaxed);
+        self.quote_attempted.store(0, Ordering::Relaxed);
+        self.quote_blocked.store(0, Ordering::Relaxed);
+        self.policy_blocked.store(0, Ordering::Relaxed);
+        self.seen_count.store(0, Ordering::Relaxed);
+        self.candidate_count.store(0, Ordering::Relaxed);
+        self.quoted_count.store(0, Ordering::Relaxed);
+        self.eligible_count.store(0, Ordering::Relaxed);
+        self.executed_count.store(0, Ordering::Relaxed);
+        self.filled_count.store(0, Ordering::Relaxed);
+        self.ref_ticks_total.store(0, Ordering::Relaxed);
+        self.book_ticks_total.store(0, Ordering::Relaxed);
+        self.ref_dedupe_dropped.store(0, Ordering::Relaxed);
+        self.share_cap_drop_count.store(0, Ordering::Relaxed);
+        self.udp_local_drop_count_baseline
+            .store(feed_udp::udp_local_drop_count(), Ordering::Relaxed);
+        self.fallback_state_code.store(0, Ordering::Relaxed);
+        self.last_ref_tick_ms.store(0, Ordering::Relaxed);
+        self.last_book_tick_ms.store(0, Ordering::Relaxed);
+        self.blocked_reasons.write().await.clear();
+        self.exit_reasons.write().await.clear();
+        self.ref_source_counts.clear();
+        self.fallback_trigger_reasons.write().await.clear();
+        self.shots.write().await.clear();
+        self.outcomes.write().await.clear();
+        *self.samples.write().await = ShadowSamples::default();
+        self.book_top_lag_by_symbol_ms.write().await.clear();
+        *self.survival_probe_overall.write().await = SurvivalProbeCounters::default();
+        self.survival_probe_by_symbol.write().await.clear();
+        self.data_total.store(0, Ordering::Relaxed);
+        self.data_invalid.store(0, Ordering::Relaxed);
+        self.seq_gap.store(0, Ordering::Relaxed);
+        self.ts_inversion.store(0, Ordering::Relaxed);
+        self.stale_tick_dropped.store(0, Ordering::Relaxed);
+        self.loss_streak.store(0, Ordering::Relaxed);
+        self.observe_only.store(false, Ordering::Relaxed);
+        self.paused.store(false, Ordering::Relaxed);
+        self.paused_since_ms.store(0, Ordering::Relaxed);
+        self.paused_total_ms.store(0, Ordering::Relaxed);
+        self.predator_c_enabled.store(false, Ordering::Relaxed);
+        self.predator_dir_up.store(0, Ordering::Relaxed);
+        self.predator_dir_down.store(0, Ordering::Relaxed);
+        self.predator_dir_neutral.store(0, Ordering::Relaxed);
+        self.predator_taker_fired.store(0, Ordering::Relaxed);
+        self.predator_taker_skipped.store(0, Ordering::Relaxed);
+        self.predator_regime_active.store(0, Ordering::Relaxed);
+        self.predator_regime_quiet.store(0, Ordering::Relaxed);
+        self.predator_regime_defend.store(0, Ordering::Relaxed);
+        self.predator_cross_symbol_fired.store(0, Ordering::Relaxed);
+        self.predator_last_30s_taker_fallback_count
+            .store(0, Ordering::Relaxed);
+        self.predator_taker_skip_reasons.write().await.clear();
+        self.predator_router_locked_by_tf_usdc.write().await.clear();
+        *self.predator_capital.write().await = CapitalUpdate {
+            available_usdc: 0.0,
+            base_quote_size: 0.0,
+            ts_ms: 0,
+        };
+        self.predator_capital_halt.store(false, Ordering::Relaxed);
+        self.probability_total.store(0, Ordering::Relaxed);
+        self.probability_degraded.store(0, Ordering::Relaxed);
+        window_id
+    }
+
+    #[inline]
+    pub(crate) fn is_current_window_ts_ns(&self, ts_ns: i64) -> bool {
+        let started_at_ms = self.started_at_ms.load(Ordering::Relaxed);
+        if started_at_ms <= 0 {
+            return true;
+        }
+        let ts_ms = ts_ns / 1_000_000;
+        // 1ms tolerance for clock granularity and ordering jitter around reset.
+        ts_ms.saturating_add(1) >= started_at_ms
+    }
+
+    pub(crate) async fn push_shot(&self, shot: ShadowShot) {
+        let ingest_seq = next_normalized_ingest_seq();
+        let source_seq = shot.t0_ns.max(0) as u64;
+        append_jsonl(
+            &dataset_path("normalized", "shadow_shots.jsonl"),
+            &serde_json::json!({
+                "ts_ms": Utc::now().timestamp_millis(),
+                "source_seq": source_seq,
+                "ingest_seq": ingest_seq,
+                "shot": shot
+            }),
+        );
+        let mut shots = self.shots.write().await;
+        push_capped(&mut shots, shot, Self::SHADOW_CAP);
+    }
+
+    pub(crate) async fn push_outcome(&self, outcome: ShadowOutcome) {
+        // Loss-streak only considers primary delay (10ms) *fillable* outcomes, so "no fills"
+        // does not trip risk controls.
+        const PRIMARY_DELAY_MS: u64 = 10;
+        if outcome.delay_ms == PRIMARY_DELAY_MS && outcome.fillable {
+            if outcome.net_markout_10s_usdc.unwrap_or(0.0) < 0.0 {
+                self.loss_streak.fetch_add(1, Ordering::Relaxed);
+            } else {
+                self.loss_streak.store(0, Ordering::Relaxed);
+            }
+        }
+        let ingest_seq = next_normalized_ingest_seq();
+        let source_seq = outcome.ts_ns.max(0) as u64;
+        append_jsonl(
+            &dataset_path("normalized", "shadow_outcomes.jsonl"),
+            &serde_json::json!({
+                "ts_ms": Utc::now().timestamp_millis(),
+                "source_seq": source_seq,
+                "ingest_seq": ingest_seq,
+                "outcome": outcome
+            }),
+        );
+        let mut outcomes = self.outcomes.write().await;
+        push_capped(&mut outcomes, outcome, Self::SHADOW_CAP);
+    }
+
+    pub(crate) fn loss_streak(&self) -> u32 {
+        self.loss_streak
+            .load(Ordering::Relaxed)
+            .min(u32::MAX as u64) as u32
+    }
+
+    pub(crate) async fn push_depth_sample(
+        &self,
+        event_backlog: f64,
+        queue_depth: f64,
+        io_queue_depth: f64,
+    ) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.event_backlog, event_backlog, Self::SAMPLE_CAP);
+        push_capped(&mut s.queue_depth, queue_depth, Self::SAMPLE_CAP);
+        push_capped(&mut s.io_queue_depth, io_queue_depth, Self::SAMPLE_CAP);
+    }
+
+    pub(crate) async fn push_latency_sample(
+        &self,
+        feed_in_ms: f64,
+        source_latency_ms: f64,
+        exchange_lag_ms: f64,
+        path_lag_ms: f64,
+        book_latency_ms: f64,
+        local_backlog_ms: f64,
+        ref_decode_ms: f64,
+    ) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.feed_in_ms, feed_in_ms, Self::SAMPLE_CAP);
+        push_capped(
+            &mut s.source_latency_ms,
+            source_latency_ms,
+            Self::SAMPLE_CAP,
+        );
+        push_capped(&mut s.exchange_lag_ms, exchange_lag_ms, Self::SAMPLE_CAP);
+        if path_lag_ms.is_finite() && path_lag_ms >= 0.0 {
+            push_capped(&mut s.path_lag_ms, path_lag_ms, Self::SAMPLE_CAP);
+        }
+        push_capped(&mut s.book_latency_ms, book_latency_ms, Self::SAMPLE_CAP);
+        push_capped(&mut s.local_backlog_ms, local_backlog_ms, Self::SAMPLE_CAP);
+        push_capped(&mut s.ref_decode_ms, ref_decode_ms, Self::SAMPLE_CAP);
+    }
+
+    pub(crate) async fn push_decision_queue_wait_ms(&self, ms: f64) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.decision_queue_wait_ms, ms, Self::SAMPLE_CAP);
+    }
+
+    pub(crate) async fn push_ack_only_ms(&self, ms: f64) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.ack_only_ms, ms, Self::SAMPLE_CAP);
+    }
+
+    pub(crate) async fn push_tick_to_ack_ms(&self, ms: f64) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.tick_to_ack_ms, ms, Self::SAMPLE_CAP);
+    }
+
+    pub(crate) async fn push_capturable_window_ms(&self, ms: f64) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.capturable_window_ms, ms, Self::SAMPLE_CAP);
+    }
+
+    pub(crate) async fn push_alpha_window_sample(&self, ms: f64, hit: bool) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.alpha_window_ms, ms.max(0.0), Self::SAMPLE_CAP);
+        push_capped(
+            &mut s.alpha_window_hit,
+            if hit { 1.0 } else { 0.0 },
+            Self::SAMPLE_CAP,
+        );
+    }
+
+    pub(crate) async fn push_book_top_lag_ms(&self, symbol: &str, ms: f64) {
+        {
+            let mut s = self.samples.write().await;
+            push_capped(&mut s.book_top_lag_ms, ms, Self::SAMPLE_CAP);
+        }
+
+        let mut by_symbol = self.book_top_lag_by_symbol_ms.write().await;
+        let entry = by_symbol.entry(symbol.to_string()).or_default();
+        push_capped(entry, ms, 4_096);
+    }
+
+    pub(crate) fn book_top_lag_p50_ms_for_symbol_sync(&self, symbol: &str) -> Option<f64> {
+        let by_symbol = self.book_top_lag_by_symbol_ms.try_read().ok()?;
+        let samples = by_symbol.get(symbol)?;
+        if samples.len() < 8 {
+            return None;
+        }
+        let mut sorted = samples.clone();
+        sorted.sort_unstable_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
+        let idx = (sorted.len() as f64 * 0.50) as usize;
+        sorted.get(idx.min(sorted.len().saturating_sub(1))).copied()
+    }
+
+    pub(crate) async fn record_survival_probe(&self, symbol: &str, delay_ms: u64, survived: bool) {
+        {
+            let mut c = self.survival_probe_overall.write().await;
+            c.record(delay_ms, survived);
+        }
+        let mut by_symbol = self.survival_probe_by_symbol.write().await;
+        let entry = by_symbol.entry(symbol.to_string()).or_default();
+        entry.record(delay_ms, survived);
+    }
+
+    pub(crate) async fn push_signal_us(&self, us: f64) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.signal_us, us, Self::SAMPLE_CAP);
+    }
+
+    pub(crate) async fn push_shadow_fill_ms(&self, ms: f64) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.shadow_fill_ms, ms, Self::SAMPLE_CAP);
+    }
+
+    pub(crate) async fn push_parse_us(&self, us: f64) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.parse_us, us, Self::SAMPLE_CAP);
+    }
+
+    pub(crate) async fn push_probability_sample(&self, estimate: &ProbabilityEstimate) {
+        self.probability_total.fetch_add(1, Ordering::Relaxed);
+        if estimate.settlement_source_degraded {
+            self.probability_degraded.fetch_add(1, Ordering::Relaxed);
+        }
+        let mut s = self.samples.write().await;
+        let delta_bps =
+            ((estimate.p_settle - estimate.p_fast).abs() * 10_000.0).clamp(0.0, 10_000.0);
+        push_capped(&mut s.settle_fast_delta_bps, delta_bps, Self::SAMPLE_CAP);
+        push_capped(
+            &mut s.probability_confidence,
+            estimate.confidence.clamp(0.0, 1.0),
+            Self::SAMPLE_CAP,
+        );
+    }
+
+    pub(crate) fn mark_attempted(&self) {
+        self.quote_attempted.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_seen(&self) {
+        self.seen_count.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_candidate(&self) {
+        self.candidate_count.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_eligible(&self) {
+        self.eligible_count.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_executed(&self) {
+        self.executed_count.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_filled(&self, n: u64) {
+        self.filled_count.fetch_add(n, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_blocked(&self) {
+        self.quote_blocked.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_policy_blocked(&self) {
+        self.policy_blocked.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) async fn mark_blocked_with_reason(&self, reason: &str) {
+        if is_quote_reject_reason(reason) {
+            self.mark_blocked();
+        }
+        if is_policy_block_reason(reason) {
+            self.mark_policy_blocked();
+        }
+        let mut reasons = self.blocked_reasons.write().await;
+        *reasons.entry(reason.to_string()).or_insert(0) += 1;
+    }
+
+    pub(crate) async fn record_issue(&self, reason: &str) {
+        let mut reasons = self.blocked_reasons.write().await;
+        *reasons.entry(reason.to_string()).or_insert(0) += 1;
+    }
+
+    pub(crate) fn mark_ref_tick(&self, source: &str, ts_ms: i64) {
+        self.ref_ticks_total.fetch_add(1, Ordering::Relaxed);
+        self.last_ref_tick_ms.store(ts_ms, Ordering::Relaxed);
+        self.ref_source_counts
+            .entry(source.to_string())
+            .and_modify(|count| *count = count.saturating_add(1))
+            .or_insert(1);
+    }
+
+    pub(crate) fn mark_ref_dedupe_dropped(&self) {
+        self.ref_dedupe_dropped.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_share_cap_drop(&self) {
+        self.share_cap_drop_count.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) async fn mark_fallback_trigger_reason(&self, reason: &str) {
+        let mut reasons = self.fallback_trigger_reasons.write().await;
+        *reasons.entry(reason.to_string()).or_insert(0) += 1;
+    }
+
+    pub(crate) fn set_fallback_state(&self, state: &str) {
+        let code = match state {
+            "ws_primary" => 0,
+            "armed" => 1,
+            "udp_fallback" => 2,
+            "cooldown" => 3,
+            _ => 0,
+        };
+        self.fallback_state_code.store(code, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_book_tick(&self, ts_ms: i64) {
+        self.book_ticks_total.fetch_add(1, Ordering::Relaxed);
+        self.last_book_tick_ms.store(ts_ms, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_data_validity(&self, valid: bool) {
+        self.data_total.fetch_add(1, Ordering::Relaxed);
+        if !valid {
+            self.data_invalid.fetch_add(1, Ordering::Relaxed);
+        }
+    }
+
+    pub(crate) fn mark_ts_inversion(&self) {
+        self.ts_inversion.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_stale_tick_dropped(&self) {
+        self.stale_tick_dropped.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) async fn record_exit_reason(&self, reason: &str) {
+        let mut reasons = self.exit_reasons.write().await;
+        *reasons.entry(reason.to_string()).or_insert(0) += 1;
+    }
+
+    pub(crate) fn observe_only(&self) -> bool {
+        self.observe_only.load(Ordering::Relaxed)
+    }
+
+    pub(crate) fn set_observe_only(&self, v: bool) {
+        self.observe_only.store(v, Ordering::Relaxed);
+    }
+
+    pub(crate) fn set_paused(&self, v: bool) {
+        let now_ms = Utc::now().timestamp_millis().max(0) as u64;
+        let was = self.paused.swap(v, Ordering::Relaxed);
+        if was == v {
+            return;
+        }
+        if v {
+            self.paused_since_ms.store(now_ms, Ordering::Relaxed);
+            return;
+        }
+        let since = self.paused_since_ms.swap(0, Ordering::Relaxed);
+        if since > 0 {
+            self.paused_total_ms
+                .fetch_add(now_ms.saturating_sub(since), Ordering::Relaxed);
+        }
+    }
+
+    pub(crate) fn set_predator_enabled(&self, v: bool) {
+        self.predator_c_enabled.store(v, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_predator_direction(&self, dir: &Direction) {
+        match dir {
+            Direction::Up => {
+                self.predator_dir_up.fetch_add(1, Ordering::Relaxed);
+            }
+            Direction::Down => {
+                self.predator_dir_down.fetch_add(1, Ordering::Relaxed);
+            }
+            Direction::Neutral => {
+                self.predator_dir_neutral.fetch_add(1, Ordering::Relaxed);
+            }
+        }
+    }
+
+    pub(crate) fn mark_predator_taker_fired(&self) {
+        self.predator_taker_fired.fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_predator_last_30s_taker_fallback(&self) {
+        self.predator_last_30s_taker_fallback_count
+            .fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) fn mark_predator_regime(&self, regime: &Regime) {
+        match regime {
+            Regime::Active => {
+                self.predator_regime_active.fetch_add(1, Ordering::Relaxed);
+            }
+            Regime::Quiet => {
+                self.predator_regime_quiet.fetch_add(1, Ordering::Relaxed);
+            }
+            Regime::Defend => {
+                self.predator_regime_defend.fetch_add(1, Ordering::Relaxed);
+            }
+        }
+    }
+
+    pub(crate) fn mark_predator_cross_symbol_fired(&self) {
+        self.predator_cross_symbol_fired
+            .fetch_add(1, Ordering::Relaxed);
+    }
+
+    pub(crate) async fn mark_predator_taker_skipped(&self, reason: &str) {
+        self.predator_taker_skipped.fetch_add(1, Ordering::Relaxed);
+        let mut reasons = self.predator_taker_skip_reasons.write().await;
+        *reasons.entry(reason.to_string()).or_insert(0) += 1;
+    }
+
+    pub(crate) async fn set_predator_router_locked_by_tf_usdc(&self, locked: HashMap<String, f64>) {
+        *self.predator_router_locked_by_tf_usdc.write().await = locked;
+    }
+
+    pub(crate) async fn set_predator_capital(&self, update: CapitalUpdate, halt: bool) {
+        *self.predator_capital.write().await = update;
+        self.predator_capital_halt.store(halt, Ordering::Relaxed);
+    }
+
+    pub(crate) fn uptime_pct(&self, elapsed: Duration) -> f64 {
+        let elapsed_ms = elapsed.as_millis() as u64;
+        if elapsed_ms == 0 {
+            return 100.0;
+        }
+        let now_ms = Utc::now().timestamp_millis().max(0) as u64;
+        let base_paused = self.paused_total_ms.load(Ordering::Relaxed);
+        let paused_extra = if self.paused.load(Ordering::Relaxed) {
+            let since = self.paused_since_ms.load(Ordering::Relaxed);
+            if since > 0 {
+                now_ms.saturating_sub(since)
+            } else {
+                0
+            }
+        } else {
+            0
+        };
+        let paused_ms = base_paused.saturating_add(paused_extra).min(elapsed_ms);
+        let uptime_ms = elapsed_ms.saturating_sub(paused_ms);
+        ((uptime_ms as f64) * 100.0 / elapsed_ms as f64).clamp(0.0, 100.0)
+    }
+}
+
+impl ShadowStats {
+    pub(crate) async fn build_live_report(&self) -> ShadowLiveReport {
+        const PRIMARY_DELAY_MS: u64 = 10;
+        let ShadowSamples {
+            decision_queue_wait_ms,
+            decision_compute_ms,
+            tick_to_decision_ms,
+            ack_only_ms,
+            tick_to_ack_ms,
+            capturable_window_ms,
+            alpha_window_ms,
+            alpha_window_hit,
+            feed_in_ms,
+            source_latency_ms,
+            exchange_lag_ms,
+            path_lag_ms,
+            book_latency_ms,
+            local_backlog_ms,
+            ref_decode_ms,
+            book_top_lag_ms,
+            signal_us,
+            quote_us,
+            risk_us,
+            shadow_fill_ms,
+            queue_depth,
+            event_backlog,
+            parse_us,
+            io_queue_depth,
+            settle_fast_delta_bps,
+            probability_confidence,
+        } = self.samples.read().await.clone();
+        let book_top_lag_by_symbol_ms = self.book_top_lag_by_symbol_ms.read().await.clone();
+        let mut blocked_reason_counts = self.blocked_reasons.read().await.clone();
+        let source_counts = self
+            .ref_source_counts
+            .iter()
+            .map(|entry| (entry.key().clone(), *entry.value()))
+            .collect::<HashMap<_, _>>();
+        let exit_reason_counts = self.exit_reasons.read().await.clone();
+        let survival_probe_overall = *self.survival_probe_overall.read().await;
+        let survival_probe_by_symbol = self.survival_probe_by_symbol.read().await.clone();
+        let elapsed = self.started_at.read().await.elapsed();
+        let uptime_pct = self.uptime_pct(elapsed);
+
+        // Avoid cloning large shot/outcome vectors per request. Under stress polling this can
+        // cause massive allocation churn and even OOM kills (esp. when market_scorecard is large).
+        let shots_guard = self.shots.read().await;
+        let outcomes_guard = self.outcomes.read().await;
+
+        let fillability_5 = fillability_ratio(&outcomes_guard, 5);
+        let fillability_10 = fillability_ratio(&outcomes_guard, 10);
+        let fillability_25 = fillability_ratio(&outcomes_guard, 25);
+        let survival_5 = survival_ratio(&outcomes_guard, 5);
+        let survival_10 = survival_ratio(&outcomes_guard, 10);
+        let survival_25 = survival_ratio(&outcomes_guard, 25);
+        let survival_probe_5 = survival_probe_overall.ratio(5);
+        let survival_probe_10 = survival_probe_overall.ratio(10);
+        let survival_probe_25 = survival_probe_overall.ratio(25);
+        let survival_probe_5_n = survival_probe_overall.n(5);
+        let survival_probe_10_n = survival_probe_overall.n(10);
+        let survival_probe_25_n = survival_probe_overall.n(25);
+
+        let shots_primary = shots_guard
+            .iter()
+            .filter(|s| s.delay_ms == PRIMARY_DELAY_MS)
+            .collect::<Vec<_>>();
+        let outcomes_primary = outcomes_guard
+            .iter()
+            .filter(|o| o.delay_ms == PRIMARY_DELAY_MS)
+            .collect::<Vec<_>>();
+        let outcomes_primary_valid = outcomes_primary
+            .iter()
+            .filter(|o| !o.is_stale_tick)
+            .collect::<Vec<_>>();
+        let net_edges = shots_primary
+            .iter()
+            .map(|s| s.edge_net_bps)
+            .collect::<Vec<_>>();
+        let net_edge_p50 = percentile(&net_edges, 0.50).unwrap_or(0.0);
+        let net_edge_p10 = percentile(&net_edges, 0.10).unwrap_or(0.0);
+        let pnl_1s = outcomes_primary_valid
+            .iter()
+            .filter_map(|o| o.net_markout_1s_bps.or(o.pnl_1s_bps))
+            .collect::<Vec<_>>();
+        let pnl_5s = outcomes_primary_valid
+            .iter()
+            .filter_map(|o| o.net_markout_5s_bps.or(o.pnl_5s_bps))
+            .collect::<Vec<_>>();
+        let pnl_10s = outcomes_primary_valid
+            .iter()
+            .filter_map(|o| o.net_markout_10s_bps.or(o.pnl_10s_bps))
+            .collect::<Vec<_>>();
+        let net_markout_10s_usdc = outcomes_primary_valid
+            .iter()
+            .filter_map(|o| o.net_markout_10s_usdc)
+            .collect::<Vec<_>>();
+        let roi_notional_10s_bps = outcomes_primary_valid
+            .iter()
+            .filter_map(|o| o.roi_notional_10s_bps)
+            .collect::<Vec<_>>();
+        let pnl_1s_p50 = percentile(&pnl_1s, 0.50).unwrap_or(0.0);
+        let pnl_5s_p50 = percentile(&pnl_5s, 0.50).unwrap_or(0.0);
+        let pnl_10s_p50_raw = percentile(&pnl_10s, 0.50).unwrap_or(0.0);
+        let net_markout_10s_usdc_p50 = percentile(&net_markout_10s_usdc, 0.50).unwrap_or(0.0);
+        let roi_notional_10s_bps_p50 = percentile(&roi_notional_10s_bps, 0.50).unwrap_or(0.0);
+        let ev_net_usdc_p50 = percentile(&net_markout_10s_usdc, 0.50).unwrap_or(0.0);
+        let ev_net_usdc_p10 = percentile(&net_markout_10s_usdc, 0.10).unwrap_or(0.0);
+        let ev_positive_ratio = if net_markout_10s_usdc.is_empty() {
+            0.0
+        } else {
+            net_markout_10s_usdc.iter().filter(|v| **v > 0.0).count() as f64
+                / net_markout_10s_usdc.len() as f64
+        };
+        let (pnl_10s_filtered, pnl_10s_outlier_ratio) = robust_filter_iqr(&pnl_10s);
+        let pnl_10s_p50_robust = percentile(&pnl_10s_filtered, 0.50).unwrap_or(pnl_10s_p50_raw);
+        let pnl_10s_sample_count = pnl_10s.len();
+
+        let attempted = self.quote_attempted.load(Ordering::Relaxed);
+        let blocked = self.quote_blocked.load(Ordering::Relaxed);
+        let policy_blocked = self.policy_blocked.load(Ordering::Relaxed);
+        let eligible_count = self.eligible_count.load(Ordering::Relaxed);
+        let executed_count = self.executed_count.load(Ordering::Relaxed);
+        let executed_over_eligible = if eligible_count == 0 {
+            0.0
+        } else {
+            executed_count as f64 / eligible_count as f64
+        };
+        let quote_block_ratio = quote_block_ratio(attempted, blocked);
+        let policy_ratio = policy_block_ratio(attempted, policy_blocked);
+
+        let tick_to_ack_p99 = percentile(&tick_to_ack_ms, 0.99).unwrap_or(0.0);
+        let scorecard = build_market_scorecard(&shots_guard, &outcomes_guard);
+        let ref_ticks_total = self.ref_ticks_total.load(Ordering::Relaxed);
+        let book_ticks_total = self.book_ticks_total.load(Ordering::Relaxed);
+        let now_ms = Utc::now().timestamp_millis();
+        let last_ref_tick_ms = self.last_ref_tick_ms.load(Ordering::Relaxed);
+        let last_book_tick_ms = self.last_book_tick_ms.load(Ordering::Relaxed);
+        let ref_freshness_ms = freshness_ms(now_ms, last_ref_tick_ms);
+        let book_freshness_ms = freshness_ms(now_ms, last_book_tick_ms);
+        let data_total = self.data_total.load(Ordering::Relaxed);
+        let data_invalid = self.data_invalid.load(Ordering::Relaxed);
+        let seq_gap = self.seq_gap.load(Ordering::Relaxed);
+        let ts_inversion = self.ts_inversion.load(Ordering::Relaxed);
+        let stale_tick_dropped = self.stale_tick_dropped.load(Ordering::Relaxed);
+        let data_valid_ratio = if data_total == 0 {
+            1.0
+        } else {
+            1.0 - (data_invalid as f64 / data_total as f64)
+        };
+        let seq_gap_rate = if data_total == 0 {
+            0.0
+        } else {
+            seq_gap as f64 / data_total as f64
+        };
+        let ts_inversion_rate = if data_total == 0 {
+            0.0
+        } else {
+            ts_inversion as f64 / data_total as f64
+        };
+        let stale_tick_drop_ratio = if data_total == 0 {
+            0.0
+        } else {
+            stale_tick_dropped as f64 / data_total as f64
+        };
+        let dedupe_dropped = self.ref_dedupe_dropped.load(Ordering::Relaxed);
+        let probability_total = self.probability_total.load(Ordering::Relaxed);
+        let probability_degraded = self.probability_degraded.load(Ordering::Relaxed);
+        let settlement_source_degraded_ratio = if probability_total == 0 {
+            0.0
+        } else {
+            probability_degraded as f64 / probability_total as f64
+        };
+        let settle_fast_delta_p50_bps = percentile(&settle_fast_delta_bps, 0.50).unwrap_or(0.0);
+        let settle_fast_delta_p90_bps = percentile(&settle_fast_delta_bps, 0.90).unwrap_or(0.0);
+        let probability_confidence_p50 = percentile(&probability_confidence, 0.50).unwrap_or(0.0);
+        if dedupe_dropped > 0 {
+            blocked_reason_counts.insert("ref_dedupe_dropped".to_string(), dedupe_dropped);
+        }
+        let mut policy_block_reason_distribution = HashMap::new();
+        let mut gate_block_reason_distribution = HashMap::new();
+        let mut gate_blocked: u64 = 0;
+        if policy_blocked > 0 {
+            for (reason, count) in &blocked_reason_counts {
+                if is_policy_block_reason(reason.as_str()) {
+                    policy_block_reason_distribution.insert(reason.clone(), *count);
+                }
+            }
+        }
+        for (reason, count) in &blocked_reason_counts {
+            if is_gate_block_reason(reason.as_str()) {
+                gate_block_reason_distribution.insert(reason.clone(), *count);
+                gate_blocked = gate_blocked.saturating_add(*count);
+            }
+        }
+        let gate_block_ratio = ratio_u64(gate_blocked, attempted.saturating_add(gate_blocked));
+        let mut source_mix_ratio = HashMap::new();
+        if ref_ticks_total > 0 {
+            for (source, cnt) in &source_counts {
+                source_mix_ratio.insert(
+                    source.clone(),
+                    (*cnt as f64 / ref_ticks_total as f64).clamp(0.0, 1.0),
+                );
+            }
+        }
+        let udp_share_effective = source_mix_ratio.get("binance_udp").copied().unwrap_or(0.0);
+        let udp_local_drop_count = feed_udp::udp_local_drop_count()
+            .saturating_sub(self.udp_local_drop_count_baseline.load(Ordering::Relaxed));
+        let share_cap_drop_count = self.share_cap_drop_count.load(Ordering::Relaxed);
+        let fallback_state = match self.fallback_state_code.load(Ordering::Relaxed) {
+            1 => "armed",
+            2 => "udp_fallback",
+            3 => "cooldown",
+            _ => "ws_primary",
+        }
+        .to_string();
+        let fallback_trigger_reason_distribution =
+            self.fallback_trigger_reasons.read().await.clone();
+        let mut exit_reason_top = exit_reason_counts.into_iter().collect::<Vec<_>>();
+        exit_reason_top.sort_by(|a, b| b.1.cmp(&a.1));
+        exit_reason_top.truncate(8);
+        let lag_half_life_ms = percentile(
+            &book_top_lag_ms
+                .iter()
+                .copied()
+                .filter(|v| v.is_finite() && *v >= 0.0)
+                .collect::<Vec<_>>(),
+            0.50,
+        )
+        .unwrap_or(0.0);
+
+        let book_top_lag_p50_ms = percentile(&book_top_lag_ms, 0.50).unwrap_or(0.0);
+        let book_top_lag_p90_ms = percentile(&book_top_lag_ms, 0.90).unwrap_or(0.0);
+        let book_top_lag_p99_ms = percentile(&book_top_lag_ms, 0.99).unwrap_or(0.0);
+        let mut book_top_lag_by_symbol_p50_ms = HashMap::new();
+        for (sym, samples) in book_top_lag_by_symbol_ms {
+            book_top_lag_by_symbol_p50_ms.insert(sym, percentile(&samples, 0.50).unwrap_or(0.0));
+        }
+
+        let mut survival_10ms_by_symbol = HashMap::new();
+        let mut survival_counts: HashMap<String, (u64, u64)> = HashMap::new();
+        for o in &outcomes_primary_valid {
+            let o = *o;
+            let e = survival_counts.entry(o.symbol.clone()).or_insert((0, 0));
+            e.0 = e.0.saturating_add(1);
+            if o.survived {
+                e.1 = e.1.saturating_add(1);
+            }
+        }
+        for (sym, (n, s)) in survival_counts {
+            survival_10ms_by_symbol.insert(sym, if n == 0 { 0.0 } else { s as f64 / n as f64 });
+        }
+        let mut survival_probe_10ms_by_symbol = HashMap::new();
+        for (sym, c) in survival_probe_by_symbol {
+            survival_probe_10ms_by_symbol.insert(sym, c.ratio(10));
+        }
+
+        let shots_primary_at_ack = shots_primary
+            .iter()
+            .copied()
+            .filter(|s| s.ack_only_ms > 0.0)
+            .collect::<Vec<_>>();
+        let book_top_lag_at_ack_ms = shots_primary_at_ack
+            .iter()
+            .map(|s| s.book_top_lag_ms)
+            .collect::<Vec<_>>();
+
+        let latency = LatencyBreakdown {
+            feed_in_p50_ms: percentile(&feed_in_ms, 0.50).unwrap_or(0.0),
+            feed_in_p90_ms: percentile(&feed_in_ms, 0.90).unwrap_or(0.0),
+            feed_in_p99_ms: percentile(&feed_in_ms, 0.99).unwrap_or(0.0),
+            signal_p50_us: percentile(&signal_us, 0.50).unwrap_or(0.0),
+            signal_p90_us: percentile(&signal_us, 0.90).unwrap_or(0.0),
+            signal_p99_us: percentile(&signal_us, 0.99).unwrap_or(0.0),
+            quote_p50_us: percentile(&quote_us, 0.50).unwrap_or(0.0),
+            quote_p90_us: percentile(&quote_us, 0.90).unwrap_or(0.0),
+            quote_p99_us: percentile(&quote_us, 0.99).unwrap_or(0.0),
+            risk_p50_us: percentile(&risk_us, 0.50).unwrap_or(0.0),
+            risk_p90_us: percentile(&risk_us, 0.90).unwrap_or(0.0),
+            risk_p99_us: percentile(&risk_us, 0.99).unwrap_or(0.0),
+            decision_queue_wait_p50_ms: percentile(&decision_queue_wait_ms, 0.50).unwrap_or(0.0),
+            decision_queue_wait_p90_ms: percentile(&decision_queue_wait_ms, 0.90).unwrap_or(0.0),
+            decision_queue_wait_p99_ms: percentile(&decision_queue_wait_ms, 0.99).unwrap_or(0.0),
+            decision_compute_p50_ms: percentile(&decision_compute_ms, 0.50).unwrap_or(0.0),
+            decision_compute_p90_ms: percentile(&decision_compute_ms, 0.90).unwrap_or(0.0),
+            decision_compute_p99_ms: percentile(&decision_compute_ms, 0.99).unwrap_or(0.0),
+            tick_to_decision_p50_ms: percentile(&tick_to_decision_ms, 0.50).unwrap_or(0.0),
+            tick_to_decision_p90_ms: percentile(&tick_to_decision_ms, 0.90).unwrap_or(0.0),
+            tick_to_decision_p99_ms: percentile(&tick_to_decision_ms, 0.99).unwrap_or(0.0),
+            ack_only_p50_ms: percentile(&ack_only_ms, 0.50).unwrap_or(0.0),
+            ack_only_p90_ms: percentile(&ack_only_ms, 0.90).unwrap_or(0.0),
+            ack_only_p99_ms: percentile(&ack_only_ms, 0.99).unwrap_or(0.0),
+            tick_to_ack_p50_ms: percentile(&tick_to_ack_ms, 0.50).unwrap_or(0.0),
+            tick_to_ack_p90_ms: percentile(&tick_to_ack_ms, 0.90).unwrap_or(0.0),
+            tick_to_ack_p99_ms: tick_to_ack_p99,
+            parse_p99_us: percentile(&parse_us, 0.99).unwrap_or(0.0),
+            io_queue_p99_ms: percentile(&io_queue_depth, 0.99).unwrap_or(0.0),
+            bus_lag_p99_ms: percentile(&event_backlog, 0.99).unwrap_or(0.0),
+            shadow_fill_p50_ms: percentile(&shadow_fill_ms, 0.50).unwrap_or(0.0),
+            shadow_fill_p90_ms: percentile(&shadow_fill_ms, 0.90).unwrap_or(0.0),
+            shadow_fill_p99_ms: percentile(&shadow_fill_ms, 0.99).unwrap_or(0.0),
+            source_latency_p50_ms: percentile(&source_latency_ms, 0.50).unwrap_or(0.0),
+            source_latency_p90_ms: percentile(&source_latency_ms, 0.90).unwrap_or(0.0),
+            source_latency_p99_ms: percentile(&source_latency_ms, 0.99).unwrap_or(0.0),
+            exchange_lag_p50_ms: percentile(&exchange_lag_ms, 0.50).unwrap_or(0.0),
+            exchange_lag_p90_ms: percentile(&exchange_lag_ms, 0.90).unwrap_or(0.0),
+            exchange_lag_p99_ms: percentile(&exchange_lag_ms, 0.99).unwrap_or(0.0),
+            path_lag_p50_ms: percentile(&path_lag_ms, 0.50).unwrap_or(0.0),
+            path_lag_p90_ms: percentile(&path_lag_ms, 0.90).unwrap_or(0.0),
+            path_lag_p99_ms: percentile(&path_lag_ms, 0.99).unwrap_or(0.0),
+            path_lag_coverage_ratio: ratio_u64(
+                path_lag_ms.len() as u64,
+                source_latency_ms.len() as u64,
+            ),
+            book_latency_p50_ms: percentile(&book_latency_ms, 0.50).unwrap_or(0.0),
+            book_latency_p90_ms: percentile(&book_latency_ms, 0.90).unwrap_or(0.0),
+            book_latency_p99_ms: percentile(&book_latency_ms, 0.99).unwrap_or(0.0),
+            local_backlog_p50_ms: percentile(&local_backlog_ms, 0.50).unwrap_or(0.0),
+            local_backlog_p90_ms: percentile(&local_backlog_ms, 0.90).unwrap_or(0.0),
+            local_backlog_p99_ms: percentile(&local_backlog_ms, 0.99).unwrap_or(0.0),
+            ref_decode_p50_ms: percentile(&ref_decode_ms, 0.50).unwrap_or(0.0),
+            ref_decode_p90_ms: percentile(&ref_decode_ms, 0.90).unwrap_or(0.0),
+            ref_decode_p99_ms: percentile(&ref_decode_ms, 0.99).unwrap_or(0.0),
+            book_top_lag_at_ack_p50_ms: percentile(&book_top_lag_at_ack_ms, 0.50).unwrap_or(0.0),
+            book_top_lag_at_ack_p90_ms: percentile(&book_top_lag_at_ack_ms, 0.90).unwrap_or(0.0),
+            book_top_lag_at_ack_p99_ms: percentile(&book_top_lag_at_ack_ms, 0.99).unwrap_or(0.0),
+            book_top_lag_at_ack_n: book_top_lag_at_ack_ms.len() as u64,
+            capturable_window_p50_ms: percentile(&capturable_window_ms, 0.50).unwrap_or(0.0),
+            capturable_window_p75_ms: percentile(&capturable_window_ms, 0.75).unwrap_or(0.0),
+            capturable_window_p90_ms: percentile(&capturable_window_ms, 0.90).unwrap_or(0.0),
+            capturable_window_p99_ms: percentile(&capturable_window_ms, 0.99).unwrap_or(0.0),
+            alpha_window_p50_ms: percentile(&alpha_window_ms, 0.50).unwrap_or(0.0),
+            alpha_window_p90_ms: percentile(&alpha_window_ms, 0.90).unwrap_or(0.0),
+            alpha_window_p99_ms: percentile(&alpha_window_ms, 0.99).unwrap_or(0.0),
+            alpha_window_hit_ratio: if alpha_window_hit.is_empty() {
+                0.0
+            } else {
+                alpha_window_hit.iter().sum::<f64>() / alpha_window_hit.len() as f64
+            },
+            alpha_window_n: alpha_window_ms.len() as u64,
+            profitable_window_ratio: if capturable_window_ms.is_empty() {
+                0.0
+            } else {
+                capturable_window_ms.iter().filter(|v| **v > 0.0).count() as f64
+                    / capturable_window_ms.len() as f64
+            },
+            capturable_window_n: capturable_window_ms.len() as u64,
+            ack_only_n: ack_only_ms.len() as u64,
+            tick_to_ack_n: tick_to_ack_ms.len() as u64,
+        };
+
+        let total_shots = shots_guard.len();
+        let total_outcomes = outcomes_guard.len();
+
+        // IMPORTANT: drop large read-guards before awaiting on other locks below.
+        drop(shots_guard);
+        drop(outcomes_guard);
+
+        let predator_c_enabled = self.predator_c_enabled.load(Ordering::Relaxed);
+        let direction_signals_up = self.predator_dir_up.load(Ordering::Relaxed);
+        let direction_signals_down = self.predator_dir_down.load(Ordering::Relaxed);
+        let direction_signals_neutral = self.predator_dir_neutral.load(Ordering::Relaxed);
+        let taker_sniper_fired = self.predator_taker_fired.load(Ordering::Relaxed);
+        let taker_sniper_skipped = self.predator_taker_skipped.load(Ordering::Relaxed);
+        let predator_regime_active = self.predator_regime_active.load(Ordering::Relaxed);
+        let predator_regime_quiet = self.predator_regime_quiet.load(Ordering::Relaxed);
+        let predator_regime_defend = self.predator_regime_defend.load(Ordering::Relaxed);
+        let predator_cross_symbol_fired = self.predator_cross_symbol_fired.load(Ordering::Relaxed);
+        let last_30s_taker_fallback_count = self
+            .predator_last_30s_taker_fallback_count
+            .load(Ordering::Relaxed);
+        let skip_reasons = self.predator_taker_skip_reasons.read().await.clone();
+        let mut skip_top = skip_reasons.into_iter().collect::<Vec<_>>();
+        skip_top.sort_by(|a, b| b.1.cmp(&a.1));
+        skip_top.truncate(10);
+        let router_locked_by_tf_usdc = self.predator_router_locked_by_tf_usdc.read().await.clone();
+        let capital = self.predator_capital.read().await.clone();
+        let capital_halt = self.predator_capital_halt.load(Ordering::Relaxed);
+
+        let gate_ready_strict = total_outcomes >= Self::GATE_MIN_OUTCOMES;
+        let gate_ready_effective = gate_ready_strict || eligible_count > 0 || executed_count > 0;
+
+        let mut live = ShadowLiveReport {
+            window_id: self.window_id.load(Ordering::Relaxed),
+            window_shots: total_shots,
+            window_outcomes: total_outcomes,
+            gate_ready: gate_ready_strict,
+            gate_ready_strict,
+            gate_ready_effective,
+            gate_fail_reasons: Vec::new(),
+            observe_only: self.observe_only(),
+            started_at_ms: self.started_at_ms.load(Ordering::Relaxed),
+            elapsed_sec: elapsed.as_secs(),
+            total_shots,
+            total_outcomes,
+            data_valid_ratio,
+            seq_gap_rate,
+            ts_inversion_rate,
+            stale_tick_drop_ratio,
+            quote_attempted: attempted,
+            quote_blocked: blocked,
+            policy_blocked,
+            fillability_5ms: fillability_5,
+            fillability_10ms: fillability_10,
+            fillability_25ms: fillability_25,
+            survival_5ms: survival_5,
+            survival_10ms: survival_10,
+            survival_25ms: survival_25,
+            survival_probe_5ms: survival_probe_5,
+            survival_probe_10ms: survival_probe_10,
+            survival_probe_25ms: survival_probe_25,
+            survival_probe_5ms_n: survival_probe_5_n,
+            survival_probe_10ms_n: survival_probe_10_n,
+            survival_probe_25ms_n: survival_probe_25_n,
+            net_edge_p50_bps: net_edge_p50,
+            net_edge_p10_bps: net_edge_p10,
+            pnl_1s_p50_bps: pnl_1s_p50,
+            pnl_5s_p50_bps: pnl_5s_p50,
+            pnl_10s_p50_bps: pnl_10s_p50_raw,
+            pnl_10s_p50_bps_raw: pnl_10s_p50_raw,
+            pnl_10s_p50_bps_robust: pnl_10s_p50_robust,
+            net_markout_10s_usdc_p50,
+            roi_notional_10s_bps_p50,
+            pnl_10s_sample_count,
+            pnl_10s_outlier_ratio,
+            eligible_count,
+            executed_count,
+            executed_over_eligible,
+            ev_net_usdc_p50,
+            ev_net_usdc_p10,
+            ev_positive_ratio,
+            quote_block_ratio,
+            policy_block_ratio: policy_ratio,
+            gate_blocked,
+            gate_block_ratio,
+            queue_depth_p99: percentile(&queue_depth, 0.99).unwrap_or(0.0),
+            event_backlog_p99: percentile(&event_backlog, 0.99).unwrap_or(0.0),
+            tick_to_decision_p50_ms: latency.tick_to_decision_p50_ms,
+            tick_to_decision_p90_ms: latency.tick_to_decision_p90_ms,
+            tick_to_decision_p99_ms: latency.tick_to_decision_p99_ms,
+            decision_queue_wait_p99_ms: latency.decision_queue_wait_p99_ms,
+            decision_compute_p99_ms: latency.decision_compute_p99_ms,
+            source_latency_p99_ms: latency.source_latency_p99_ms,
+            exchange_lag_p99_ms: latency.exchange_lag_p99_ms,
+            path_lag_p99_ms: latency.path_lag_p99_ms,
+            local_backlog_p99_ms: latency.local_backlog_p99_ms,
+            lag_half_life_ms,
+            probability_total,
+            settlement_source_degraded_ratio,
+            settle_fast_delta_p50_bps,
+            settle_fast_delta_p90_bps,
+            probability_confidence_p50,
+            ack_only_p50_ms: latency.ack_only_p50_ms,
+            ack_only_p90_ms: latency.ack_only_p90_ms,
+            ack_only_p99_ms: latency.ack_only_p99_ms,
+            alpha_window_p50_ms: latency.alpha_window_p50_ms,
+            alpha_window_p90_ms: latency.alpha_window_p90_ms,
+            alpha_window_p99_ms: latency.alpha_window_p99_ms,
+            alpha_window_hit_ratio: latency.alpha_window_hit_ratio,
+            alpha_window_n: latency.alpha_window_n,
+            strategy_uptime_pct: uptime_pct,
+            tick_to_ack_p99_ms: tick_to_ack_p99,
+            ref_ticks_total,
+            book_ticks_total,
+            ref_freshness_ms,
+            book_freshness_ms,
+            book_top_lag_p50_ms,
+            book_top_lag_p90_ms,
+            book_top_lag_p99_ms,
+            book_top_lag_by_symbol_p50_ms,
+            survival_10ms_by_symbol,
+            survival_probe_10ms_by_symbol,
+            blocked_reason_counts,
+            policy_block_reason_distribution,
+            gate_block_reason_distribution,
+            source_mix_ratio,
+            udp_share_effective,
+            udp_local_drop_count,
+            share_cap_drop_count,
+            fallback_state,
+            fallback_trigger_reason_distribution,
+            source_health: Vec::new(),
+            exit_reason_top,
+            edge_model_version: "unknown".to_string(),
+            latency,
+            market_scorecard: scorecard,
+            predator_c_enabled,
+            direction_signals_up,
+            direction_signals_down,
+            direction_signals_neutral,
+            taker_sniper_fired,
+            taker_sniper_skipped,
+            predator_regime_active,
+            predator_regime_quiet,
+            predator_regime_defend,
+            predator_cross_symbol_fired,
+            taker_sniper_skip_reasons_top: skip_top,
+            last_30s_taker_fallback_count,
+            router_locked_by_tf_usdc,
+            capital_available_usdc: capital.available_usdc,
+            capital_base_quote_size: capital.base_quote_size,
+            capital_halt,
+        };
+        live.gate_fail_reasons =
+            gate_eval::compute_gate_fail_reasons(&live, Self::GATE_MIN_OUTCOMES);
+        live.gate_ready_strict = live.window_outcomes >= Self::GATE_MIN_OUTCOMES;
+        live.gate_ready_effective =
+            live.gate_ready_strict || live.eligible_count > 0 || live.executed_count > 0;
+        live.gate_ready = live.gate_ready_strict;
+        live
+    }
+
+    pub(crate) async fn build_final_report(&self) -> ShadowFinalReport {
+        let live = self.build_live_report().await;
+        let failed = live.gate_fail_reasons.clone();
+
+        let gate = GateEvaluation {
+            window_id: live.window_id,
+            gate_ready: live.gate_ready_strict,
+            min_outcomes: Self::GATE_MIN_OUTCOMES,
+            pass: failed.is_empty(),
+            data_valid_ratio: live.data_valid_ratio,
+            seq_gap_rate: live.seq_gap_rate,
+            ts_inversion_rate: live.ts_inversion_rate,
+            stale_tick_drop_ratio: live.stale_tick_drop_ratio,
+            fillability_10ms: live.fillability_10ms,
+            net_edge_p50_bps: live.net_edge_p50_bps,
+            net_edge_p10_bps: live.net_edge_p10_bps,
+            net_markout_10s_usdc_p50: live.net_markout_10s_usdc_p50,
+            roi_notional_10s_bps_p50: live.roi_notional_10s_bps_p50,
+            pnl_10s_p50_bps_raw: live.pnl_10s_p50_bps_raw,
+            pnl_10s_p50_bps_robust: live.pnl_10s_p50_bps_robust,
+            pnl_10s_sample_count: live.pnl_10s_sample_count,
+            pnl_10s_outlier_ratio: live.pnl_10s_outlier_ratio,
+            eligible_count: live.eligible_count,
+            executed_count: live.executed_count,
+            executed_over_eligible: live.executed_over_eligible,
+            ev_net_usdc_p50: live.ev_net_usdc_p50,
+            ev_net_usdc_p10: live.ev_net_usdc_p10,
+            ev_positive_ratio: live.ev_positive_ratio,
+            quote_block_ratio: live.quote_block_ratio,
+            policy_block_ratio: live.policy_block_ratio,
+            gate_blocked: live.gate_blocked,
+            gate_block_ratio: live.gate_block_ratio,
+            strategy_uptime_pct: live.strategy_uptime_pct,
+            tick_to_ack_p99_ms: live.tick_to_ack_p99_ms,
+            decision_queue_wait_p99_ms: live.decision_queue_wait_p99_ms,
+            decision_compute_p99_ms: live.decision_compute_p99_ms,
+            source_latency_p99_ms: live.latency.source_latency_p99_ms,
+            exchange_lag_p99_ms: live.latency.exchange_lag_p99_ms,
+            path_lag_p99_ms: live.latency.path_lag_p99_ms,
+            local_backlog_p99_ms: live.latency.local_backlog_p99_ms,
+            failed_reasons: failed,
+        };
+        ShadowFinalReport { live, gate }
+    }
+
+    pub(crate) async fn build_engine_pnl_report(&self) -> EnginePnlReport {
+        const PRIMARY_DELAY_MS: u64 = 10;
+        let shots = self.shots.read().await.clone();
+        let outcomes = self.outcomes.read().await.clone();
+        let mut style_by_shot = HashMap::<String, ExecutionStyle>::new();
+        for shot in shots.iter().filter(|s| s.delay_ms == PRIMARY_DELAY_MS) {
+            style_by_shot.insert(shot.shot_id.clone(), shot.execution_style.clone());
+        }
+
+        let mut maker = Vec::<f64>::new();
+        let mut taker = Vec::<f64>::new();
+        let mut arb = Vec::<f64>::new();
+
+        for outcome in outcomes
+            .iter()
+            .filter(|o| o.delay_ms == PRIMARY_DELAY_MS && !o.is_stale_tick)
+        {
+            let Some(markout) = outcome.net_markout_10s_usdc else {
+                continue;
+            };
+            let style = style_by_shot
+                .get(&outcome.shot_id)
+                .cloned()
+                .unwrap_or_else(|| outcome.execution_style.clone());
+            match style {
+                ExecutionStyle::Maker => maker.push(markout),
+                ExecutionStyle::Taker => taker.push(markout),
+                ExecutionStyle::Arb => arb.push(markout),
+            }
+        }
+
+        let maker_total = maker.iter().sum::<f64>();
+        let taker_total = taker.iter().sum::<f64>();
+        let arb_total = arb.iter().sum::<f64>();
+
+        EnginePnlReport {
+            window_id: self.window_id.load(Ordering::Relaxed),
+            breakdown: EnginePnLBreakdown {
+                maker_usdc: maker_total,
+                taker_usdc: taker_total,
+                arb_usdc: arb_total,
+            },
+            rows: vec![
+                build_engine_pnl_row("maker", &maker),
+                build_engine_pnl_row("taker", &taker),
+                build_engine_pnl_row("arb", &arb),
+            ],
+        }
+    }
+}
+
+pub(crate) fn build_engine_pnl_row(engine: &str, values: &[f64]) -> EnginePnlRow {
+    let samples = values.len();
+    let total_usdc = values.iter().sum::<f64>();
+    let p50_usdc = percentile(values, 0.50).unwrap_or(0.0);
+    let p10_usdc = percentile(values, 0.10).unwrap_or(0.0);
+    let positive_ratio = if values.is_empty() {
+        0.0
+    } else {
+        values.iter().filter(|v| **v > 0.0).count() as f64 / values.len() as f64
+    };
+    EnginePnlRow {
+        engine: engine.to_string(),
+        samples,
+        total_usdc,
+        p50_usdc,
+        p10_usdc,
+        positive_ratio,
+    }
+}
diff --git a/crates/app_runner/src/stats_utils.rs b/crates/app_runner/src/stats_utils.rs
index d7ab368..67f6a22 100644
--- a/crates/app_runner/src/stats_utils.rs
+++ b/crates/app_runner/src/stats_utils.rs
@@ -1,4 +1,5 @@
 use chrono::Utc;
+use std::cmp::Ordering;
 use std::collections::VecDeque;
 
 pub fn push_capped<T>(dst: &mut Vec<T>, value: T, cap: usize) {
@@ -19,15 +20,20 @@ pub fn percentile(values: &[f64], p: f64) -> Option<f64> {
     v.get(idx).copied()
 }
 
-pub fn percentile_deque(values: &VecDeque<f64>, p: f64) -> Option<f64> {
+pub fn percentile_deque_capped(values: &VecDeque<f64>, p: f64, cap: usize) -> Option<f64> {
     if values.is_empty() {
         return None;
     }
-    // Avoid calling `percentile(&vec)` which would clone again internally.
-    let mut v: Vec<f64> = values.iter().copied().collect();
-    v.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
+    let n = values.len().min(cap.max(1));
+    if n == 0 {
+        return None;
+    }
+    // Most recent samples are more relevant; take from the back.
+    let mut v: Vec<f64> = values.iter().rev().take(n).copied().collect();
     let idx = ((v.len() as f64 - 1.0) * p.clamp(0.0, 1.0)).round() as usize;
-    v.get(idx).copied()
+    let (_, nth, _) =
+        v.select_nth_unstable_by(idx, |a, b| a.partial_cmp(b).unwrap_or(Ordering::Equal));
+    Some(*nth)
 }
 
 pub fn robust_filter_iqr(values: &[f64]) -> (Vec<f64>, f64) {
diff --git a/crates/app_runner/src/strategy_policy.rs b/crates/app_runner/src/strategy_policy.rs
new file mode 100644
index 0000000..d76e6ad
--- /dev/null
+++ b/crates/app_runner/src/strategy_policy.rs
@@ -0,0 +1,447 @@
+use std::collections::HashMap;
+use std::sync::Arc;
+use std::sync::OnceLock;
+
+use core_types::{
+    BookTop, InventoryState, OrderSide, ShadowShot, TimeframeClass, ToxicDecision, ToxicFeatures,
+    ToxicRegime,
+};
+use portfolio::PortfolioBook;
+use risk_engine::RiskLimits;
+use strategy_maker::MakerConfig;
+
+use crate::state::{EdgeModelConfig, EngineShared, MarketToxicState, ToxicityConfig};
+use crate::stats_utils::{now_ns, percentile, percentile_deque_capped};
+
+pub(super) fn inventory_for_market(portfolio: &PortfolioBook, market_id: &str) -> InventoryState {
+    let positions = portfolio.positions();
+    if let Some(pos) = positions.get(market_id) {
+        InventoryState {
+            market_id: market_id.to_string(),
+            net_yes: pos.yes,
+            net_no: pos.no,
+            exposure_notional: pos.yes.abs() + pos.no.abs(),
+        }
+    } else {
+        InventoryState {
+            market_id: market_id.to_string(),
+            net_yes: 0.0,
+            net_no: 0.0,
+            exposure_notional: 0.0,
+        }
+    }
+}
+pub(super) fn build_toxic_features(
+    book: &BookTop,
+    symbol: &str,
+    stale_ms: f64,
+    fair_yes: f64,
+    attempted: u64,
+    no_quote: u64,
+    markout_1s_p50: f64,
+    markout_5s_p50: f64,
+    markout_10s_p50: f64,
+) -> ToxicFeatures {
+    let mid_yes = ((book.bid_yes + book.ask_yes) * 0.5).max(0.0001);
+    let spread_bps = ((book.ask_yes - book.bid_yes).max(0.0) / mid_yes) * 10_000.0;
+    let microprice_drift = fair_yes - mid_yes;
+    let imbalance_den = (book.bid_yes + book.ask_yes + book.bid_no + book.ask_no).abs();
+    let imbalance = if imbalance_den <= 1e-12 {
+        0.0
+    } else {
+        ((book.bid_yes + book.ask_no) - (book.ask_yes + book.bid_no)) / imbalance_den
+    };
+    let attempted = attempted.max(1);
+    let cancel_burst = (no_quote as f64 / attempted as f64).clamp(0.0, 1.0);
+
+    ToxicFeatures {
+        market_id: book.market_id.clone(),
+        symbol: symbol.to_string(),
+        markout_1s: markout_1s_p50,
+        markout_5s: markout_5s_p50,
+        markout_10s: markout_10s_p50,
+        spread_bps,
+        microprice_drift,
+        stale_ms,
+        imbalance,
+        cancel_burst,
+        ts_ns: now_ns(),
+    }
+}
+
+pub(super) fn evaluate_toxicity(features: &ToxicFeatures, cfg: &ToxicityConfig) -> ToxicDecision {
+    let neg_markout_1s = (-features.markout_1s).max(0.0) / 20.0;
+    let neg_markout_5s = (-features.markout_5s).max(0.0) / 20.0;
+    let neg_markout_10s = (-features.markout_10s).max(0.0) / 20.0;
+    let spread_z = features.spread_bps / 50.0;
+    let microprice_drift_z = (features.microprice_drift.abs() * 10_000.0) / 20.0;
+    let stale_z = features.stale_ms / 1_500.0;
+    let raw = cfg.w1 * neg_markout_1s
+        + cfg.w2 * neg_markout_5s
+        + cfg.w3 * neg_markout_10s
+        + cfg.w4 * spread_z
+        + cfg.w5 * microprice_drift_z
+        + cfg.w6 * stale_z;
+    let markout_1s_danger = features.markout_1s <= cfg.markout_1s_danger_bps;
+    let markout_5s_danger = features.markout_5s <= cfg.markout_5s_danger_bps;
+    let markout_10s_danger = features.markout_10s <= cfg.markout_10s_danger_bps;
+    let markout_1s_caution = features.markout_1s <= cfg.markout_1s_caution_bps;
+    let markout_5s_caution = features.markout_5s <= cfg.markout_5s_caution_bps;
+    let markout_10s_caution = features.markout_10s <= cfg.markout_10s_caution_bps;
+
+    let mut horizon_boost = 0.0;
+    if markout_1s_danger {
+        horizon_boost += 0.30;
+    } else if markout_1s_caution {
+        horizon_boost += 0.15;
+    }
+    if markout_5s_danger {
+        horizon_boost += 0.25;
+    } else if markout_5s_caution {
+        horizon_boost += 0.12;
+    }
+    if markout_10s_danger {
+        horizon_boost += 0.20;
+    } else if markout_10s_caution {
+        horizon_boost += 0.10;
+    }
+    let tox_score = (sigmoid(raw) + horizon_boost).clamp(0.0, 1.0);
+
+    let mut reasons = Vec::new();
+    if markout_1s_danger {
+        reasons.push("markout_1s_danger".to_string());
+    } else if markout_1s_caution {
+        reasons.push("markout_1s_caution".to_string());
+    } else if features.markout_1s < 0.0 {
+        reasons.push("markout_1s_negative".to_string());
+    }
+    if markout_5s_danger {
+        reasons.push("markout_5s_danger".to_string());
+    } else if markout_5s_caution {
+        reasons.push("markout_5s_caution".to_string());
+    } else if features.markout_5s < 0.0 {
+        reasons.push("markout_5s_negative".to_string());
+    }
+    if markout_10s_danger {
+        reasons.push("markout_10s_danger".to_string());
+    } else if markout_10s_caution {
+        reasons.push("markout_10s_caution".to_string());
+    } else if features.markout_10s < 0.0 {
+        reasons.push("markout_10s_negative".to_string());
+    }
+    if features.spread_bps > 60.0 {
+        reasons.push("spread_wide".to_string());
+    }
+    if features.stale_ms > 1_500.0 {
+        reasons.push("stale_feed".to_string());
+    }
+    if reasons.is_empty() {
+        reasons.push("normal".to_string());
+    }
+
+    let regime = if markout_1s_danger || markout_5s_danger || markout_10s_danger {
+        ToxicRegime::Danger
+    } else if markout_1s_caution || markout_5s_caution || markout_10s_caution {
+        ToxicRegime::Caution
+    } else if tox_score >= cfg.caution_threshold {
+        ToxicRegime::Danger
+    } else if tox_score >= cfg.safe_threshold {
+        ToxicRegime::Caution
+    } else {
+        ToxicRegime::Safe
+    };
+
+    ToxicDecision {
+        market_id: features.market_id.clone(),
+        symbol: features.symbol.clone(),
+        tox_score,
+        regime,
+        reason_codes: reasons,
+        ts_ns: now_ns(),
+    }
+}
+
+pub(super) fn compute_market_score(
+    state: &MarketToxicState,
+    tox_score: f64,
+    markout_samples: usize,
+) -> f64 {
+    let attempted = state.attempted.max(1);
+    let no_quote_rate = state.no_quote as f64 / attempted as f64;
+    let symbol_missing_rate = state.symbol_missing as f64 / attempted as f64;
+    let markout_10s = percentile_deque_capped(&state.markout_10s, 0.50, 2048).unwrap_or(0.0);
+    if markout_samples < 20 {
+        let warmup_score = 80.0 - no_quote_rate * 6.0 - symbol_missing_rate * 6.0;
+        return warmup_score.clamp(45.0, 100.0);
+    }
+    let score = 70.0 + (markout_10s * 1.5).clamp(-30.0, 30.0)
+        - no_quote_rate * 25.0
+        - symbol_missing_rate * 30.0
+        - tox_score * 20.0;
+    score.clamp(0.0, 100.0)
+}
+
+pub(super) fn compute_market_score_from_snapshot(
+    attempted: u64,
+    no_quote: u64,
+    symbol_missing: u64,
+    tox_score: f64,
+    markout_samples: usize,
+    markout_10s_p50: f64,
+) -> f64 {
+    let attempted = attempted.max(1);
+    let no_quote_rate = no_quote as f64 / attempted as f64;
+    let symbol_missing_rate = symbol_missing as f64 / attempted as f64;
+    if markout_samples < 20 {
+        let warmup_score = 80.0 - no_quote_rate * 6.0 - symbol_missing_rate * 6.0;
+        return warmup_score.clamp(45.0, 100.0);
+    }
+    let score = 70.0 + (markout_10s_p50 * 1.5).clamp(-30.0, 30.0)
+        - no_quote_rate * 25.0
+        - symbol_missing_rate * 30.0
+        - tox_score * 20.0;
+    score.clamp(0.0, 100.0)
+}
+
+pub(super) fn non_risk_gate_relax_ratio() -> f64 {
+    static RELAX_RATIO: OnceLock<f64> = OnceLock::new();
+    *RELAX_RATIO.get_or_init(|| {
+        std::env::var("POLYEDGE_NON_RISK_GATE_RELAX_RATIO")
+            .ok()
+            .and_then(|v| v.parse::<f64>().ok())
+            .unwrap_or(0.85)
+            .clamp(0.50, 1.0)
+    })
+}
+
+pub(super) fn edge_gate_bps(
+    cfg: &EdgeModelConfig,
+    tox_score: f64,
+    local_backlog_ms: f64,
+    source_latency_ms: f64,
+    no_quote_rate: f64,
+) -> f64 {
+    if !cfg.gate_mode.eq_ignore_ascii_case("dynamic") {
+        return cfg.base_gate_bps.max(0.0);
+    }
+    let congestion = cfg.congestion_penalty_bps * no_quote_rate.clamp(0.0, 1.0);
+    let latency = cfg.latency_penalty_bps
+        * ((local_backlog_ms / 100.0).clamp(0.0, 1.0)
+            + (source_latency_ms / 800.0).clamp(0.0, 1.0));
+    let tox = cfg.fail_cost_bps * tox_score.clamp(0.0, 1.0);
+    (cfg.base_gate_bps + congestion + latency + tox).max(0.0)
+}
+
+pub(super) fn adaptive_max_spread(
+    base_max_spread: f64,
+    tox_score: f64,
+    markout_samples: usize,
+) -> f64 {
+    let relax_ratio = non_risk_gate_relax_ratio();
+    if markout_samples < 20 {
+        return (base_max_spread * (1.2 + (1.0 - relax_ratio) * 0.5)).clamp(0.003, 0.08);
+    }
+    (base_max_spread * (1.0 - tox_score * 0.35 + (1.0 - relax_ratio) * 0.2))
+        .clamp(0.002, base_max_spread * 1.15)
+}
+
+pub(super) async fn timeframe_weight(
+    shared: &Arc<EngineShared>,
+    timeframe: &TimeframeClass,
+) -> f64 {
+    let baseline = match timeframe {
+        TimeframeClass::Tf5m | TimeframeClass::Tf15m => 1.0,
+        TimeframeClass::Tf1h => 0.35,
+        TimeframeClass::Tf1d => 0.20,
+    };
+    if matches!(timeframe, TimeframeClass::Tf5m | TimeframeClass::Tf15m) {
+        return baseline;
+    }
+
+    let outcomes = shared.shadow_stats.outcomes.read().await;
+    if outcomes.is_empty() {
+        return baseline;
+    }
+    let market_tf = shared.market_to_timeframe.read().await;
+    let mut markouts = Vec::new();
+    for o in outcomes.iter().rev() {
+        if o.delay_ms != 10 || !o.fillable {
+            continue;
+        }
+        let Some(tf) = market_tf.get(&o.market_id) else {
+            continue;
+        };
+        if tf != timeframe {
+            continue;
+        }
+        if let Some(v) = o.net_markout_10s_bps {
+            markouts.push(v);
+        }
+        if markouts.len() >= 200 {
+            break;
+        }
+    }
+
+    if markouts.len() < 30 {
+        return baseline;
+    }
+    let p50 = percentile(&markouts, 0.50).unwrap_or(0.0);
+    if p50 <= -8.0 {
+        0.05
+    } else if p50 <= -2.0 {
+        0.12
+    } else if p50 <= 0.0 {
+        0.20
+    } else if p50 <= 3.0 {
+        baseline
+    } else {
+        (baseline * 1.4).clamp(0.0, 1.0)
+    }
+}
+
+pub(super) fn should_observe_only_symbol(
+    symbol: &str,
+    cfg: &MakerConfig,
+    tox: &ToxicDecision,
+    stale_ms: f64,
+    spread_yes: f64,
+    book_top_lag_ms: f64,
+) -> bool {
+    if !symbol.eq_ignore_ascii_case("SOLUSDT") {
+        return false;
+    }
+    let profile = cfg.market_tier_profile.to_ascii_lowercase();
+    if !(profile.contains("sol_guard") || profile.contains("balanced")) {
+        return false;
+    }
+
+    // Keep SOL observe-only unless the local "ref lead vs book" lag is within a tight bound.
+    // This avoids letting one slow/volatile venue degrade the overall engine quality.
+    let relax = (1.0 - non_risk_gate_relax_ratio()).clamp(0.0, 0.5);
+    let lag_guard_ms = 130.0 + 80.0 * relax;
+    let stale_guard_ms = 250.0 + 120.0 * relax;
+    let spread_guard = 0.020 + 0.006 * relax;
+    book_top_lag_ms > lag_guard_ms
+        || matches!(tox.regime, ToxicRegime::Danger)
+        || stale_ms > stale_guard_ms
+        || spread_yes > spread_guard
+}
+
+pub(super) fn estimate_queue_fill_proxy(tox_score: f64, spread_yes: f64, stale_ms: f64) -> f64 {
+    let spread_pen = (spread_yes / 0.03).clamp(0.0, 1.0);
+    let latency_pen = (stale_ms / 800.0).clamp(0.0, 1.0);
+    (1.0 - (tox_score * 0.45 + spread_pen * 0.35 + latency_pen * 0.20)).clamp(0.0, 1.0)
+}
+
+pub(super) fn estimate_queue_fill_prob(shot: &ShadowShot, book: &BookTop, latency_ms: f64) -> f64 {
+    let spread = match shot.side {
+        OrderSide::BuyYes | OrderSide::SellYes => (book.ask_yes - book.bid_yes).max(0.0),
+        OrderSide::BuyNo | OrderSide::SellNo => (book.ask_no - book.bid_no).max(0.0),
+    };
+    let spread_pen = (spread / 0.03).clamp(0.0, 1.0);
+    // P3: è°ƒæ•´ delay_pen åˆ†æ¯ä»Ž 25 åˆ° 50ï¼Œå‡å°‘å»¶è¿Ÿæƒ©ç½šæƒé‡
+    let delay_pen = (shot.delay_ms as f64 / 50.0).clamp(0.0, 1.0);
+    let latency_pen = (latency_ms / 100.0).clamp(0.0, 1.0);
+    (1.0 - (shot.tox_score * 0.35 + spread_pen * 0.30 + delay_pen * 0.20 + latency_pen * 0.15))
+        .clamp(0.0, 1.0)
+}
+
+pub(super) fn is_market_in_top_n(
+    states: &HashMap<String, MarketToxicState>,
+    market_id: &str,
+    top_n: usize,
+) -> bool {
+    if top_n == 0 {
+        return true;
+    }
+    if states.is_empty() {
+        return true;
+    }
+    let Some(target) = states.get(market_id) else {
+        return false;
+    };
+    let target_score = target.market_score;
+
+    // O(n) rank check without heap allocations/sorting.
+    let better = states
+        .iter()
+        .filter(|(id, st)| {
+            st.market_score > target_score
+                || (st.market_score == target_score && id.as_str() < market_id)
+        })
+        .count();
+    better < top_n.max(1)
+}
+
+pub(super) fn cooldown_secs_for_score(tox_score: f64, cfg: &ToxicityConfig) -> u64 {
+    let t = tox_score.clamp(0.0, 1.0);
+    ((cfg.cooldown_min_sec as f64)
+        + ((cfg.cooldown_max_sec as f64) - (cfg.cooldown_min_sec as f64)) * t)
+        .round() as u64
+}
+
+pub(super) fn adaptive_size_scale(
+    drawdown_pct: f64,
+    market_notional: f64,
+    asset_notional: f64,
+    limits: &RiskLimits,
+    tox_score: f64,
+    tox_regime: &ToxicRegime,
+) -> f64 {
+    let dd_cap = limits.max_drawdown_pct.abs().max(0.01);
+    let dd_ratio = (drawdown_pct.abs() / dd_cap).clamp(0.0, 1.0);
+    let drawdown_scale = (1.0 - 0.75 * dd_ratio).clamp(0.25, 1.0);
+
+    let market_util = if limits.max_market_notional > 0.0 {
+        (market_notional.max(0.0) / limits.max_market_notional).clamp(0.0, 2.0)
+    } else {
+        1.0
+    };
+    let asset_util = if limits.max_asset_notional > 0.0 {
+        (asset_notional.max(0.0) / limits.max_asset_notional).clamp(0.0, 2.0)
+    } else {
+        1.0
+    };
+    let util = market_util.max(asset_util);
+    let exposure_scale = (1.0 - 0.80 * util).clamp(0.20, 1.0);
+
+    let regime_scale = match tox_regime {
+        ToxicRegime::Safe => 1.0,
+        ToxicRegime::Caution => 0.70,
+        ToxicRegime::Danger => 0.40,
+    };
+    let tox_scale = (regime_scale * (1.0 - 0.35 * tox_score.clamp(0.0, 1.0))).clamp(0.20, 1.0);
+
+    (drawdown_scale * exposure_scale * tox_scale).clamp(0.05, 1.0)
+}
+
+pub(super) fn net_markout(markout_bps: Option<f64>, shot: &ShadowShot) -> Option<f64> {
+    markout_bps.map(|v| v - shot.fee_paid_bps + shot.rebate_est_bps)
+}
+
+pub(super) fn estimate_entry_notional_usdc(shot: &ShadowShot) -> f64 {
+    (shot.intended_price.max(0.0) * shot.size.max(0.0)).max(0.0)
+}
+
+pub(super) fn bps_to_usdc(bps: Option<f64>, notional_usdc: f64) -> Option<f64> {
+    if notional_usdc <= 0.0 {
+        return None;
+    }
+    bps.map(|v| (v / 10_000.0) * notional_usdc)
+}
+
+pub(super) fn roi_bps_from_usdc(markout_usdc: Option<f64>, notional_usdc: f64) -> Option<f64> {
+    if notional_usdc <= 0.0 {
+        return None;
+    }
+    markout_usdc.map(|v| (v / notional_usdc) * 10_000.0)
+}
+
+pub(super) fn sigmoid(x: f64) -> f64 {
+    if x >= 0.0 {
+        1.0 / (1.0 + (-x).exp())
+    } else {
+        let ex = x.exp();
+        ex / (1.0 + ex)
+    }
+}
diff --git a/crates/app_runner/src/strategy_runtime.rs b/crates/app_runner/src/strategy_runtime.rs
new file mode 100644
index 0000000..237bb1c
--- /dev/null
+++ b/crates/app_runner/src/strategy_runtime.rs
@@ -0,0 +1,1950 @@
+use std::collections::HashMap;
+use std::sync::Arc;
+use std::time::{Duration, Instant};
+
+use core_types::{
+    new_id, BookTop, Direction, DirectionSignal, EngineEvent, ExecutionStyle, ExecutionVenue,
+    OrderAck, OrderIntentV2, OrderSide, OrderTimeInForce, PaperAction, QuoteIntent, Regime,
+    RiskContext, RiskManager, ShadowShot, SourceHealth, Stage, TimeframeClass, TimeframeOpp,
+    ToxicRegime,
+};
+use execution_clob::ClobExecution;
+use exit_manager::PositionLifecycle;
+use infra_bus::RingBus;
+use paper_executor::ShadowExecutor;
+use portfolio::PortfolioBook;
+use risk_engine::RiskLimits;
+use strategy_maker::MakerConfig;
+use taker_sniper::{FirePlan, TakerAction};
+
+use crate::engine_core::{classify_execution_error_reason, normalize_reject_code};
+use crate::paper_runtime::{global_paper_runtime, PaperIntentCtx};
+use crate::execution_eval::{
+    aggressive_price_for_side, edge_gross_bps_for_side, get_fee_rate_bps_cached,
+    get_rebate_bps_cached, mid_for_side, prebuild_order_payload, spread_for_side,
+};
+use crate::feed_runtime::settlement_prob_yes_for_symbol;
+use crate::fusion_engine::TokenBucket;
+use crate::state::{
+    EngineShared, PredatorCConfig, PredatorCPriority, PredatorRegimeConfig, SourceHealthConfig,
+    V52DualArbConfig, V52ExecutionConfig, V52TimePhaseConfig,
+};
+use crate::stats_utils::{freshness_ms, now_ns};
+use crate::strategy_policy::{
+    adaptive_size_scale, edge_gate_bps, inventory_for_market, timeframe_weight,
+};
+use crate::{
+    publish_if_telemetry_subscribers, spawn_predator_exit_lifecycle, spawn_detached,
+    spawn_shadow_outcome_task, PredatorExecResult,
+};
+
+#[derive(Debug, Clone, Copy, PartialEq, Eq)]
+pub(crate) enum TimePhase {
+    Early,
+    Maturity,
+    Late,
+}
+
+pub(crate) fn timeframe_total_ms(timeframe: TimeframeClass) -> Option<i64> {
+    match timeframe {
+        TimeframeClass::Tf5m => Some(300_000),
+        TimeframeClass::Tf15m => Some(900_000),
+        _ => None,
+    }
+}
+
+fn timeframe_tag(timeframe: TimeframeClass) -> &'static str {
+    match timeframe {
+        TimeframeClass::Tf5m => "5m",
+        TimeframeClass::Tf15m => "15m",
+        TimeframeClass::Tf1h => "1h",
+        TimeframeClass::Tf1d => "1d",
+    }
+}
+
+pub(crate) fn classify_time_phase(remaining_ratio: f64, cfg: &V52TimePhaseConfig) -> TimePhase {
+    if remaining_ratio <= cfg.late_max_ratio {
+        TimePhase::Late
+    } else if remaining_ratio <= cfg.early_min_ratio {
+        TimePhase::Maturity
+    } else {
+        TimePhase::Early
+    }
+}
+
+pub(crate) fn time_phase_size_scale(phase: TimePhase, cfg: &V52TimePhaseConfig) -> f64 {
+    let scale = match phase {
+        TimePhase::Early => cfg.early_size_scale,
+        TimePhase::Maturity => cfg.maturity_size_scale,
+        TimePhase::Late => cfg.late_size_scale,
+    };
+    scale.clamp(0.10, 5.0)
+}
+
+pub(crate) fn stage_for_phase(phase: TimePhase, momentum: bool) -> Stage {
+    match phase {
+        TimePhase::Early => Stage::Early,
+        TimePhase::Late => Stage::Late,
+        TimePhase::Maturity => {
+            if momentum {
+                Stage::Momentum
+            } else {
+                Stage::Maturity
+            }
+        }
+    }
+}
+
+pub(crate) fn allow_dual_side_arb(
+    yes_price: f64,
+    no_price: f64,
+    fee_rate_bps: f64,
+    cfg: &V52DualArbConfig,
+) -> bool {
+    if !cfg.enabled {
+        return false;
+    }
+    let fee_buffer = (fee_rate_bps.max(0.0) / 10_000.0).max(0.0);
+    let safety_margin = (cfg.safety_margin_bps.max(0.0) / 10_000.0).max(0.0);
+    yes_price + no_price + fee_buffer + safety_margin < cfg.threshold
+}
+
+fn side_to_direction(side: &OrderSide) -> Direction {
+    match side {
+        OrderSide::BuyYes | OrderSide::SellNo => Direction::Up,
+        OrderSide::BuyNo | OrderSide::SellYes => Direction::Down,
+    }
+}
+
+fn direction_signal_for_side(base: &DirectionSignal, side: &OrderSide) -> DirectionSignal {
+    let mut out = base.clone();
+    out.direction = side_to_direction(side);
+    out
+}
+
+pub(crate) fn should_force_taker_fallback(
+    phase: TimePhase,
+    time_to_expiry_ms: i64,
+    cfg: &V52ExecutionConfig,
+) -> bool {
+    let force_in_phase = match phase {
+        TimePhase::Early => false,
+        TimePhase::Maturity => cfg.apply_force_taker_in_maturity,
+        TimePhase::Late => cfg.apply_force_taker_in_late,
+    };
+    force_in_phase && time_to_expiry_ms <= cfg.late_force_taker_remaining_ms as i64
+}
+
+fn spawn_force_taker_fallback_for_maker(
+    shared: Arc<EngineShared>,
+    execution: Arc<ClobExecution>,
+    shadow: Arc<ShadowExecutor>,
+    market_id: String,
+    token_id: String,
+    side: OrderSide,
+    size: f64,
+    ttl_ms: u64,
+    maker_order_id: String,
+    fee_rate_bps: f64,
+    expected_edge_net_bps: f64,
+    timeframe: TimeframeClass,
+    force_remaining_ms: u64,
+    maker_wait_ms: u64,
+    taker_max_slippage_bps: f64,
+) {
+    spawn_detached("v52_force_taker_fallback", false, async move {
+        if maker_wait_ms > 0 {
+            tokio::time::sleep(Duration::from_millis(maker_wait_ms)).await;
+        }
+        let Some(frame_total_ms) = timeframe_total_ms(timeframe) else {
+            return;
+        };
+        let threshold = force_remaining_ms as i64;
+        loop {
+            if !execution.has_open_order(&maker_order_id) {
+                return;
+            }
+            let now_ms = chrono::Utc::now().timestamp_millis();
+            let remain_ms = (frame_total_ms - now_ms.rem_euclid(frame_total_ms)).max(0);
+            if remain_ms <= threshold {
+                break;
+            }
+            let sleep_ms = (remain_ms - threshold).clamp(25, 250) as u64;
+            tokio::time::sleep(Duration::from_millis(sleep_ms)).await;
+        }
+        if !execution.has_open_order(&maker_order_id) {
+            return;
+        }
+        if execution.cancel_order(&maker_order_id, &market_id).await.is_err() {
+            return;
+        }
+        shadow.cancel(&maker_order_id);
+        let book = shared.latest_books.read().await.get(&market_id).cloned();
+        let Some(book) = book else {
+            return;
+        };
+        let taker_price = aggressive_price_for_side(&book, &side);
+        if !taker_price.is_finite() || taker_price <= 0.0 {
+            return;
+        }
+        let order = OrderIntentV2 {
+            market_id: market_id.clone(),
+            token_id: Some(token_id),
+            side: side.clone(),
+            price: taker_price,
+            size: size.max(0.01),
+            ttl_ms: ttl_ms.min(150),
+            style: ExecutionStyle::Taker,
+            tif: OrderTimeInForce::Fak,
+            max_slippage_bps: taker_max_slippage_bps.max(0.0),
+            fee_rate_bps,
+            expected_edge_net_bps,
+            client_order_id: Some(new_id()),
+            hold_to_resolution: false,
+            prebuilt_payload: None,
+        };
+        match execution.place_order_v2(order).await {
+            Ok(ack) if ack.accepted => {
+                shared.shadow_stats.mark_predator_last_30s_taker_fallback();
+                shared.shadow_stats.mark_executed();
+                let ack_event = OrderAck {
+                    order_id: ack.order_id,
+                    market_id: ack.market_id,
+                    accepted: true,
+                    ts_ms: ack.ts_ms,
+                };
+                shadow.register_order(
+                    &ack_event,
+                    QuoteIntent {
+                        market_id,
+                        side,
+                        price: taker_price,
+                        size: size.max(0.01),
+                        ttl_ms: ttl_ms.min(150),
+                    },
+                    ExecutionStyle::Taker,
+                    ((book.bid_yes + book.ask_yes) * 0.5).max(0.0),
+                    fee_rate_bps.max(0.0),
+                );
+            }
+            _ => {}
+        }
+    });
+}
+
+fn spawn_alpha_window_probe(
+    shared: Arc<EngineShared>,
+    market_id: String,
+    side: OrderSide,
+    anchor_price: f64,
+    move_bps: f64,
+    poll_ms: u64,
+    max_wait_ms: u64,
+) {
+    if !anchor_price.is_finite() || anchor_price <= 0.0 {
+        return;
+    }
+    let move_abs = (anchor_price * (move_bps.max(0.0) / 10_000.0)).max(1e-6);
+    let poll_ms = poll_ms.clamp(1, 200);
+    let max_wait_ms = max_wait_ms.clamp(50, 5_000);
+
+    spawn_detached("v52_alpha_window_probe", false, async move {
+        let started = Instant::now();
+        loop {
+            let elapsed_ms = started.elapsed().as_secs_f64() * 1_000.0;
+            let current_price = shared
+                .latest_books
+                .read()
+                .await
+                .get(&market_id)
+                .map(|book| aggressive_price_for_side(book, &side))
+                .unwrap_or(0.0);
+            if current_price.is_finite() && current_price > 0.0 {
+                let delta = (current_price - anchor_price).abs();
+                if delta >= move_abs {
+                    shared
+                        .shadow_stats
+                        .push_alpha_window_sample(elapsed_ms, true)
+                        .await;
+                    metrics::histogram!("latency.alpha_window_ms").record(elapsed_ms);
+                    return;
+                }
+            }
+            if elapsed_ms >= max_wait_ms as f64 {
+                let capped = max_wait_ms as f64;
+                shared
+                    .shadow_stats
+                    .push_alpha_window_sample(capped, false)
+                    .await;
+                metrics::histogram!("latency.alpha_window_ms").record(capped);
+                return;
+            }
+            tokio::time::sleep(Duration::from_millis(poll_ms)).await;
+        }
+    });
+}
+
+pub(super) async fn evaluate_and_route_v52(
+    shared: &Arc<EngineShared>,
+    bus: &RingBus<EngineEvent>,
+    portfolio: &Arc<PortfolioBook>,
+    execution: &Arc<ClobExecution>,
+    shadow: &Arc<ShadowExecutor>,
+    market_rate_budget: &mut HashMap<String, TokenBucket>,
+    global_rate_budget: &mut TokenBucket,
+    predator_cfg: &PredatorCConfig,
+    symbol: &str,
+    tick_fast_recv_ts_ms: i64,
+    tick_fast_recv_ts_local_ns: i64,
+    now_ms: i64,
+    direction_override: Option<DirectionSignal>,
+) -> PredatorExecResult {
+    let mut total = run_predator_c_for_symbol(
+        shared,
+        bus,
+        portfolio,
+        execution,
+        shadow,
+        market_rate_budget,
+        global_rate_budget,
+        predator_cfg,
+        symbol,
+        tick_fast_recv_ts_ms,
+        tick_fast_recv_ts_local_ns,
+        now_ms,
+        direction_override.clone(),
+    )
+    .await;
+
+    let leader_direction = if let Some(sig) = direction_override {
+        Some(sig)
+    } else {
+        shared
+            .predator_latest_direction
+            .read()
+            .await
+            .get(symbol)
+            .cloned()
+    };
+    if let Some(leader_direction) = leader_direction {
+        let cross_res = run_predator_c_cross_symbol(
+            shared,
+            bus,
+            portfolio,
+            execution,
+            shadow,
+            market_rate_budget,
+            global_rate_budget,
+            predator_cfg,
+            &leader_direction,
+            tick_fast_recv_ts_ms,
+            tick_fast_recv_ts_local_ns,
+            now_ms,
+        )
+        .await;
+        total.attempted = total.attempted.saturating_add(cross_res.attempted);
+        total.executed = total.executed.saturating_add(cross_res.executed);
+    }
+    if predator_cfg.strategy_d.enabled {
+        let d_res = run_predator_d_for_symbol(
+            shared,
+            bus,
+            portfolio,
+            execution,
+            shadow,
+            market_rate_budget,
+            global_rate_budget,
+            predator_cfg,
+            symbol,
+            tick_fast_recv_ts_ms,
+            tick_fast_recv_ts_local_ns,
+            now_ms,
+        )
+        .await;
+        total.attempted = total.attempted.saturating_add(d_res.attempted);
+        total.executed = total.executed.saturating_add(d_res.executed);
+    }
+    total
+}
+
+pub(super) async fn run_predator_c_for_symbol(
+    shared: &Arc<EngineShared>,
+    bus: &RingBus<EngineEvent>,
+    portfolio: &Arc<PortfolioBook>,
+    execution: &Arc<ClobExecution>,
+    shadow: &Arc<ShadowExecutor>,
+    market_rate_budget: &mut HashMap<String, TokenBucket>,
+    global_rate_budget: &mut TokenBucket,
+    predator_cfg: &PredatorCConfig,
+    symbol: &str,
+    tick_fast_recv_ts_ms: i64,
+    tick_fast_recv_ts_local_ns: i64,
+    now_ms: i64,
+    direction_override: Option<DirectionSignal>,
+) -> PredatorExecResult {
+    shared
+        .shadow_stats
+        .set_predator_enabled(predator_cfg.enabled);
+    if !predator_cfg.enabled {
+        return PredatorExecResult::default();
+    }
+    let live_armed = std::env::var("POLYEDGE_LIVE_ARMED")
+        .ok()
+        .map(|v| v.eq_ignore_ascii_case("true") || v == "1")
+        .unwrap_or(false);
+    if live_armed
+        && predator_cfg.v52.execution.require_compounder_when_live
+        && !predator_cfg.compounder.enabled
+    {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("compounder_required_when_live")
+            .await;
+        return PredatorExecResult::default();
+    }
+    let source_health_cfg = shared.source_health_cfg.read().await.clone();
+    let primary_fast_source = shared
+        .latest_fast_ticks
+        .get(symbol)
+        .map(|tick| tick.source.clone());
+    let primary_source_health = {
+        let map = shared.source_health_latest.read().await;
+        let from_fast = primary_fast_source
+            .as_ref()
+            .and_then(|source| map.get(source.as_str()).cloned());
+        let best_binance = map
+            .values()
+            .filter(|h| h.source.to_ascii_lowercase().contains("binance"))
+            .max_by(|a, b| {
+                a.score
+                    .partial_cmp(&b.score)
+                    .unwrap_or(std::cmp::Ordering::Equal)
+            })
+            .cloned();
+        match (from_fast, best_binance) {
+            (Some(a), Some(b)) => Some(if b.score > a.score { b } else { a }),
+            (Some(a), None) => Some(a),
+            (None, Some(b)) => Some(b),
+            (None, None) => None,
+        }
+    };
+
+    let direction_signal = if let Some(sig) = direction_override {
+        sig
+    } else {
+        let mut direction_signal = {
+            let det = shared.predator_direction_detector.read().await;
+            det.evaluate(symbol, now_ms)
+        };
+        if direction_signal.is_none() {
+            let fallback_signal = shared
+                .predator_latest_direction
+                .read()
+                .await
+                .get(symbol)
+                .cloned();
+            if let Some(cached) = fallback_signal {
+                let cached_ms = cached.ts_ns.div_euclid(1_000_000);
+                let age_ms = now_ms.saturating_sub(cached_ms);
+                if age_ms <= 2_500 {
+                    direction_signal = Some(cached);
+                }
+            }
+        }
+        let Some(direction_signal) = direction_signal else {
+            shared
+                .shadow_stats
+                .mark_predator_taker_skipped("no_direction_signal")
+                .await;
+            return PredatorExecResult::default();
+        };
+        direction_signal
+    };
+
+    shared
+        .shadow_stats
+        .mark_predator_direction(&direction_signal.direction);
+    {
+        let mut map = shared.predator_latest_direction.write().await;
+        map.insert(symbol.to_string(), direction_signal.clone());
+    }
+    publish_if_telemetry_subscribers(bus, EngineEvent::DirectionSignal(direction_signal.clone()));
+
+    if matches!(direction_signal.direction, Direction::Neutral) {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped("neutral_direction")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    let market_ids = shared
+        .symbol_to_markets
+        .read()
+        .await
+        .get(symbol)
+        .cloned()
+        .unwrap_or_default();
+    if market_ids.is_empty() {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped("no_symbol_markets")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    let (symbol_tox_score, symbol_tox_regime) = symbol_toxic_snapshot(shared, &market_ids).await;
+    let regime = classify_predator_regime(
+        &predator_cfg.regime,
+        &direction_signal,
+        symbol_tox_score,
+        &symbol_tox_regime,
+        primary_source_health.as_ref(),
+        &source_health_cfg,
+    );
+    shared.shadow_stats.mark_predator_regime(&regime);
+    if matches!(regime, Regime::Defend) {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped("predator_regime_defend")
+            .await;
+        return PredatorExecResult::default();
+    }
+    if matches!(regime, Regime::Quiet)
+        && matches!(predator_cfg.priority, PredatorCPriority::MakerFirst)
+    {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped("predator_regime_quiet")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    let maker_cfg = shared.strategy_cfg.read().await.clone();
+    let edge_model_cfg = shared.edge_model_cfg.read().await.clone();
+    let tf_weights = HashMap::from([
+        (
+            TimeframeClass::Tf5m,
+            timeframe_weight(shared, &TimeframeClass::Tf5m).await,
+        ),
+        (
+            TimeframeClass::Tf15m,
+            timeframe_weight(shared, &TimeframeClass::Tf15m).await,
+        ),
+        (
+            TimeframeClass::Tf1h,
+            timeframe_weight(shared, &TimeframeClass::Tf1h).await,
+        ),
+        (
+            TimeframeClass::Tf1d,
+            timeframe_weight(shared, &TimeframeClass::Tf1d).await,
+        ),
+    ]);
+
+    let static_quote_notional_usdc = (predator_cfg.compounder.initial_capital_usdc.max(0.0)
+        * predator_cfg.compounder.position_fraction.clamp(0.0, 1.0))
+    .max(predator_cfg.compounder.min_quote_size.max(0.01));
+    let (quote_notional_usdc, total_capital_usdc) = if predator_cfg.compounder.enabled {
+        let c = shared.predator_compounder.read().await;
+        (c.recommended_quote_notional_usdc(), c.available())
+    } else {
+        (
+            static_quote_notional_usdc,
+            predator_cfg.compounder.initial_capital_usdc.max(0.0),
+        )
+    };
+
+    #[derive(Debug, Clone)]
+    struct PredatorCandIn {
+        market_id: String,
+        timeframe: TimeframeClass,
+        side: OrderSide,
+        entry_price: f64,
+        spread: f64,
+        fee_bps: f64,
+        edge_gross_bps: f64,
+        edge_net_bps: f64,
+        size: f64,
+        dual_pair: bool,
+    }
+
+    let market_ids = market_ids.into_iter().take(32).collect::<Vec<_>>();
+    let tf_by_market = {
+        let map = shared.market_to_timeframe.read().await;
+        market_ids
+            .iter()
+            .filter_map(|id| map.get(id).cloned().map(|tf| (id.clone(), tf)))
+            .collect::<HashMap<String, TimeframeClass>>()
+    };
+    let book_by_market = {
+        let map = shared.latest_books.read().await;
+        market_ids
+            .iter()
+            .filter_map(|id| map.get(id).cloned().map(|b| (id.clone(), b)))
+            .collect::<HashMap<String, BookTop>>()
+    };
+
+    let mut cand_inputs_by_market: HashMap<String, Vec<PredatorCandIn>> = HashMap::new();
+    for market_id in market_ids {
+        let Some(timeframe) = tf_by_market.get(&market_id).cloned() else {
+            continue;
+        };
+        let Some(frame_total_ms) = timeframe_total_ms(timeframe.clone()) else {
+            shared
+                .shadow_stats
+                .mark_blocked_with_reason("v52_blocked_timeframe")
+                .await;
+            continue;
+        };
+        if !predator_cfg
+            .v52
+            .time_phase
+            .allow_timeframes
+            .iter()
+            .any(|v| v == timeframe_tag(timeframe.clone()))
+        {
+            shared
+                .shadow_stats
+                .mark_blocked_with_reason("v52_timeframe_not_allowed")
+                .await;
+            continue;
+        }
+        let Some(book) = book_by_market.get(&market_id).cloned() else {
+            continue;
+        };
+        let sig_entry = shared
+            .latest_signals
+            .get(&market_id)
+            .map(|v| v.value().clone());
+        let Some(sig_entry) = sig_entry else {
+            continue;
+        };
+        if now_ms.saturating_sub(sig_entry.ts_ms) > 5_000 {
+            continue;
+        }
+
+        let time_to_expiry_ms = (frame_total_ms - now_ms.rem_euclid(frame_total_ms)).max(0);
+        let remaining_ratio = (time_to_expiry_ms as f64 / frame_total_ms as f64).clamp(0.0, 1.0);
+        let time_phase = classify_time_phase(remaining_ratio, &predator_cfg.v52.time_phase);
+
+        let fee_bps = get_fee_rate_bps_cached(shared, &market_id).await;
+        let rebate_est_bps = get_rebate_bps_cached(shared, &market_id, fee_bps).await;
+        let yes_price = aggressive_price_for_side(&book, &OrderSide::BuyYes);
+        let no_price = aggressive_price_for_side(&book, &OrderSide::BuyNo);
+        let dual_arb_ok = allow_dual_side_arb(yes_price, no_price, fee_bps, &predator_cfg.v52.dual_arb);
+        let book_top_lag_ms = if tick_fast_recv_ts_local_ns > 0 && book.recv_ts_local_ns > 0 {
+            ((book.recv_ts_local_ns - tick_fast_recv_ts_local_ns).max(0) as f64) / 1_000_000.0
+        } else {
+            0.0
+        };
+        let settlement_prob_yes =
+            settlement_prob_yes_for_symbol(shared, symbol, sig_entry.signal.fair_yes, now_ms).await;
+        let probability = {
+            let engine = shared.predator_probability_engine.read().await;
+            engine.estimate(
+                &sig_entry.signal,
+                &direction_signal,
+                settlement_prob_yes,
+                book_top_lag_ms,
+                now_ms,
+            )
+        };
+        {
+            let mut map = shared.predator_latest_probability.write().await;
+            map.insert(market_id.clone(), probability.clone());
+        }
+        shared
+            .shadow_stats
+            .push_probability_sample(&probability)
+            .await;
+        let yes_edge_gross = edge_gross_bps_for_side(probability.p_settle, &OrderSide::BuyYes, yes_price);
+        let no_edge_gross = edge_gross_bps_for_side(probability.p_settle, &OrderSide::BuyNo, no_price);
+        let yes_edge_net = yes_edge_gross - fee_bps + rebate_est_bps - edge_model_cfg.fail_cost_bps;
+        let no_edge_net = no_edge_gross - fee_bps + rebate_est_bps - edge_model_cfg.fail_cost_bps;
+        if yes_edge_net > 0.0 && no_edge_net > 0.0 && !dual_arb_ok {
+            shared
+                .shadow_stats
+                .mark_blocked_with_reason("dual_arb_gate_blocked")
+                .await;
+        }
+        let tf_weight = tf_weights
+            .get(&timeframe)
+            .copied()
+            .unwrap_or(1.0)
+            .clamp(0.0, 1.0);
+        if tf_weight <= 0.0 {
+            continue;
+        }
+        let phase_size_scale = time_phase_size_scale(time_phase, &predator_cfg.v52.time_phase);
+        let side_size_scale = (tf_weight * phase_size_scale).max(0.0);
+        let mk_size = |entry_price: f64| {
+            let base_size = if quote_notional_usdc > 0.0 {
+                (quote_notional_usdc / entry_price.max(1e-6)).max(0.01)
+            } else {
+                maker_cfg.base_quote_size.max(0.01)
+            };
+            (base_size * side_size_scale).max(0.01)
+        };
+        let push_candidate = |bucket: &mut Vec<PredatorCandIn>,
+                              side: OrderSide,
+                              entry_price: f64,
+                              spread: f64,
+                              edge_gross_bps: f64,
+                              edge_net_bps: f64,
+                              dual_pair: bool| {
+            bucket.push(PredatorCandIn {
+                market_id: market_id.clone(),
+                timeframe: timeframe.clone(),
+                side,
+                entry_price,
+                spread,
+                fee_bps,
+                edge_gross_bps,
+                edge_net_bps,
+                size: mk_size(entry_price),
+                dual_pair,
+            });
+        };
+        let bucket = cand_inputs_by_market.entry(market_id.clone()).or_default();
+        if dual_arb_ok && yes_edge_net > 0.0 && no_edge_net > 0.0 {
+            push_candidate(
+                bucket,
+                OrderSide::BuyYes,
+                yes_price,
+                spread_for_side(&book, &OrderSide::BuyYes),
+                yes_edge_gross,
+                yes_edge_net,
+                true,
+            );
+            push_candidate(
+                bucket,
+                OrderSide::BuyNo,
+                no_price,
+                spread_for_side(&book, &OrderSide::BuyNo),
+                no_edge_gross,
+                no_edge_net,
+                true,
+            );
+        } else {
+            let (side, entry_price, edge_gross_bps, edge_net_bps) = if no_edge_net > yes_edge_net {
+                (OrderSide::BuyNo, no_price, no_edge_gross, no_edge_net)
+            } else {
+                (OrderSide::BuyYes, yes_price, yes_edge_gross, yes_edge_net)
+            };
+            push_candidate(
+                bucket,
+                side.clone(),
+                entry_price,
+                spread_for_side(&book, &side),
+                edge_gross_bps,
+                edge_net_bps,
+                false,
+            );
+        }
+    }
+
+    let mut fire_plans_by_market: HashMap<String, FirePlan> = HashMap::new();
+    let mut dual_fire_pairs: Vec<(FirePlan, FirePlan)> = Vec::new();
+    let mut skip_reasons: Vec<String> = Vec::new();
+    {
+        let mut sniper = shared.predator_taker_sniper.write().await;
+        let normalize_plan = |mut plan: FirePlan, cin: &PredatorCandIn| {
+            plan.opportunity.side = cin.side.clone();
+            plan.opportunity.direction = side_to_direction(&cin.side);
+            plan.opportunity.entry_price = cin.entry_price;
+            plan.opportunity.edge_gross_bps = cin.edge_gross_bps;
+            plan.opportunity.edge_net_bps = cin.edge_net_bps;
+            plan.opportunity.ts_ms = now_ms;
+            plan
+        };
+        let evaluate = |sn: &mut taker_sniper::TakerSniper,
+                        cin: &PredatorCandIn,
+                        sig: &DirectionSignal| {
+            sn.evaluate(&taker_sniper::EvaluateCtx {
+                market_id: &cin.market_id,
+                symbol,
+                timeframe: cin.timeframe.clone(),
+                direction_signal: sig,
+                entry_price: cin.entry_price,
+                spread: cin.spread,
+                fee_bps: cin.fee_bps,
+                edge_gross_bps: cin.edge_gross_bps,
+                edge_net_bps: cin.edge_net_bps,
+                size: cin.size,
+                now_ms,
+            })
+        };
+        for (_, mut cands) in cand_inputs_by_market {
+            if cands.is_empty() {
+                continue;
+            }
+            cands.sort_by(|a, b| {
+                b.edge_net_bps
+                    .partial_cmp(&a.edge_net_bps)
+                    .unwrap_or(std::cmp::Ordering::Equal)
+            });
+            let dual_eligible = cands.len() == 2 && cands.iter().all(|c| c.dual_pair);
+            if dual_eligible {
+                let mut dry_cfg = sniper.cfg().clone();
+                dry_cfg.cooldown_ms_per_market = 0;
+                let mut dry_sniper = taker_sniper::TakerSniper::new(dry_cfg);
+
+                let primary = &cands[0];
+                let hedge = &cands[1];
+                let primary_sig = direction_signal_for_side(&direction_signal, &primary.side);
+                let hedge_sig = direction_signal_for_side(&direction_signal, &hedge.side);
+
+                let primary_probe = evaluate(&mut dry_sniper, primary, &primary_sig);
+                let hedge_probe = evaluate(&mut dry_sniper, hedge, &hedge_sig);
+                if matches!(primary_probe.action, TakerAction::Fire)
+                    && matches!(hedge_probe.action, TakerAction::Fire)
+                {
+                    let primary_live = evaluate(&mut sniper, primary, &primary_sig);
+                    match primary_live.action {
+                        TakerAction::Fire => {
+                            if let (Some(primary_plan), Some(hedge_plan)) =
+                                (primary_live.fire_plan, hedge_probe.fire_plan)
+                            {
+                                dual_fire_pairs.push((
+                                    normalize_plan(primary_plan, primary),
+                                    normalize_plan(hedge_plan, hedge),
+                                ));
+                                continue;
+                            }
+                            skip_reasons.push("dual_arb_plan_missing".to_string());
+                        }
+                        TakerAction::Skip => {
+                            skip_reasons.push(primary_live.reason);
+                        }
+                    }
+                } else {
+                    if matches!(primary_probe.action, TakerAction::Skip) {
+                        skip_reasons.push(primary_probe.reason);
+                    }
+                    if matches!(hedge_probe.action, TakerAction::Skip) {
+                        skip_reasons.push(hedge_probe.reason);
+                    }
+                }
+            }
+
+            let best = &cands[0];
+            let best_sig = direction_signal_for_side(&direction_signal, &best.side);
+            let decision = evaluate(&mut sniper, best, &best_sig);
+            match decision.action {
+                TakerAction::Fire => {
+                    if let Some(plan) = decision.fire_plan {
+                        let plan = normalize_plan(plan, best);
+                        fire_plans_by_market.insert(plan.opportunity.market_id.clone(), plan);
+                    }
+                }
+                TakerAction::Skip => skip_reasons.push(decision.reason),
+            }
+        }
+    }
+    for reason in skip_reasons {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped(reason.as_str())
+            .await;
+    }
+
+    if matches!(regime, Regime::Quiet) {
+        let quiet_min_edge = predator_cfg.taker_sniper.min_edge_net_bps.max(0.0)
+            * predator_cfg.regime.quiet_min_edge_multiplier.max(1.0);
+        fire_plans_by_market.retain(|_, plan| plan.opportunity.edge_net_bps >= quiet_min_edge);
+        dual_fire_pairs.retain(|(a, b)| {
+            a.opportunity.edge_net_bps >= quiet_min_edge && b.opportunity.edge_net_bps >= quiet_min_edge
+        });
+        let chunk_scale = predator_cfg.regime.quiet_chunk_scale.clamp(0.05, 1.0);
+        for plan in fire_plans_by_market.values_mut() {
+            let len = plan.chunks.len();
+            if len <= 1 {
+                continue;
+            }
+            let keep = ((len as f64) * chunk_scale).ceil() as usize;
+            let keep = keep.clamp(1, len);
+            plan.chunks.truncate(keep);
+            if let Some(first) = plan.chunks.first_mut() {
+                first.send_delay_ms = 0;
+            }
+        }
+        for (plan_a, plan_b) in dual_fire_pairs.iter_mut() {
+            for plan in [plan_a, plan_b] {
+                let len = plan.chunks.len();
+                if len <= 1 {
+                    continue;
+                }
+                let keep = ((len as f64) * chunk_scale).ceil() as usize;
+                let keep = keep.clamp(1, len);
+                plan.chunks.truncate(keep);
+                if let Some(first) = plan.chunks.first_mut() {
+                    first.send_delay_ms = 0;
+                }
+            }
+        }
+    }
+
+    if fire_plans_by_market.is_empty() && dual_fire_pairs.is_empty() {
+        return PredatorExecResult::default();
+    }
+
+    let mut locked_plans: Vec<FirePlan> = Vec::new();
+    let mut locked_dual_pairs: Vec<(FirePlan, FirePlan)> = Vec::new();
+    let mut locked_by_tf_usdc: HashMap<String, f64> = HashMap::new();
+    let mut router_skip_reasons: Vec<String> = Vec::new();
+    {
+        let mut router = shared.predator_router.write().await;
+        let selected = router.route(
+            fire_plans_by_market
+                .values()
+                .map(|plan| plan.opportunity.clone())
+                .collect::<Vec<_>>(),
+            total_capital_usdc.max(0.0),
+            now_ms,
+        );
+        for opp in selected {
+            if router.lock(&opp, now_ms) {
+                if let Some(plan) = fire_plans_by_market.remove(&opp.market_id) {
+                    locked_plans.push(plan);
+                }
+            }
+        }
+        for (plan_a, plan_b) in dual_fire_pairs {
+            let notional = (plan_a.opportunity.entry_price.max(0.0) * plan_a.opportunity.size.max(0.0))
+                + (plan_b.opportunity.entry_price.max(0.0) * plan_b.opportunity.size.max(0.0));
+            if notional <= 0.0 {
+                continue;
+            }
+            let mut lock_opp = if plan_a.opportunity.edge_net_bps >= plan_b.opportunity.edge_net_bps {
+                plan_a.opportunity.clone()
+            } else {
+                plan_b.opportunity.clone()
+            };
+            lock_opp.entry_price = 1.0;
+            lock_opp.size = notional.max(0.01);
+            if router.lock(&lock_opp, now_ms) {
+                locked_dual_pairs.push((plan_a, plan_b));
+            } else {
+                router_skip_reasons.push("dual_arb_router_lock_blocked".to_string());
+            }
+        }
+        for (tf, v) in router.locked_by_tf_usdc(now_ms) {
+            locked_by_tf_usdc.insert(tf.to_string(), v);
+        }
+    }
+    for reason in router_skip_reasons {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped(reason.as_str())
+            .await;
+    }
+    shared
+        .shadow_stats
+        .set_predator_router_locked_by_tf_usdc(locked_by_tf_usdc)
+        .await;
+
+    if locked_plans.is_empty() && locked_dual_pairs.is_empty() {
+        return PredatorExecResult::default();
+    }
+
+    let single_futures: Vec<_> = locked_plans
+        .into_iter()
+        .map(|plan| {
+            let shared = shared.clone();
+            let bus = bus.clone();
+            let portfolio = portfolio.clone();
+            let execution = execution.clone();
+            let shadow = shadow.clone();
+            let maker_cfg = maker_cfg.clone();
+            let direction_signal = direction_signal_for_side(&direction_signal, &plan.opportunity.side);
+            let mut market_rate_budget_local = market_rate_budget.clone();
+            let mut global_rate_budget_local = global_rate_budget.clone();
+            async move {
+                execute_fire_plan(
+                    &shared,
+                    &bus,
+                    &portfolio,
+                    &execution,
+                    &shadow,
+                    &mut market_rate_budget_local,
+                    &mut global_rate_budget_local,
+                    &maker_cfg,
+                    predator_cfg,
+                    &direction_signal,
+                    &plan,
+                    tick_fast_recv_ts_ms,
+                    tick_fast_recv_ts_local_ns,
+                    now_ms,
+                )
+                .await
+            }
+        })
+        .collect();
+
+    let mut out = PredatorExecResult::default();
+    for r in futures::future::join_all(single_futures).await {
+        out.attempted = out.attempted.saturating_add(r.attempted);
+        out.executed = out.executed.saturating_add(r.executed);
+    }
+
+    let dual_futures: Vec<_> = locked_dual_pairs
+        .into_iter()
+        .map(|(plan_a, plan_b)| {
+            let shared = shared.clone();
+            let bus = bus.clone();
+            let portfolio = portfolio.clone();
+            let execution = execution.clone();
+            let shadow = shadow.clone();
+            let maker_cfg = maker_cfg.clone();
+            let dir_a = direction_signal_for_side(&direction_signal, &plan_a.opportunity.side);
+            let dir_b = direction_signal_for_side(&direction_signal, &plan_b.opportunity.side);
+            let mut market_rate_budget_local_a = market_rate_budget.clone();
+            let mut global_rate_budget_local_a = global_rate_budget.clone();
+            let mut market_rate_budget_local_b = market_rate_budget.clone();
+            let mut global_rate_budget_local_b = global_rate_budget.clone();
+            async move {
+                let leg_a = execute_fire_plan(
+                    &shared,
+                    &bus,
+                    &portfolio,
+                    &execution,
+                    &shadow,
+                    &mut market_rate_budget_local_a,
+                    &mut global_rate_budget_local_a,
+                    &maker_cfg,
+                    predator_cfg,
+                    &dir_a,
+                    &plan_a,
+                    tick_fast_recv_ts_ms,
+                    tick_fast_recv_ts_local_ns,
+                    now_ms,
+                );
+                let leg_b = execute_fire_plan(
+                    &shared,
+                    &bus,
+                    &portfolio,
+                    &execution,
+                    &shadow,
+                    &mut market_rate_budget_local_b,
+                    &mut global_rate_budget_local_b,
+                    &maker_cfg,
+                    predator_cfg,
+                    &dir_b,
+                    &plan_b,
+                    tick_fast_recv_ts_ms,
+                    tick_fast_recv_ts_local_ns,
+                    now_ms,
+                );
+                let (res_a, res_b) = tokio::join!(leg_a, leg_b);
+                PredatorExecResult {
+                    attempted: res_a.attempted.saturating_add(res_b.attempted),
+                    executed: res_a.executed.saturating_add(res_b.executed),
+                    stop_firing: res_a.stop_firing || res_b.stop_firing,
+                }
+            }
+        })
+        .collect();
+
+    for r in futures::future::join_all(dual_futures).await {
+        out.attempted = out.attempted.saturating_add(r.attempted);
+        out.executed = out.executed.saturating_add(r.executed);
+    }
+    out
+}
+
+async fn execute_fire_plan(
+    shared: &Arc<EngineShared>,
+    bus: &RingBus<EngineEvent>,
+    portfolio: &Arc<PortfolioBook>,
+    execution: &Arc<ClobExecution>,
+    shadow: &Arc<ShadowExecutor>,
+    market_rate_budget: &mut HashMap<String, TokenBucket>,
+    global_rate_budget: &mut TokenBucket,
+    maker_cfg: &MakerConfig,
+    predator_cfg: &PredatorCConfig,
+    direction_signal: &DirectionSignal,
+    plan: &FirePlan,
+    tick_fast_recv_ts_ms: i64,
+    tick_fast_recv_ts_local_ns: i64,
+    now_ms: i64,
+) -> PredatorExecResult {
+    let mut plan_result = PredatorExecResult::default();
+    let opp = &plan.opportunity;
+    for (idx, chunk) in plan.chunks.iter().enumerate() {
+        if chunk.size <= 0.0 {
+            continue;
+        }
+        if idx > 0 && chunk.send_delay_ms > 0 {
+            tokio::time::sleep(Duration::from_millis(chunk.send_delay_ms)).await;
+        }
+        shared.shadow_stats.mark_predator_taker_fired();
+        let res = predator_execute_opportunity(
+            shared,
+            bus,
+            portfolio,
+            execution,
+            shadow,
+            market_rate_budget,
+            global_rate_budget,
+            maker_cfg,
+            predator_cfg,
+            direction_signal,
+            opp,
+            chunk.size,
+            tick_fast_recv_ts_ms,
+            tick_fast_recv_ts_local_ns,
+            now_ms,
+        )
+        .await;
+        plan_result.attempted = plan_result.attempted.saturating_add(res.attempted);
+        plan_result.executed = plan_result.executed.saturating_add(res.executed);
+        if plan.stop_on_reject && res.stop_firing {
+            break;
+        }
+    }
+    plan_result
+}
+
+pub(super) async fn run_predator_d_for_symbol(
+    shared: &Arc<EngineShared>,
+    bus: &RingBus<EngineEvent>,
+    portfolio: &Arc<PortfolioBook>,
+    execution: &Arc<ClobExecution>,
+    shadow: &Arc<ShadowExecutor>,
+    market_rate_budget: &mut HashMap<String, TokenBucket>,
+    global_rate_budget: &mut TokenBucket,
+    predator_cfg: &PredatorCConfig,
+    symbol: &str,
+    tick_fast_recv_ts_ms: i64,
+    tick_fast_recv_ts_local_ns: i64,
+    now_ms: i64,
+) -> PredatorExecResult {
+    let d_cfg = &predator_cfg.strategy_d;
+    if !predator_cfg.enabled || !d_cfg.enabled {
+        return PredatorExecResult::default();
+    }
+
+    let direction_signal = {
+        let mut direction_signal = {
+            let det = shared.predator_direction_detector.read().await;
+            det.evaluate(symbol, now_ms)
+        };
+        if direction_signal.is_none() {
+            let fallback_signal = shared
+                .predator_latest_direction
+                .read()
+                .await
+                .get(symbol)
+                .cloned();
+            if let Some(cached) = fallback_signal {
+                let cached_ms = cached.ts_ns.div_euclid(1_000_000);
+                let age_ms = now_ms.saturating_sub(cached_ms);
+                if age_ms <= 2_500 {
+                    direction_signal = Some(cached);
+                }
+            }
+        }
+        let Some(sig) = direction_signal else {
+            return PredatorExecResult::default();
+        };
+        sig
+    };
+    if matches!(direction_signal.direction, Direction::Neutral) {
+        return PredatorExecResult::default();
+    }
+
+    let side = match direction_signal.direction {
+        Direction::Up => OrderSide::BuyYes,
+        Direction::Down => OrderSide::BuyNo,
+        Direction::Neutral => OrderSide::BuyYes,
+    };
+    let maker_cfg = shared.strategy_cfg.read().await.clone();
+    let edge_model_cfg = shared.edge_model_cfg.read().await.clone();
+    let market_ids = shared
+        .symbol_to_markets
+        .read()
+        .await
+        .get(symbol)
+        .cloned()
+        .unwrap_or_default();
+    if market_ids.is_empty() {
+        return PredatorExecResult::default();
+    }
+
+    let mut out = PredatorExecResult::default();
+    for market_id in market_ids.into_iter().take(32) {
+        if d_cfg.cooldown_ms_per_market > 0 {
+            let last_fire = shared
+                .predator_d_last_fire_ms
+                .read()
+                .await
+                .get(&market_id)
+                .copied()
+                .unwrap_or(0);
+            if now_ms.saturating_sub(last_fire) < d_cfg.cooldown_ms_per_market as i64 {
+                continue;
+            }
+        }
+
+        let book = shared.latest_books.read().await.get(&market_id).cloned();
+        let Some(book) = book else {
+            continue;
+        };
+        let entry_price = aggressive_price_for_side(&book, &side);
+        if entry_price <= 0.0 {
+            continue;
+        }
+        let spread = spread_for_side(&book, &side);
+        let mid_px = mid_for_side(&book, &side).max(1e-6);
+        let spread_bps = (spread / mid_px) * 10_000.0;
+        if spread_bps < d_cfg.min_gap_bps {
+            continue;
+        }
+
+        let sig_entry = shared
+            .latest_signals
+            .get(&market_id)
+            .map(|v| v.value().clone());
+        let Some(sig_entry) = sig_entry else {
+            continue;
+        };
+        if now_ms.saturating_sub(sig_entry.ts_ms) > 5_000 {
+            continue;
+        }
+
+        let book_top_lag_ms = if tick_fast_recv_ts_local_ns > 0 && book.recv_ts_local_ns > 0 {
+            ((book.recv_ts_local_ns - tick_fast_recv_ts_local_ns).max(0) as f64) / 1_000_000.0
+        } else {
+            0.0
+        };
+        let settlement_prob_yes =
+            settlement_prob_yes_for_symbol(shared, symbol, sig_entry.signal.fair_yes, now_ms).await;
+        let probability = {
+            let engine = shared.predator_probability_engine.read().await;
+            engine.estimate(
+                &sig_entry.signal,
+                &direction_signal,
+                settlement_prob_yes,
+                book_top_lag_ms,
+                now_ms,
+            )
+        };
+        if probability.confidence < d_cfg.min_confidence {
+            continue;
+        }
+        let fee_bps = get_fee_rate_bps_cached(shared, &market_id).await;
+        let rebate_est_bps = get_rebate_bps_cached(shared, &market_id, fee_bps).await;
+        let edge_gross_bps = edge_gross_bps_for_side(probability.p_settle, &side, entry_price);
+        let edge_net_bps = edge_gross_bps - fee_bps + rebate_est_bps - edge_model_cfg.fail_cost_bps;
+        if edge_net_bps < d_cfg.min_edge_net_bps {
+            continue;
+        }
+        let timeframe = shared
+            .market_to_timeframe
+            .read()
+            .await
+            .get(&market_id)
+            .cloned()
+            .unwrap_or(TimeframeClass::Tf5m);
+        let max_notional = d_cfg.max_notional_usdc.max(maker_cfg.base_quote_size);
+        let size = (max_notional / entry_price.max(1e-6)).max(0.01);
+        let lock_minutes = match timeframe {
+            TimeframeClass::Tf5m => 5.0,
+            TimeframeClass::Tf15m => 15.0,
+            TimeframeClass::Tf1h => 60.0,
+            TimeframeClass::Tf1d => 1440.0,
+        };
+        let notional_usdc = (entry_price.max(0.0) * size.max(0.0)).max(0.0);
+        let edge_net_usdc = (edge_net_bps / 10_000.0) * notional_usdc;
+        let density = if lock_minutes <= 0.0 {
+            0.0
+        } else {
+            edge_net_usdc / lock_minutes
+        };
+        let opp = TimeframeOpp {
+            timeframe,
+            market_id: market_id.clone(),
+            symbol: symbol.to_string(),
+            direction: direction_signal.direction.clone(),
+            side: side.clone(),
+            entry_price,
+            size,
+            edge_gross_bps,
+            edge_net_bps,
+            edge_net_usdc,
+            fee_bps,
+            lock_minutes,
+            density,
+            confidence: probability.confidence,
+            ts_ms: now_ms,
+        };
+        let res = predator_execute_opportunity(
+            shared,
+            bus,
+            portfolio,
+            execution,
+            shadow,
+            market_rate_budget,
+            global_rate_budget,
+            &maker_cfg,
+            predator_cfg,
+            &direction_signal,
+            &opp,
+            size,
+            tick_fast_recv_ts_ms,
+            tick_fast_recv_ts_local_ns,
+            now_ms,
+        )
+        .await;
+        if res.attempted > 0 {
+            shared
+                .predator_d_last_fire_ms
+                .write()
+                .await
+                .insert(market_id, now_ms);
+        }
+        out.attempted = out.attempted.saturating_add(res.attempted);
+        out.executed = out.executed.saturating_add(res.executed);
+    }
+    out
+}
+
+pub(super) async fn run_predator_c_cross_symbol(
+    shared: &Arc<EngineShared>,
+    bus: &RingBus<EngineEvent>,
+    portfolio: &Arc<PortfolioBook>,
+    execution: &Arc<ClobExecution>,
+    shadow: &Arc<ShadowExecutor>,
+    market_rate_budget: &mut HashMap<String, TokenBucket>,
+    global_rate_budget: &mut TokenBucket,
+    predator_cfg: &PredatorCConfig,
+    leader_direction: &DirectionSignal,
+    tick_fast_recv_ts_ms: i64,
+    tick_fast_recv_ts_local_ns: i64,
+    now_ms: i64,
+) -> PredatorExecResult {
+    let cross_cfg = &predator_cfg.cross_symbol;
+    if !cross_cfg.enabled {
+        return PredatorExecResult::default();
+    }
+    if !leader_direction
+        .symbol
+        .eq_ignore_ascii_case(&cross_cfg.leader_symbol)
+    {
+        return PredatorExecResult::default();
+    }
+    if matches!(leader_direction.direction, Direction::Neutral) {
+        return PredatorExecResult::default();
+    }
+    if leader_direction.confidence < cross_cfg.min_leader_confidence
+        || leader_direction.magnitude_pct.abs() < cross_cfg.min_leader_magnitude_pct
+    {
+        return PredatorExecResult::default();
+    }
+    let follower_symbols = cross_cfg
+        .follower_symbols
+        .iter()
+        .filter(|s| !s.eq_ignore_ascii_case(&leader_direction.symbol))
+        .cloned()
+        .collect::<Vec<_>>();
+    if follower_symbols.is_empty() {
+        return PredatorExecResult::default();
+    }
+
+    let correlated_used =
+        correlated_locked_positions_for_symbols(shared, &follower_symbols, now_ms).await;
+    let mut slots_left = cross_cfg
+        .max_correlated_positions
+        .saturating_sub(correlated_used);
+    if slots_left == 0 {
+        return PredatorExecResult::default();
+    }
+
+    let mut out = PredatorExecResult::default();
+    for follower in follower_symbols {
+        if slots_left == 0 {
+            break;
+        }
+        let follower_sig = {
+            let det = shared.predator_direction_detector.read().await;
+            det.evaluate(&follower, now_ms)
+        };
+        if let Some(sig) = follower_sig {
+            let same_dir = sig.direction == leader_direction.direction;
+            if same_dir && sig.confidence > cross_cfg.follower_stale_confidence_max {
+                continue;
+            }
+        }
+
+        let mut forced = leader_direction.clone();
+        forced.symbol = follower.clone();
+        let res = run_predator_c_for_symbol(
+            shared,
+            bus,
+            portfolio,
+            execution,
+            shadow,
+            market_rate_budget,
+            global_rate_budget,
+            predator_cfg,
+            &follower,
+            tick_fast_recv_ts_ms,
+            tick_fast_recv_ts_local_ns,
+            now_ms,
+            Some(forced),
+        )
+        .await;
+        if res.attempted > 0 {
+            slots_left = slots_left.saturating_sub(1);
+            shared.shadow_stats.mark_predator_cross_symbol_fired();
+        }
+        out.attempted = out.attempted.saturating_add(res.attempted);
+        out.executed = out.executed.saturating_add(res.executed);
+    }
+    out
+}
+
+pub(super) async fn correlated_locked_positions_for_symbols(
+    shared: &Arc<EngineShared>,
+    symbols: &[String],
+    now_ms: i64,
+) -> usize {
+    if symbols.is_empty() {
+        return 0;
+    }
+    let locks = {
+        let mut router = shared.predator_router.write().await;
+        router.snapshot_locks(now_ms)
+    };
+    if locks.is_empty() {
+        return 0;
+    }
+    let symbol_set = symbols
+        .iter()
+        .map(|s| s.to_ascii_uppercase())
+        .collect::<std::collections::HashSet<_>>();
+    let market_to_symbol = shared.market_to_symbol.read().await.clone();
+    locks
+        .iter()
+        .filter(|lock| {
+            market_to_symbol
+                .get(&lock.market_id)
+                .map(|s| symbol_set.contains(&s.to_ascii_uppercase()))
+                .unwrap_or(false)
+        })
+        .count()
+}
+
+pub(super) async fn symbol_toxic_snapshot(
+    shared: &Arc<EngineShared>,
+    market_ids: &[String],
+) -> (f64, ToxicRegime) {
+    if market_ids.is_empty() {
+        return (0.0, ToxicRegime::Safe);
+    }
+    let states = shared.tox_state.read().await;
+    let mut max_score = 0.0_f64;
+    let mut has_caution = false;
+    let mut has_danger = false;
+    for market_id in market_ids {
+        if let Some(st) = states.get(market_id) {
+            max_score = max_score.max(st.last_tox_score);
+            match st.last_regime {
+                ToxicRegime::Danger => has_danger = true,
+                ToxicRegime::Caution => has_caution = true,
+                ToxicRegime::Safe => {}
+            }
+        }
+    }
+    let regime = if has_danger {
+        ToxicRegime::Danger
+    } else if has_caution {
+        ToxicRegime::Caution
+    } else {
+        ToxicRegime::Safe
+    };
+    (max_score, regime)
+}
+
+pub(super) fn classify_predator_regime(
+    cfg: &PredatorRegimeConfig,
+    direction_signal: &DirectionSignal,
+    tox_score: f64,
+    tox_regime: &ToxicRegime,
+    source_health: Option<&SourceHealth>,
+    source_health_cfg: &SourceHealthConfig,
+) -> Regime {
+    if !cfg.enabled {
+        return Regime::Active;
+    }
+    let source_low = source_health
+        .map(|h| {
+            h.sample_count >= source_health_cfg.min_samples
+                && h.score
+                    < cfg
+                        .defend_min_source_health
+                        .max(source_health_cfg.min_score_for_trading)
+                || (h.sample_count >= source_health_cfg.min_samples && h.freshness_score < 0.25)
+        })
+        .unwrap_or(false);
+    if source_low {
+        return Regime::Defend;
+    }
+    if tox_score >= cfg.defend_tox_score {
+        return Regime::Defend;
+    }
+    if cfg.defend_on_toxic_danger && matches!(tox_regime, ToxicRegime::Danger) {
+        return Regime::Defend;
+    }
+    if direction_signal.confidence >= cfg.active_min_confidence
+        && direction_signal.magnitude_pct.abs() >= cfg.active_min_magnitude_pct
+    {
+        Regime::Active
+    } else {
+        Regime::Quiet
+    }
+}
+
+pub(super) async fn predator_execute_opportunity(
+    shared: &Arc<EngineShared>,
+    bus: &RingBus<EngineEvent>,
+    portfolio: &Arc<PortfolioBook>,
+    execution: &Arc<ClobExecution>,
+    shadow: &Arc<ShadowExecutor>,
+    market_rate_budget: &mut HashMap<String, TokenBucket>,
+    global_rate_budget: &mut TokenBucket,
+    maker_cfg: &MakerConfig,
+    predator_cfg: &PredatorCConfig,
+    direction_signal: &DirectionSignal,
+    opp: &TimeframeOpp,
+    chunk_size: f64,
+    tick_fast_recv_ts_ms: i64,
+    tick_fast_recv_ts_local_ns: i64,
+    now_ms: i64,
+) -> PredatorExecResult {
+    let mut intent = QuoteIntent {
+        market_id: opp.market_id.clone(),
+        side: opp.side.clone(),
+        price: opp.entry_price,
+        size: chunk_size,
+        ttl_ms: maker_cfg.ttl_ms,
+    };
+
+    let book = shared
+        .latest_books
+        .read()
+        .await
+        .get(&intent.market_id)
+        .cloned();
+    let Some(book) = book else {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped("book_missing")
+            .await;
+        return PredatorExecResult::default();
+    };
+    let Some(frame_total_ms) = timeframe_total_ms(opp.timeframe.clone()) else {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("v52_blocked_timeframe")
+            .await;
+        return PredatorExecResult::default();
+    };
+    let time_to_expiry_ms = (frame_total_ms - now_ms.rem_euclid(frame_total_ms)).max(0);
+    let remaining_ratio = (time_to_expiry_ms as f64 / frame_total_ms as f64).clamp(0.0, 1.0);
+    let time_phase = classify_time_phase(remaining_ratio, &predator_cfg.v52.time_phase);
+    let force_taker_now =
+        should_force_taker_fallback(time_phase, time_to_expiry_ms, &predator_cfg.v52.execution);
+    let apply_force_taker_for_phase = match time_phase {
+        TimePhase::Early => false,
+        TimePhase::Maturity => predator_cfg.v52.execution.apply_force_taker_in_maturity,
+        TimePhase::Late => predator_cfg.v52.execution.apply_force_taker_in_late,
+    };
+    if force_taker_now {
+        shared.shadow_stats.mark_predator_last_30s_taker_fallback();
+    }
+
+    // Same interpretation as the maker path: positive means our fast ref tick arrived earlier
+    // than the Polymarket book update. For Predator, the ref tick is per-symbol while the book
+    // is per-market, so this is still a useful (if approximate) window estimate.
+    let tick_age_ms = freshness_ms(now_ms, tick_fast_recv_ts_ms);
+    let book_top_lag_ms =
+        if tick_age_ms <= 1_500 && tick_fast_recv_ts_local_ns > 0 && book.recv_ts_local_ns > 0 {
+            ((book.recv_ts_local_ns - tick_fast_recv_ts_local_ns).max(0) as f64) / 1_000_000.0
+        } else {
+            0.0
+        };
+
+    let inventory = inventory_for_market(portfolio, &intent.market_id);
+    let pending_market_exposure = execution.open_order_notional_for_market(&intent.market_id);
+    let pending_total_exposure = execution.open_order_notional_total();
+    let drawdown = portfolio.snapshot().max_drawdown_pct;
+    let risk_limits_snapshot = shared
+        .risk_limits
+        .read()
+        .map(|g| g.clone())
+        .unwrap_or_else(|_| RiskLimits::default());
+    let open_orders_now = execution.open_orders_count();
+    let risk_open_orders_soft_cap = risk_limits_snapshot.max_open_orders.saturating_sub(1);
+    if open_orders_now >= risk_open_orders_soft_cap.max(1) {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("open_orders_pressure_precheck")
+            .await;
+        return PredatorExecResult::default();
+    }
+    shared.shadow_stats.mark_attempted();
+    let (tox_score, tox_regime) = {
+        let map = shared.tox_state.read().await;
+        map.get(&intent.market_id)
+            .map(|st| (st.last_tox_score, st.last_regime.clone()))
+            .unwrap_or((0.0, ToxicRegime::Safe))
+    };
+    let pre_scale = adaptive_size_scale(
+        drawdown,
+        inventory.exposure_notional + pending_market_exposure,
+        inventory.exposure_notional + pending_total_exposure,
+        &risk_limits_snapshot,
+        tox_score,
+        &tox_regime,
+    );
+    intent.size = (intent.size * pre_scale).max(0.01);
+    let proposed_notional_usdc = (intent.price.max(0.0) * intent.size.max(0.0)).max(0.0);
+    let ctx = RiskContext {
+        market_id: intent.market_id.clone(),
+        symbol: opp.symbol.clone(),
+        order_count: execution.open_orders_count(),
+        proposed_size: intent.size,
+        proposed_notional_usdc,
+        market_notional: inventory.exposure_notional + pending_market_exposure,
+        asset_notional: inventory.exposure_notional + pending_total_exposure,
+        drawdown_pct: drawdown,
+        loss_streak: shared.shadow_stats.loss_streak(),
+        now_ms,
+    };
+    let decision = shared.risk_manager.evaluate(&ctx);
+    if !decision.allow {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason(&format!("risk:{}", decision.reason))
+            .await;
+        return PredatorExecResult::default();
+    }
+    if decision.capped_size <= 0.0 {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("risk_capped_zero")
+            .await;
+        return PredatorExecResult::default();
+    }
+    intent.size = intent.size.min(decision.capped_size);
+
+    let intended_notional_usdc = (intent.price.max(0.0) * intent.size.max(0.0)).max(0.0);
+    if intended_notional_usdc < maker_cfg.min_eval_notional_usdc {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("tiny_notional")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    let edge_net_usdc = (opp.edge_net_bps / 10_000.0) * intended_notional_usdc;
+    let edge_model_cfg = shared.edge_model_cfg.read().await.clone();
+    let dynamic_gate_bps = edge_gate_bps(
+        &edge_model_cfg,
+        0.0,
+        tick_age_ms as f64,
+        book_top_lag_ms,
+        0.0,
+    );
+    if opp.edge_net_bps < maker_cfg.min_edge_bps + dynamic_gate_bps {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("edge_below_dynamic_gate")
+            .await;
+        return PredatorExecResult::default();
+    }
+    if edge_net_usdc < maker_cfg.min_expected_edge_usdc {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("edge_notional_too_small")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    let per_market_rps = (shared.rate_limit_rps / 8.0).max(0.5);
+    let market_bucket = market_rate_budget
+        .entry(intent.market_id.clone())
+        .or_insert_with(|| TokenBucket::new(per_market_rps, (per_market_rps * 2.0).max(1.0)));
+    if !global_rate_budget.try_take(1.0) {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("rate_budget_global")
+            .await;
+        return PredatorExecResult::default();
+    }
+    if !market_bucket.try_take(1.0) {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("rate_budget_market")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    shared.shadow_stats.mark_eligible();
+    let order_build_start = Instant::now();
+    let token_id = match intent.side {
+        OrderSide::BuyYes | OrderSide::SellYes => book.token_id_yes.clone(),
+        OrderSide::BuyNo | OrderSide::SellNo => book.token_id_no.clone(),
+    };
+    let execution_style = if force_taker_now {
+        ExecutionStyle::Taker
+    } else {
+        ExecutionStyle::Maker
+    };
+    let v2_intent = OrderIntentV2 {
+        market_id: intent.market_id.clone(),
+        token_id: Some(token_id.clone()),
+        side: intent.side.clone(),
+        price: intent.price,
+        size: intent.size,
+        ttl_ms: intent.ttl_ms,
+        style: execution_style.clone(),
+        tif: if execution_style == ExecutionStyle::Maker {
+            OrderTimeInForce::PostOnly
+        } else {
+            OrderTimeInForce::Fak
+        },
+        max_slippage_bps: if execution_style == ExecutionStyle::Maker {
+            0.0
+        } else {
+            maker_cfg.taker_max_slippage_bps
+        },
+        fee_rate_bps: opp.fee_bps,
+        expected_edge_net_bps: opp.edge_net_bps,
+        client_order_id: Some(new_id()),
+        hold_to_resolution: false,
+        prebuilt_payload: None,
+    };
+    let mut v2_intent = v2_intent;
+    if execution.is_live() {
+        v2_intent.prebuilt_payload = prebuild_order_payload(&v2_intent);
+    }
+    let order_build_ms = order_build_start.elapsed().as_secs_f64() * 1_000.0;
+    let place_start = Instant::now();
+
+    let mut out = PredatorExecResult::default();
+    out.attempted = out.attempted.saturating_add(1);
+
+    match execution.place_order_v2(v2_intent).await {
+        Ok(ack_v2) if ack_v2.accepted => {
+            let accepted_size = ack_v2.accepted_size.max(0.0).min(intent.size);
+            if accepted_size <= 0.0 {
+                shared
+                    .shadow_stats
+                    .mark_blocked_with_reason("exchange_reject_zero_size")
+                    .await;
+                return out;
+            }
+            intent.size = accepted_size;
+            shared.shadow_stats.mark_executed();
+            out.executed = out.executed.saturating_add(1);
+            let accepted_notional_usdc = (intent.price.max(0.0) * intent.size.max(0.0)).max(0.0);
+            let entry_edge_usdc = (opp.edge_net_bps / 10_000.0) * accepted_notional_usdc;
+            {
+                let mut exit_mgr = shared.predator_exit_manager.write().await;
+                exit_mgr.register(PositionLifecycle {
+                    position_id: ack_v2.order_id.clone(),
+                    market_id: intent.market_id.clone(),
+                    symbol: opp.symbol.clone(),
+                    opened_at_ms: now_ms,
+                    entry_edge_usdc,
+                    entry_notional_usdc: accepted_notional_usdc,
+                });
+            }
+            spawn_predator_exit_lifecycle(
+                shared.clone(),
+                bus.clone(),
+                execution.clone(),
+                shadow.clone(),
+                ack_v2.order_id.clone(),
+                intent.market_id.clone(),
+                opp.symbol.clone(),
+                intent.side.clone(),
+                intent.price,
+                intent.size,
+                maker_cfg.ttl_ms,
+                intent.price + opp.edge_gross_bps / 10_000.0,
+            );
+
+            let ack_only_ms = if ack_v2.exchange_latency_ms > 0.0 {
+                ack_v2.exchange_latency_ms
+            } else {
+                // Keep latency visibility in non-live mode via local order path RTT.
+                place_start.elapsed().as_secs_f64() * 1_000.0
+            };
+            let tick_to_ack_ms = order_build_ms + ack_only_ms;
+            let capturable_window_ms = if ack_only_ms > 0.0 {
+                book_top_lag_ms - tick_to_ack_ms
+            } else {
+                0.0
+            };
+            if ack_only_ms > 0.0 {
+                shared.shadow_stats.push_ack_only_ms(ack_only_ms).await;
+                shared
+                    .shadow_stats
+                    .push_tick_to_ack_ms(tick_to_ack_ms)
+                    .await;
+                shared
+                    .shadow_stats
+                    .push_capturable_window_ms(capturable_window_ms)
+                    .await;
+                metrics::histogram!("latency.ack_only_ms").record(ack_only_ms);
+                metrics::histogram!("latency.tick_to_ack_ms").record(tick_to_ack_ms);
+                metrics::histogram!("latency.capturable_window_ms").record(capturable_window_ms);
+            }
+
+            let ack = OrderAck {
+                order_id: ack_v2.order_id,
+                market_id: ack_v2.market_id,
+                accepted: true,
+                ts_ms: ack_v2.ts_ms,
+            };
+            publish_if_telemetry_subscribers(bus, EngineEvent::OrderAck(ack.clone()));
+            let effective_fee_bps = if execution_style == ExecutionStyle::Maker {
+                -get_rebate_bps_cached(shared, &intent.market_id, opp.fee_bps)
+                    .await
+                    .max(0.0)
+            } else {
+                opp.fee_bps.max(0.0)
+            };
+            shadow.register_order(
+                &ack,
+                intent.clone(),
+                execution_style.clone(),
+                mid_for_side(&book, &intent.side).max(0.0),
+                effective_fee_bps,
+            );
+            if predator_cfg.v52.execution.alpha_window_enabled {
+                let anchor_price = aggressive_price_for_side(&book, &intent.side);
+                spawn_alpha_window_probe(
+                    shared.clone(),
+                    intent.market_id.clone(),
+                    intent.side.clone(),
+                    anchor_price,
+                    predator_cfg.v52.execution.alpha_window_move_bps,
+                    predator_cfg.v52.execution.alpha_window_poll_ms,
+                    predator_cfg.v52.execution.alpha_window_max_wait_ms,
+                );
+            }
+            if execution_style == ExecutionStyle::Maker && apply_force_taker_for_phase {
+                spawn_force_taker_fallback_for_maker(
+                    shared.clone(),
+                    execution.clone(),
+                    shadow.clone(),
+                    intent.market_id.clone(),
+                    token_id.clone(),
+                    intent.side.clone(),
+                    intent.size,
+                    intent.ttl_ms,
+                    ack.order_id.clone(),
+                    opp.fee_bps,
+                    opp.edge_net_bps,
+                    opp.timeframe.clone(),
+                    predator_cfg.v52.execution.late_force_taker_remaining_ms,
+                    predator_cfg.v52.execution.maker_wait_ms_before_force,
+                    maker_cfg.taker_max_slippage_bps,
+                );
+            }
+            if let Some(paper) = global_paper_runtime() {
+                let momentum_overlay = matches!(time_phase, TimePhase::Maturity)
+                    && direction_signal.velocity_bps_per_sec.abs()
+                        >= predator_cfg.direction_detector.min_velocity_bps_per_sec;
+                let stage = stage_for_phase(time_phase, momentum_overlay);
+                let (prob_fast, prob_settle) = shared
+                    .predator_latest_probability
+                    .read()
+                    .await
+                    .get(intent.market_id.as_str())
+                    .map(|p| (p.p_fast, p.p_settle))
+                    .unwrap_or((0.5, 0.5));
+                paper
+                    .register_order_intent(
+                        &ack,
+                        PaperIntentCtx {
+                            market_id: intent.market_id.clone(),
+                            symbol: opp.symbol.clone(),
+                            timeframe: opp.timeframe.to_string(),
+                            stage,
+                            direction: direction_signal.direction.clone(),
+                            velocity_bps_per_sec: direction_signal.velocity_bps_per_sec,
+                            edge_bps: opp.edge_net_bps,
+                            prob_fast,
+                            prob_settle,
+                            confidence: opp.confidence,
+                            action: PaperAction::Enter,
+                            intent: execution_style.clone(),
+                            requested_size_usdc: (intent.price * intent.size).max(0.0),
+                            requested_size_contracts: intent.size,
+                            entry_price: intent.price,
+                        },
+                    )
+                    .await;
+            }
+
+            for delay_ms in [5_u64, 10_u64, 25_u64] {
+                let shot = ShadowShot {
+                    shot_id: new_id(),
+                    market_id: intent.market_id.clone(),
+                    symbol: opp.symbol.clone(),
+                    side: intent.side.clone(),
+                    execution_style: execution_style.clone(),
+                    book_top_lag_ms,
+                    ack_only_ms,
+                    tick_to_ack_ms,
+                    capturable_window_ms,
+                    survival_probe_price: aggressive_price_for_side(&book, &intent.side),
+                    intended_price: intent.price,
+                    size: intent.size,
+                    edge_gross_bps: opp.edge_gross_bps,
+                    edge_net_bps: opp.edge_net_bps,
+                    fee_paid_bps: opp.fee_bps,
+                    rebate_est_bps: if execution_style == ExecutionStyle::Maker {
+                        get_rebate_bps_cached(shared, &intent.market_id, opp.fee_bps).await
+                    } else {
+                        0.0
+                    },
+                    delay_ms,
+                    t0_ns: now_ns(),
+                    min_edge_bps: predator_cfg.taker_sniper.min_edge_net_bps,
+                    tox_score: 0.0,
+                    ttl_ms: intent.ttl_ms,
+                };
+                shared.shadow_stats.push_shot(shot.clone()).await;
+                publish_if_telemetry_subscribers(bus, EngineEvent::ShadowShot(shot.clone()));
+                spawn_shadow_outcome_task(shared.clone(), bus.clone(), shot);
+            }
+        }
+        Ok(ack_v2) => {
+            let reject_code = ack_v2
+                .reject_code
+                .as_deref()
+                .map(normalize_reject_code)
+                .unwrap_or_else(|| "unknown".to_string());
+            shared
+                .shadow_stats
+                .mark_blocked_with_reason(&format!("exchange_reject_{reject_code}"))
+                .await;
+            metrics::counter!("execution.place_rejected").increment(1);
+            out.stop_firing = true;
+        }
+        Err(err) => {
+            let reason = classify_execution_error_reason(&err);
+            shared.shadow_stats.mark_blocked_with_reason(reason).await;
+            tracing::warn!(?err, "predator place_order failed");
+            metrics::counter!("execution.place_error").increment(1);
+        }
+    }
+
+    out
+}
diff --git a/crates/app_runner/src/tests.rs b/crates/app_runner/src/tests.rs
new file mode 100644
index 0000000..a16fc03
--- /dev/null
+++ b/crates/app_runner/src/tests.rs
@@ -0,0 +1,941 @@
+use std::collections::HashMap;
+use std::sync::atomic::{AtomicBool, Ordering};
+use std::sync::{Arc, RwLock as StdRwLock};
+use std::time::{Duration, Instant};
+
+use chrono::Utc;
+use core_types::{
+    new_id, BookTop, ControlCommand, Direction, DirectionSignal, EngineEvent, ExecutionStyle,
+    ExecutionVenue, OrderIntentV2, OrderSide, OrderTimeInForce, RefTick, Regime,
+    Stage,
+    Signal, SourceHealth, TimeframeClass, ToxicDecision, ToxicRegime,
+};
+use dashmap::DashMap;
+use direction_detector::DirectionDetector;
+use exit_manager::{ExitManager, PositionLifecycle};
+use fair_value::BasisMrConfig;
+use execution_clob::{wss_user_feed::WssFillEvent, ClobExecution, ExecutionMode};
+use infra_bus::RingBus;
+use paper_executor::ShadowExecutor;
+use probability_engine::ProbabilityEngine;
+use reqwest::Client;
+use risk_engine::{DefaultRiskManager, RiskLimits};
+use settlement_compounder::SettlementCompounder;
+use strategy_maker::MakerConfig;
+use taker_sniper::TakerSniper;
+use timeframe_router::TimeframeRouter;
+use tokio::sync::RwLock;
+use tokio::time::{sleep, timeout};
+
+use crate::config_loader::parse_toml_array_for_key;
+use crate::engine_core::normalize_reject_code;
+use crate::execution_eval::prebuild_order_payload;
+use crate::spawn_predator_exit_lifecycle;
+use crate::feed_runtime::{blend_settlement_probability, build_source_health_snapshot, SourceRuntimeStats};
+use crate::fusion_engine::{
+    compute_coalesce_policy, estimate_feed_latency, fast_tick_allowed_in_fusion_mode,
+    is_ref_tick_duplicate, reset_path_lag_calib_for_tests, should_arm_ws_primary_fallback,
+    should_enforce_udp_share_cap, should_replace_ref_tick, upsert_latest_tick_slot,
+};
+use crate::state::{
+    to_exit_manager_config, EdgeModelConfig, EngineShared, ExitConfig, FusionConfig,
+    MarketToxicState, PredatorCConfig, PredatorRegimeConfig, SettlementConfig, ShadowStats,
+    SignalCacheEntry, SourceHealthConfig, ToxicityConfig, V52DualArbConfig,
+    V52ExecutionConfig, V52TimePhaseConfig,
+};
+use crate::stats_utils::{now_ns, percentile, policy_block_ratio, quote_block_ratio, robust_filter_iqr};
+use crate::strategy_policy::{is_market_in_top_n, should_observe_only_symbol};
+use crate::strategy_runtime::{
+    allow_dual_side_arb, classify_predator_regime, classify_time_phase, should_force_taker_fallback,
+    stage_for_phase, time_phase_size_scale, timeframe_total_ms, TimePhase,
+};
+use crate::engine_loop::build_reversal_reentry_order;
+
+fn test_engine_shared_with_wss() -> (
+    Arc<EngineShared>,
+    Arc<tokio::sync::broadcast::Sender<WssFillEvent>>,
+) {
+    let strategy_cfg = Arc::new(RwLock::new(Arc::new(MakerConfig::default())));
+    let settlement_cfg = Arc::new(RwLock::new(SettlementConfig::default()));
+    let source_health_cfg = Arc::new(RwLock::new(SourceHealthConfig::default()));
+    let fusion_cfg = Arc::new(RwLock::new(FusionConfig::default()));
+    let edge_model_cfg = Arc::new(RwLock::new(EdgeModelConfig::default()));
+    let exit_cfg_value = ExitConfig {
+        enabled: true,
+        flatten_on_trigger: true,
+        ..ExitConfig::default()
+    };
+    let exit_cfg = Arc::new(RwLock::new(exit_cfg_value.clone()));
+    let fair_value_cfg = Arc::new(StdRwLock::new(BasisMrConfig::default()));
+    let toxicity_cfg = Arc::new(RwLock::new(Arc::new(ToxicityConfig::default())));
+    let risk_limits = Arc::new(StdRwLock::new(RiskLimits::default()));
+    let risk_manager = Arc::new(DefaultRiskManager::new(risk_limits.clone()));
+    let predator_cfg_value = PredatorCConfig::default();
+    let predator_cfg = Arc::new(RwLock::new(predator_cfg_value.clone()));
+    let predator_direction_detector = Arc::new(RwLock::new(DirectionDetector::new(
+        predator_cfg_value.direction_detector.clone(),
+    )));
+    let predator_probability_engine = Arc::new(RwLock::new(ProbabilityEngine::new(
+        predator_cfg_value.probability_engine.clone(),
+    )));
+    let predator_taker_sniper = Arc::new(RwLock::new(TakerSniper::new(
+        predator_cfg_value.taker_sniper.clone(),
+    )));
+    let predator_router = Arc::new(RwLock::new(TimeframeRouter::new(
+        predator_cfg_value.router.clone(),
+    )));
+    let predator_compounder = Arc::new(RwLock::new(SettlementCompounder::new(
+        predator_cfg_value.compounder.clone(),
+    )));
+    let predator_exit_manager = Arc::new(RwLock::new(ExitManager::new(to_exit_manager_config(
+        &exit_cfg_value,
+    ))));
+    let (wss_tx, _rx) = tokio::sync::broadcast::channel(64);
+    let wss_tx = Arc::new(wss_tx);
+
+    let shared = Arc::new(EngineShared {
+        latest_books: Arc::new(RwLock::new(HashMap::new())),
+        latest_signals: Arc::new(DashMap::new()),
+        latest_fast_ticks: Arc::new(DashMap::new()),
+        latest_anchor_ticks: Arc::new(DashMap::new()),
+        market_to_symbol: Arc::new(RwLock::new(HashMap::new())),
+        token_to_symbol: Arc::new(RwLock::new(HashMap::new())),
+        market_to_timeframe: Arc::new(RwLock::new(HashMap::new())),
+        symbol_to_markets: Arc::new(RwLock::new(HashMap::new())),
+        fee_cache: Arc::new(RwLock::new(HashMap::new())),
+        fee_refresh_inflight: Arc::new(RwLock::new(HashMap::new())),
+        scoring_cache: Arc::new(RwLock::new(HashMap::new())),
+        http: Client::new(),
+        clob_endpoint: "http://127.0.0.1:0".to_string(),
+        strategy_cfg,
+        settlement_cfg,
+        source_health_cfg,
+        source_health_latest: Arc::new(RwLock::new(HashMap::new())),
+        settlement_prices: Arc::new(RwLock::new(HashMap::new())),
+        fusion_cfg,
+        edge_model_cfg,
+        exit_cfg,
+        fair_value_cfg,
+        toxicity_cfg,
+        risk_manager,
+        risk_limits,
+        universe_symbols: Arc::new(vec!["BTCUSDT".to_string()]),
+        universe_market_types: Arc::new(vec!["updown".to_string()]),
+        universe_timeframes: Arc::new(vec!["5m".to_string(), "15m".to_string()]),
+        rate_limit_rps: 20.0,
+        tox_state: Arc::new(RwLock::new(HashMap::new())),
+        shadow_stats: Arc::new(ShadowStats::new()),
+        predator_cfg,
+        predator_direction_detector,
+        predator_latest_direction: Arc::new(RwLock::new(HashMap::new())),
+        predator_latest_probability: Arc::new(RwLock::new(HashMap::new())),
+        predator_probability_engine,
+        predator_taker_sniper,
+        predator_d_last_fire_ms: Arc::new(RwLock::new(HashMap::new())),
+        predator_router,
+        predator_compounder,
+        predator_exit_manager,
+        wss_fill_tx: Some(wss_tx.clone()),
+    });
+
+    (shared, wss_tx)
+}
+
+#[test]
+fn robust_filter_marks_outliers() {
+    let values = vec![1.0, 1.1, 1.2, 1.3, 99.0];
+    let (filtered, outlier_ratio) = robust_filter_iqr(&values);
+    assert!(filtered.len() < values.len());
+    assert!(outlier_ratio > 0.0);
+}
+
+#[test]
+fn robust_filter_small_sample_passthrough() {
+    let values = vec![1.0, 2.0, 3.0, 4.0];
+    let (filtered, outlier_ratio) = robust_filter_iqr(&values);
+    assert_eq!(filtered, values);
+    assert_eq!(outlier_ratio, 0.0);
+}
+
+#[test]
+fn percentile_basic_behavior() {
+    let values = vec![1.0, 5.0, 3.0, 2.0, 4.0];
+    assert_eq!(percentile(&values, 0.50), Some(3.0));
+    assert_eq!(percentile(&values, 0.0), Some(1.0));
+    assert_eq!(percentile(&values, 1.0), Some(5.0));
+}
+
+#[test]
+fn ref_tick_dedupe_uses_relative_bps_and_window() {
+    let cfg = FusionConfig {
+        dedupe_window_ms: 120,
+        dedupe_price_bps: 0.2,
+        ..FusionConfig::default()
+    };
+    assert!(is_ref_tick_duplicate(1_000, 100.001, 980, 100.0, &cfg));
+    assert!(!is_ref_tick_duplicate(1_500, 100.001, 980, 100.0, &cfg));
+    assert!(!is_ref_tick_duplicate(1_000, 100.005, 980, 100.0, &cfg));
+}
+
+#[test]
+fn websocket_primary_mode_keeps_dual_fast_sources() {
+    assert!(fast_tick_allowed_in_fusion_mode(
+        "binance_ws",
+        "websocket_primary"
+    ));
+    assert!(fast_tick_allowed_in_fusion_mode(
+        "binance_udp",
+        "websocket_primary"
+    ));
+    assert!(!fast_tick_allowed_in_fusion_mode(
+        "binance_udp",
+        "direct_only"
+    ));
+}
+
+#[test]
+fn websocket_primary_fallback_arms_only_when_ws_unavailable() {
+    assert!(should_arm_ws_primary_fallback(
+        "websocket_primary",
+        false,
+        true,
+        false
+    ));
+    assert!(!should_arm_ws_primary_fallback(
+        "websocket_primary",
+        true,
+        true,
+        false
+    ));
+    assert!(!should_arm_ws_primary_fallback(
+        "websocket_primary",
+        false,
+        true,
+        true
+    ));
+    assert!(!should_arm_ws_primary_fallback(
+        "active_active",
+        false,
+        true,
+        false
+    ));
+    assert!(!should_arm_ws_primary_fallback(
+        "websocket_primary",
+        false,
+        false,
+        false
+    ));
+}
+
+#[test]
+fn udp_share_cap_enforced_when_not_in_fallback() {
+    assert!(should_enforce_udp_share_cap(
+        "websocket_primary",
+        false,
+        true
+    ));
+    assert!(should_enforce_udp_share_cap("active_active", false, true));
+    assert!(!should_enforce_udp_share_cap(
+        "websocket_primary",
+        true,
+        true
+    ));
+    assert!(!should_enforce_udp_share_cap(
+        "websocket_primary",
+        false,
+        false
+    ));
+}
+
+#[test]
+fn fusion_default_stays_safe_baseline() {
+    let cfg = FusionConfig::default();
+    assert_eq!(cfg.mode, "direct_only");
+    assert!(cfg.enable_udp);
+    assert!(cfg.udp_share_cap > 0.0 && cfg.udp_share_cap <= 1.0);
+    assert!(cfg.jitter_threshold_ms >= 1.0);
+}
+
+#[test]
+fn reversal_taker_flatten_then_opposite_maker_reentry_order_shape() {
+    let book = BookTop {
+        market_id: "m".to_string(),
+        token_id_yes: "yes".to_string(),
+        token_id_no: "no".to_string(),
+        bid_yes: 0.48,
+        ask_yes: 0.52,
+        bid_no: 0.47,
+        ask_no: 0.53,
+        ts_ms: 1,
+        recv_ts_local_ns: 1_000_000,
+    };
+    let order = build_reversal_reentry_order("m", &OrderSide::BuyYes, &book, 2.0, 400, 2.5)
+        .expect("reentry order");
+    assert_eq!(order.side, OrderSide::BuyNo);
+    assert_eq!(order.token_id.as_deref(), Some("no"));
+    assert_eq!(order.price, book.bid_no);
+    assert_eq!(order.style, ExecutionStyle::Maker);
+    assert_eq!(order.tif, OrderTimeInForce::PostOnly);
+    assert!(order.size > 0.0);
+}
+
+#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
+async fn reversal_taker_to_opposite_maker_reentry_end_to_end_records_report() {
+    let (shared, wss_tx) = test_engine_shared_with_wss();
+    let bus = RingBus::new(256);
+    let execution = Arc::new(ClobExecution::new(
+        ExecutionMode::Paper,
+        "http://127.0.0.1:0".to_string(),
+    ));
+    let shadow = Arc::new(ShadowExecutor::default());
+    let market_id = "m_reversal".to_string();
+    let symbol = "BTCUSDT".to_string();
+    let now_ms = Utc::now().timestamp_millis();
+
+    shared.latest_books.write().await.insert(
+        market_id.clone(),
+        BookTop {
+            market_id: market_id.clone(),
+            token_id_yes: "yes_token".to_string(),
+            token_id_no: "no_token".to_string(),
+            bid_yes: 0.45,
+            ask_yes: 0.46,
+            bid_no: 0.54,
+            ask_no: 0.55,
+            ts_ms: now_ms,
+            recv_ts_local_ns: now_ns(),
+        },
+    );
+    shared.latest_signals.insert(
+        market_id.clone(),
+        SignalCacheEntry {
+            signal: Signal {
+                market_id: market_id.clone(),
+                fair_yes: 0.20,
+                edge_bps_bid: 12.0,
+                edge_bps_ask: -12.0,
+                confidence: 0.92,
+            },
+            ts_ms: now_ms,
+        },
+    );
+
+    let seen_direction_signal = Arc::new(AtomicBool::new(false));
+    let seen_flatten = Arc::new(AtomicBool::new(false));
+    let mut rx = bus.subscribe();
+    let execution_for_listener = execution.clone();
+    let seen_direction_signal_l = seen_direction_signal.clone();
+    let seen_flatten_l = seen_flatten.clone();
+    let listener = tokio::spawn(async move {
+        let deadline = Instant::now() + Duration::from_secs(3);
+        while Instant::now() < deadline {
+            match timeout(Duration::from_millis(250), rx.recv()).await {
+                Ok(Ok(EngineEvent::DirectionSignal(_))) => {
+                    seen_direction_signal_l.store(true, Ordering::Relaxed);
+                }
+                Ok(Ok(EngineEvent::Control(ControlCommand::Flatten))) => {
+                    seen_flatten_l.store(true, Ordering::Relaxed);
+                    let _ = execution_for_listener.flatten_all().await;
+                }
+                _ => {}
+            }
+        }
+    });
+
+    let _ = bus.publish(EngineEvent::DirectionSignal(DirectionSignal {
+        symbol: symbol.clone(),
+        direction: Direction::Up,
+        magnitude_pct: 0.32,
+        confidence: 0.93,
+        recommended_tf: TimeframeClass::Tf5m,
+        velocity_bps_per_sec: 12.0,
+        acceleration: 3.0,
+        tick_consistency: 4,
+        triple_confirm: true,
+        momentum_spike: true,
+        ts_ns: now_ns(),
+    }));
+
+    let entry_ack = execution
+        .place_order_v2(OrderIntentV2 {
+            market_id: market_id.clone(),
+            token_id: Some("yes_token".to_string()),
+            side: OrderSide::BuyYes,
+            price: 0.52,
+            size: 2.0,
+            ttl_ms: 500,
+            style: ExecutionStyle::Taker,
+            tif: OrderTimeInForce::Fak,
+            max_slippage_bps: 10.0,
+            fee_rate_bps: 2.0,
+            expected_edge_net_bps: 15.0,
+            client_order_id: Some(new_id()),
+            hold_to_resolution: false,
+            prebuilt_payload: None,
+        })
+        .await
+        .expect("paper entry ack");
+    assert!(entry_ack.accepted);
+
+    {
+        let mut manager = shared.predator_exit_manager.write().await;
+        manager.register(PositionLifecycle {
+            position_id: entry_ack.order_id.clone(),
+            market_id: market_id.clone(),
+            symbol: symbol.clone(),
+            opened_at_ms: now_ms,
+            entry_edge_usdc: 0.20,
+            entry_notional_usdc: 1.04,
+        });
+    }
+
+    spawn_predator_exit_lifecycle(
+        shared.clone(),
+        bus.clone(),
+        execution.clone(),
+        shadow,
+        entry_ack.order_id.clone(),
+        market_id.clone(),
+        symbol.clone(),
+        OrderSide::BuyYes,
+        0.52,
+        2.0,
+        500,
+        0.70,
+    );
+
+    sleep(Duration::from_millis(120)).await;
+    let _ = wss_tx.send(WssFillEvent {
+        order_id: entry_ack.order_id.clone(),
+        market_id: market_id.clone(),
+        price: 0.45,
+        size: 2.0,
+        event_type: "trade",
+        ts_ms: Utc::now().timestamp_millis(),
+    });
+    sleep(Duration::from_millis(900)).await;
+    let _ = listener.await;
+
+    let report = shared.shadow_stats.build_live_report().await;
+    let has_reversal_reason = report.exit_reason_top.iter().any(|(reason, count)| {
+        *count > 0 && (reason == "t_plus_100ms_reversal" || reason == "t_plus_300ms_reversal")
+    });
+
+    assert!(
+        seen_direction_signal.load(Ordering::Relaxed),
+        "direction signal stage must be observed"
+    );
+    assert!(
+        seen_flatten.load(Ordering::Relaxed),
+        "reversal path must publish flatten control"
+    );
+    assert!(
+        has_reversal_reason,
+        "live report must record reversal exit reason"
+    );
+    assert!(
+        report.executed_count >= 1,
+        "live report must include executed re-entry orders"
+    );
+}
+
+#[test]
+fn normalize_reject_code_sanitizes_non_alnum() {
+    let normalized = normalize_reject_code("HTTP 429/Too Many Requests");
+    assert_eq!(normalized, "http_429_too_many_requests");
+}
+
+#[test]
+fn estimate_feed_latency_separates_source_and_backlog() {
+    reset_path_lag_calib_for_tests();
+    let now = now_ns();
+    let now_ms = now / 1_000_000;
+    let tick = RefTick {
+        source: "binance_ws".to_string().into(),
+        symbol: "BTCUSDT".to_string(),
+        source_seq: now_ms as u64,
+        event_ts_ms: now_ms - 300,
+        recv_ts_ms: now_ms - 200,
+        event_ts_exchange_ms: now_ms - 300,
+        recv_ts_local_ns: now - 200_000_000,
+        ingest_ts_local_ns: now - 198_000_000,
+        ts_first_hop_ms: None,
+        price: 70_000.0,
+    };
+    let book = BookTop {
+        market_id: "m".to_string(),
+        token_id_yes: "yes".to_string(),
+        token_id_no: "no".to_string(),
+        bid_yes: 0.49,
+        ask_yes: 0.51,
+        bid_no: 0.49,
+        ask_no: 0.51,
+        ts_ms: now_ms - 40,
+        recv_ts_local_ns: now - 20_000_000,
+    };
+
+    let sample = estimate_feed_latency(&tick, &book);
+    assert!(sample.source_latency_ms >= 95.0);
+    assert!(sample.source_latency_ms <= 110.0);
+    assert!(sample.local_backlog_ms >= 10.0);
+    assert!(sample.local_backlog_ms <= 40.0);
+    assert!(sample.feed_in_ms >= 1.0);
+    assert!(sample.feed_in_ms <= 4.0);
+    assert!((sample.feed_in_ms - sample.ref_decode_ms).abs() < 0.0001);
+}
+
+#[test]
+fn estimate_feed_latency_calibrates_path_lag_with_clock_offset() {
+    reset_path_lag_calib_for_tests();
+    let now = now_ns();
+    let now_ms = now / 1_000_000;
+    let book = BookTop {
+        market_id: "m".to_string(),
+        token_id_yes: "yes".to_string(),
+        token_id_no: "no".to_string(),
+        bid_yes: 0.49,
+        ask_yes: 0.51,
+        bid_no: 0.49,
+        ask_no: 0.51,
+        ts_ms: now_ms - 10,
+        recv_ts_local_ns: now - 5_000_000,
+    };
+
+    // First sample establishes floor with a negative raw delta (clock skew baseline).
+    let tick_floor = RefTick {
+        source: "binance_udp_calib".to_string().into(),
+        symbol: "BTCUSDT".to_string(),
+        source_seq: 1,
+        event_ts_ms: now_ms - 120,
+        recv_ts_ms: now_ms - 100,
+        event_ts_exchange_ms: now_ms - 120,
+        recv_ts_local_ns: now - 100_000_000,
+        ingest_ts_local_ns: now - 99_000_000,
+        ts_first_hop_ms: Some(now_ms - 90),
+        price: 70_000.0,
+    };
+    let first = estimate_feed_latency(&tick_floor, &book);
+    assert!(first.path_lag_ms <= 0.01);
+
+    // Second sample has larger delta and should show positive path lag after calibration.
+    let tick_next = RefTick {
+        source_seq: 2,
+        recv_ts_ms: now_ms - 80,
+        ts_first_hop_ms: Some(now_ms - 95),
+        ..tick_floor.clone()
+    };
+    let second = estimate_feed_latency(&tick_next, &book);
+    assert!(second.path_lag_ms >= 20.0);
+    assert!(second.path_lag_ms <= 35.0);
+}
+
+#[test]
+fn should_replace_ref_tick_respects_staleness_budget_for_same_event() {
+    let current = RefTick {
+        source: "binance_ws".to_string().into(),
+        symbol: "BTCUSDT".to_string(),
+        source_seq: 10,
+        event_ts_ms: 1_000,
+        recv_ts_ms: 1_010,
+        event_ts_exchange_ms: 1_000,
+        recv_ts_local_ns: 1_000_000_000,
+        ingest_ts_local_ns: 1_000_100_000,
+        ts_first_hop_ms: None,
+        price: 100.0,
+    };
+    let mut next = current.clone();
+    next.source = "binance_udp".to_string().into();
+    next.recv_ts_local_ns = current.recv_ts_local_ns + 2_000_000;
+    next.recv_ts_ms = current.recv_ts_ms + 2;
+
+    assert!(!should_replace_ref_tick(&current, &next));
+}
+
+#[test]
+fn upsert_latest_tick_slot_reports_source_switch_delta() {
+    let ticks = DashMap::<String, RefTick>::new();
+    let first = RefTick {
+        source: "binance_ws".to_string().into(),
+        symbol: "BTCUSDT".to_string(),
+        source_seq: 1,
+        event_ts_ms: 1_000,
+        recv_ts_ms: 1_010,
+        event_ts_exchange_ms: 1_000,
+        recv_ts_local_ns: 1_000_000_000,
+        ingest_ts_local_ns: 1_000_050_000,
+        ts_first_hop_ms: None,
+        price: 100.0,
+    };
+    let mut second = first.clone();
+    second.source = "binance_udp".to_string().into();
+    second.event_ts_exchange_ms += 2;
+    second.recv_ts_ms += 1;
+    second.recv_ts_local_ns += 400_000;
+    second.price = 100.2;
+
+    let first_delta = upsert_latest_tick_slot(&ticks, first, should_replace_ref_tick);
+    assert!(first_delta.is_none());
+    let second_delta = upsert_latest_tick_slot(&ticks, second, should_replace_ref_tick);
+    assert_eq!(second_delta, Some(400_000));
+}
+
+#[test]
+fn sol_guard_observe_only_for_high_latency_or_spread() {
+    let mut cfg = MakerConfig::default();
+    cfg.market_tier_profile = "balanced_sol_guard".to_string();
+    let tox = ToxicDecision {
+        market_id: "m".to_string(),
+        symbol: "SOLUSDT".to_string(),
+        tox_score: 0.2,
+        regime: ToxicRegime::Safe,
+        reason_codes: vec![],
+        ts_ns: 1,
+    };
+    assert!(should_observe_only_symbol(
+        "SOLUSDT", &cfg, &tox, 120.0, 0.01, 180.0
+    ));
+    assert!(should_observe_only_symbol(
+        "SOLUSDT", &cfg, &tox, 320.0, 0.01, 80.0
+    ));
+    assert!(should_observe_only_symbol(
+        "SOLUSDT", &cfg, &tox, 120.0, 0.03, 80.0
+    ));
+    assert!(!should_observe_only_symbol(
+        "SOLUSDT", &cfg, &tox, 120.0, 0.01, 80.0
+    ));
+    assert!(!should_observe_only_symbol(
+        "BTCUSDT", &cfg, &tox, 260.0, 0.03, 999.0
+    ));
+}
+
+#[test]
+fn quote_block_ratio_matches_contract_and_is_bounded() {
+    assert_eq!(quote_block_ratio(0, 0), 0.0);
+    assert_eq!(quote_block_ratio(10, 0), 0.0);
+    assert_eq!(quote_block_ratio(0, 10), 1.0);
+
+    let r = quote_block_ratio(10, 2);
+    assert!(r > 0.0 && r < 1.0);
+}
+
+#[test]
+fn policy_block_ratio_matches_contract_and_is_bounded() {
+    assert_eq!(policy_block_ratio(0, 0), 0.0);
+    assert_eq!(policy_block_ratio(10, 0), 0.0);
+    assert_eq!(policy_block_ratio(0, 10), 1.0);
+
+    let r = policy_block_ratio(10, 2);
+    assert!(r > 0.0 && r < 1.0);
+}
+
+#[test]
+fn uptime_pct_is_bounded() {
+    let stats = ShadowStats::new();
+    let u = stats.uptime_pct(Duration::from_secs(1));
+    assert!((0.0..=100.0).contains(&u));
+}
+
+#[test]
+fn parse_toml_array_for_key_handles_multiline_arrays() {
+    let raw = r#"
+assets = [
+  "BTCUSDT",
+  "ETHUSDT",
+  "XRPUSDT",
+]
+market_types = ["updown", "range"]
+timeframes = ["5m", "15m", "1h", "1d"]
+"#;
+    let assets = parse_toml_array_for_key(raw, "assets").unwrap_or_default();
+    assert_eq!(
+        assets,
+        vec![
+            "BTCUSDT".to_string(),
+            "ETHUSDT".to_string(),
+            "XRPUSDT".to_string()
+        ]
+    );
+    let market_types = parse_toml_array_for_key(raw, "market_types").unwrap_or_default();
+    assert_eq!(
+        market_types,
+        vec!["updown".to_string(), "range".to_string()]
+    );
+    let timeframes = parse_toml_array_for_key(raw, "timeframes").unwrap_or_default();
+    assert_eq!(
+        timeframes,
+        vec![
+            "5m".to_string(),
+            "15m".to_string(),
+            "1h".to_string(),
+            "1d".to_string()
+        ]
+    );
+}
+
+#[test]
+fn parse_toml_array_for_key_returns_none_for_missing_or_empty() {
+    let raw = "foo = 1\nassets = []\n";
+    assert!(parse_toml_array_for_key(raw, "missing").is_none());
+    assert!(parse_toml_array_for_key(raw, "assets").is_none());
+}
+
+#[test]
+fn blend_settlement_probability_moves_toward_half_when_gap_widens() {
+    let p_small_gap = blend_settlement_probability(0.80, 100.0, 99.9);
+    let p_large_gap = blend_settlement_probability(0.80, 100.0, 97.5);
+    assert!(p_small_gap > 0.70);
+    assert!(p_large_gap < p_small_gap);
+    assert!(p_large_gap > 0.50);
+}
+
+#[test]
+fn blend_settlement_probability_is_stable_when_prices_match() {
+    let p = blend_settlement_probability(0.63, 100.0, 100.0);
+    assert!((p - 0.63).abs() < 1e-9);
+}
+
+#[test]
+fn source_health_snapshot_penalizes_bad_stream() {
+    let cfg = SourceHealthConfig::default();
+    let stats = SourceRuntimeStats {
+        sample_count: 256,
+        latency_sum_ms: 256.0 * 24.0,
+        latency_sq_sum_ms: 256.0 * (24.0f64.powi(2) + 18.0f64.powi(2)),
+        out_of_order_count: 12,
+        gap_count: 16,
+        last_event_ts_ms: 1_699_999_994_900,
+        last_recv_ts_ms: 1_699_999_995_000,
+        deviation_ema_bps: 80.0,
+    };
+    let row = build_source_health_snapshot("binance", &stats, &cfg, 1_700_000_000_000);
+    assert!(row.score < 0.45);
+    assert!(row.gap_rate > 0.01);
+    assert!(row.out_of_order_rate > 0.01);
+    assert!(row.jitter_ms > cfg.jitter_limit_ms);
+    assert!(row.freshness_score < 0.5);
+}
+
+#[test]
+fn source_health_snapshot_stays_high_for_clean_stream() {
+    let cfg = SourceHealthConfig::default();
+    let stats = SourceRuntimeStats {
+        sample_count: 512,
+        latency_sum_ms: 512.0 * 4.0,
+        latency_sq_sum_ms: 512.0 * (4.0f64.powi(2) + 0.8f64.powi(2)),
+        out_of_order_count: 0,
+        gap_count: 0,
+        last_event_ts_ms: 1_699_999_999_996,
+        last_recv_ts_ms: 1_699_999_999_998,
+        deviation_ema_bps: 3.0,
+    };
+    let row = build_source_health_snapshot("coinbase", &stats, &cfg, 1_700_000_000_000);
+    assert!(row.score > 0.75);
+    assert!(row.jitter_ms < cfg.jitter_limit_ms);
+    assert!(row.price_deviation_bps < cfg.deviation_limit_bps);
+    assert!(row.freshness_score > 0.9);
+}
+
+#[test]
+fn classify_predator_regime_defend_on_toxicity_or_source_health() {
+    let cfg = PredatorRegimeConfig::default();
+    let source_cfg = SourceHealthConfig::default();
+    let signal = DirectionSignal {
+        symbol: "BTCUSDT".to_string(),
+        direction: Direction::Up,
+        magnitude_pct: 0.25,
+        confidence: 0.92,
+        recommended_tf: TimeframeClass::Tf15m,
+        velocity_bps_per_sec: 10.0,
+        acceleration: 1.0,
+        tick_consistency: 3,
+        triple_confirm: true,
+        momentum_spike: false,
+        ts_ns: 1,
+    };
+
+    let regime_tox =
+        classify_predator_regime(&cfg, &signal, 0.95, &ToxicRegime::Danger, None, &source_cfg);
+    assert_eq!(regime_tox, Regime::Defend);
+
+    let source_low = SourceHealth {
+        source: "binance_udp".to_string(),
+        latency_ms: 20.0,
+        jitter_ms: 5.0,
+        out_of_order_rate: 0.0,
+        gap_rate: 0.0,
+        price_deviation_bps: 0.0,
+        freshness_score: 1.0,
+        score: 0.10,
+        sample_count: source_cfg.min_samples,
+        ts_ms: 1,
+    };
+    let regime_source = classify_predator_regime(
+        &cfg,
+        &signal,
+        0.10,
+        &ToxicRegime::Safe,
+        Some(&source_low),
+        &source_cfg,
+    );
+    assert_eq!(regime_source, Regime::Defend);
+}
+
+#[test]
+fn classify_predator_regime_switches_between_active_and_quiet() {
+    let cfg = PredatorRegimeConfig::default();
+    let source_cfg = SourceHealthConfig::default();
+    let mut active_signal = DirectionSignal {
+        symbol: "BTCUSDT".to_string(),
+        direction: Direction::Up,
+        magnitude_pct: 0.20,
+        confidence: 0.85,
+        recommended_tf: TimeframeClass::Tf5m,
+        velocity_bps_per_sec: 8.0,
+        acceleration: 1.2,
+        tick_consistency: 3,
+        triple_confirm: true,
+        momentum_spike: false,
+        ts_ns: 1,
+    };
+
+    let active = classify_predator_regime(
+        &cfg,
+        &active_signal,
+        0.15,
+        &ToxicRegime::Safe,
+        None,
+        &source_cfg,
+    );
+    assert_eq!(active, Regime::Active);
+
+    active_signal.confidence = 0.45;
+    active_signal.magnitude_pct = 0.02;
+    let quiet = classify_predator_regime(
+        &cfg,
+        &active_signal,
+        0.10,
+        &ToxicRegime::Safe,
+        None,
+        &source_cfg,
+    );
+    assert_eq!(quiet, Regime::Quiet);
+}
+
+#[test]
+fn is_market_in_top_n_matches_score_order_without_sorting() {
+    let mut states = HashMap::<String, MarketToxicState>::new();
+    let mut s1 = MarketToxicState::default();
+    s1.market_score = 95.0;
+    states.insert("m1".to_string(), s1);
+    let mut s2 = MarketToxicState::default();
+    s2.market_score = 88.0;
+    states.insert("m2".to_string(), s2);
+    let mut s3 = MarketToxicState::default();
+    s3.market_score = 70.0;
+    states.insert("m3".to_string(), s3);
+
+    assert!(is_market_in_top_n(&states, "m1", 1));
+    assert!(!is_market_in_top_n(&states, "m2", 1));
+    assert!(is_market_in_top_n(&states, "m2", 2));
+    assert!(!is_market_in_top_n(&states, "m3", 2));
+}
+
+#[test]
+fn prebuild_order_payload_uses_intent_tif_and_style() {
+    let intent = OrderIntentV2 {
+        market_id: "m1".to_string(),
+        side: OrderSide::BuyYes,
+        token_id: Some("t1".to_string()),
+        price: 0.52,
+        size: 5.0,
+        ttl_ms: 120,
+        style: ExecutionStyle::Maker,
+        tif: OrderTimeInForce::PostOnly,
+        client_order_id: Some("cid1".to_string()),
+        max_slippage_bps: 12.0,
+        fee_rate_bps: 2.0,
+        expected_edge_net_bps: 8.0,
+        hold_to_resolution: false,
+        prebuilt_payload: None,
+    };
+    let bytes = prebuild_order_payload(&intent).expect("payload");
+    let value: serde_json::Value = serde_json::from_slice(&bytes).expect("json");
+    assert_eq!(value["style"], "maker");
+    assert_eq!(value["tif"], "POST_ONLY");
+    assert_eq!(value["token_id"], "t1");
+}
+
+#[test]
+fn compute_coalesce_policy_skips_for_shallow_queue() {
+    let p = compute_coalesce_policy(3, Some(10.0), 96, 4, 200);
+    assert_eq!(p.max_events, 0);
+    assert_eq!(p.budget_us, 0);
+}
+
+#[test]
+fn compute_coalesce_policy_scales_for_deep_queue() {
+    let p = compute_coalesce_policy(40, Some(50.0), 96, 4, 200);
+    assert!(p.max_events >= 24);
+    assert!(p.max_events <= 40);
+    assert_eq!(p.budget_us, 160);
+
+    let fast = compute_coalesce_policy(40, Some(10.0), 96, 4, 200);
+    assert_eq!(fast.budget_us, 40);
+}
+
+#[test]
+fn compute_coalesce_policy_uses_drain_mode_for_very_deep_queue() {
+    let p = compute_coalesce_policy(200, Some(60.0), 256, 4, 120);
+    assert_eq!(p.max_events, 200);
+    assert_eq!(p.budget_us, 800);
+}
+
+#[test]
+fn v52_time_phase_boundaries_for_5m_and_15m() {
+    let cfg = V52TimePhaseConfig::default();
+    let tf_5m_total = timeframe_total_ms(TimeframeClass::Tf5m).expect("5m total");
+    let tf_15m_total = timeframe_total_ms(TimeframeClass::Tf15m).expect("15m total");
+    assert_eq!(tf_5m_total, 300_000);
+    assert_eq!(tf_15m_total, 900_000);
+
+    assert_eq!(classify_time_phase(0.56, &cfg), TimePhase::Early);
+    assert_eq!(classify_time_phase(0.55, &cfg), TimePhase::Maturity);
+    assert_eq!(classify_time_phase(0.11, &cfg), TimePhase::Maturity);
+    assert_eq!(classify_time_phase(0.10, &cfg), TimePhase::Late);
+    assert_eq!(classify_time_phase(0.01, &cfg), TimePhase::Late);
+}
+
+#[test]
+fn v52_momentum_overlay_only_in_maturity() {
+    assert_eq!(stage_for_phase(TimePhase::Early, true), Stage::Early);
+    assert_eq!(stage_for_phase(TimePhase::Late, true), Stage::Late);
+    assert_eq!(stage_for_phase(TimePhase::Maturity, false), Stage::Maturity);
+    assert_eq!(stage_for_phase(TimePhase::Maturity, true), Stage::Momentum);
+}
+
+#[test]
+fn v52_phase_size_scale_is_configurable() {
+    let mut cfg = V52TimePhaseConfig::default();
+    cfg.early_size_scale = 0.7;
+    cfg.maturity_size_scale = 1.1;
+    cfg.late_size_scale = 1.4;
+    assert!((time_phase_size_scale(TimePhase::Early, &cfg) - 0.7).abs() < 1e-9);
+    assert!((time_phase_size_scale(TimePhase::Maturity, &cfg) - 1.1).abs() < 1e-9);
+    assert!((time_phase_size_scale(TimePhase::Late, &cfg) - 1.4).abs() < 1e-9);
+}
+
+#[test]
+fn v52_force_taker_rule_applies_to_maturity_and_late() {
+    let cfg = V52ExecutionConfig::default();
+    assert!(!should_force_taker_fallback(TimePhase::Early, 29_000, &cfg));
+    assert!(should_force_taker_fallback(TimePhase::Maturity, 29_000, &cfg));
+    assert!(should_force_taker_fallback(TimePhase::Late, 29_000, &cfg));
+    assert!(!should_force_taker_fallback(TimePhase::Maturity, 31_000, &cfg));
+}
+
+#[test]
+fn v52_dual_arb_threshold_formula() {
+    let cfg = V52DualArbConfig::default();
+    assert!(allow_dual_side_arb(0.40, 0.40, 2.0, &cfg));
+    assert!(!allow_dual_side_arb(0.50, 0.49, 2.0, &cfg));
+}
diff --git a/crates/app_runner/src/toxicity_report.rs b/crates/app_runner/src/toxicity_report.rs
new file mode 100644
index 0000000..cbb376a
--- /dev/null
+++ b/crates/app_runner/src/toxicity_report.rs
@@ -0,0 +1,106 @@
+use std::collections::HashMap;
+use std::sync::Arc;
+
+use chrono::Utc;
+use core_types::ToxicRegime;
+use execution_clob::ClobExecution;
+use tokio::sync::RwLock;
+
+use crate::state::{
+    MarketToxicState, ShadowStats, ToxicityConfig, ToxicityLiveReport, ToxicityMarketRow,
+};
+use crate::stats_utils::percentile_deque_capped;
+use crate::strategy_policy::compute_market_score;
+
+pub(super) async fn build_toxicity_live_report(
+    tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
+    shadow_stats: Arc<ShadowStats>,
+    execution: Arc<ClobExecution>,
+    toxicity_cfg: Arc<RwLock<Arc<ToxicityConfig>>>,
+) -> ToxicityLiveReport {
+    let cfg = toxicity_cfg.read().await.clone();
+    let states = tox_state.read().await.clone();
+    let shots = shadow_stats.shots.read().await.clone();
+    let outcomes = shadow_stats.outcomes.read().await.clone();
+
+    let mut rows = Vec::<ToxicityMarketRow>::new();
+    let mut safe = 0usize;
+    let mut caution = 0usize;
+    let mut danger = 0usize;
+    let mut tox_sum = 0.0;
+
+    for (market_id, st) in states {
+        let symbol = if !st.symbol.is_empty() {
+            st.symbol.clone()
+        } else {
+            shots
+                .iter()
+                .find(|s| s.market_id == market_id)
+                .map(|s| s.symbol.clone())
+                .or_else(|| {
+                    outcomes
+                        .iter()
+                        .find(|o| o.market_id == market_id)
+                        .map(|o| o.symbol.clone())
+                })
+                .unwrap_or_else(|| "UNKNOWN".to_string())
+        };
+        let attempted = st.attempted.max(1);
+        let no_quote_rate = st.no_quote as f64 / attempted as f64;
+        let symbol_missing_rate = st.symbol_missing as f64 / attempted as f64;
+        let markout_10s_bps = percentile_deque_capped(&st.markout_10s, 0.50, 2048).unwrap_or(0.0);
+        let markout_samples = st
+            .markout_1s
+            .len()
+            .max(st.markout_5s.len())
+            .max(st.markout_10s.len());
+        let market_score = if st.market_score > 0.0 {
+            st.market_score
+        } else {
+            compute_market_score(&st, st.last_tox_score, markout_samples)
+        };
+        let pending_exposure = execution.open_order_notional_for_market(&market_id);
+
+        tox_sum += st.last_tox_score;
+        match st.last_regime {
+            ToxicRegime::Safe => safe += 1,
+            ToxicRegime::Caution => caution += 1,
+            ToxicRegime::Danger => danger += 1,
+        }
+
+        rows.push(ToxicityMarketRow {
+            market_rank: 0,
+            market_id,
+            symbol,
+            tox_score: st.last_tox_score,
+            regime: st.last_regime,
+            market_score,
+            markout_10s_bps,
+            no_quote_rate,
+            symbol_missing_rate,
+            pending_exposure,
+            active_for_quoting: false,
+        });
+    }
+
+    rows.sort_by(|a, b| b.market_score.total_cmp(&a.market_score));
+    let top_n = cfg.active_top_n_markets;
+    for (idx, row) in rows.iter_mut().enumerate() {
+        row.market_rank = idx + 1;
+        row.active_for_quoting = top_n == 0 || (idx < top_n);
+    }
+    let avg = if rows.is_empty() {
+        0.0
+    } else {
+        tox_sum / (rows.len() as f64)
+    };
+
+    ToxicityLiveReport {
+        ts_ms: Utc::now().timestamp_millis(),
+        average_tox_score: avg,
+        safe_count: safe,
+        caution_count: caution,
+        danger_count: danger,
+        rows,
+    }
+}
diff --git a/crates/app_runner/src/toxicity_runtime.rs b/crates/app_runner/src/toxicity_runtime.rs
new file mode 100644
index 0000000..268f4e6
--- /dev/null
+++ b/crates/app_runner/src/toxicity_runtime.rs
@@ -0,0 +1,39 @@
+use std::collections::VecDeque;
+
+use core_types::ShadowOutcome;
+
+use crate::state::EngineShared;
+use crate::strategy_policy::compute_market_score;
+
+pub(super) async fn update_toxic_state_from_outcome(
+    shared: &EngineShared,
+    outcome: &ShadowOutcome,
+) {
+    if !outcome.fillable || outcome.delay_ms != 10 {
+        return;
+    }
+    let mut states = shared.tox_state.write().await;
+    let st = states.entry(outcome.market_id.clone()).or_default();
+    if let Some(v) = outcome.net_markout_1s_bps.or(outcome.pnl_1s_bps) {
+        push_rolling(&mut st.markout_1s, v, 2048);
+    }
+    if let Some(v) = outcome.net_markout_5s_bps.or(outcome.pnl_5s_bps) {
+        push_rolling(&mut st.markout_5s, v, 2048);
+    }
+    if let Some(v) = outcome.net_markout_10s_bps.or(outcome.pnl_10s_bps) {
+        push_rolling(&mut st.markout_10s, v, 2048);
+    }
+    let samples = st
+        .markout_1s
+        .len()
+        .max(st.markout_5s.len())
+        .max(st.markout_10s.len());
+    st.market_score = compute_market_score(st, st.last_tox_score, samples);
+}
+
+pub(super) fn push_rolling(dst: &mut VecDeque<f64>, value: f64, cap: usize) {
+    dst.push_back(value);
+    while dst.len() > cap {
+        dst.pop_front();
+    }
+}
diff --git a/crates/core_types/Cargo.toml b/crates/core_types/Cargo.toml
index 8103336..c788fb7 100644
--- a/crates/core_types/Cargo.toml
+++ b/crates/core_types/Cargo.toml
@@ -11,5 +11,6 @@ chrono.workspace = true
 futures.workspace = true
 serde.workspace = true
 serde_json.workspace = true
+smol_str.workspace = true
 thiserror.workspace = true
 uuid.workspace = true
diff --git a/crates/core_types/src/lib.rs b/crates/core_types/src/lib.rs
index cb13499..37d9708 100644
--- a/crates/core_types/src/lib.rs
+++ b/crates/core_types/src/lib.rs
@@ -5,19 +5,30 @@ use async_trait::async_trait;
 use chrono::{DateTime, Utc};
 use futures::stream::BoxStream;
 use serde::{Deserialize, Serialize};
+use smol_str::SmolStr;
 use thiserror::Error;
 use uuid::Uuid;
 
 #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
 pub struct RefTick {
-    pub source: String,
+    pub source: SmolStr,
     pub symbol: String,
     pub event_ts_ms: i64,
     pub recv_ts_ms: i64,
     #[serde(default)]
+    pub source_seq: u64,
+    #[serde(default)]
     pub event_ts_exchange_ms: i64,
     #[serde(default)]
     pub recv_ts_local_ns: i64,
+    /// Local timestamp taken after decoding/parsing and right before enqueueing/publishing.
+    /// This enables measuring pure local decode/ingest latency independent of exchange clocks.
+    #[serde(default)]
+    pub ingest_ts_local_ns: i64,
+    /// First-hop local timestamp recorded at Tokyo relay ingress.
+    /// Used to split exchange-lag vs private-path-lag in reports.
+    #[serde(default)]
+    pub ts_first_hop_ms: Option<i64>,
     pub price: f64,
 }
 
@@ -99,6 +110,136 @@ pub struct Signal {
     pub confidence: f64,
 }
 
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
+pub enum TimeframeClass {
+    Tf5m,
+    Tf15m,
+    Tf1h,
+    Tf1d,
+}
+
+impl fmt::Display for TimeframeClass {
+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+        let value = match self {
+            Self::Tf5m => "5m",
+            Self::Tf15m => "15m",
+            Self::Tf1h => "1h",
+            Self::Tf1d => "1d",
+        };
+        f.write_str(value)
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
+pub enum Direction {
+    Up,
+    Down,
+    Neutral,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct DirectionSignal {
+    pub symbol: String,
+    pub direction: Direction,
+    /// Price move magnitude in percentage points, e.g. 0.35 means +0.35%.
+    pub magnitude_pct: f64,
+    /// Confidence in [0,1], derived from multi-source consistency.
+    pub confidence: f64,
+    pub recommended_tf: TimeframeClass,
+    /// First derivative of price move in bps/s.
+    #[serde(default)]
+    pub velocity_bps_per_sec: f64,
+    /// Second derivative in (bps/s)/s.
+    #[serde(default)]
+    pub acceleration: f64,
+    /// Count of consecutive same-direction ticks used by the triple-confirm gate.
+    #[serde(default)]
+    pub tick_consistency: u8,
+    /// Whether the triple-confirm gate passed (velocity + acceleration/volume + consecutive ticks).
+    /// Used by downstream scorers (e.g. WinRateScore) to assess signal quality.
+    #[serde(default)]
+    pub triple_confirm: bool,
+    /// Whether the velocity exceeded the momentum-spike multiplier threshold.
+    #[serde(default)]
+    pub momentum_spike: bool,
+    pub ts_ns: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct CapitalUpdate {
+    pub available_usdc: f64,
+    /// "Base quote size" used by Predator C+ sizing logic. Interpreted as USDC notional.
+    pub base_quote_size: f64,
+    pub ts_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct ProbabilityEstimate {
+    pub p_fast: f64,
+    pub p_settle: f64,
+    pub confidence: f64,
+    #[serde(default)]
+    pub settlement_source_degraded: bool,
+    pub ts_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
+#[serde(rename_all = "snake_case")]
+pub enum Stage {
+    Early,
+    Momentum,
+    Maturity,
+    Late,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct ExecutionIntent {
+    pub market_id: String,
+    pub symbol: String,
+    pub side: OrderSide,
+    pub style: ExecutionStyle,
+    pub stage: Stage,
+    pub edge_net_bps: f64,
+    pub confidence: f64,
+    pub ts_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct SourceHealth {
+    pub source: String,
+    pub latency_ms: f64,
+    pub jitter_ms: f64,
+    pub out_of_order_rate: f64,
+    pub gap_rate: f64,
+    pub price_deviation_bps: f64,
+    #[serde(default)]
+    pub freshness_score: f64,
+    pub score: f64,
+    #[serde(default)]
+    pub sample_count: u64,
+    #[serde(default)]
+    pub ts_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct TimeframeOpp {
+    pub timeframe: TimeframeClass,
+    pub market_id: String,
+    pub symbol: String,
+    pub direction: Direction,
+    pub side: OrderSide,
+    pub entry_price: f64,
+    pub size: f64,
+    pub edge_gross_bps: f64,
+    pub edge_net_bps: f64,
+    pub edge_net_usdc: f64,
+    pub fee_bps: f64,
+    pub lock_minutes: f64,
+    pub density: f64,
+    pub confidence: f64,
+    pub ts_ms: i64,
+}
+
 #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
 pub enum OrderSide {
     BuyYes,
@@ -188,6 +329,8 @@ pub struct OrderAck {
 pub struct OrderIntentV2 {
     pub market_id: String,
     pub side: OrderSide,
+    #[serde(default)]
+    pub token_id: Option<String>,
     pub price: f64,
     pub size: f64,
     pub ttl_ms: u64,
@@ -196,6 +339,8 @@ pub struct OrderIntentV2 {
     #[serde(default = "default_order_tif")]
     pub tif: OrderTimeInForce,
     #[serde(default)]
+    pub client_order_id: Option<String>,
+    #[serde(default)]
     pub max_slippage_bps: f64,
     #[serde(default)]
     pub fee_rate_bps: f64,
@@ -203,6 +348,11 @@ pub struct OrderIntentV2 {
     pub expected_edge_net_bps: f64,
     #[serde(default)]
     pub hold_to_resolution: bool,
+    /// B: é¢„åºåˆ—åŒ– JSON payload â€” åœ¨ä¿¡å·ç¡®è®¤åŽç«‹å³æž„å»ºï¼Œè·³è¿‡ place_order_v2 é‡Œçš„ serde å¼€é”€ã€‚
+    /// è®¾ç½®åŽ execution_clob ç›´æŽ¥ç”¨æ­¤å­—èŠ‚ä¸²ä½œä¸º HTTP bodyï¼Œä¸å†é‡æ–°åºåˆ—åŒ–ã€‚
+    /// `None` æ—¶å›žé€€åˆ°åŽŸå§‹åºåˆ—åŒ–è·¯å¾„ï¼Œä¿è¯å‘åŽå…¼å®¹ã€‚
+    #[serde(skip)]
+    pub prebuilt_payload: Option<Vec<u8>>,
 }
 
 impl From<QuoteIntent> for OrderIntentV2 {
@@ -210,15 +360,18 @@ impl From<QuoteIntent> for OrderIntentV2 {
         Self {
             market_id: value.market_id,
             side: value.side,
+            token_id: None,
             price: value.price,
             size: value.size,
             ttl_ms: value.ttl_ms,
             style: ExecutionStyle::Maker,
             tif: OrderTimeInForce::PostOnly,
+            client_order_id: None,
             max_slippage_bps: 0.0,
             fee_rate_bps: 0.0,
             expected_edge_net_bps: 0.0,
             hold_to_resolution: false,
+            prebuilt_payload: None,
         }
     }
 }
@@ -242,12 +395,142 @@ pub struct FillEvent {
     pub order_id: String,
     pub market_id: String,
     pub side: OrderSide,
+    #[serde(default = "default_execution_style")]
+    pub style: ExecutionStyle,
     pub price: f64,
     pub size: f64,
     pub fee: f64,
+    #[serde(default)]
+    pub mid_price: Option<f64>,
+    #[serde(default)]
+    pub slippage_bps: Option<f64>,
     pub ts_ms: i64,
 }
 
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
+#[serde(rename_all = "snake_case")]
+pub enum PaperAction {
+    Enter,
+    Add,
+    ReversalExit,
+    LateHeavy,
+    DoubleSide,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct PaperIntent {
+    pub ts_ms: i64,
+    pub order_id: String,
+    pub market_id: String,
+    pub symbol: String,
+    pub timeframe: String,
+    pub stage: Stage,
+    pub direction: Direction,
+    pub velocity_bps_per_sec: f64,
+    pub edge_bps: f64,
+    pub prob_fast: f64,
+    pub prob_settle: f64,
+    pub confidence: f64,
+    pub action: PaperAction,
+    pub intent: ExecutionStyle,
+    pub requested_size_usdc: f64,
+    pub requested_size_contracts: f64,
+    pub entry_price: f64,
+    pub seat_layer: Option<String>,
+    pub tuned_params_before: Option<serde_json::Value>,
+    pub tuned_params_after: Option<serde_json::Value>,
+    pub rollback_triggered: Option<String>,
+    pub shadow_pnl_comparison: Option<f64>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct PaperFill {
+    pub ts_ms: i64,
+    pub order_id: String,
+    pub market_id: String,
+    pub side: OrderSide,
+    pub style: ExecutionStyle,
+    pub requested_size_usdc: f64,
+    pub executed_size_usdc: f64,
+    pub entry_price: f64,
+    pub fill_price: f64,
+    pub mid_price: f64,
+    pub slippage_bps: f64,
+    pub fee_usdc: f64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct PaperTradeRecord {
+    pub ts_ms: i64,
+    pub paper_mode: String,
+    pub market_id: String,
+    pub symbol: String,
+    pub timeframe: String,
+    pub stage: Stage,
+    pub direction: Direction,
+    pub velocity_bps_per_sec: f64,
+    pub edge_bps: f64,
+    pub prob_fast: f64,
+    pub prob_settle: f64,
+    pub confidence: f64,
+    pub action: PaperAction,
+    pub intent: ExecutionStyle,
+    pub requested_size_usdc: f64,
+    pub executed_size_usdc: f64,
+    pub entry_price: f64,
+    pub fill_price: f64,
+    pub slippage_bps: f64,
+    pub fee_usdc: f64,
+    pub realized_pnl_usdc: f64,
+    pub bankroll_before: f64,
+    pub bankroll_after: f64,
+    pub settlement_price: f64,
+    pub chainlink_settlement_price: Option<f64>,
+    pub settlement_source: String,
+    pub forced_settlement: bool,
+    pub trade_duration_ms: i64,
+    pub seat_layer: Option<String>,
+    pub tuned_params_before: Option<serde_json::Value>,
+    pub tuned_params_after: Option<serde_json::Value>,
+    pub rollback_triggered: Option<String>,
+    pub shadow_pnl_comparison: Option<f64>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct PaperDailySummary {
+    pub utc_day: String,
+    pub starting_bankroll: f64,
+    pub ending_bankroll: f64,
+    pub daily_roi_pct: f64,
+    pub trades: u64,
+    pub win_rate: f64,
+    pub fee_total_usdc: f64,
+    pub pnl_total_usdc: f64,
+    pub avg_trade_duration_ms: f64,
+    pub median_trade_duration_ms: f64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct PaperLiveReport {
+    pub ts_ms: i64,
+    pub run_id: String,
+    pub initial_capital: f64,
+    pub bankroll: f64,
+    pub trades: u64,
+    pub wins: u64,
+    pub losses: u64,
+    pub win_rate: f64,
+    pub roi_pct: f64,
+    pub max_drawdown_pct: f64,
+    pub fee_total_usdc: f64,
+    pub pnl_total_usdc: f64,
+    pub fee_ratio: f64,
+    pub avg_trade_duration_ms: f64,
+    pub median_trade_duration_ms: f64,
+    pub trade_count_source: String,
+    pub open_positions_count: usize,
+}
+
 #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
 pub struct RiskDecision {
     pub allow: bool,
@@ -293,6 +576,14 @@ pub enum ToxicRegime {
     Danger,
 }
 
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
+#[serde(rename_all = "snake_case")]
+pub enum Regime {
+    Active,
+    Quiet,
+    Defend,
+}
+
 #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
 pub struct ToxicFeatures {
     pub market_id: String,
@@ -424,6 +715,19 @@ pub struct ShadowShot {
     pub side: OrderSide,
     #[serde(default = "default_execution_style")]
     pub execution_style: ExecutionStyle,
+    /// Positive means: our fast reference tick arrived earlier than the Polymarket book update.
+    /// See docs/metrics_contract.md for the contract definition.
+    #[serde(default)]
+    pub book_top_lag_ms: f64,
+    /// Execution venue request/ack duration only (real in live mode).
+    #[serde(default)]
+    pub ack_only_ms: f64,
+    /// End-to-end decision+execution latency (see app_runner for definition).
+    #[serde(default)]
+    pub tick_to_ack_ms: f64,
+    /// `book_top_lag_ms - tick_to_ack_ms`; positive means we likely had time to capture.
+    #[serde(default)]
+    pub capturable_window_ms: f64,
     #[serde(default)]
     pub survival_probe_price: f64,
     pub intended_price: f64,
@@ -498,6 +802,7 @@ pub enum EngineEvent {
     BookDelta(BookDelta),
     BookDigest(OrderbookStateDigest),
     Signal(Signal),
+    DirectionSignal(DirectionSignal),
     ToxicFeatures(ToxicFeatures),
     ToxicDecision(ToxicDecision),
     QuoteIntent(QuoteIntent),
@@ -506,6 +811,7 @@ pub enum EngineEvent {
     Fill(FillEvent),
     ShadowShot(ShadowShot),
     ShadowOutcome(ShadowOutcome),
+    CapitalUpdate(CapitalUpdate),
     Pnl(PnLSnapshot),
     Control(ControlCommand),
 }
@@ -624,8 +930,11 @@ mod tests {
             symbol: "BTCUSDT".to_string(),
             event_ts_ms: 1,
             recv_ts_ms: 2,
+            source_seq: 0,
             event_ts_exchange_ms: 1,
             recv_ts_local_ns: 2,
+            ingest_ts_local_ns: 2,
+            ts_first_hop_ms: None,
             price: 50000.0,
         });
 
diff --git a/crates/direction_detector/Cargo.toml b/crates/direction_detector/Cargo.toml
new file mode 100644
index 0000000..582fa67
--- /dev/null
+++ b/crates/direction_detector/Cargo.toml
@@ -0,0 +1,10 @@
+[package]
+name = "direction_detector"
+version.workspace = true
+edition.workspace = true
+license.workspace = true
+
+[dependencies]
+core_types = { path = "../core_types" }
+serde.workspace = true
+
diff --git a/crates/direction_detector/src/lib.rs b/crates/direction_detector/src/lib.rs
new file mode 100644
index 0000000..dcda1e4
--- /dev/null
+++ b/crates/direction_detector/src/lib.rs
@@ -0,0 +1,784 @@
+use std::collections::{HashMap, VecDeque};
+
+use core_types::{Direction, DirectionSignal, RefTick, TimeframeClass};
+use serde::{Deserialize, Serialize};
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct DirectionConfig {
+    /// Maximum window length for stored ticks (seconds).
+    pub window_max_sec: u64,
+    /// Thresholds in percent (e.g. 0.10 means 0.10%).
+    pub threshold_5m_pct: f64,
+    pub threshold_15m_pct: f64,
+    pub threshold_1h_pct: f64,
+    pub threshold_1d_pct: f64,
+    /// Lookback windows (seconds).
+    pub lookback_short_sec: u64,
+    pub lookback_long_sec: u64,
+    /// Multi-source consistency.
+    pub min_sources_for_high_confidence: usize,
+    /// Cold-start guard.
+    pub min_ticks_for_signal: usize,
+    /// Triple-confirm gate: minimum consecutive same-direction ticks.
+    pub min_consecutive_ticks: u8,
+    /// Triple-confirm gate: minimum absolute velocity in bps/s.
+    pub min_velocity_bps_per_sec: f64,
+    /// Triple-confirm gate: minimum directional acceleration.
+    pub min_acceleration: f64,
+    /// If abs(velocity) is above this multiple of min_velocity, treat as momentum spike.
+    pub momentum_spike_multiplier: f64,
+    /// Triple-confirm gate: minimum short/long tick-rate ratio treated as volume spike proxy.
+    pub min_tick_rate_spike_ratio: f64,
+    /// Window for short-horizon tick-rate in ms.
+    pub tick_rate_short_ms: i64,
+    /// Window for long-horizon tick-rate in ms.
+    pub tick_rate_long_ms: i64,
+    /// Enable source vote gate: Binance confirmation is mandatory.
+    pub enable_source_vote_gate: bool,
+    /// Require Chainlink secondary source confirmation when available.
+    pub require_secondary_confirmation: bool,
+    /// Ignore source snapshots older than this window when voting.
+    pub source_vote_max_age_ms: i64,
+    /// å¿«é€Ÿç¡®è®¤é€Ÿåº¦é˜ˆå€¼ (bps/s)ã€‚
+    /// å½“ velocity è¶…è¿‡æ­¤å€¼æ—¶ï¼Œåªéœ€ 1 ä¸ªåŒå‘ Tick å³å¯è§¦å‘ï¼ˆä¸ç­‰ min_consecutive_ticksï¼‰ã€‚
+    /// è®¾è®¡å“²å­¦: æžå¼ºåŠ¨é‡æœ¬èº«å°±æ˜¯é«˜ç½®ä¿¡åº¦ä¿¡å·ï¼Œç­‰å¾…ç¬¬ 2 ä¸ª Tick ä¼šæŸå¤± 10-50ms çª—å£ã€‚
+    pub fast_confirm_velocity_bps_per_sec: f64,
+}
+
+impl Default for DirectionConfig {
+    fn default() -> Self {
+        Self {
+            window_max_sec: 120,
+            // 5min å¸‚åœºæ³¢åŠ¨æ›´å°ï¼Œé˜ˆå€¼æ›´ä½Žæ‰èƒ½æ•èŽ·ä¿¡å·
+            threshold_5m_pct: 0.02,
+            threshold_15m_pct: 0.05,
+            threshold_1h_pct: 0.20,
+            threshold_1d_pct: 0.50,
+            lookback_short_sec: 15,
+            lookback_long_sec: 60,
+            min_sources_for_high_confidence: 2,
+            min_ticks_for_signal: 3,
+            min_consecutive_ticks: 2,
+            min_velocity_bps_per_sec: 3.0,
+            min_acceleration: 0.0,
+            momentum_spike_multiplier: 1.8,
+            min_tick_rate_spike_ratio: 1.8,
+            tick_rate_short_ms: 300,
+            tick_rate_long_ms: 3_000,
+            enable_source_vote_gate: true,
+            require_secondary_confirmation: true,
+            source_vote_max_age_ms: 2_000,
+            // æžå¼ºåŠ¨é‡: velocity > 30 bps/s â†’ å• Tick è§¦å‘ï¼Œä¸ç­‰ç¬¬ 2 ä¸ª
+            fast_confirm_velocity_bps_per_sec: 30.0,
+        }
+    }
+}
+
+// ============================================================
+// SymbolWindow â€” æ¯ä¸ª symbol çš„æ»‘åŠ¨çª—å£çŠ¶æ€
+// è®¾è®¡åŽŸåˆ™: on_tick æ—¶å¢žé‡ç»´æŠ¤ï¼Œevaluate æ—¶ O(1) è¯»å–ç¼“å­˜
+// æ¶ˆé™¤ evaluate è·¯å¾„ä¸Šçš„æ‰€æœ‰ O(n) æ‰«æ
+// ============================================================
+#[derive(Debug, Default)]
+struct SymbolWindow {
+    // (recv_ts_ms, price) â€” æŒ‰æ—¶é—´æˆ³å‡åº
+    ticks: VecDeque<(i64, f64)>,
+    // å„æ•°æ®æºæœ€æ–°ä»·æ ¼å’Œæ—¶é—´æˆ³
+    latest_by_source: HashMap<String, f64>,
+    latest_ts_by_source: HashMap<String, i64>,
+
+    // --------------------------------------------------------
+    // å¢žé‡ç»´æŠ¤çš„æ»‘åŠ¨çª—å£è®¡æ•°å™¨ (on_tick O(1) æ›´æ–°)
+    // æ¶ˆé™¤ evaluate é‡Œä¸¤æ¬¡ O(n) å…¨é‡æ‰«æ
+    // --------------------------------------------------------
+    /// æœ€è¿‘ tick_rate_short_ms å†…çš„ tick æ•°
+    short_window_count: u32,
+    /// æœ€è¿‘ tick_rate_long_ms å†…çš„ tick æ•°
+    long_window_count: u32,
+    /// è¿žç»­åŒå‘ tick è®¡æ•° (å¢žé‡ç»´æŠ¤)
+    consecutive_dir_count: u8,
+    /// æœ€åŽä¸€ä¸ª tick çš„æ–¹å‘ç¬¦å·: -1/0/1
+    last_dir_sign: i8,
+
+    // --------------------------------------------------------
+    // æºç±»åž‹ç¼“å­˜ â€” é¿å…æ¯æ¬¡ is_binance/chainlink åˆ†é… String
+    // --------------------------------------------------------
+    /// å·²è§è¿‡çš„ Binance æº key (ç¬¬ä¸€æ¬¡è§åˆ°æ—¶ç¼“å­˜)
+    binance_source_key: Option<String>,
+    /// å·²è§è¿‡çš„ Chainlink æº key (ç¬¬ä¸€æ¬¡è§åˆ°æ—¶ç¼“å­˜)
+    chainlink_source_key: Option<String>,
+}
+
+#[derive(Debug)]
+pub struct DirectionDetector {
+    windows: HashMap<String, SymbolWindow>,
+    cfg: DirectionConfig,
+    /// Tick counter for lazy pruning - only prune every N ticks
+    tick_counter: usize,
+    /// Cached tick_rate_short_ms as i64 for hot-path use
+    cfg_tick_rate_short_ms: i64,
+    /// Cached tick_rate_long_ms as i64 for hot-path use
+    cfg_tick_rate_long_ms: i64,
+}
+
+impl DirectionDetector {
+    pub fn new(cfg: DirectionConfig) -> Self {
+        let short = cfg.tick_rate_short_ms;
+        let long = cfg.tick_rate_long_ms;
+        Self {
+            windows: HashMap::new(),
+            cfg,
+            tick_counter: 0,
+            cfg_tick_rate_short_ms: short,
+            cfg_tick_rate_long_ms: long,
+        }
+    }
+
+    pub fn cfg(&self) -> &DirectionConfig {
+        &self.cfg
+    }
+
+    pub fn set_cfg(&mut self, cfg: DirectionConfig) {
+        self.cfg_tick_rate_short_ms = cfg.tick_rate_short_ms;
+        self.cfg_tick_rate_long_ms = cfg.tick_rate_long_ms;
+        self.cfg = cfg;
+        // Keep windows; pruning will happen on next tick/evaluate.
+    }
+
+    pub fn on_tick(&mut self, tick: &RefTick) {
+        let w = self.windows.entry(tick.symbol.clone()).or_default();
+
+        // --------------------------------------------------------
+        // æºç±»åž‹ç¼“å­˜: ç¬¬ä¸€æ¬¡è§åˆ° binance/chainlink æºæ—¶è®°å½• key
+        // åŽç»­ source_vote ç›´æŽ¥æ¯”è¾ƒ keyï¼Œä¸å† to_ascii_lowercase()
+        // --------------------------------------------------------
+        if w.binance_source_key.is_none() && is_binance_source(&tick.source) {
+            w.binance_source_key = Some(tick.source.to_string());
+        }
+        if w.chainlink_source_key.is_none() && is_chainlink_source(&tick.source) {
+            w.chainlink_source_key = Some(tick.source.to_string());
+        }
+
+        w.latest_by_source
+            .insert(tick.source.to_string(), tick.price);
+        w.latest_ts_by_source
+            .insert(tick.source.to_string(), tick.recv_ts_ms);
+
+        // --------------------------------------------------------
+        // å¢žé‡ç»´æŠ¤è¿žç»­æ–¹å‘è®¡æ•°
+        // åªçœ‹æœ€æ–° tick ä¸Žä¸Šä¸€ä¸ª tick çš„æ–¹å‘å…³ç³»ï¼ŒO(1)
+        // --------------------------------------------------------
+        if let Some(&(_, prev_price)) = w.ticks.back() {
+            if prev_price > 0.0 && tick.price > 0.0 {
+                let delta = tick.price - prev_price;
+                let sign: i8 = if delta > 0.0 {
+                    1
+                } else if delta < 0.0 {
+                    -1
+                } else {
+                    0
+                };
+                if sign == 0 {
+                    w.consecutive_dir_count = 0;
+                    w.last_dir_sign = 0;
+                } else if sign == w.last_dir_sign {
+                    w.consecutive_dir_count = w.consecutive_dir_count.saturating_add(1);
+                } else {
+                    w.consecutive_dir_count = 1;
+                    w.last_dir_sign = sign;
+                }
+            }
+        }
+
+        w.ticks.push_back((tick.recv_ts_ms, tick.price));
+
+        // --------------------------------------------------------
+        // å¢žé‡ç»´æŠ¤æ»‘åŠ¨çª—å£è®¡æ•°å™¨
+        // æ–° tick è¿›æ¥æ—¶: short/long count +1
+        // è¿‡æœŸ tick å¼¹å‡ºæ—¶: ç›¸åº” count -1
+        // --------------------------------------------------------
+        let short_ms = self.cfg_tick_rate_short_ms;
+        let long_ms = self.cfg_tick_rate_long_ms;
+        let now = tick.recv_ts_ms;
+        w.short_window_count += 1;
+        w.long_window_count += 1;
+
+        // æ‡’æƒ°å‰ªæž: æ¯ 100 ticks æ¸…ç†è¿‡æœŸæ•°æ®ï¼ŒåŒæ—¶ä¿®æ­£è®¡æ•°å™¨
+        self.tick_counter += 1;
+        if self.tick_counter >= 100 {
+            self.tick_counter = 0;
+            let window_cutoff =
+                now.saturating_sub((self.cfg.window_max_sec as i64).saturating_mul(1_000));
+            let short_cutoff = now.saturating_sub(short_ms);
+            let long_cutoff = now.saturating_sub(long_ms);
+            // é‡æ–°ç²¾ç¡®è®¡ç®—è®¡æ•°å™¨ï¼ˆæ¯ 100 ticks ä¸€æ¬¡ï¼Œåˆ†æ‘Šæˆæœ¬ï¼‰
+            w.short_window_count =
+                w.ticks.iter().filter(|(ts, _)| *ts >= short_cutoff).count() as u32;
+            w.long_window_count =
+                w.ticks.iter().filter(|(ts, _)| *ts >= long_cutoff).count() as u32;
+            while matches!(w.ticks.front(), Some((ts, _)) if *ts < window_cutoff) {
+                w.ticks.pop_front();
+            }
+        }
+    }
+
+    pub fn evaluate(&self, symbol: &str, now_ms: i64) -> Option<DirectionSignal> {
+        let w = self.windows.get(symbol)?;
+        if w.ticks.len() < self.cfg.min_ticks_for_signal {
+            return None;
+        }
+
+        let latest = w.ticks.back().map(|(_, px)| *px)?;
+        if latest <= 0.0 {
+            return None;
+        }
+
+        let anchor_short_ms =
+            now_ms.saturating_sub((self.cfg.lookback_short_sec as i64).saturating_mul(1_000));
+        let anchor_long_ms =
+            now_ms.saturating_sub((self.cfg.lookback_long_sec as i64).saturating_mul(1_000));
+        let anchor_short = find_anchor_price(&w.ticks, anchor_short_ms)?;
+        let anchor_long = find_anchor_price(&w.ticks, anchor_long_ms)?;
+        if anchor_short <= 0.0 || anchor_long <= 0.0 {
+            return None;
+        }
+
+        let ret_short = (latest - anchor_short) / anchor_short;
+        let ret_long = (latest - anchor_long) / anchor_long;
+        let magnitude_pct = (ret_short * 0.7 + ret_long * 0.3) * 100.0;
+        // kinematics_from_ticks \u73b0\u5728\u53ea\u8fd4\u56de (velocity, acceleration)
+        // tick_consistency \u7531 SymbolWindow \u589e\u91cf\u7ef4\u62a4\uff0cO(1) \u8bfb\u53d6
+        let (velocity_bps_per_sec, acceleration) = kinematics_from_ticks(&w.ticks);
+        let tick_consistency = w.consecutive_dir_count;
+
+        let mut raw_direction = if magnitude_pct > self.cfg.threshold_15m_pct {
+            Direction::Up
+        } else if magnitude_pct < -self.cfg.threshold_15m_pct {
+            Direction::Down
+        } else {
+            Direction::Neutral
+        };
+        let velocity_direction = if velocity_bps_per_sec > 0.0 {
+            Direction::Up
+        } else if velocity_bps_per_sec < 0.0 {
+            Direction::Down
+        } else {
+            Direction::Neutral
+        };
+        let velocity_spike_only = matches!(raw_direction, Direction::Neutral)
+            && !matches!(velocity_direction, Direction::Neutral)
+            && tick_consistency >= self.cfg.min_consecutive_ticks.max(1)
+            && velocity_bps_per_sec.abs()
+                >= self.cfg.min_velocity_bps_per_sec.max(0.0)
+                    * self.cfg.momentum_spike_multiplier.max(1.0);
+
+        if velocity_spike_only {
+            raw_direction = velocity_direction;
+        }
+        let direction_sign = match raw_direction {
+            Direction::Up => 1.0,
+            Direction::Down => -1.0,
+            Direction::Neutral => 0.0,
+        };
+        let velocity_abs = velocity_bps_per_sec.abs();
+        let directional_acceleration = acceleration * direction_sign;
+        let momentum_spike = velocity_abs
+            >= self.cfg.min_velocity_bps_per_sec.max(0.0)
+                * self.cfg.momentum_spike_multiplier.max(1.0);
+        // --------------------------------------------------------
+        // volume_spike: ç›´æŽ¥ç”¨ç¼“å­˜çš„æ»‘åŠ¨çª—å£è®¡æ•°å™¨ï¼ŒO(1) è¯»å–
+        // æ›¿ä»£åŽŸæ¥çš„ tick_rate_spike_ratio() O(2n) å…¨é‡æ‰«æ
+        // --------------------------------------------------------
+        let short_ms = self.cfg_tick_rate_short_ms.clamp(50, 10_000);
+        let long_ms = self
+            .cfg_tick_rate_long_ms
+            .max(short_ms + 50)
+            .clamp(100, 60_000);
+        let short_rate = w.short_window_count as f64 / (short_ms as f64 / 1_000.0);
+        let long_rate = (w.long_window_count as f64 / (long_ms as f64 / 1_000.0)).max(1e-6);
+        let tick_rate_ratio = short_rate / long_rate;
+        let volume_spike = tick_rate_ratio >= self.cfg.min_tick_rate_spike_ratio.max(1.0);
+        // --------------------------------------------------------
+        // é€Ÿåº¦åˆ†çº§å¿«é€Ÿç¡®è®¤:
+        //   æžå¼ºåŠ¨é‡ (velocity > fast_confirm_threshold) â†’ å• Tick å³å¯è§¦å‘
+        //   æ™®é€šåŠ¨é‡ â†’ éœ€è¦ min_consecutive_ticks ä¸ªåŒå‘ Tick
+        // è®¾è®¡å“²å­¦: æžå¼ºåŠ¨é‡æœ¬èº«æ˜¯é«˜ç½®ä¿¡åº¦ï¼Œç­‰å¾…ç¬¬ 2 ä¸ª Tick ä¼šæŸå¤±å¥—åˆ©çª—å£
+        // --------------------------------------------------------
+        let required_ticks = if velocity_abs >= self.cfg.fast_confirm_velocity_bps_per_sec.max(1.0)
+        {
+            1u8
+        } else {
+            self.cfg.min_consecutive_ticks.max(1)
+        };
+        // ç›´æŽ¥è¯»ç¼“å­˜çš„ tick_consistencyï¼Œä¸å†è°ƒç”¨ consecutive_direction_count()
+        let tick_consistency = w.consecutive_dir_count;
+        let triple_confirm = !matches!(raw_direction, Direction::Neutral)
+            && tick_consistency >= required_ticks
+            && velocity_abs >= self.cfg.min_velocity_bps_per_sec.max(0.0)
+            && (directional_acceleration >= self.cfg.min_acceleration
+                || momentum_spike
+                || volume_spike);
+        let vote = source_vote_cached(
+            &w.latest_by_source,
+            &w.latest_ts_by_source,
+            w.binance_source_key.as_deref(),
+            w.chainlink_source_key.as_deref(),
+            anchor_short,
+            &raw_direction,
+            now_ms,
+            self.cfg.source_vote_max_age_ms,
+        );
+        // é—¨æŽ§å…³é—­ æˆ– æ–¹å‘ä¸­æ€§ â†’ ç›´æŽ¥æ”¾è¡Œï¼›å¦åˆ™æ£€æŸ¥æ•°æ®æºç¡®è®¤
+        let vote_passed = !self.cfg.enable_source_vote_gate
+            || matches!(raw_direction, Direction::Neutral)
+            || if self.cfg.require_secondary_confirmation {
+                vote.binance_confirms && (!vote.secondary_available || vote.secondary_confirms)
+            } else {
+                vote.binance_confirms
+            };
+        let direction = if triple_confirm && vote_passed {
+            raw_direction
+        } else {
+            Direction::Neutral
+        };
+
+        let recommended_tf = recommended_timeframe(&self.cfg, magnitude_pct.abs());
+
+        let confidence = compute_confidence(
+            &w.latest_by_source,
+            anchor_short,
+            &direction,
+            self.cfg.min_sources_for_high_confidence,
+        );
+
+        Some(DirectionSignal {
+            symbol: symbol.to_string(),
+            direction,
+            magnitude_pct,
+            confidence,
+            recommended_tf,
+            velocity_bps_per_sec,
+            acceleration,
+            tick_consistency,
+            triple_confirm,
+            momentum_spike,
+            ts_ns: now_ms.max(0) * 1_000_000,
+        })
+    }
+}
+
+#[derive(Debug, Default, Clone, Copy)]
+struct SourceVote {
+    binance_confirms: bool,
+    secondary_available: bool,
+    secondary_confirms: bool,
+}
+
+// ============================================================
+// source_vote_cached â€” åˆ©ç”¨ç¼“å­˜çš„æº key é¿å…çƒ­è·¯å¾„ String åˆ†é…
+// æ›¿ä»£åŽŸæ¥çš„ source_vote() é‡Œæ¯æ¬¡ is_binance/chainlink_source() çš„ alloc
+// ============================================================
+fn source_vote_cached(
+    latest_by_source: &HashMap<String, f64>,
+    latest_ts_by_source: &HashMap<String, i64>,
+    binance_key: Option<&str>,
+    chainlink_key: Option<&str>,
+    anchor_short: f64,
+    direction: &Direction,
+    now_ms: i64,
+    max_age_ms: i64,
+) -> SourceVote {
+    if anchor_short <= 0.0 || matches!(direction, Direction::Neutral) {
+        return SourceVote::default();
+    }
+    let mut out = SourceVote::default();
+    let max_age_ms = max_age_ms.max(50);
+
+    // æ£€æŸ¥ Binance æºç¡®è®¤
+    if let Some(key) = binance_key {
+        if let (Some(&px), Some(&ts)) = (latest_by_source.get(key), latest_ts_by_source.get(key)) {
+            if now_ms.saturating_sub(ts) <= max_age_ms {
+                let ret = (px - anchor_short) / anchor_short;
+                out.binance_confirms = match direction {
+                    Direction::Up => ret > 0.0,
+                    Direction::Down => ret < 0.0,
+                    Direction::Neutral => false,
+                };
+            }
+        }
+    }
+
+    // æ£€æŸ¥ Chainlink æºç¡®è®¤
+    if let Some(key) = chainlink_key {
+        if let (Some(&px), Some(&ts)) = (latest_by_source.get(key), latest_ts_by_source.get(key)) {
+            out.secondary_available = true;
+            if now_ms.saturating_sub(ts) <= max_age_ms {
+                let ret = (px - anchor_short) / anchor_short;
+                out.secondary_confirms = match direction {
+                    Direction::Up => ret > 0.0,
+                    Direction::Down => ret < 0.0,
+                    Direction::Neutral => false,
+                };
+            }
+        }
+    }
+
+    out
+}
+
+// ============================================================
+// is_binance/chainlink_source â€” æ— åˆ†é…ç‰ˆæœ¬
+// åŽŸæ¥çš„ to_ascii_lowercase() æ¯æ¬¡åˆ†é…æ–° String
+// çŽ°åœ¨ç”¨ bytes æ¯”è¾ƒï¼Œé›¶åˆ†é…
+// ============================================================
+#[inline]
+fn is_binance_source(source: &str) -> bool {
+    let b = source.as_bytes();
+    b.windows(7).any(|w| w.eq_ignore_ascii_case(b"binance"))
+}
+
+#[inline]
+fn is_chainlink_source(source: &str) -> bool {
+    let b = source.as_bytes();
+    b.windows(9).any(|w| w.eq_ignore_ascii_case(b"chainlink"))
+}
+
+// ============================================================
+// kinematics_from_ticks â€” è®¡ç®—é€Ÿåº¦å’ŒåŠ é€Ÿåº¦
+// æ³¨æ„: tick_consistency çŽ°åœ¨ç”± SymbolWindow å¢žé‡ç»´æŠ¤
+// è¿™é‡Œåªè¿”å›ž (velocity, acceleration)ï¼Œä¸å†è°ƒç”¨ consecutive_direction_count()
+// ============================================================
+fn kinematics_from_ticks(ticks: &VecDeque<(i64, f64)>) -> (f64, f64) {
+    if ticks.len() < 3 {
+        return (0.0, 0.0);
+    }
+    let mut it = ticks.iter().rev();
+    let (t2, p2) = *it.next().unwrap_or(&(0, 0.0));
+    let (t1, p1) = *it.next().unwrap_or(&(0, 0.0));
+    let (t0, p0) = *it.next().unwrap_or(&(0, 0.0));
+    let v2 = velocity_bps_per_sec(t1, p1, t2, p2);
+    let v1 = velocity_bps_per_sec(t0, p0, t1, p1);
+    let dt_s = ((t2 - t1).max(1) as f64) / 1_000.0;
+    let acceleration = (v2 - v1) / dt_s.max(1e-6);
+    (v2, acceleration)
+}
+
+fn velocity_bps_per_sec(t0_ms: i64, p0: f64, t1_ms: i64, p1: f64) -> f64 {
+    if p0 <= 0.0 || p1 <= 0.0 {
+        return 0.0;
+    }
+    let dt_ms = (t1_ms - t0_ms).max(1) as f64;
+    let dt_s = dt_ms / 1_000.0;
+    let ret = (p1 - p0) / p0;
+    let v = (ret * 10_000.0) / dt_s.max(1e-6);
+    if v.is_finite() {
+        v
+    } else {
+        0.0
+    }
+}
+
+// ============================================================
+// find_anchor_price â€” äºŒåˆ†æŸ¥æ‰¾ O(log n)
+// deque æŒ‰æ—¶é—´æˆ³å‡åºï¼Œpartition_point æ‰¾åˆ°ç¬¬ä¸€ä¸ª ts > target_ms çš„ä½ç½®
+// å–å…¶å‰ä¸€ä¸ªå…ƒç´ ï¼Œå³æœ€æ–°çš„ ts <= target_ms çš„ä»·æ ¼
+// ============================================================
+#[inline]
+fn find_anchor_price(ticks: &VecDeque<(i64, f64)>, target_ms: i64) -> Option<f64> {
+    // partition_point: è¿”å›žç¬¬ä¸€ä¸ªä¸æ»¡è¶³æ¡ä»¶çš„ç´¢å¼•
+    // æ¡ä»¶: ts <= target_msï¼Œæ‰€ä»¥è¿”å›žçš„æ˜¯ç¬¬ä¸€ä¸ª ts > target_ms çš„ä½ç½®
+    let idx = ticks.partition_point(|(ts, _)| *ts <= target_ms);
+    if idx == 0 {
+        return None; // æ‰€æœ‰ tick éƒ½åœ¨ target_ms ä¹‹åŽ
+    }
+    ticks.get(idx - 1).map(|(_, px)| *px)
+}
+
+fn recommended_timeframe(cfg: &DirectionConfig, abs_magnitude_pct: f64) -> TimeframeClass {
+    if abs_magnitude_pct >= cfg.threshold_1d_pct {
+        TimeframeClass::Tf1d
+    } else if abs_magnitude_pct >= cfg.threshold_1h_pct {
+        TimeframeClass::Tf1h
+    } else if abs_magnitude_pct >= cfg.threshold_15m_pct {
+        TimeframeClass::Tf15m
+    } else {
+        TimeframeClass::Tf5m
+    }
+}
+
+fn compute_confidence(
+    latest_by_source: &HashMap<String, f64>,
+    anchor_short: f64,
+    direction: &Direction,
+    min_sources_for_high_confidence: usize,
+) -> f64 {
+    if latest_by_source.is_empty() || anchor_short <= 0.0 {
+        return 0.0;
+    }
+    let mut consistent = 0usize;
+    let mut total = 0usize;
+    // Use a small threshold for Neutral instead of exact equality
+    // Floating-point exact equality is nearly impossible, so we use 0.1% threshold
+    const NEUTRAL_THRESHOLD: f64 = 0.001;
+    for (source, px) in latest_by_source {
+        if is_chainlink_source(source) {
+            continue;
+        }
+        total += 1;
+        let ret = (*px - anchor_short) / anchor_short;
+        let ok = match direction {
+            Direction::Up => ret > 0.0,
+            Direction::Down => ret < 0.0,
+            Direction::Neutral => ret.abs() <= NEUTRAL_THRESHOLD,
+        };
+        if ok {
+            consistent += 1;
+        }
+    }
+    if total == 0 {
+        total = latest_by_source.len();
+        consistent = 0;
+        for px in latest_by_source.values() {
+            let ret = (*px - anchor_short) / anchor_short;
+            let ok = match direction {
+                Direction::Up => ret > 0.0,
+                Direction::Down => ret < 0.0,
+                Direction::Neutral => ret.abs() <= NEUTRAL_THRESHOLD,
+            };
+            if ok {
+                consistent += 1;
+            }
+        }
+    }
+    let mut c = (consistent as f64 / total as f64).clamp(0.0, 1.0);
+    if consistent >= min_sources_for_high_confidence {
+        c = c.max(0.85);
+    }
+    c
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    fn tick(source: &str, symbol: &str, recv_ts_ms: i64, price: f64) -> RefTick {
+        RefTick {
+            source: source.to_string(),
+            symbol: symbol.to_string(),
+            event_ts_ms: recv_ts_ms,
+            recv_ts_ms,
+            source_seq: 0,
+            event_ts_exchange_ms: recv_ts_ms,
+            recv_ts_local_ns: recv_ts_ms * 1_000_000,
+            ingest_ts_local_ns: recv_ts_ms * 1_000_000,
+            ts_first_hop_ms: None,
+            price,
+        }
+    }
+
+    #[test]
+    fn no_signal_when_cold_start() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 5,
+            require_secondary_confirmation: false,
+            ..DirectionConfig::default()
+        });
+        let now = 1_000_000i64;
+        det.on_tick(&tick("binance", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("binance", "BTCUSDT", now - 15_000, 100.0));
+        det.on_tick(&tick("binance", "BTCUSDT", now, 100.2));
+        assert!(det.evaluate("BTCUSDT", now).is_none());
+    }
+
+    #[test]
+    fn up_direction_when_move_exceeds_threshold() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 3,
+            threshold_15m_pct: 0.10,
+            min_consecutive_ticks: 1,
+            min_velocity_bps_per_sec: 0.0,
+            require_secondary_confirmation: false,
+            ..DirectionConfig::default()
+        });
+        let now = 1_000_000i64;
+        det.on_tick(&tick("binance", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("binance", "BTCUSDT", now - 15_000, 100.0));
+        det.on_tick(&tick("binance", "BTCUSDT", now, 100.2));
+        let sig = det.evaluate("BTCUSDT", now).unwrap();
+        assert_eq!(sig.direction, Direction::Up);
+        assert!(sig.magnitude_pct > 0.10);
+        assert!(sig.velocity_bps_per_sec > 0.0);
+    }
+
+    #[test]
+    fn recommended_timeframe_mapping() {
+        let cfg = DirectionConfig::default();
+        assert_eq!(recommended_timeframe(&cfg, 0.01), TimeframeClass::Tf5m);
+        assert_eq!(recommended_timeframe(&cfg, 0.10), TimeframeClass::Tf15m);
+        assert_eq!(recommended_timeframe(&cfg, 0.25), TimeframeClass::Tf1h);
+        assert_eq!(recommended_timeframe(&cfg, 0.60), TimeframeClass::Tf1d);
+    }
+
+    #[test]
+    fn multi_source_high_confidence_floor() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 3,
+            min_sources_for_high_confidence: 2,
+            min_consecutive_ticks: 1,
+            min_velocity_bps_per_sec: 0.0,
+            require_secondary_confirmation: true,
+            ..DirectionConfig::default()
+        });
+        let now = 1_000_000i64;
+        det.on_tick(&tick("binance", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("chainlink_rtds", "BTCUSDT", now - 15_000, 100.0));
+        det.on_tick(&tick("binance", "BTCUSDT", now, 100.2));
+        det.on_tick(&tick("chainlink_rtds", "BTCUSDT", now, 100.21));
+        let sig = det.evaluate("BTCUSDT", now).unwrap();
+        assert_eq!(sig.direction, Direction::Up);
+        assert!(sig.confidence >= 0.85);
+    }
+
+    #[test]
+    fn triple_confirm_blocks_single_tick_fakeout() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 3,
+            threshold_15m_pct: 0.10,
+            min_consecutive_ticks: 2,
+            min_velocity_bps_per_sec: 1.0,
+            require_secondary_confirmation: false,
+            ..DirectionConfig::default()
+        });
+        let now = 1_000_000i64;
+        det.on_tick(&tick("binance", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("binance", "BTCUSDT", now - 15_000, 100.0));
+        det.on_tick(&tick("binance", "BTCUSDT", now - 1_000, 100.2));
+        det.on_tick(&tick("binance", "BTCUSDT", now, 100.1));
+        let sig = det.evaluate("BTCUSDT", now).unwrap();
+        assert_eq!(sig.direction, Direction::Neutral);
+    }
+
+    #[test]
+    fn triple_confirm_passes_consistent_move() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 4,
+            threshold_15m_pct: 0.05,
+            min_consecutive_ticks: 2,
+            min_velocity_bps_per_sec: 1.0,
+            require_secondary_confirmation: false,
+            ..DirectionConfig::default()
+        });
+        let now = 1_000_000i64;
+        det.on_tick(&tick("binance", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("binance", "BTCUSDT", now - 2_000, 100.05));
+        det.on_tick(&tick("binance", "BTCUSDT", now - 1_000, 100.10));
+        det.on_tick(&tick("binance", "BTCUSDT", now, 100.20));
+        let sig = det.evaluate("BTCUSDT", now).unwrap();
+        assert_eq!(sig.direction, Direction::Up);
+        assert!(sig.tick_consistency >= 2);
+    }
+
+    #[test]
+    fn source_vote_blocks_when_binance_unconfirmed() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 3,
+            min_consecutive_ticks: 1,
+            min_velocity_bps_per_sec: 0.0,
+            require_secondary_confirmation: true,
+            ..DirectionConfig::default()
+        });
+        let now = 1_000_000i64;
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("chainlink_rtds", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 1_000, 99.9));
+        det.on_tick(&tick("chainlink_rtds", "BTCUSDT", now, 100.2));
+        let sig = det.evaluate("BTCUSDT", now).unwrap();
+        assert_eq!(sig.direction, Direction::Neutral);
+    }
+
+    #[test]
+    fn source_vote_passes_with_binance_plus_secondary() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 3,
+            threshold_15m_pct: 0.10,
+            min_consecutive_ticks: 1,
+            min_velocity_bps_per_sec: 0.0,
+            require_secondary_confirmation: true,
+            ..DirectionConfig::default()
+        });
+        let now = 1_000_000i64;
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("chainlink_rtds", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 1_000, 100.2));
+        det.on_tick(&tick("chainlink_rtds", "BTCUSDT", now, 100.21));
+        let sig = det.evaluate("BTCUSDT", now).unwrap();
+        assert_eq!(sig.direction, Direction::Up);
+    }
+
+    #[test]
+    fn source_vote_accepts_chainlink_as_secondary() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 3,
+            threshold_15m_pct: 0.10,
+            min_consecutive_ticks: 1,
+            min_velocity_bps_per_sec: 0.0,
+            require_secondary_confirmation: true,
+            ..DirectionConfig::default()
+        });
+        let now = 1_000_000i64;
+        det.on_tick(&tick("binance_udp", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("chainlink_rtds", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("binance_udp", "BTCUSDT", now - 1_000, 100.2));
+        det.on_tick(&tick("chainlink_rtds", "BTCUSDT", now, 100.21));
+        let sig = det.evaluate("BTCUSDT", now).unwrap();
+        assert_eq!(sig.direction, Direction::Up);
+    }
+
+    #[test]
+    fn velocity_spike_overrides_magnitude_neutral() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 4,
+            threshold_15m_pct: 0.10,
+            min_consecutive_ticks: 2,
+            min_velocity_bps_per_sec: 5.0,
+            momentum_spike_multiplier: 1.8,
+            require_secondary_confirmation: false,
+            ..DirectionConfig::default()
+        });
+        let now = 1_000_000i64;
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 60_000, 100.0));
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 1_000, 100.00));
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 800, 100.04));
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 600, 100.08));
+        let sig = det.evaluate("BTCUSDT", now).unwrap();
+        assert_eq!(sig.direction, Direction::Up);
+        assert!(sig.magnitude_pct < 0.10);
+    }
+
+    #[test]
+    fn volume_spike_passes_triple_confirm_even_with_low_acceleration() {
+        let mut det = DirectionDetector::new(DirectionConfig {
+            min_ticks_for_signal: 4,
+            threshold_15m_pct: 0.05,
+            lookback_short_sec: 1,
+            lookback_long_sec: 3,
+            min_consecutive_ticks: 2,
+            min_velocity_bps_per_sec: 0.5,
+            min_acceleration: 10_000.0,
+            min_tick_rate_spike_ratio: 2.0,
+            tick_rate_short_ms: 300,
+            tick_rate_long_ms: 3_000,
+            require_secondary_confirmation: false,
+            ..DirectionConfig::default()
+        });
+        let now = 2_000_000i64;
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 4_000, 100.0));
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 2_000, 100.02));
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 200, 100.07));
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 120, 100.12));
+        det.on_tick(&tick("binance_ws", "BTCUSDT", now - 40, 100.17));
+        let sig = det.evaluate("BTCUSDT", now).unwrap();
+        assert_eq!(sig.direction, Direction::Up);
+        assert!(sig.tick_consistency >= 2);
+    }
+}
diff --git a/crates/execution_clob/Cargo.toml b/crates/execution_clob/Cargo.toml
index 671d641..bc4c1aa 100644
--- a/crates/execution_clob/Cargo.toml
+++ b/crates/execution_clob/Cargo.toml
@@ -9,7 +9,11 @@ anyhow.workspace = true
 async-trait.workspace = true
 chrono.workspace = true
 core_types = { path = "../core_types" }
+futures.workspace = true
 parking_lot.workspace = true
 reqwest.workspace = true
 serde.workspace = true
 serde_json.workspace = true
+tokio.workspace = true
+tokio-tungstenite.workspace = true
+tracing.workspace = true
diff --git a/crates/execution_clob/src/lib.rs b/crates/execution_clob/src/lib.rs
index 17a5da5..f7db4f7 100644
--- a/crates/execution_clob/src/lib.rs
+++ b/crates/execution_clob/src/lib.rs
@@ -1,13 +1,18 @@
 use std::collections::HashMap;
+use std::sync::atomic::{AtomicU64, Ordering};
 use std::sync::Arc;
+use std::time::Duration;
 use std::time::Instant;
 
 use anyhow::{bail, Result};
 use async_trait::async_trait;
 use chrono::Utc;
 use core_types::{new_id, ExecutionVenue, OrderAck, OrderAckV2, OrderIntentV2, QuoteIntent};
-use parking_lot::RwLock;
+use parking_lot::{Mutex, RwLock};
 use reqwest::Client;
+use serde::Serialize;
+
+pub mod wss_user_feed;
 
 #[derive(Debug, Clone, Copy, PartialEq, Eq)]
 pub enum ExecutionMode {
@@ -15,12 +20,52 @@ pub enum ExecutionMode {
     Live,
 }
 
-#[derive(Clone)]
 pub struct ClobExecution {
     mode: ExecutionMode,
     http: Client,
     clob_endpoint: String,
+    order_primary_endpoint: String,
+    order_backup_endpoint: Option<String>,
+    order_failover_timeout: Duration,
     open_orders: Arc<RwLock<HashMap<String, PaperOpenOrder>>>,
+    last_prune: Mutex<Instant>,
+    ack_probe: Option<Arc<AckProbe>>,
+}
+
+fn env_flag_enabled(name: &str) -> bool {
+    std::env::var(name)
+        .ok()
+        .map(|v| {
+            let normalized = v.trim().to_ascii_lowercase();
+            matches!(normalized.as_str(), "1" | "true" | "yes" | "on")
+        })
+        .unwrap_or(false)
+}
+
+impl Clone for ClobExecution {
+    fn clone(&self) -> Self {
+        Self {
+            mode: self.mode,
+            http: self.http.clone(),
+            clob_endpoint: self.clob_endpoint.clone(),
+            order_primary_endpoint: self.order_primary_endpoint.clone(),
+            order_backup_endpoint: self.order_backup_endpoint.clone(),
+            order_failover_timeout: self.order_failover_timeout,
+            open_orders: self.open_orders.clone(),
+            last_prune: Mutex::new(Instant::now()),
+            ack_probe: self.ack_probe.clone(),
+        }
+    }
+}
+
+/// Minimum interval between order pruning to reduce lock contention
+const PRUNE_INTERVAL: Duration = Duration::from_secs(60);
+
+#[derive(Debug)]
+struct AckProbe {
+    url: String,
+    every: u64,
+    counter: AtomicU64,
 }
 
 #[derive(Debug, Clone)]
@@ -29,25 +74,164 @@ struct PaperOpenOrder {
     created_at: Instant,
 }
 
+#[derive(Serialize)]
+struct LiveOrderPayload<'a> {
+    market_id: &'a str,
+    token_id: Option<&'a str>,
+    side: &'a str,
+    price: f64,
+    size: f64,
+    ttl_ms: u64,
+    style: &'a str,
+    tif: &'a str,
+    client_order_id: Option<&'a str>,
+    max_slippage_bps: f64,
+    fee_rate_bps: f64,
+    expected_edge_net_bps: f64,
+    hold_to_resolution: bool,
+}
+
+fn encode_live_order_payload(intent: &OrderIntentV2) -> Vec<u8> {
+    let side = intent.side.to_string();
+    let style = intent.style.to_string();
+    let tif = intent.tif.to_string();
+    let payload = LiveOrderPayload {
+        market_id: intent.market_id.as_str(),
+        token_id: intent.token_id.as_deref(),
+        side: side.as_str(),
+        price: intent.price,
+        size: intent.size,
+        ttl_ms: intent.ttl_ms,
+        style: style.as_str(),
+        tif: tif.as_str(),
+        client_order_id: intent.client_order_id.as_deref(),
+        max_slippage_bps: intent.max_slippage_bps,
+        fee_rate_bps: intent.fee_rate_bps,
+        expected_edge_net_bps: intent.expected_edge_net_bps,
+        hold_to_resolution: intent.hold_to_resolution,
+    };
+    serde_json::to_vec(&payload).unwrap_or_default()
+}
+
 impl ClobExecution {
     pub fn new(mode: ExecutionMode, clob_endpoint: String) -> Self {
-        Self::new_with_timeout(mode, clob_endpoint, std::time::Duration::from_millis(3_000))
+        Self::new_with_order_routing(
+            mode,
+            clob_endpoint,
+            None,
+            None,
+            std::time::Duration::from_millis(3_000),
+            std::time::Duration::from_millis(200),
+        )
     }
 
     pub fn new_with_timeout(
         mode: ExecutionMode,
         clob_endpoint: String,
         timeout: std::time::Duration,
+    ) -> Self {
+        Self::new_with_order_routing(
+            mode,
+            clob_endpoint,
+            None,
+            None,
+            timeout,
+            std::time::Duration::from_millis(200),
+        )
+    }
+
+    pub fn new_with_order_routing(
+        mode: ExecutionMode,
+        clob_endpoint: String,
+        order_primary_endpoint: Option<String>,
+        order_backup_endpoint: Option<String>,
+        timeout: std::time::Duration,
+        order_failover_timeout: std::time::Duration,
     ) -> Self {
         let http = Client::builder()
+            // Keep the request budget bounded (engine must never hang on IO).
             .timeout(timeout)
+            // Connection pooling + keepalive to reduce RTT tail spikes.
+            .pool_max_idle_per_host(
+                std::env::var("POLYEDGE_HTTP_POOL_IDLE_PER_HOST")
+                    .ok()
+                    .and_then(|v| v.parse::<usize>().ok())
+                    .unwrap_or(16)
+                    .max(1),
+            )
+            .pool_idle_timeout(Some(Duration::from_secs(
+                std::env::var("POLYEDGE_HTTP_POOL_IDLE_TIMEOUT_SEC")
+                    .ok()
+                    .and_then(|v| v.parse::<u64>().ok())
+                    .unwrap_or(90)
+                    .max(5),
+            )))
+            .tcp_keepalive(Some(Duration::from_secs(
+                std::env::var("POLYEDGE_HTTP_TCP_KEEPALIVE_SEC")
+                    .ok()
+                    .and_then(|v| v.parse::<u64>().ok())
+                    .unwrap_or(30)
+                    .max(5),
+            )))
+            .tcp_nodelay(true)
+            // Force HTTP/2 without negotiation (Polymarket CLOB supports it)
+            .http2_prior_knowledge()
+            // If the peer supports it (ALPN), this can cut head-of-line blocking.
+            .http2_keep_alive_interval(Some(Duration::from_secs(
+                std::env::var("POLYEDGE_HTTP2_KEEPALIVE_INTERVAL_SEC")
+                    .ok()
+                    .and_then(|v| v.parse::<u64>().ok())
+                    .unwrap_or(30)
+                    .max(5),
+            )))
+            .http2_keep_alive_timeout(Duration::from_secs(
+                std::env::var("POLYEDGE_HTTP2_KEEPALIVE_TIMEOUT_SEC")
+                    .ok()
+                    .and_then(|v| v.parse::<u64>().ok())
+                    .unwrap_or(10)
+                    .max(1),
+            ))
+            .http2_keep_alive_while_idle(true)
             .build()
             .unwrap_or_else(|_| Client::new());
+        let ack_probe = if env_flag_enabled("POLYEDGE_ACK_ONLY_PROBE_ENABLED") {
+            std::env::var("POLYEDGE_ACK_ONLY_PROBE_URL")
+                .ok()
+                .filter(|s| !s.trim().is_empty())
+                .map(|url| {
+                    let every = std::env::var("POLYEDGE_ACK_ONLY_PROBE_EVERY")
+                        .ok()
+                        .and_then(|v| v.parse::<u64>().ok())
+                        .unwrap_or(20)
+                        .max(5);
+                    Arc::new(AckProbe {
+                        url,
+                        every,
+                        counter: AtomicU64::new(0),
+                    })
+                })
+        } else {
+            None
+        };
+
+        let primary = order_primary_endpoint
+            .map(|v| v.trim().trim_end_matches('/').to_string())
+            .filter(|v| !v.is_empty())
+            .unwrap_or_else(|| clob_endpoint.trim().trim_end_matches('/').to_string());
+        let backup = order_backup_endpoint
+            .map(|v| v.trim().trim_end_matches('/').to_string())
+            .filter(|v| !v.is_empty() && v != &primary);
+
         Self {
             mode,
             http,
             clob_endpoint,
+            order_primary_endpoint: primary,
+            order_backup_endpoint: backup,
+            order_failover_timeout,
             open_orders: Arc::new(RwLock::new(HashMap::new())),
+            last_prune: Mutex::new(Instant::now()),
+            ack_probe,
         }
     }
 
@@ -79,13 +263,55 @@ impl ClobExecution {
             .sum()
     }
 
+    pub fn has_open_order(&self, order_id: &str) -> bool {
+        self.prune_expired_orders();
+        self.open_orders.read().contains_key(order_id)
+    }
+
+    pub fn mark_order_closed_local(&self, order_id: &str) {
+        self.open_orders.write().remove(order_id);
+    }
+
+    /// Best-effort warmup for the internal HTTP client pool. Intended to run on startup so the
+    /// first order/ack path doesn't pay DNS+TLS handshake cost.
+    pub async fn prewarm_urls(&self, urls: &[String]) {
+        for url in urls {
+            let _ = self.http.get(url).send().await;
+        }
+    }
+
+    pub fn order_endpoints(&self) -> Vec<String> {
+        let mut out = Vec::with_capacity(2);
+        out.push(self.order_primary_endpoint.clone());
+        if let Some(backup) = &self.order_backup_endpoint {
+            out.push(backup.clone());
+        }
+        out
+    }
+
+    /// Prune expired orders with lazy cleanup (only every 60 seconds)
+    /// This reduces lock contention from O(n) per call to O(n) per minute
     fn prune_expired_orders(&self) {
-        let mut orders = self.open_orders.write();
-        let now = Instant::now();
-        orders.retain(|_, o| {
-            let ttl = std::time::Duration::from_millis(o.intent.ttl_ms.max(1));
-            now.duration_since(o.created_at) < ttl
-        });
+        // Check if enough time has passed since last prune
+        let should_prune = {
+            let mut last = self.last_prune.lock();
+            let now = Instant::now();
+            if now.duration_since(*last) >= PRUNE_INTERVAL {
+                *last = now;
+                true
+            } else {
+                false
+            }
+        };
+
+        if should_prune {
+            let mut orders = self.open_orders.write();
+            let now = Instant::now();
+            orders.retain(|_, o| {
+                let ttl = Duration::from_millis(o.intent.ttl_ms.max(1));
+                now.duration_since(o.created_at) < ttl
+            });
+        }
     }
 }
 
@@ -121,98 +347,187 @@ impl ExecutionVenue for ClobExecution {
                         created_at: Instant::now(),
                     },
                 );
+                // In paper mode, there is no real exchange RTT. Optionally probe a configured URL
+                // at a low sampling rate to estimate ack_only_ms without placing orders.
+                let mut exchange_latency_ms = 0.0;
+                if let Some(probe) = &self.ack_probe {
+                    let n = probe
+                        .counter
+                        .fetch_add(1, Ordering::Relaxed)
+                        .wrapping_add(1);
+                    if n % probe.every == 0 {
+                        let t0 = Instant::now();
+                        let _ = self.http.get(&probe.url).send().await;
+                        exchange_latency_ms = t0.elapsed().as_secs_f64() * 1_000.0;
+                    }
+                }
                 Ok(OrderAckV2 {
                     order_id,
                     market_id: intent.market_id,
                     accepted: true,
                     accepted_size: intent.size,
                     reject_code: None,
-                    exchange_latency_ms: started.elapsed().as_secs_f64() * 1_000.0,
+                    // Note: default is 0.0 unless probing is enabled.
+                    exchange_latency_ms,
                     ts_ms: Utc::now().timestamp_millis(),
                 })
             }
             ExecutionMode::Live => {
-                let payload = serde_json::json!({
-                    "market_id": intent.market_id,
-                    "side": intent.side.to_string(),
-                    "price": intent.price,
-                    "size": intent.size,
-                    "ttl_ms": intent.ttl_ms,
-                    "style": intent.style.to_string(),
-                    "tif": intent.tif.to_string(),
-                    "max_slippage_bps": intent.max_slippage_bps,
-                    "fee_rate_bps": intent.fee_rate_bps,
-                    "expected_edge_net_bps": intent.expected_edge_net_bps,
-                    "hold_to_resolution": intent.hold_to_resolution,
-                });
-
-                let res = self
-                    .http
-                    .post(format!("{}/orders", self.clob_endpoint))
-                    .json(&payload)
-                    .send()
-                    .await?;
-                let status = res.status();
-                let exchange_latency_ms = started.elapsed().as_secs_f64() * 1_000.0;
-
-                if !status.is_success() {
+                if env_flag_enabled("POLYEDGE_FORCE_PAPER") {
                     return Ok(OrderAckV2 {
                         order_id: new_id(),
                         market_id: intent.market_id,
                         accepted: false,
                         accepted_size: 0.0,
-                        reject_code: Some(format!("http_{}", status.as_u16())),
-                        exchange_latency_ms,
+                        reject_code: Some("force_paper_guard".to_string()),
+                        exchange_latency_ms: 0.0,
                         ts_ms: Utc::now().timestamp_millis(),
                     });
                 }
-
-                let payload_value = res
-                    .json::<serde_json::Value>()
-                    .await
-                    .unwrap_or_else(|_| serde_json::json!({}));
-                let order_id = payload_value
-                    .get("order_id")
-                    .and_then(|v| v.as_str())
-                    .or_else(|| payload_value.get("id").and_then(|v| v.as_str()))
-                    .or_else(|| payload_value.get("orderID").and_then(|v| v.as_str()))
-                    .map(ToString::to_string)
-                    .unwrap_or_else(new_id);
-                let accepted_size = payload_value
-                    .get("accepted_size")
-                    .and_then(|v| v.as_f64())
-                    .or_else(|| payload_value.get("size").and_then(|v| v.as_f64()))
-                    .unwrap_or(intent.size);
-                let mut accepted = payload_value
-                    .get("accepted")
-                    .and_then(|v| v.as_bool())
-                    .unwrap_or(true);
-                let mut reject_code = payload_value
-                    .get("reject_code")
-                    .and_then(|v| v.as_str())
-                    .or_else(|| payload_value.get("reason").and_then(|v| v.as_str()))
-                    .or_else(|| payload_value.get("error").and_then(|v| v.as_str()))
-                    .map(ToString::to_string);
-
-                if accepted_size <= 0.0 {
-                    accepted = false;
-                    reject_code.get_or_insert_with(|| "zero_fill".to_string());
+                // Validate price is finite and within valid range before sending
+                if !intent.price.is_finite() || intent.price <= 0.0 || intent.price >= 1.0 {
+                    return Ok(OrderAckV2 {
+                        order_id: new_id(),
+                        market_id: intent.market_id,
+                        accepted: false,
+                        accepted_size: 0.0,
+                        reject_code: Some("invalid_price".to_string()),
+                        exchange_latency_ms: 0.0,
+                        ts_ms: Utc::now().timestamp_millis(),
+                    });
                 }
-                if accepted && matches!(intent.tif, core_types::OrderTimeInForce::Fok) {
-                    let missing = intent.size - accepted_size;
-                    if missing > 1e-9 {
-                        accepted = false;
-                        reject_code.get_or_insert_with(|| "fok_partial_fill".to_string());
+
+                let body_bytes: Vec<u8> = if let Some(ref prebuilt) = intent.prebuilt_payload {
+                    prebuilt.clone()
+                } else {
+                    encode_live_order_payload(&intent)
+                };
+
+                const MAX_RETRIES: u32 = 2;
+                let mut last_network_error: Option<String> = None;
+                for (idx, endpoint) in self.order_endpoints().iter().enumerate() {
+                    let primary_leg = idx == 0;
+                    for attempt in 0..MAX_RETRIES {
+                        let mut req = self
+                            .http
+                            .post(format!("{endpoint}/orders"))
+                            .header("content-type", "application/json")
+                            .body(body_bytes.clone());
+                        if primary_leg && self.order_failover_timeout > Duration::from_millis(0) {
+                            req = req.timeout(self.order_failover_timeout);
+                        }
+                        let res = match req.send().await {
+                            Ok(res) => res,
+                            Err(err) => {
+                                last_network_error = Some(err.to_string());
+                                if attempt + 1 < MAX_RETRIES {
+                                    continue;
+                                }
+                                break;
+                            }
+                        };
+
+                        let status = res.status();
+                        let raw = res.text().await.unwrap_or_default();
+                        let payload_value = serde_json::from_str::<serde_json::Value>(&raw)
+                            .unwrap_or_else(|_| {
+                                serde_json::json!({
+                                    "raw": raw,
+                                })
+                            });
+                        let order_id = payload_value
+                            .get("order_id")
+                            .and_then(|v| v.as_str())
+                            .or_else(|| payload_value.get("id").and_then(|v| v.as_str()))
+                            .or_else(|| payload_value.get("orderID").and_then(|v| v.as_str()))
+                            .map(ToString::to_string)
+                            .unwrap_or_else(new_id);
+                        let accepted_size = payload_value
+                            .get("accepted_size")
+                            .and_then(|v| v.as_f64())
+                            .or_else(|| payload_value.get("size").and_then(|v| v.as_f64()))
+                            .unwrap_or_else(|| {
+                                if status.is_success() {
+                                    intent.size
+                                } else {
+                                    0.0
+                                }
+                            })
+                            .max(0.0);
+                        let mut accepted = payload_value
+                            .get("accepted")
+                            .and_then(|v| v.as_bool())
+                            .unwrap_or(status.is_success());
+                        let mut reject_code = payload_value
+                            .get("reject_code")
+                            .and_then(|v| v.as_str())
+                            .or_else(|| payload_value.get("reason").and_then(|v| v.as_str()))
+                            .or_else(|| payload_value.get("error").and_then(|v| v.as_str()))
+                            .map(ToString::to_string);
+
+                        if !status.is_success() {
+                            accepted = false;
+                            if reject_code.is_none() {
+                                reject_code = Some(format!("http_{}", status.as_u16()));
+                            }
+                        }
+                        if accepted_size <= 0.0 {
+                            accepted = false;
+                        }
+                        if status.is_server_error() && attempt + 1 < MAX_RETRIES {
+                            continue;
+                        }
+                        if accepted {
+                            if matches!(intent.tif, core_types::OrderTimeInForce::PostOnly) {
+                                self.open_orders.write().insert(
+                                    order_id.clone(),
+                                    PaperOpenOrder {
+                                        intent: QuoteIntent {
+                                            market_id: intent.market_id.clone(),
+                                            side: intent.side.clone(),
+                                            price: intent.price,
+                                            size: accepted_size.max(0.0),
+                                            ttl_ms: intent.ttl_ms,
+                                        },
+                                        created_at: Instant::now(),
+                                    },
+                                );
+                            }
+                            return Ok(OrderAckV2 {
+                                order_id,
+                                market_id: intent.market_id,
+                                accepted: true,
+                                accepted_size,
+                                reject_code: None,
+                                exchange_latency_ms: started.elapsed().as_secs_f64() * 1_000.0,
+                                ts_ms: Utc::now().timestamp_millis(),
+                            });
+                        }
+                        if primary_leg {
+                            break;
+                        }
+                        return Ok(OrderAckV2 {
+                            order_id,
+                            market_id: intent.market_id,
+                            accepted: false,
+                            accepted_size: 0.0,
+                            reject_code,
+                            exchange_latency_ms: started.elapsed().as_secs_f64() * 1_000.0,
+                            ts_ms: Utc::now().timestamp_millis(),
+                        });
                     }
                 }
 
+                let reject_code = last_network_error
+                    .map(|e| format!("network_error:{e}"))
+                    .unwrap_or_else(|| "network_error_after_failover".to_string());
                 Ok(OrderAckV2 {
-                    order_id,
+                    order_id: new_id(),
                     market_id: intent.market_id,
-                    accepted,
-                    accepted_size: accepted_size.max(0.0),
-                    reject_code,
-                    exchange_latency_ms,
+                    accepted: false,
+                    accepted_size: 0.0,
+                    reject_code: Some(reject_code),
+                    exchange_latency_ms: started.elapsed().as_secs_f64() * 1_000.0,
                     ts_ms: Utc::now().timestamp_millis(),
                 })
             }
@@ -226,21 +541,101 @@ impl ExecutionVenue for ClobExecution {
                 Ok(())
             }
             ExecutionMode::Live => {
-                let res = self
-                    .http
-                    .delete(format!("{}/orders/{order_id}", self.clob_endpoint))
-                    .send()
-                    .await?;
-                if !res.status().is_success() {
-                    bail!("cancel failed with status {}", res.status());
+                if env_flag_enabled("POLYEDGE_FORCE_PAPER") {
+                    bail!("force_paper_guard: cancel blocked in live mode");
                 }
-                Ok(())
+                let mut last_status: Option<reqwest::StatusCode> = None;
+                for endpoint in self.order_endpoints() {
+                    let res = self
+                        .http
+                        .delete(format!("{endpoint}/orders/{order_id}"))
+                        .send()
+                        .await?;
+                    if res.status().is_success() {
+                        self.open_orders.write().remove(order_id);
+                        return Ok(());
+                    }
+                    last_status = Some(res.status());
+                }
+                bail!(
+                    "cancel failed with status {}",
+                    last_status
+                        .map(|s| s.as_u16().to_string())
+                        .unwrap_or_else(|| "unknown".to_string())
+                )
             }
         }
     }
 
     async fn flatten_all(&self) -> Result<()> {
         self.open_orders.write().clear();
-        Ok(())
+        match self.mode {
+            ExecutionMode::Paper => Ok(()),
+            ExecutionMode::Live => {
+                if env_flag_enabled("POLYEDGE_FORCE_PAPER") {
+                    bail!("force_paper_guard: flatten blocked in live mode");
+                }
+                let mut last_status: Option<reqwest::StatusCode> = None;
+                for endpoint in self.order_endpoints() {
+                    let res = self.http.post(format!("{endpoint}/flatten")).send().await?;
+                    if res.status().is_success() {
+                        return Ok(());
+                    }
+                    last_status = Some(res.status());
+                }
+                bail!(
+                    "flatten failed with status {}",
+                    last_status
+                        .map(|s| s.as_u16().to_string())
+                        .unwrap_or_else(|| "unknown".to_string())
+                )
+            }
+        }
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn env_flag_enabled_parses_common_true_values() {
+        for value in ["1", "true", "TRUE", "yes", "on"] {
+            std::env::set_var("POLYEDGE_TEST_FLAG", value);
+            assert!(env_flag_enabled("POLYEDGE_TEST_FLAG"), "value={value}");
+        }
+        std::env::remove_var("POLYEDGE_TEST_FLAG");
+        assert!(!env_flag_enabled("POLYEDGE_TEST_FLAG"));
+    }
+
+    #[test]
+    fn order_endpoints_include_backup_when_configured() {
+        let exec = ClobExecution::new_with_order_routing(
+            ExecutionMode::Paper,
+            "https://clob.polymarket.com".to_string(),
+            Some("http://127.0.0.1:9001".to_string()),
+            Some("http://127.0.0.1:9002".to_string()),
+            Duration::from_millis(1_000),
+            Duration::from_millis(200),
+        );
+        let endpoints = exec.order_endpoints();
+        assert_eq!(endpoints.len(), 2);
+        assert_eq!(endpoints[0], "http://127.0.0.1:9001");
+        assert_eq!(endpoints[1], "http://127.0.0.1:9002");
+    }
+
+    #[test]
+    fn order_endpoints_dedup_empty_backup() {
+        let exec = ClobExecution::new_with_order_routing(
+            ExecutionMode::Paper,
+            "https://clob.polymarket.com".to_string(),
+            Some("http://127.0.0.1:9001".to_string()),
+            Some("http://127.0.0.1:9001".to_string()),
+            Duration::from_millis(1_000),
+            Duration::from_millis(200),
+        );
+        let endpoints = exec.order_endpoints();
+        assert_eq!(endpoints.len(), 1);
+        assert_eq!(endpoints[0], "http://127.0.0.1:9001");
     }
 }
diff --git a/crates/execution_clob/src/wss_user_feed.rs b/crates/execution_clob/src/wss_user_feed.rs
new file mode 100644
index 0000000..29e2c0e
--- /dev/null
+++ b/crates/execution_clob/src/wss_user_feed.rs
@@ -0,0 +1,199 @@
+use std::sync::atomic::{AtomicU64, Ordering};
+use std::sync::Arc;
+use std::time::Duration;
+
+use anyhow::Result;
+use futures::{SinkExt, StreamExt};
+use serde::Deserialize;
+use tokio::sync::broadcast;
+use tokio_tungstenite::connect_async;
+use tokio_tungstenite::tungstenite::Message;
+
+// -----------------------------------------------------------------------
+// å…¬å¼€ç±»åž‹
+// -----------------------------------------------------------------------
+
+/// ä»Ž WSS user channel è§£æžå‡ºçš„ fill äº‹ä»¶ï¼ˆä»…ä¿ç•™ exit lifecycle å…³å¿ƒçš„å­—æ®µï¼‰
+#[derive(Debug, Clone)]
+pub struct WssFillEvent {
+    /// è®¢å• IDï¼ˆå¯¹åº” OrderAckV2.order_idï¼‰
+    pub order_id: String,
+    /// å¸‚åœº ID
+    pub market_id: String,
+    /// æˆäº¤ä»·æ ¼
+    pub price: f64,
+    /// æˆäº¤æ•°é‡
+    pub size: f64,
+    /// äº‹ä»¶ç±»åž‹: "trade" | "order"
+    pub event_type: &'static str,
+    /// æœåŠ¡ç«¯æ—¶é—´æˆ³ ms
+    pub ts_ms: i64,
+}
+
+// -----------------------------------------------------------------------
+// å†…éƒ¨ JSON ç»“æž„ï¼ˆPolymarket WSS user channel æ ¼å¼ï¼‰
+// -----------------------------------------------------------------------
+
+#[derive(Debug, Deserialize)]
+struct WssEnvelope {
+    event_type: Option<String>,
+    #[serde(default)]
+    data: Vec<WssEventData>,
+}
+
+#[derive(Debug, Deserialize)]
+struct WssEventData {
+    #[serde(default)]
+    order_id: String,
+    #[serde(default)]
+    market: String,
+    #[serde(default)]
+    price: String,
+    #[serde(default)]
+    size: String,
+    #[serde(default)]
+    timestamp: String,
+    // order äº‹ä»¶å­—æ®µ
+    #[serde(default)]
+    id: String,
+    #[serde(default)]
+    market_id: String,
+}
+
+// -----------------------------------------------------------------------
+// å…¬å¼€å…¥å£ï¼šapp_runner å¯ç”¨è‡ªå·±çš„ broadcast::Sender å¯åŠ¨ WSS å¾ªçŽ¯
+// -----------------------------------------------------------------------
+
+/// å¯åŠ¨ WSS user channel å¾ªçŽ¯ï¼ˆè‡ªåŠ¨é‡è¿žï¼Œæ°¸ä¸é€€å‡ºï¼‰
+///
+/// `tx`: å¹¿æ’­å‘é€ç«¯ï¼ˆapp_runner æŒæœ‰ Arc<Sender>ï¼Œæ­¤å¤„å…±äº«ï¼‰
+/// `wss_url`: Polymarket user channel URL
+/// `api_key`: CLOB API keyï¼ˆç”¨äºŽ subscribe æ¶ˆæ¯è®¤è¯ï¼‰
+pub async fn run_wss_loop_with_sender(
+    tx: Arc<broadcast::Sender<WssFillEvent>>,
+    wss_url: String,
+    api_key: String,
+) {
+    let mut backoff_ms = 500_u64;
+    loop {
+        match connect_and_stream(&tx, &wss_url, &api_key).await {
+            Ok(()) => {
+                tracing::info!("wss_user_feed: connection closed, reconnecting");
+                backoff_ms = 500;
+            }
+            Err(err) => {
+                tracing::warn!(
+                    ?err,
+                    backoff_ms,
+                    "wss_user_feed: connection error, retrying"
+                );
+                backoff_ms = (backoff_ms * 2).min(30_000);
+            }
+        }
+        tokio::time::sleep(Duration::from_millis(backoff_ms)).await;
+    }
+}
+
+// -----------------------------------------------------------------------
+// æ ¸å¿ƒè¿žæŽ¥å¾ªçŽ¯
+// -----------------------------------------------------------------------
+
+async fn connect_and_stream(
+    tx: &Arc<broadcast::Sender<WssFillEvent>>,
+    wss_url: &str,
+    api_key: &str,
+) -> Result<()> {
+    let (mut ws, _) = connect_async(wss_url).await?;
+    tracing::info!(wss_url, "wss_user_feed: connected");
+
+    // å‘é€ subscribe æ¶ˆæ¯ï¼ˆPolymarket user channel è®¤è¯æ ¼å¼ï¼‰
+    let subscribe_json = serde_json::json!({
+        "auth": { "apiKey": api_key },
+        "type": "subscribe",
+        "channel": "user",
+    })
+    .to_string();
+    ws.send(Message::Text(subscribe_json.into())).await?;
+
+    while let Some(msg) = ws.next().await {
+        let msg = msg?;
+        match msg {
+            Message::Text(text) => {
+                if let Ok(envelope) = serde_json::from_str::<WssEnvelope>(&text) {
+                    parse_and_broadcast(tx, envelope);
+                }
+            }
+            // tungstenite 0.24+ è‡ªåŠ¨å“åº” Pingï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†
+            Message::Close(_) => break,
+            _ => {}
+        }
+    }
+    Ok(())
+}
+
+// -----------------------------------------------------------------------
+// äº‹ä»¶è§£æž â€” é›¶åˆ†é…çƒ­è·¯å¾„
+// -----------------------------------------------------------------------
+
+fn parse_and_broadcast(tx: &Arc<broadcast::Sender<WssFillEvent>>, envelope: WssEnvelope) {
+    let event_type = match envelope.event_type.as_deref() {
+        Some("trade") => "trade",
+        Some("order") => "order",
+        _ => return, // å¿½ç•¥éž fill äº‹ä»¶ï¼ˆheartbeat ç­‰ï¼‰
+    };
+
+    for data in envelope.data {
+        let order_id = if !data.order_id.is_empty() {
+            data.order_id.clone()
+        } else {
+            data.id.clone()
+        };
+        if order_id.is_empty() {
+            continue;
+        }
+
+        let market_id = if !data.market.is_empty() {
+            data.market.clone()
+        } else {
+            data.market_id.clone()
+        };
+
+        let Ok(price) = data.price.parse::<f64>() else {
+            record_parse_error("price");
+            continue;
+        };
+        let Ok(size) = data.size.parse::<f64>() else {
+            record_parse_error("size");
+            continue;
+        };
+        let ts_ms = data
+            .timestamp
+            .parse::<i64>()
+            .unwrap_or_else(|_| chrono::Utc::now().timestamp_millis());
+
+        let event = WssFillEvent {
+            order_id,
+            market_id,
+            price,
+            size,
+            event_type,
+            ts_ms,
+        };
+
+        // å¿½ç•¥ lagged receiver é”™è¯¯ï¼ˆæ¶ˆè´¹è€…å¤ªæ…¢æ—¶ä¸¢å¼ƒæ—§äº‹ä»¶ï¼‰
+        let _ = tx.send(event);
+    }
+}
+
+static PARSE_ERROR_COUNT: AtomicU64 = AtomicU64::new(0);
+
+fn record_parse_error(field: &'static str) {
+    let count = PARSE_ERROR_COUNT.fetch_add(1, Ordering::Relaxed) + 1;
+    if count.is_power_of_two() {
+        tracing::warn!(
+            field,
+            count,
+            "wss_user_feed: dropping malformed fill event field"
+        );
+    }
+}
diff --git a/crates/exit_manager/Cargo.toml b/crates/exit_manager/Cargo.toml
new file mode 100644
index 0000000..ab61b2c
--- /dev/null
+++ b/crates/exit_manager/Cargo.toml
@@ -0,0 +1,9 @@
+[package]
+name = "exit_manager"
+version.workspace = true
+edition.workspace = true
+license.workspace = true
+
+[dependencies]
+serde.workspace = true
+
diff --git a/crates/exit_manager/src/lib.rs b/crates/exit_manager/src/lib.rs
new file mode 100644
index 0000000..0567607
--- /dev/null
+++ b/crates/exit_manager/src/lib.rs
@@ -0,0 +1,463 @@
+use std::collections::HashMap;
+
+use serde::{Deserialize, Serialize};
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct ExitManagerConfig {
+    /// Early reversal threshold (bps) for the 100ms..300ms window.
+    pub t100ms_reversal_bps: f64,
+    /// Reversal threshold (bps) for the 300ms..3s window.
+    pub t300ms_reversal_bps: f64,
+    /// Convergence ratio threshold. Exit once PM has closed enough of the fair-value gap.
+    pub convergence_exit_ratio: f64,
+    /// T+3s take-profit ratio against entry edge.
+    pub t3_take_ratio: f64,
+    /// Minimum unrealized PnL at T+15s.
+    pub t15_min_unrealized_usdc: f64,
+    /// Probability guard floor at T+60s.
+    pub t60_true_prob_floor: f64,
+    /// Hard max holding time in ms.
+    pub t300_force_exit_ms: u64,
+    /// Allow-hold probability threshold near expiry.
+    pub t300_hold_prob_threshold: f64,
+    /// Allow-hold remaining-time threshold in ms.
+    pub t300_hold_time_to_expiry_ms: u64,
+    /// Max allowed loss per position in USDC.
+    pub max_single_trade_loss_usdc: f64,
+}
+
+impl Default for ExitManagerConfig {
+    fn default() -> Self {
+        Self {
+            t100ms_reversal_bps: -3.0,
+            t300ms_reversal_bps: -2.0,
+            convergence_exit_ratio: 0.85,
+            t3_take_ratio: 0.60,
+            t15_min_unrealized_usdc: 0.0,
+            t60_true_prob_floor: 0.70,
+            t300_force_exit_ms: 300_000,
+            t300_hold_prob_threshold: 0.95,
+            t300_hold_time_to_expiry_ms: 300_000,
+            max_single_trade_loss_usdc: 1.0,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct PositionLifecycle {
+    pub position_id: String,
+    pub market_id: String,
+    pub symbol: String,
+    pub opened_at_ms: i64,
+    pub entry_edge_usdc: f64,
+    pub entry_notional_usdc: f64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct MarketEvalInput {
+    pub now_ms: i64,
+    pub unrealized_pnl_usdc: f64,
+    pub true_prob: f64,
+    pub time_to_expiry_ms: i64,
+    /// Current PM YES mid used for convergence checks.
+    pub pm_mid_yes: f64,
+    /// PM YES mid at entry.
+    pub entry_pm_mid_yes: f64,
+    /// Fair YES value at entry.
+    pub entry_fair_yes: f64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
+#[serde(rename_all = "snake_case")]
+pub enum ExitReason {
+    /// Hard stop on max per-trade loss.
+    StopLoss,
+    /// Sharp reversal in 100ms..300ms.
+    Reversal100ms,
+    /// Sustained reversal in 300ms..3s.
+    Reversal300ms,
+    /// PM price has converged enough to fair value.
+    ConvergenceExit,
+    /// Profit target reached at/after T+3s.
+    TakeProfit3s,
+    /// Any positive pnl at/after T+15s.
+    TakeProfit15s,
+    /// Probability guard at/after T+60s.
+    ProbGuard60s,
+    /// Hard close after max hold time.
+    ForceClose300s,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct ExitAction {
+    pub position_id: String,
+    pub market_id: String,
+    pub symbol: String,
+    pub reason: ExitReason,
+}
+
+#[derive(Debug)]
+pub struct ExitManager {
+    cfg: ExitManagerConfig,
+    open: HashMap<String, PositionLifecycle>,
+}
+
+impl ExitManager {
+    pub fn new(cfg: ExitManagerConfig) -> Self {
+        Self {
+            cfg,
+            open: HashMap::new(),
+        }
+    }
+
+    pub fn cfg(&self) -> &ExitManagerConfig {
+        &self.cfg
+    }
+
+    pub fn set_cfg(&mut self, cfg: ExitManagerConfig) {
+        self.cfg = cfg;
+    }
+
+    pub fn register(&mut self, position: PositionLifecycle) {
+        // Keep one active position per market to avoid stale entries that can never be selected.
+        if let Some(existing_id) = self
+            .open
+            .iter()
+            .find_map(|(id, p)| (p.market_id == position.market_id).then(|| id.clone()))
+        {
+            self.open.remove(&existing_id);
+        }
+        self.open.insert(position.position_id.clone(), position);
+    }
+
+    pub fn close(&mut self, position_id: &str) -> Option<PositionLifecycle> {
+        self.open.remove(position_id)
+    }
+
+    pub fn open_count(&self) -> usize {
+        self.open.len()
+    }
+
+    pub fn evaluate_market(
+        &mut self,
+        market_id: &str,
+        input: MarketEvalInput,
+    ) -> Option<ExitAction> {
+        let position = self
+            .open
+            .values()
+            .filter(|p| p.market_id == market_id)
+            .max_by_key(|p| p.opened_at_ms)
+            .cloned()?;
+        let reason = self.evaluate_position(&position, &input)?;
+        self.open.remove(&position.position_id);
+        Some(ExitAction {
+            position_id: position.position_id,
+            market_id: position.market_id,
+            symbol: position.symbol,
+            reason,
+        })
+    }
+
+    fn evaluate_position(
+        &self,
+        position: &PositionLifecycle,
+        input: &MarketEvalInput,
+    ) -> Option<ExitReason> {
+        let elapsed_ms = input.now_ms.saturating_sub(position.opened_at_ms).max(0) as u64;
+        let true_prob = input.true_prob.clamp(0.0, 1.0);
+
+        if input.unrealized_pnl_usdc <= -self.cfg.max_single_trade_loss_usdc {
+            return Some(ExitReason::StopLoss);
+        }
+
+        if position.entry_notional_usdc > 0.0 && (100..300).contains(&elapsed_ms) {
+            let pnl_bps = (input.unrealized_pnl_usdc / position.entry_notional_usdc) * 10_000.0;
+            if pnl_bps <= self.cfg.t100ms_reversal_bps {
+                return Some(ExitReason::Reversal100ms);
+            }
+        }
+
+        if position.entry_notional_usdc > 0.0 && (300..3_000).contains(&elapsed_ms) {
+            let pnl_bps = (input.unrealized_pnl_usdc / position.entry_notional_usdc) * 10_000.0;
+            if pnl_bps <= self.cfg.t300ms_reversal_bps {
+                return Some(ExitReason::Reversal300ms);
+            }
+        }
+
+        if self.cfg.convergence_exit_ratio > 0.0
+            && input.pm_mid_yes > 0.0
+            && input.entry_pm_mid_yes > 0.0
+            && input.entry_fair_yes > 0.0
+        {
+            let gap_total = (input.entry_fair_yes - input.entry_pm_mid_yes).abs();
+            if gap_total > 1e-6 {
+                let gap_remaining = (input.entry_fair_yes - input.pm_mid_yes).abs();
+                let convergence_ratio = 1.0 - (gap_remaining / gap_total);
+                if convergence_ratio >= self.cfg.convergence_exit_ratio {
+                    return Some(ExitReason::ConvergenceExit);
+                }
+            }
+        }
+
+        if elapsed_ms >= 3_000 {
+            let t3_target = position.entry_edge_usdc.max(0.0) * self.cfg.t3_take_ratio;
+            if input.unrealized_pnl_usdc > t3_target {
+                return Some(ExitReason::TakeProfit3s);
+            }
+        }
+
+        // Default t15_min_unrealized_usdc=0.0 means any positive PnL exits at T+15s.
+        if elapsed_ms >= 15_000 && input.unrealized_pnl_usdc > self.cfg.t15_min_unrealized_usdc {
+            return Some(ExitReason::TakeProfit15s);
+        }
+
+        if elapsed_ms >= 60_000 && true_prob <= self.cfg.t60_true_prob_floor {
+            return Some(ExitReason::ProbGuard60s);
+        }
+
+        if elapsed_ms >= self.cfg.t300_force_exit_ms {
+            let allow_hold = true_prob > self.cfg.t300_hold_prob_threshold
+                && input.time_to_expiry_ms >= 0
+                && (input.time_to_expiry_ms as u64) < self.cfg.t300_hold_time_to_expiry_ms;
+            if !allow_hold {
+                return Some(ExitReason::ForceClose300s);
+            }
+        }
+
+        None
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    fn sample_position(opened_at_ms: i64) -> PositionLifecycle {
+        PositionLifecycle {
+            position_id: "p1".to_string(),
+            market_id: "m1".to_string(),
+            symbol: "BTCUSDT".to_string(),
+            opened_at_ms,
+            entry_edge_usdc: 1.0,
+            entry_notional_usdc: 50.0,
+        }
+    }
+
+    fn eval(
+        now_ms: i64,
+        unrealized_pnl_usdc: f64,
+        true_prob: f64,
+        time_to_expiry_ms: i64,
+    ) -> MarketEvalInput {
+        MarketEvalInput {
+            now_ms,
+            unrealized_pnl_usdc,
+            true_prob,
+            time_to_expiry_ms,
+            pm_mid_yes: 0.0,
+            entry_pm_mid_yes: 0.0,
+            entry_fair_yes: 0.0,
+        }
+    }
+
+    #[test]
+    fn stop_loss_triggers_immediately() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(1_100, -1.1, 0.9, 600_000));
+        assert!(matches!(
+            action.map(|a| a.reason),
+            Some(ExitReason::StopLoss)
+        ));
+    }
+
+    #[test]
+    fn reversal_100ms_triggers_on_fast_reversal() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(1_150, -0.02, 0.9, 600_000));
+        assert!(matches!(
+            action.map(|a| a.reason),
+            Some(ExitReason::Reversal100ms)
+        ));
+    }
+
+    #[test]
+    fn reversal_100ms_does_not_trigger_too_early() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(1_050, -0.02, 0.9, 600_000));
+        assert!(action.is_none());
+    }
+
+    #[test]
+    fn reversal_100ms_does_not_trigger_on_small_loss() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(1_150, -0.005, 0.9, 600_000));
+        assert!(action.is_none());
+    }
+
+    #[test]
+    fn reversal_300ms_triggers_before_t3() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(1_400, -0.01, 0.9, 500_000));
+        assert!(matches!(
+            action.map(|a| a.reason),
+            Some(ExitReason::Reversal300ms)
+        ));
+    }
+
+    #[test]
+    fn t3_take_profit_triggers() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(4_500, 0.7, 0.8, 500_000));
+        assert!(matches!(
+            action.map(|a| a.reason),
+            Some(ExitReason::TakeProfit3s)
+        ));
+    }
+
+    #[test]
+    fn t15_positive_exit_triggers() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(20_500, 0.01, 0.9, 450_000));
+        assert!(matches!(
+            action.map(|a| a.reason),
+            Some(ExitReason::TakeProfit15s)
+        ));
+    }
+
+    #[test]
+    fn t60_prob_guard_triggers_on_low_prob() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(62_000, -0.2, 0.65, 360_000));
+        assert!(matches!(
+            action.map(|a| a.reason),
+            Some(ExitReason::ProbGuard60s)
+        ));
+    }
+
+    #[test]
+    fn t300_force_close_triggers() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(305_000, -0.01, 0.93, 1_000_000));
+        assert!(matches!(
+            action.map(|a| a.reason),
+            Some(ExitReason::ForceClose300s)
+        ));
+    }
+
+    #[test]
+    fn t300_allows_hold_near_expiry_with_high_prob() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market("m1", eval(305_000, -0.01, 0.97, 240_000));
+        assert!(action.is_none());
+        assert_eq!(manager.open_count(), 1);
+    }
+
+    #[test]
+    fn evaluate_market_uses_latest_position() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(PositionLifecycle {
+            position_id: "old".to_string(),
+            opened_at_ms: 1_000,
+            ..sample_position(1_000)
+        });
+        manager.register(PositionLifecycle {
+            position_id: "new".to_string(),
+            opened_at_ms: 10_000,
+            ..sample_position(10_000)
+        });
+        let action = manager.evaluate_market("m1", eval(15_000, 1.0, 0.9, 600_000));
+        let Some(action) = action else {
+            panic!("expected action");
+        };
+        assert_eq!(action.position_id, "new");
+    }
+
+    #[test]
+    fn register_enforces_single_position_per_market() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(PositionLifecycle {
+            position_id: "old".to_string(),
+            opened_at_ms: 1_000,
+            ..sample_position(1_000)
+        });
+        manager.register(PositionLifecycle {
+            position_id: "new".to_string(),
+            opened_at_ms: 2_000,
+            ..sample_position(2_000)
+        });
+        assert_eq!(manager.open_count(), 1);
+        let action = manager.evaluate_market("m1", eval(6_000, 1.0, 0.9, 600_000));
+        assert_eq!(action.map(|a| a.position_id), Some("new".to_string()));
+    }
+
+    #[test]
+    fn convergence_exit_triggers_at_85_percent() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market(
+            "m1",
+            MarketEvalInput {
+                now_ms: 1_500,
+                unrealized_pnl_usdc: 0.5,
+                true_prob: 0.9,
+                time_to_expiry_ms: 600_000,
+                pm_mid_yes: 0.785,
+                entry_pm_mid_yes: 0.70,
+                entry_fair_yes: 0.80,
+            },
+        );
+        assert!(matches!(
+            action.map(|a| a.reason),
+            Some(ExitReason::ConvergenceExit)
+        ));
+    }
+
+    #[test]
+    fn convergence_exit_does_not_trigger_below_threshold() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market(
+            "m1",
+            MarketEvalInput {
+                now_ms: 1_500,
+                unrealized_pnl_usdc: 0.3,
+                true_prob: 0.9,
+                time_to_expiry_ms: 600_000,
+                pm_mid_yes: 0.77,
+                entry_pm_mid_yes: 0.70,
+                entry_fair_yes: 0.80,
+            },
+        );
+        assert!(action.is_none());
+    }
+
+    #[test]
+    fn convergence_exit_skipped_when_pm_mid_zero() {
+        let mut manager = ExitManager::new(ExitManagerConfig::default());
+        manager.register(sample_position(1_000));
+        let action = manager.evaluate_market(
+            "m1",
+            MarketEvalInput {
+                now_ms: 1_500,
+                unrealized_pnl_usdc: 0.5,
+                true_prob: 0.9,
+                time_to_expiry_ms: 600_000,
+                pm_mid_yes: 0.0,
+                entry_pm_mid_yes: 0.70,
+                entry_fair_yes: 0.80,
+            },
+        );
+        assert!(action.is_none());
+    }
+}
diff --git a/crates/fair_value/Cargo.toml b/crates/fair_value/Cargo.toml
index ee9b27f..d81c669 100644
--- a/crates/fair_value/Cargo.toml
+++ b/crates/fair_value/Cargo.toml
@@ -7,3 +7,4 @@ license.workspace = true
 [dependencies]
 core_types = { path = "../core_types" }
 serde.workspace = true
+parking_lot.workspace = true
diff --git a/crates/fair_value/src/lib.rs b/crates/fair_value/src/lib.rs
index 95b416f..4c94ef7 100644
--- a/crates/fair_value/src/lib.rs
+++ b/crates/fair_value/src/lib.rs
@@ -1,7 +1,8 @@
 use std::collections::HashMap;
-use std::sync::{Arc, Mutex, RwLock};
+use std::sync::{Arc, RwLock};
 
 use core_types::{BookTop, FairValueModel, RefTick, Signal};
+use parking_lot::Mutex;
 use serde::{Deserialize, Serialize};
 
 #[derive(Debug, Clone, Serialize, Deserialize)]
@@ -67,18 +68,17 @@ impl Default for BasisMrFairValue {
 
 impl FairValueModel for BasisMrFairValue {
     fn evaluate(&self, tick: &RefTick, book: &BookTop) -> Signal {
-        let cfg = self
-            .cfg
-            .read()
-            .map(|g| g.clone())
-            .unwrap_or_else(|_| BasisMrConfig::default());
+        let cfg = match self.cfg.read() {
+            Ok(guard) => guard.clone(),
+            Err(poisoned) => poisoned.into_inner().clone(),
+        };
         let mid_yes = ((book.bid_yes + book.ask_yes) * 0.5).clamp(0.001, 0.999);
         let spread = (book.ask_yes - book.bid_yes).max(0.0001);
         // Fix DESIGN-2: Key by symbol only (e.g. "BTCUSDT") to share specific fair value state
         // across all markets (e.g. daily, 15m) for that asset. This prevents warmup reset on rollover.
         let key = tick.symbol.clone();
 
-        let mut map = self.state.lock().unwrap_or_else(|e| e.into_inner());
+        let mut map = self.state.lock();
         let st = map.entry(key).or_default();
 
         let ret = if st.last_ref_px > 0.0 {
@@ -137,8 +137,11 @@ mod tests {
             symbol: "BTCUSDT".to_string(),
             event_ts_ms: ts,
             recv_ts_ms: ts,
+            source_seq: ts.max(0) as u64,
             event_ts_exchange_ms: ts,
             recv_ts_local_ns: ts * 1_000_000,
+            ingest_ts_local_ns: ts * 1_000_000,
+            ts_first_hop_ms: None,
             price: px,
         }
     }
diff --git a/crates/feed_polymarket/src/lib.rs b/crates/feed_polymarket/src/lib.rs
index 92fdd98..c40e752 100644
--- a/crates/feed_polymarket/src/lib.rs
+++ b/crates/feed_polymarket/src/lib.rs
@@ -13,10 +13,21 @@ use rand::Rng;
 use reqwest::Client;
 use serde::Deserialize;
 use tokio::sync::mpsc;
+use tokio::time::timeout;
 use tokio_stream::wrappers::ReceiverStream;
 use tokio_tungstenite::connect_async;
 use tokio_tungstenite::tungstenite::Message;
 
+/// WebSocket connection timeout
+const WS_CONNECT_TIMEOUT: Duration = Duration::from_secs(10);
+/// WebSocket read timeout - prevents hanging on stale connections
+const WS_READ_TIMEOUT: Duration = Duration::from_secs(30);
+
+/// Validates that a price value is finite and within valid range [0, 1]
+fn validate_price(price: f64) -> bool {
+    price.is_finite() && (0.0..=1.0).contains(&price)
+}
+
 #[derive(Debug, Clone)]
 pub struct PolymarketEndpoints {
     pub gamma_markets: String,
@@ -154,11 +165,11 @@ impl PolymarketFeed {
         let this = self.clone();
 
         tokio::spawn(async move {
-            loop {
-                if let Err(err) = this.run_market_loop(&tx).await {
-                    tracing::warn!(?err, "polymarket market ws loop failed; reconnecting");
-                }
-                sleep_with_jitter(this.reconnect_backoff).await;
+            // NOTE: app_runner owns the reconnect lifecycle for market feed.
+            // Keep this worker single-shot to avoid nested reconnect loops that
+            // can fan out into discovery storms (and trigger Gamma 429s).
+            if let Err(err) = this.run_market_loop(&tx).await {
+                tracing::warn!(?err, "polymarket market ws loop failed");
             }
         });
 
@@ -184,9 +195,13 @@ impl PolymarketFeed {
             "polymarket market ws subscribing"
         );
 
-        let (mut ws, _) = connect_async(&self.endpoints.clob_ws_market)
-            .await
-            .context("connect polymarket market ws")?;
+        let (mut ws, _) = timeout(
+            WS_CONNECT_TIMEOUT,
+            connect_async(&self.endpoints.clob_ws_market),
+        )
+        .await
+        .context("connect polymarket market ws timeout")?
+        .context("connect polymarket market ws")?;
         tracing::info!(endpoint = %self.endpoints.clob_ws_market, "polymarket market ws connected");
 
         let sub = serde_json::json!({
@@ -200,21 +215,51 @@ impl PolymarketFeed {
 
         let mut ping = tokio::time::interval(Duration::from_secs(15));
         ping.set_missed_tick_behavior(tokio::time::MissedTickBehavior::Delay);
+        // Many Polymarket markets (especially 5m/15m contracts) expire quickly. If the WS
+        // connection stays up, we would otherwise keep subscribing to stale/closed assets and
+        // stop seeing updates. Force a periodic re-discovery + resubscribe.
+        let refresh_every = std::env::var("POLYEDGE_MARKET_REFRESH_SEC")
+            .ok()
+            .and_then(|v| v.parse::<u64>().ok())
+            .map(Duration::from_secs)
+            .unwrap_or(Duration::from_secs(120));
+        let refresh_deadline = tokio::time::sleep(refresh_every);
+        tokio::pin!(refresh_deadline);
         let mut parse_failures = 0_u64;
         let mut no_update_msgs = 0_u64;
         let mut seen_msgs = 0_u64;
 
         loop {
             tokio::select! {
+                _ = &mut refresh_deadline => {
+                    tracing::info!(
+                        refresh_sec = refresh_every.as_secs(),
+                        "polymarket market ws refresh triggered; resubscribing"
+                    );
+                    break;
+                }
                 _ = ping.tick() => {
                     // The Polymarket WS docs recommend an application-level "PING".
                     ws.send(Message::Text("PING".to_string().into()))
                         .await
                         .context("send polymarket ping")?;
                 }
-                msg = ws.next() => {
-                    let Some(msg) = msg else { break };
-                    let msg = msg.context("polymarket ws read")?;
+                msg = timeout(WS_READ_TIMEOUT, ws.next()) => {
+                    let msg = match msg {
+                        Ok(m) => m,
+                        Err(_) => {
+                            tracing::warn!("polymarket ws read timeout, reconnecting");
+                            break;
+                        }
+                    };
+                    let msg = match msg {
+                        Some(Ok(m)) => m,
+                        None => break, // Stream ended
+                        Some(Err(e)) => {
+                            tracing::warn!(error = %e, "polymarket ws read error");
+                            break;
+                        }
+                    };
                     let text = match msg {
                         Message::Text(t) => t.to_string(),
                         Message::Binary(b) => String::from_utf8_lossy(&b).to_string(),
@@ -285,11 +330,20 @@ impl PolymarketFeed {
                             } else {
                                 &mut state.no
                             };
+                            // Validate price data before assignment
                             if let Some(v) = update.best_bid {
-                                target.bid = v;
+                                if validate_price(v) {
+                                    target.bid = v;
+                                } else {
+                                    tracing::warn!(price = v, "invalid bid price, skipping");
+                                }
                             }
                             if let Some(v) = update.best_ask {
-                                target.ask = v;
+                                if validate_price(v) {
+                                    target.ask = v;
+                                } else {
+                                    tracing::warn!(price = v, "invalid ask price, skipping");
+                                }
                             }
                             target.ts_exchange_ms = update.ts_exchange_ms;
                             target.recv_ts_local_ns = update.recv_ts_local_ns;
@@ -350,8 +404,9 @@ async fn run_book_update_loop(
 ) -> Result<()> {
     let token_market_map = fetch_token_market_map(gamma_endpoint, token_ids).await?;
 
-    let (mut ws, _) = connect_async(endpoint)
+    let (mut ws, _) = timeout(WS_CONNECT_TIMEOUT, connect_async(endpoint))
         .await
+        .with_context(|| format!("connect polymarket ws timeout: {endpoint}"))?
         .with_context(|| format!("connect polymarket ws: {endpoint}"))?;
 
     let sub = serde_json::json!({
@@ -373,9 +428,22 @@ async fn run_book_update_loop(
                     .await
                     .context("send polymarket book ping")?;
             }
-            msg = ws.next() => {
-                let Some(msg) = msg else { break };
-                let msg = msg.context("polymarket book ws read")?;
+            msg = timeout(WS_READ_TIMEOUT, ws.next()) => {
+                let msg = match msg {
+                    Ok(m) => m,
+                    Err(_) => {
+                        tracing::warn!("polymarket book ws read timeout, reconnecting");
+                        break;
+                    }
+                };
+                let msg = match msg {
+                    Some(Ok(m)) => m,
+                    None => break,
+                    Some(Err(e)) => {
+                        tracing::warn!(error = %e, "polymarket book ws read error");
+                        break;
+                    }
+                };
                 let text = match msg {
                     Message::Text(t) => t.to_string(),
                     Message::Binary(b) => String::from_utf8_lossy(&b).to_string(),
@@ -417,7 +485,16 @@ async fn run_book_update_loop(
                         if let Some(market_id) = token_market_map.get(&snapshot.asset_id) {
                             snapshot.market_id = market_id.clone();
                         }
-                        if tx.send(BookUpdate::Snapshot(snapshot)).await.is_err() {
+                        // Validate snapshot price levels
+                        let mut valid_snapshot = true;
+                        for level in snapshot.bids.iter().chain(snapshot.asks.iter()) {
+                            if !validate_price(level.price) {
+                                tracing::warn!(price = level.price, "invalid snapshot price level");
+                                valid_snapshot = false;
+                                break;
+                            }
+                        }
+                        if valid_snapshot && tx.send(BookUpdate::Snapshot(snapshot)).await.is_err() {
                             return Ok(());
                         }
                     }
@@ -426,6 +503,13 @@ async fn run_book_update_loop(
                         if let Some(market_id) = token_market_map.get(&delta.asset_id) {
                             delta.market_id = market_id.clone();
                         }
+                        // Validate delta prices
+                        let valid_bid = delta.best_bid.map(validate_price).unwrap_or(true);
+                        let valid_ask = delta.best_ask.map(validate_price).unwrap_or(true);
+                        if !valid_bid || !valid_ask {
+                            tracing::warn!("invalid delta prices, skipping");
+                            continue;
+                        }
                         let digest = OrderbookStateDigest {
                             market_id: delta.market_id.clone(),
                             asset_id: delta.asset_id.clone(),
@@ -693,8 +777,12 @@ fn top_level_price(value: Option<&Vec<WsLevel>>) -> Option<f64> {
     value?.first()?.price
 }
 
+/// Fast timestamp using SystemTime (more efficient than chrono::Utc::now())
 fn now_ms() -> i64 {
-    chrono::Utc::now().timestamp_millis()
+    std::time::SystemTime::now()
+        .duration_since(std::time::UNIX_EPOCH)
+        .map(|d| d.as_millis() as i64)
+        .unwrap_or(0)
 }
 
 async fn sleep_with_jitter(base: Duration) {
@@ -704,9 +792,10 @@ async fn sleep_with_jitter(base: Duration) {
 }
 
 fn now_ns() -> i64 {
-    chrono::Utc::now()
-        .timestamp_nanos_opt()
-        .unwrap_or_else(|| now_ms() * 1_000_000)
+    std::time::SystemTime::now()
+        .duration_since(std::time::UNIX_EPOCH)
+        .map(|d| d.as_nanos() as i64)
+        .unwrap_or_else(|_| now_ms() * 1_000_000)
 }
 
 #[derive(Debug, Deserialize)]
diff --git a/crates/feed_reference/src/lib.rs b/crates/feed_reference/src/lib.rs
index e4e2c08..d2e5681 100644
--- a/crates/feed_reference/src/lib.rs
+++ b/crates/feed_reference/src/lib.rs
@@ -1,5 +1,6 @@
 use std::collections::HashSet;
-use std::time::Duration;
+use std::sync::atomic::{AtomicU64, Ordering};
+use std::time::{Duration, Instant};
 
 use anyhow::{Context, Result};
 use core_types::{DynStream, RefPriceFeed, RefPriceWsFeed, RefTick};
@@ -8,10 +9,29 @@ use rand::Rng;
 use reqwest::Client;
 use serde::Deserialize;
 use tokio::sync::mpsc;
+use tokio::time::timeout;
 use tokio_stream::wrappers::ReceiverStream;
 use tokio_tungstenite::connect_async;
 use tokio_tungstenite::tungstenite::Message;
 
+/// WebSocket connection timeout
+const WS_CONNECT_TIMEOUT: Duration = Duration::from_secs(10);
+/// WebSocket read timeout - prevents hanging on stale connections
+const WS_READ_TIMEOUT: Duration = Duration::from_secs(30);
+const REF_TICK_QUEUE_DEFAULT: usize = 16_384;
+
+/// Validates that a price value is finite and positive
+fn validate_price(price: f64) -> bool {
+    price.is_finite() && price > 0.0
+}
+
+fn env_flag(key: &str, default: bool) -> bool {
+    std::env::var(key)
+        .ok()
+        .map(|v| v != "0" && !v.eq_ignore_ascii_case("false"))
+        .unwrap_or(default)
+}
+
 #[derive(Debug, Clone)]
 pub struct MultiSourceRefFeed {
     _http: Client,
@@ -37,46 +57,28 @@ impl RefPriceFeed for MultiSourceRefFeed {
 #[async_trait::async_trait]
 impl RefPriceWsFeed for MultiSourceRefFeed {
     async fn stream_ticks_ws(&self, symbols: Vec<String>) -> Result<DynStream<RefTick>> {
-        let (tx, rx) = mpsc::channel::<RefTick>(16_384);
+        let queue_cap = std::env::var("POLYEDGE_REF_TICK_QUEUE_CAP")
+            .ok()
+            .and_then(|v| v.parse::<usize>().ok())
+            .unwrap_or(REF_TICK_QUEUE_DEFAULT)
+            .clamp(1_024, 65_536);
+        let (tx, rx) = mpsc::channel::<RefTick>(queue_cap);
 
         let binance_symbols = symbols.clone();
         let tx_binance = tx.clone();
         let backoff = self.reconnect_backoff;
-        tokio::spawn(async move {
-            loop {
-                if let Err(err) = run_binance_stream(&binance_symbols, &tx_binance).await {
-                    tracing::warn!(?err, "binance ws stream failed; reconnecting");
-                }
-                sleep_with_jitter(backoff).await;
-            }
-        });
-
-        let bybit_symbols = symbols.clone();
-        let tx_bybit = tx.clone();
-        tokio::spawn(async move {
-            loop {
-                if let Err(err) = run_bybit_stream(&bybit_symbols, &tx_bybit).await {
-                    tracing::warn!(?err, "bybit ws stream failed; reconnecting");
-                }
-                sleep_with_jitter(backoff).await;
-            }
-        });
-
-        let coinbase_symbols = symbols.clone();
-        let tx_coinbase = tx.clone();
-        tokio::spawn(async move {
-            loop {
-                if let Err(err) = run_coinbase_stream(&coinbase_symbols, &tx_coinbase).await {
-                    tracing::warn!(?err, "coinbase ws stream failed; reconnecting");
+        if env_flag("POLYEDGE_ENABLE_BINANCE_WS", true) {
+            tokio::spawn(async move {
+                loop {
+                    if let Err(err) = run_binance_stream(&binance_symbols, &tx_binance).await {
+                        tracing::warn!(?err, "binance ws stream failed; reconnecting");
+                    }
+                    sleep_with_jitter(backoff).await;
                 }
-                sleep_with_jitter(backoff).await;
-            }
-        });
+            });
+        }
 
-        let enable_chainlink_anchor = std::env::var("POLYEDGE_ENABLE_CHAINLINK_ANCHOR")
-            .ok()
-            .map(|v| v != "0" && !v.eq_ignore_ascii_case("false"))
-            .unwrap_or(true);
+        let enable_chainlink_anchor = env_flag("POLYEDGE_ENABLE_CHAINLINK_ANCHOR", true);
         if enable_chainlink_anchor {
             let anchor_symbols = symbols.clone();
             let tx_anchor = tx.clone();
@@ -103,6 +105,32 @@ async fn sleep_with_jitter(base: Duration) {
     tokio::time::sleep(Duration::from_millis(base_ms.saturating_add(jitter_ms))).await;
 }
 
+enum TickDispatch {
+    Sent,
+    Dropped,
+    Closed,
+}
+
+fn dispatch_ref_tick(
+    tx: &mpsc::Sender<RefTick>,
+    tick: RefTick,
+    source: &'static str,
+) -> TickDispatch {
+    static DROP_COUNTER: AtomicU64 = AtomicU64::new(0);
+
+    match tx.try_send(tick) {
+        Ok(()) => TickDispatch::Sent,
+        Err(mpsc::error::TrySendError::Full(_)) => {
+            let dropped = DROP_COUNTER.fetch_add(1, Ordering::Relaxed) + 1;
+            if dropped.is_multiple_of(1024) {
+                tracing::warn!(source, dropped, "ref tick queue full, dropping stale ticks");
+            }
+            TickDispatch::Dropped
+        }
+        Err(mpsc::error::TrySendError::Closed(_)) => TickDispatch::Closed,
+    }
+}
+
 async fn run_binance_stream(symbols: &[String], tx: &mpsc::Sender<RefTick>) -> Result<()> {
     if symbols.is_empty() {
         anyhow::bail!("binance symbols list is empty");
@@ -114,16 +142,17 @@ async fn run_binance_stream(symbols: &[String], tx: &mpsc::Sender<RefTick>) -> R
         .collect::<Vec<_>>()
         .join("/");
     let endpoint_candidates = binance_ws_endpoints(&streams);
+    let endpoint_candidates = pick_best_ws_endpoint(endpoint_candidates).await;
     let mut last_err: Option<anyhow::Error> = None;
     let mut ws = None;
 
     for endpoint in endpoint_candidates {
-        match connect_async(&endpoint).await {
-            Ok((socket, _)) => {
+        match timeout(WS_CONNECT_TIMEOUT, connect_async(&endpoint)).await {
+            Ok(Ok((socket, _))) => {
                 ws = Some(socket);
                 break;
             }
-            Err(err) => {
+            Ok(Err(err)) => {
                 tracing::warn!(
                     ?err,
                     endpoint,
@@ -131,6 +160,10 @@ async fn run_binance_stream(symbols: &[String], tx: &mpsc::Sender<RefTick>) -> R
                 );
                 last_err = Some(anyhow::Error::new(err));
             }
+            Err(_) => {
+                tracing::warn!(endpoint = %endpoint, "connect binance ws timeout; trying next endpoint");
+                last_err = Some(anyhow::anyhow!("connection timeout"));
+            }
         }
     }
     let mut ws = ws.ok_or_else(|| {
@@ -138,46 +171,142 @@ async fn run_binance_stream(symbols: &[String], tx: &mpsc::Sender<RefTick>) -> R
             .unwrap_or_else(|| anyhow::anyhow!("connect binance ws failed: no endpoint available"))
     })?;
 
-    while let Some(msg) = ws.next().await {
-        let msg = msg.context("binance ws read")?;
-        let text = match msg {
-            Message::Text(t) => t.to_string(),
-            Message::Binary(b) => String::from_utf8_lossy(&b).to_string(),
-            Message::Ping(v) => {
-                let _ = ws.send(Message::Pong(v)).await;
-                continue;
+    loop {
+        match timeout(WS_READ_TIMEOUT, ws.next()).await {
+            Ok(Some(Ok(msg))) => {
+                // Capture local receive timestamp as close as possible to socket delivery.
+                let recv_ns = now_ns();
+                let recv_ms = recv_ns / 1_000_000;
+                let text = match msg {
+                    Message::Text(t) => t.to_string(),
+                    Message::Binary(b) => String::from_utf8_lossy(&b).to_string(),
+                    Message::Ping(v) => {
+                        let _ = ws.send(Message::Pong(v)).await;
+                        continue;
+                    }
+                    Message::Pong(_) => continue,
+                    Message::Close(_) => break,
+                    Message::Frame(_) => continue,
+                };
+
+                let Ok(payload) = serde_json::from_str::<BinanceWsMessage>(&text) else {
+                    continue;
+                };
+                let trade = payload.into_trade();
+                let symbol = trade.symbol;
+                let price = trade.price;
+
+                // Validate price before creating tick
+                if !validate_price(price) {
+                    tracing::warn!(price = price, "invalid binance price, skipping");
+                    continue;
+                }
+
+                let event_ts = trade.event_ts.unwrap_or_else(now_ms);
+                let ingest_ns = now_ns();
+
+                let tick = RefTick {
+                    source: "binance_ws".into(),
+                    symbol,
+                    event_ts_ms: event_ts,
+                    recv_ts_ms: recv_ms,
+                    source_seq: event_ts.max(0) as u64,
+                    event_ts_exchange_ms: event_ts,
+                    recv_ts_local_ns: recv_ns,
+                    ingest_ts_local_ns: ingest_ns,
+                    ts_first_hop_ms: None,
+                    price,
+                };
+
+                match dispatch_ref_tick(tx, tick, "binance_ws") {
+                    TickDispatch::Sent | TickDispatch::Dropped => {}
+                    TickDispatch::Closed => break,
+                }
+            }
+            Ok(None) => break, // Stream ended
+            Ok(Some(Err(e))) => {
+                tracing::warn!(error = %e, "binance ws read error");
+                break;
+            }
+            Err(_) => {
+                tracing::warn!("binance ws read timeout, reconnecting");
+                break;
             }
-            Message::Pong(_) => continue,
-            Message::Close(_) => break,
-            Message::Frame(_) => continue,
-        };
-
-        let Ok(payload) = serde_json::from_str::<BinanceWsMessage>(&text) else {
-            continue;
-        };
-        let trade = payload.into_trade();
-        let symbol = trade.symbol;
-        let price = trade.price;
-        let event_ts = trade.event_ts.unwrap_or_else(now_ms);
-
-        let tick = RefTick {
-            source: "binance_ws".to_string(),
-            symbol,
-            event_ts_ms: event_ts,
-            recv_ts_ms: now_ms(),
-            event_ts_exchange_ms: event_ts,
-            recv_ts_local_ns: now_ns(),
-            price,
-        };
-
-        if tx.send(tick).await.is_err() {
-            break;
         }
     }
 
     Ok(())
 }
 
+async fn pick_best_ws_endpoint(endpoints: Vec<String>) -> Vec<String> {
+    if endpoints.len() <= 1 {
+        return endpoints;
+    }
+
+    // Probe all candidates concurrently at startup and prefer the fastest handshake.
+    // This matters because some Binance hosts/ports resolve to different regions and DNS can
+    // change over time; we want a deterministic "fastest-first" order.
+    let timeout = Duration::from_secs(
+        std::env::var("POLYEDGE_WS_PROBE_TIMEOUT_SEC")
+            .ok()
+            .and_then(|v| v.parse::<u64>().ok())
+            .unwrap_or(3)
+            .max(1),
+    );
+
+    let mut join_set = tokio::task::JoinSet::new();
+    for ep in endpoints.iter().cloned() {
+        join_set.spawn(async move {
+            let started = Instant::now();
+            let ok = tokio::time::timeout(timeout, connect_async(&ep)).await;
+            match ok {
+                Ok(Ok((ws, _resp))) => {
+                    drop(ws);
+                    Some((ep, started.elapsed().as_secs_f64() * 1_000.0))
+                }
+                _ => None,
+            }
+        });
+    }
+
+    let mut results: Vec<(String, f64)> = Vec::new();
+    while let Some(res) = join_set.join_next().await {
+        if let Ok(Some(v)) = res {
+            results.push(v);
+        }
+    }
+
+    if results.is_empty() {
+        return endpoints;
+    }
+
+    results.sort_by(|a, b| a.1.total_cmp(&b.1));
+    for (ep, ms) in results.iter().take(8) {
+        tracing::info!(
+            endpoint = ep.as_str(),
+            handshake_ms = *ms,
+            "ws endpoint probe result"
+        );
+    }
+    let best = results[0].0.clone();
+    tracing::info!(
+        endpoint = best.as_str(),
+        handshake_ms = results[0].1,
+        candidates = endpoints.len(),
+        "selected best ws endpoint by handshake latency"
+    );
+
+    // Return endpoints reordered: best first, then the rest in original order.
+    let mut out = Vec::with_capacity(endpoints.len());
+    out.push(best.clone());
+    for ep in endpoints {
+        if ep != best {
+            out.push(ep);
+        }
+    }
+    out
+}
+
 fn binance_ws_endpoints(streams: &str) -> Vec<String> {
     if let Ok(raw) = std::env::var("POLYEDGE_BINANCE_WS_BASES") {
         let endpoints = raw
@@ -201,177 +330,13 @@ fn binance_ws_endpoints(streams: &str) -> Vec<String> {
     }
 
     vec![
-        format!("wss://stream.binance.com/stream?streams={streams}"),
         format!("wss://stream.binance.com:9443/stream?streams={streams}"),
         format!("wss://data-stream.binance.vision/stream?streams={streams}"),
+        // Keep the default host as a fallback, but do not prefer it.
+        format!("wss://stream.binance.com/stream?streams={streams}"),
     ]
 }
 
-async fn run_bybit_stream(symbols: &[String], tx: &mpsc::Sender<RefTick>) -> Result<()> {
-    if symbols.is_empty() {
-        anyhow::bail!("bybit symbols list is empty");
-    }
-
-    let endpoint = "wss://stream.bybit.com/v5/public/spot";
-    let (mut ws, _) = connect_async(endpoint).await.context("connect bybit ws")?;
-
-    let args = symbols
-        .iter()
-        .map(|s| format!("tickers.{s}"))
-        .collect::<Vec<_>>();
-    let sub = serde_json::json!({
-        "op": "subscribe",
-        "args": args,
-    });
-    ws.send(Message::Text(sub.to_string().into()))
-        .await
-        .context("send bybit subscribe")?;
-
-    while let Some(msg) = ws.next().await {
-        let msg = msg.context("bybit ws read")?;
-        let text = match msg {
-            Message::Text(t) => t.to_string(),
-            Message::Binary(b) => String::from_utf8_lossy(&b).to_string(),
-            Message::Ping(v) => {
-                let _ = ws.send(Message::Pong(v)).await;
-                continue;
-            }
-            Message::Pong(_) => continue,
-            Message::Close(_) => break,
-            Message::Frame(_) => continue,
-        };
-
-        let Ok(payload) = serde_json::from_str::<BybitWsMessage>(&text) else {
-            continue;
-        };
-        if payload.success.is_some() {
-            continue;
-        }
-        let topic = payload.topic.as_deref().unwrap_or_default();
-        if !topic.starts_with("tickers.") {
-            continue;
-        }
-
-        let symbol = payload
-            .data
-            .as_ref()
-            .and_then(|d| d.symbol.clone())
-            .or_else(|| topic.split('.').nth(1).map(ToOwned::to_owned));
-        let price = payload
-            .data
-            .as_ref()
-            .and_then(|d| d.last_price.as_deref())
-            .or_else(|| payload.data.as_ref().and_then(|d| d.mark_price.as_deref()))
-            .and_then(parse_f64_str);
-        let event_ts = payload
-            .ts
-            .or_else(|| payload.data.as_ref().and_then(|d| d.ts))
-            .unwrap_or_else(now_ms);
-
-        let (Some(symbol), Some(price)) = (symbol, price) else {
-            continue;
-        };
-
-        let tick = RefTick {
-            source: "bybit_ws".to_string(),
-            symbol,
-            event_ts_ms: event_ts,
-            recv_ts_ms: now_ms(),
-            event_ts_exchange_ms: event_ts,
-            recv_ts_local_ns: now_ns(),
-            price,
-        };
-
-        if tx.send(tick).await.is_err() {
-            break;
-        }
-    }
-
-    Ok(())
-}
-
-async fn run_coinbase_stream(symbols: &[String], tx: &mpsc::Sender<RefTick>) -> Result<()> {
-    if symbols.is_empty() {
-        anyhow::bail!("coinbase symbols list is empty");
-    }
-
-    let products = symbols
-        .iter()
-        .filter_map(|s| to_coinbase_pair(s))
-        .collect::<Vec<_>>();
-    if products.is_empty() {
-        anyhow::bail!("coinbase has no supported symbols");
-    }
-
-    let endpoint = "wss://ws-feed.exchange.coinbase.com";
-    let (mut ws, _) = connect_async(endpoint)
-        .await
-        .context("connect coinbase ws")?;
-
-    let sub = serde_json::json!({
-        "type": "subscribe",
-        "product_ids": products,
-        "channels": ["ticker"],
-    });
-    ws.send(Message::Text(sub.to_string().into()))
-        .await
-        .context("send coinbase subscribe")?;
-
-    while let Some(msg) = ws.next().await {
-        let msg = msg.context("coinbase ws read")?;
-        let text = match msg {
-            Message::Text(t) => t.to_string(),
-            Message::Binary(b) => String::from_utf8_lossy(&b).to_string(),
-            Message::Ping(v) => {
-                let _ = ws.send(Message::Pong(v)).await;
-                continue;
-            }
-            Message::Pong(_) => continue,
-            Message::Close(_) => break,
-            Message::Frame(_) => continue,
-        };
-
-        let Ok(payload) = serde_json::from_str::<CoinbaseWsMessage>(&text) else {
-            continue;
-        };
-        let msg_type = payload.kind.as_deref().unwrap_or_default();
-        if msg_type != "ticker" {
-            continue;
-        }
-        let product_id = payload.product_id.as_deref().unwrap_or_default();
-        let Some(symbol) = from_coinbase_pair(product_id) else {
-            continue;
-        };
-
-        let price = payload.price.as_deref().and_then(parse_f64_str);
-        let event_ts = payload
-            .time
-            .as_deref()
-            .and_then(parse_rfc3339_ms)
-            .unwrap_or_else(now_ms);
-
-        let Some(price) = price else {
-            continue;
-        };
-
-        let tick = RefTick {
-            source: "coinbase_ws".to_string(),
-            symbol,
-            event_ts_ms: event_ts,
-            recv_ts_ms: now_ms(),
-            event_ts_exchange_ms: event_ts,
-            recv_ts_local_ns: now_ns(),
-            price,
-        };
-
-        if tx.send(tick).await.is_err() {
-            break;
-        }
-    }
-
-    Ok(())
-}
-
 #[derive(Debug, Deserialize)]
 struct RtdsEnvelope {
     #[serde(default)]
@@ -436,13 +401,15 @@ async fn run_chainlink_rtds_stream(symbols: &[String], tx: &mpsc::Sender<RefTick
                 // RTDS docs recommend sending a ping periodically.
                 let _ = ws.send(Message::Ping(Vec::new().into())).await;
             }
-            msg = ws.next() => {
-                let Some(msg) = msg else { break; };
-                let msg = msg.context("chainlink rtds read")?;
-                let text = match msg {
-                    Message::Text(t) => t.to_string(),
-                    Message::Binary(b) => String::from_utf8_lossy(&b).to_string(),
-                    Message::Ping(v) => {
+             msg = ws.next() => {
+                 let Some(msg) = msg else { break; };
+                 let msg = msg.context("chainlink rtds read")?;
+                 let recv_ns = now_ns();
+                 let recv_ms = recv_ns / 1_000_000;
+                 let text = match msg {
+                     Message::Text(t) => t.to_string(),
+                     Message::Binary(b) => String::from_utf8_lossy(&b).to_string(),
+                     Message::Ping(v) => {
                         let _ = ws.send(Message::Pong(v)).await;
                         continue;
                     }
@@ -475,19 +442,24 @@ async fn run_chainlink_rtds_stream(symbols: &[String], tx: &mpsc::Sender<RefTick
                     continue;
                 };
                 let event_ts = payload.timestamp.or(env.timestamp).unwrap_or_else(now_ms);
+                let ingest_ns = now_ns();
 
                 let tick = RefTick {
-                    source: "chainlink_rtds".to_string(),
+                    source: "chainlink_rtds".into(),
                     symbol,
                     event_ts_ms: event_ts,
-                    recv_ts_ms: now_ms(),
+                    recv_ts_ms: recv_ms,
+                    source_seq: event_ts.max(0) as u64,
                     event_ts_exchange_ms: event_ts,
-                    recv_ts_local_ns: now_ns(),
+                    recv_ts_local_ns: recv_ns,
+                    ingest_ts_local_ns: ingest_ns,
+                    ts_first_hop_ms: None,
                     price,
                 };
 
-                if tx.send(tick).await.is_err() {
-                    break;
+                match dispatch_ref_tick(tx, tick, "chainlink_rtds") {
+                    TickDispatch::Sent | TickDispatch::Dropped => {}
+                    TickDispatch::Closed => break,
                 }
             }
         }
@@ -496,16 +468,6 @@ async fn run_chainlink_rtds_stream(symbols: &[String], tx: &mpsc::Sender<RefTick
     Ok(())
 }
 
-fn parse_rfc3339_ms(value: &str) -> Option<i64> {
-    chrono::DateTime::parse_from_rfc3339(value)
-        .ok()
-        .map(|dt| dt.timestamp_millis())
-}
-
-fn parse_f64_str(value: &str) -> Option<f64> {
-    value.parse::<f64>().ok()
-}
-
 #[derive(Debug, Deserialize)]
 #[serde(untagged)]
 enum BinanceWsMessage {
@@ -532,42 +494,6 @@ struct BinanceTrade {
     event_ts: Option<i64>,
 }
 
-#[derive(Debug, Deserialize)]
-struct BybitWsMessage {
-    #[serde(default)]
-    success: Option<bool>,
-    #[serde(default)]
-    topic: Option<String>,
-    #[serde(default)]
-    ts: Option<i64>,
-    #[serde(default)]
-    data: Option<BybitTickData>,
-}
-
-#[derive(Debug, Deserialize)]
-struct BybitTickData {
-    #[serde(default)]
-    symbol: Option<String>,
-    #[serde(rename = "lastPrice", default)]
-    last_price: Option<String>,
-    #[serde(rename = "markPrice", default)]
-    mark_price: Option<String>,
-    #[serde(default)]
-    ts: Option<i64>,
-}
-
-#[derive(Debug, Deserialize)]
-struct CoinbaseWsMessage {
-    #[serde(rename = "type", default)]
-    kind: Option<String>,
-    #[serde(default)]
-    product_id: Option<String>,
-    #[serde(default)]
-    price: Option<String>,
-    #[serde(default)]
-    time: Option<String>,
-}
-
 fn de_f64_from_str<'de, D>(deserializer: D) -> Result<f64, D::Error>
 where
     D: serde::Deserializer<'de>,
@@ -586,43 +512,25 @@ where
     }
 }
 
-fn to_coinbase_pair(symbol: &str) -> Option<String> {
-    let base = symbol.strip_suffix("USDT")?;
-    Some(format!("{base}-USD"))
-}
-
-fn from_coinbase_pair(product_id: &str) -> Option<String> {
-    let base = product_id.strip_suffix("-USD")?;
-    Some(format!("{base}USDT"))
-}
-
+/// Fast timestamp using SystemTime (more efficient than chrono::Utc::now())
 fn now_ms() -> i64 {
-    chrono::Utc::now().timestamp_millis()
+    std::time::SystemTime::now()
+        .duration_since(std::time::UNIX_EPOCH)
+        .map(|d| d.as_millis() as i64)
+        .unwrap_or(0)
 }
 
 fn now_ns() -> i64 {
-    chrono::Utc::now()
-        .timestamp_nanos_opt()
-        .unwrap_or_else(|| now_ms() * 1_000_000)
+    std::time::SystemTime::now()
+        .duration_since(std::time::UNIX_EPOCH)
+        .map(|d| d.as_nanos() as i64)
+        .unwrap_or_else(|_| now_ms() * 1_000_000)
 }
 
 #[cfg(test)]
 mod tests {
     use super::*;
 
-    #[test]
-    fn coinbase_pair_conversion() {
-        assert_eq!(to_coinbase_pair("BTCUSDT").as_deref(), Some("BTC-USD"));
-        assert_eq!(to_coinbase_pair("FOO"), None);
-        assert_eq!(from_coinbase_pair("ETH-USD").as_deref(), Some("ETHUSDT"));
-    }
-
-    #[test]
-    fn parse_time_works() {
-        let ts = parse_rfc3339_ms("2026-02-13T12:34:56.789Z").expect("parse");
-        assert!(ts > 0);
-    }
-
     #[test]
     fn chainlink_symbol_conversion() {
         assert_eq!(
diff --git a/crates/feed_udp/Cargo.toml b/crates/feed_udp/Cargo.toml
new file mode 100644
index 0000000..ff008ac
--- /dev/null
+++ b/crates/feed_udp/Cargo.toml
@@ -0,0 +1,13 @@
+[package]
+name = "feed_udp"
+version = "0.1.0"
+edition = "2021"
+
+[dependencies]
+tokio = { workspace = true, features = ["full"] }
+tokio-stream = { workspace = true }
+anyhow = { workspace = true }
+async-trait = { workspace = true }
+poly_wire = { path = "../poly_wire" }
+core_types = { path = "../core_types" }
+libc = "0.2"
diff --git a/crates/feed_udp/src/lib.rs b/crates/feed_udp/src/lib.rs
new file mode 100644
index 0000000..acd77bb
--- /dev/null
+++ b/crates/feed_udp/src/lib.rs
@@ -0,0 +1,525 @@
+use anyhow::{Context, Result};
+use async_trait::async_trait;
+use core_types::{DynStream, RefPriceFeed, RefTick};
+use poly_wire::{
+    decode_auto, WirePacket, WIRE_BOOK_TOP24_SIZE, WIRE_MAX_PACKET_SIZE, WIRE_MOMENTUM_TICK32_SIZE,
+};
+use std::collections::{HashMap, HashSet};
+use std::net::{IpAddr, SocketAddr, UdpSocket as StdUdpSocket};
+#[cfg(target_os = "linux")]
+use std::os::fd::AsRawFd;
+use std::sync::atomic::{AtomicU64, Ordering};
+use std::time::{Duration, Instant};
+use tokio::sync::mpsc;
+use tokio_stream::wrappers::ReceiverStream;
+
+pub struct UdpBinanceFeed {
+    port: u16,
+}
+
+static UDP_LOCAL_DROP_COUNT: AtomicU64 = AtomicU64::new(0);
+
+pub fn udp_local_drop_count() -> u64 {
+    UDP_LOCAL_DROP_COUNT.load(Ordering::Relaxed)
+}
+
+#[derive(Debug, Clone)]
+struct UdpLocalPolicy {
+    local_only: bool,
+    allow_private: bool,
+    allowlist: HashSet<IpAddr>,
+}
+
+impl UdpLocalPolicy {
+    fn from_env() -> Self {
+        let local_only = std::env::var("POLYEDGE_UDP_LOCAL_ONLY")
+            .ok()
+            .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+            .unwrap_or(true);
+        let allow_private = std::env::var("POLYEDGE_UDP_LOCAL_ALLOW_PRIVATE")
+            .ok()
+            .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+            .unwrap_or(false);
+        let allowlist =
+            parse_ip_allowlist(&std::env::var("POLYEDGE_UDP_LOCAL_ALLOW").unwrap_or_default());
+        Self {
+            local_only,
+            allow_private,
+            allowlist,
+        }
+    }
+
+    fn allows(&self, addr: &SocketAddr) -> bool {
+        if !self.local_only {
+            return true;
+        }
+        let ip = addr.ip();
+        if ip.is_loopback() {
+            return true;
+        }
+        if self.allow_private && is_private_ip(&ip) {
+            return true;
+        }
+        self.allowlist.contains(&ip)
+    }
+}
+
+#[derive(Debug, Clone, Copy)]
+#[cfg_attr(not(target_os = "linux"), allow(dead_code))]
+struct UdpRecvTuning {
+    rcvbuf_bytes: Option<usize>,
+    busy_poll_us: Option<u32>,
+    user_spin: bool,
+    drop_on_full: bool,
+}
+
+impl UdpRecvTuning {
+    fn from_env() -> Self {
+        let rcvbuf_bytes = std::env::var("POLYEDGE_UDP_RCVBUF_BYTES")
+            .ok()
+            .and_then(|v| v.parse::<usize>().ok())
+            .filter(|v| *v > 0);
+        let busy_poll_us = std::env::var("POLYEDGE_UDP_BUSY_POLL_US")
+            .ok()
+            .and_then(|v| v.parse::<u32>().ok())
+            .filter(|v| *v > 0);
+        let user_spin = std::env::var("POLYEDGE_UDP_USER_SPIN")
+            .ok()
+            .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+            .unwrap_or(false);
+        let drop_on_full = std::env::var("POLYEDGE_UDP_DROP_ON_FULL")
+            .ok()
+            .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+            .unwrap_or(true);
+        Self {
+            rcvbuf_bytes,
+            busy_poll_us,
+            user_spin,
+            drop_on_full,
+        }
+    }
+}
+
+impl UdpBinanceFeed {
+    pub fn new(port: u16) -> Self {
+        Self { port }
+    }
+}
+
+#[async_trait]
+impl RefPriceFeed for UdpBinanceFeed {
+    async fn stream_ticks(&self, symbols: Vec<String>) -> Result<DynStream<RefTick>> {
+        let rx_queue_cap = std::env::var("POLYEDGE_UDP_RX_QUEUE_CAP")
+            .ok()
+            .and_then(|v| v.parse::<usize>().ok())
+            .unwrap_or(4_096)
+            .clamp(512, 65_536);
+        let (tx, rx) = mpsc::channel::<Result<RefTick>>(rx_queue_cap);
+        let normalized_symbols = normalize_symbols(&symbols);
+        let bindings = udp_bindings(self.port, &normalized_symbols);
+        let tuning = UdpRecvTuning::from_env();
+        let core_map =
+            parse_port_core_map(&std::env::var("POLYEDGE_UDP_PIN_CORES").unwrap_or_default());
+
+        if bindings.is_empty() {
+            let symbol = normalized_symbols
+                .first()
+                .cloned()
+                .unwrap_or_else(|| "BTCUSDT".to_string());
+            let addr: SocketAddr = format!("0.0.0.0:{}", self.port)
+                .parse()
+                .context("parse udp bind addr")?;
+            let socket = StdUdpSocket::bind(addr).context("bind udp feed socket")?;
+            let core_id = core_map.get(&self.port).copied();
+            spawn_recv_loop(socket, symbol, tx.clone(), tuning, core_id)?;
+        } else {
+            for (symbol, port) in bindings {
+                let addr: SocketAddr = format!("0.0.0.0:{port}")
+                    .parse()
+                    .context("parse udp bind addr")?;
+                let socket = StdUdpSocket::bind(addr).with_context(|| {
+                    format!("bind udp feed socket for symbol={symbol} port={port}")
+                })?;
+                let core_id = core_map.get(&port).copied();
+                spawn_recv_loop(socket, symbol, tx.clone(), tuning, core_id)?;
+            }
+        }
+        drop(tx);
+
+        Ok(Box::pin(ReceiverStream::new(rx)))
+    }
+}
+
+fn spawn_recv_loop(
+    socket: StdUdpSocket,
+    symbol: String,
+    tx: mpsc::Sender<Result<RefTick>>,
+    tuning: UdpRecvTuning,
+    core_id: Option<usize>,
+) -> Result<()> {
+    socket
+        .set_nonblocking(tuning.user_spin)
+        .context("configure udp nonblocking")?;
+    apply_udp_recv_socket_tuning(&socket, tuning)?;
+
+    std::thread::Builder::new()
+        .name(format!("udp-recv-{symbol}"))
+        .spawn(move || {
+            if let Some(core) = core_id {
+                if let Err(err) = pin_current_thread(core) {
+                    let _ = tx.blocking_send(Err(err));
+                }
+            }
+
+            let mut buf = [0u8; WIRE_MAX_PACKET_SIZE];
+            let mut local_policy = UdpLocalPolicy::from_env();
+            let mut local_policy_refresh_at = Instant::now();
+            loop {
+                let recv = socket.recv_from(&mut buf);
+                let (amt, src) = match recv {
+                    Ok(v) => v,
+                    Err(err)
+                        if tuning.user_spin && err.kind() == std::io::ErrorKind::WouldBlock =>
+                    {
+                        std::hint::spin_loop();
+                        continue;
+                    }
+                    Err(err) => {
+                        let send_err = if tuning.drop_on_full {
+                            match tx.try_send(Err(err.into())) {
+                                Ok(_) | Err(mpsc::error::TrySendError::Full(_)) => false,
+                                Err(mpsc::error::TrySendError::Closed(_)) => true,
+                            }
+                        } else {
+                            tx.blocking_send(Err(err.into())).is_err()
+                        };
+                        if send_err {
+                            break;
+                        }
+                        continue;
+                    }
+                };
+                if local_policy_refresh_at.elapsed() >= Duration::from_secs(1) {
+                    local_policy = UdpLocalPolicy::from_env();
+                    local_policy_refresh_at = Instant::now();
+                }
+                if !local_policy.allows(&src) {
+                    UDP_LOCAL_DROP_COUNT.fetch_add(1, Ordering::Relaxed);
+                    continue;
+                }
+                if amt != WIRE_BOOK_TOP24_SIZE
+                    && amt != WIRE_MOMENTUM_TICK32_SIZE
+                    && amt != poly_wire::WIRE_RELAY_TICK40_SIZE
+                {
+                    continue;
+                }
+
+                let recv_ns = now_ns();
+                let (ts_micros, bid, ask, ts_first_hop_ms) = match decode_auto(&buf[..amt]) {
+                    Ok(WirePacket::BookTop24(pkt)) => (pkt.ts_micros, pkt.bid, pkt.ask, None),
+                    Ok(WirePacket::MomentumTick32(pkt)) => (pkt.ts_micros, pkt.bid, pkt.ask, None),
+                    Ok(WirePacket::RelayTick40(pkt)) => {
+                        (pkt.ts_micros, pkt.bid, pkt.ask, Some(pkt.ts_first_hop_ms))
+                    }
+                    Err(err) => {
+                        let send_err = if tuning.drop_on_full {
+                            match tx.try_send(Err(err.into())) {
+                                Ok(_) | Err(mpsc::error::TrySendError::Full(_)) => false,
+                                Err(mpsc::error::TrySendError::Closed(_)) => true,
+                            }
+                        } else {
+                            tx.blocking_send(Err(err.into())).is_err()
+                        };
+                        if send_err {
+                            break;
+                        }
+                        continue;
+                    }
+                };
+
+                let event_ms = (ts_micros / 1_000) as i64;
+                let mid = (bid + ask) * 0.5;
+                if !mid.is_finite() || mid <= 0.0 {
+                    continue;
+                }
+
+                let tick = RefTick {
+                    source: "binance_udp".into(),
+                    symbol: symbol.clone(),
+                    event_ts_ms: event_ms,
+                    recv_ts_ms: recv_ns / 1_000_000,
+                    source_seq: stable_udp_seq(ts_micros, bid, ask),
+                    event_ts_exchange_ms: event_ms,
+                    recv_ts_local_ns: recv_ns,
+                    ingest_ts_local_ns: recv_ns,
+                    ts_first_hop_ms,
+                    price: mid,
+                };
+
+                let send_err = if tuning.drop_on_full {
+                    match tx.try_send(Ok(tick)) {
+                        Ok(_) | Err(mpsc::error::TrySendError::Full(_)) => false,
+                        Err(mpsc::error::TrySendError::Closed(_)) => true,
+                    }
+                } else {
+                    tx.blocking_send(Ok(tick)).is_err()
+                };
+                if send_err {
+                    break;
+                }
+            }
+        })
+        .context("spawn udp receiver thread")?;
+
+    Ok(())
+}
+
+#[cfg(target_os = "linux")]
+fn apply_udp_recv_socket_tuning(socket: &StdUdpSocket, tuning: UdpRecvTuning) -> Result<()> {
+    if let Some(bytes) = tuning.rcvbuf_bytes {
+        let value: libc::c_int = bytes.try_into().unwrap_or(libc::c_int::MAX);
+        let rc = unsafe {
+            libc::setsockopt(
+                socket.as_raw_fd(),
+                libc::SOL_SOCKET,
+                libc::SO_RCVBUF,
+                (&value as *const libc::c_int).cast(),
+                std::mem::size_of::<libc::c_int>() as libc::socklen_t,
+            )
+        };
+        if rc != 0 {
+            let err = std::io::Error::last_os_error();
+            anyhow::bail!("set SO_RCVBUF={} failed: {}", bytes, err);
+        }
+    }
+    if let Some(us) = tuning.busy_poll_us {
+        let value: libc::c_int = us.try_into().unwrap_or(libc::c_int::MAX);
+        let rc = unsafe {
+            libc::setsockopt(
+                socket.as_raw_fd(),
+                libc::SOL_SOCKET,
+                libc::SO_BUSY_POLL,
+                (&value as *const libc::c_int).cast(),
+                std::mem::size_of::<libc::c_int>() as libc::socklen_t,
+            )
+        };
+        if rc != 0 {
+            let err = std::io::Error::last_os_error();
+            anyhow::bail!("set SO_BUSY_POLL={} failed: {}", us, err);
+        }
+    }
+    Ok(())
+}
+
+#[cfg(not(target_os = "linux"))]
+fn apply_udp_recv_socket_tuning(_socket: &StdUdpSocket, _tuning: UdpRecvTuning) -> Result<()> {
+    Ok(())
+}
+
+#[cfg(target_os = "linux")]
+fn pin_current_thread(core_id: usize) -> Result<()> {
+    let mut cpuset: libc::cpu_set_t = unsafe { std::mem::zeroed() };
+    unsafe {
+        libc::CPU_ZERO(&mut cpuset);
+        libc::CPU_SET(core_id, &mut cpuset);
+        let rc = libc::pthread_setaffinity_np(
+            libc::pthread_self(),
+            std::mem::size_of::<libc::cpu_set_t>(),
+            &cpuset,
+        );
+        if rc != 0 {
+            let err = std::io::Error::from_raw_os_error(rc);
+            anyhow::bail!("pthread_setaffinity_np(core={core_id}) failed: {err}");
+        }
+    }
+    Ok(())
+}
+
+#[cfg(not(target_os = "linux"))]
+fn pin_current_thread(_core_id: usize) -> Result<()> {
+    Ok(())
+}
+
+fn normalize_symbols(symbols: &[String]) -> Vec<String> {
+    let mut out: Vec<String> = symbols
+        .iter()
+        .map(|s| s.trim().to_ascii_uppercase())
+        .filter(|s| !s.is_empty())
+        .collect();
+    if out.is_empty() {
+        out.push("BTCUSDT".to_string());
+    }
+    out
+}
+
+fn udp_bindings(default_port: u16, symbols: &[String]) -> Vec<(String, u16)> {
+    let raw = std::env::var("POLYEDGE_UDP_SYMBOL_PORTS").unwrap_or_default();
+    udp_bindings_from_raw(default_port, symbols, &raw)
+}
+
+fn udp_bindings_from_raw(default_port: u16, symbols: &[String], raw: &str) -> Vec<(String, u16)> {
+    let map = parse_symbol_port_map(raw);
+    if map.is_empty() {
+        if symbols.len() <= 1 {
+            return vec![];
+        }
+        return symbols
+            .iter()
+            .enumerate()
+            .filter_map(|(idx, symbol)| {
+                let delta = u16::try_from(idx).ok()?;
+                let port = default_port.checked_add(delta)?;
+                Some((symbol.clone(), port))
+            })
+            .collect();
+    }
+    let mut out = Vec::<(String, u16)>::new();
+    for symbol in symbols {
+        if let Some(port) = map.get(symbol).copied() {
+            out.push((symbol.clone(), port));
+        }
+    }
+    if out.is_empty() && symbols.len() == 1 {
+        out.push((symbols[0].clone(), default_port));
+    }
+    out
+}
+
+fn parse_symbol_port_map(raw: &str) -> HashMap<String, u16> {
+    let mut out = HashMap::<String, u16>::new();
+    for item in raw.split(',') {
+        let token = item.trim();
+        if token.is_empty() {
+            continue;
+        }
+        let mut parts = token.split(':');
+        let symbol = parts.next().unwrap_or_default().trim().to_ascii_uppercase();
+        let port = parts.next().unwrap_or_default().trim();
+        if symbol.is_empty() || port.is_empty() || parts.next().is_some() {
+            continue;
+        }
+        if let Ok(parsed_port) = port.parse::<u16>() {
+            out.insert(symbol, parsed_port);
+        }
+    }
+    out
+}
+
+fn parse_port_core_map(raw: &str) -> HashMap<u16, usize> {
+    let mut out = HashMap::<u16, usize>::new();
+    for item in raw.split(',') {
+        let token = item.trim();
+        if token.is_empty() {
+            continue;
+        }
+        let mut pair = token.split(':');
+        let port = pair.next().unwrap_or_default().trim();
+        let core = pair.next().unwrap_or_default().trim();
+        if port.is_empty() || core.is_empty() || pair.next().is_some() {
+            continue;
+        }
+        if let (Ok(port_id), Ok(core_id)) = (port.parse::<u16>(), core.parse::<usize>()) {
+            out.insert(port_id, core_id);
+        }
+    }
+    out
+}
+
+fn parse_ip_allowlist(raw: &str) -> HashSet<IpAddr> {
+    let mut out = HashSet::new();
+    for token in raw.split(',') {
+        let candidate = token.trim();
+        if candidate.is_empty() {
+            continue;
+        }
+        if let Ok(ip) = candidate.parse::<IpAddr>() {
+            out.insert(ip);
+        }
+    }
+    out
+}
+
+fn is_private_ip(ip: &IpAddr) -> bool {
+    match ip {
+        IpAddr::V4(v4) => v4.is_private() || v4.is_link_local(),
+        IpAddr::V6(v6) => v6.is_unique_local() || v6.is_unicast_link_local(),
+    }
+}
+
+#[inline]
+fn now_ns() -> i64 {
+    std::time::SystemTime::now()
+        .duration_since(std::time::UNIX_EPOCH)
+        .unwrap_or_default()
+        .as_nanos() as i64
+}
+
+#[inline]
+fn stable_udp_seq(ts_micros: u64, bid: f64, ask: f64) -> u64 {
+    let mut h = ts_micros
+        ^ bid.to_bits().rotate_left(13)
+        ^ ask.to_bits().rotate_right(7)
+        ^ 0x9E37_79B9_7F4A_7C15;
+    if h == 0 {
+        h = 1;
+    }
+    h
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn stable_udp_seq_is_non_zero() {
+        assert_ne!(stable_udp_seq(0, 1.0, 1.0), 0);
+    }
+
+    #[test]
+    fn parse_symbol_port_map_accepts_valid_pairs() {
+        let map = parse_symbol_port_map("BTCUSDT:6666,ETHUSDT:6667");
+        assert_eq!(map.get("BTCUSDT"), Some(&6666));
+        assert_eq!(map.get("ETHUSDT"), Some(&6667));
+    }
+
+    #[test]
+    fn parse_symbol_port_map_ignores_invalid_tokens() {
+        let map = parse_symbol_port_map("BTCUSDT:6666,bad,ETHUSDT:notaport, :7777");
+        assert_eq!(map.get("BTCUSDT"), Some(&6666));
+        assert_eq!(map.len(), 1);
+    }
+
+    #[test]
+    fn udp_bindings_defaults_to_sequential_ports_for_multi_symbol() {
+        let symbols = vec![
+            "BTCUSDT".to_string(),
+            "ETHUSDT".to_string(),
+            "SOLUSDT".to_string(),
+        ];
+        let bindings = udp_bindings_from_raw(6666, &symbols, "");
+        assert_eq!(
+            bindings,
+            vec![
+                ("BTCUSDT".to_string(), 6666),
+                ("ETHUSDT".to_string(), 6667),
+                ("SOLUSDT".to_string(), 6668),
+            ]
+        );
+    }
+
+    #[test]
+    fn parse_port_core_map_accepts_pairs() {
+        let map = parse_port_core_map("6666:2,6667:3");
+        assert_eq!(map.get(&6666), Some(&2usize));
+        assert_eq!(map.get(&6667), Some(&3usize));
+    }
+
+    #[test]
+    fn parse_ip_allowlist_accepts_valid_ips() {
+        let allowlist = parse_ip_allowlist("127.0.0.1,10.0.0.2,::1,bad");
+        assert!(allowlist.contains(&"127.0.0.1".parse::<IpAddr>().unwrap()));
+        assert!(allowlist.contains(&"10.0.0.2".parse::<IpAddr>().unwrap()));
+        assert!(allowlist.contains(&"::1".parse::<IpAddr>().unwrap()));
+        assert_eq!(allowlist.len(), 3);
+    }
+}
diff --git a/crates/feeder_tokyo/Cargo.toml b/crates/feeder_tokyo/Cargo.toml
new file mode 100644
index 0000000..c497ecc
--- /dev/null
+++ b/crates/feeder_tokyo/Cargo.toml
@@ -0,0 +1,13 @@
+[package]
+name = "feeder_tokyo"
+version = "0.1.0"
+edition = "2021"
+
+[dependencies]
+tokio = { workspace = true, features = ["full"] }
+tokio-tungstenite = { workspace = true }
+futures = { workspace = true }
+anyhow = { workspace = true }
+poly_wire = { path = "../poly_wire" }
+rustls = { workspace = true }
+libc = "0.2"
diff --git a/crates/feeder_tokyo/src/bin/receiver.rs b/crates/feeder_tokyo/src/bin/receiver.rs
new file mode 100644
index 0000000..d6b4971
--- /dev/null
+++ b/crates/feeder_tokyo/src/bin/receiver.rs
@@ -0,0 +1,173 @@
+use anyhow::{Context, Result};
+use poly_wire::{
+    decode_auto, now_micros, WirePacket, WIRE_BOOK_TOP24_SIZE, WIRE_MAX_PACKET_SIZE,
+    WIRE_MOMENTUM_TICK32_SIZE, WIRE_RELAY_TICK40_SIZE,
+};
+use std::net::UdpSocket;
+#[cfg(target_os = "linux")]
+use std::os::fd::AsRawFd;
+
+fn main() -> Result<()> {
+    let bind_addr = std::env::var("BIND_ADDR").unwrap_or_else(|_| "0.0.0.0:6666".to_string());
+    let print_every = std::env::var("PRINT_EVERY")
+        .ok()
+        .and_then(|v| v.parse::<u64>().ok())
+        .filter(|v| *v > 0)
+        .unwrap_or(1);
+    let pin_core = std::env::var("PIN_CORE")
+        .ok()
+        .and_then(|v| v.parse::<usize>().ok());
+    let busy_poll_us = std::env::var("BUSY_POLL_US")
+        .ok()
+        .and_then(|v| v.parse::<u32>().ok())
+        .filter(|v| *v > 0);
+    let rcvbuf_bytes = std::env::var("RCVBUF_BYTES")
+        .ok()
+        .and_then(|v| v.parse::<usize>().ok())
+        .filter(|v| *v > 0);
+
+    if let Some(core_id) = pin_core {
+        pin_current_thread(core_id)?;
+    }
+
+    let socket = UdpSocket::bind(&bind_addr)
+        .with_context(|| format!("bind receiver UDP socket at {bind_addr}"))?;
+    apply_udp_socket_tuning(&socket, rcvbuf_bytes, busy_poll_us)?;
+    socket
+        .set_nonblocking(true)
+        .context("set receiver UDP socket nonblocking")?;
+
+    eprintln!(
+        "receiver: listening={} packet_sizes=[{},{},{}] print_every={} (busy-spin mode)",
+        bind_addr,
+        WIRE_BOOK_TOP24_SIZE,
+        WIRE_MOMENTUM_TICK32_SIZE,
+        WIRE_RELAY_TICK40_SIZE,
+        print_every
+    );
+
+    let mut buf = [0u8; WIRE_MAX_PACKET_SIZE];
+    let mut last_packet_ts: u64 = 0;
+    let mut recv_ok: u64 = 0;
+    let mut dropped_out_of_order: u64 = 0;
+    let mut dropped_size: u64 = 0;
+
+    loop {
+        match socket.recv_from(&mut buf) {
+            Ok((amt, _src)) => {
+                if amt != WIRE_BOOK_TOP24_SIZE
+                    && amt != WIRE_MOMENTUM_TICK32_SIZE
+                    && amt != WIRE_RELAY_TICK40_SIZE
+                {
+                    dropped_size = dropped_size.saturating_add(1);
+                    continue;
+                }
+
+                let (ts_micros, bid, ask) = match decode_auto(&buf[..amt]) {
+                    Ok(WirePacket::BookTop24(pkt)) => (pkt.ts_micros, pkt.bid, pkt.ask),
+                    Ok(WirePacket::MomentumTick32(pkt)) => (pkt.ts_micros, pkt.bid, pkt.ask),
+                    Ok(WirePacket::RelayTick40(pkt)) => (pkt.ts_micros, pkt.bid, pkt.ask),
+                    Err(_) => continue,
+                };
+
+                if ts_micros < last_packet_ts {
+                    dropped_out_of_order = dropped_out_of_order.saturating_add(1);
+                    continue;
+                }
+                last_packet_ts = ts_micros;
+
+                recv_ok = recv_ok.saturating_add(1);
+                if recv_ok.is_multiple_of(print_every) {
+                    let now = now_micros();
+                    let latency_us = now.saturating_sub(ts_micros);
+                    println!(
+                        "latency_us={} bid={:.8} ask={:.8} recv_ok={} drop_ooo={} drop_size={}",
+                        latency_us, bid, ask, recv_ok, dropped_out_of_order, dropped_size
+                    );
+                }
+            }
+            Err(err) if err.kind() == std::io::ErrorKind::WouldBlock => {
+                // Busy-wait for lowest wakeup latency.
+                std::hint::spin_loop();
+            }
+            Err(err) => return Err(err).context("udp recv_from failed"),
+        }
+    }
+}
+
+#[cfg(target_os = "linux")]
+fn apply_udp_socket_tuning(
+    socket: &UdpSocket,
+    rcvbuf_bytes: Option<usize>,
+    busy_poll_us: Option<u32>,
+) -> Result<()> {
+    if let Some(bytes) = rcvbuf_bytes {
+        let value: libc::c_int = bytes.try_into().unwrap_or(libc::c_int::MAX);
+        let rc = unsafe {
+            libc::setsockopt(
+                socket.as_raw_fd(),
+                libc::SOL_SOCKET,
+                libc::SO_RCVBUF,
+                (&value as *const libc::c_int).cast(),
+                std::mem::size_of::<libc::c_int>() as libc::socklen_t,
+            )
+        };
+        if rc != 0 {
+            anyhow::bail!("set SO_RCVBUF failed: {}", std::io::Error::last_os_error());
+        }
+    }
+    if let Some(us) = busy_poll_us {
+        let value: libc::c_int = us.try_into().unwrap_or(libc::c_int::MAX);
+        let rc = unsafe {
+            libc::setsockopt(
+                socket.as_raw_fd(),
+                libc::SOL_SOCKET,
+                libc::SO_BUSY_POLL,
+                (&value as *const libc::c_int).cast(),
+                std::mem::size_of::<libc::c_int>() as libc::socklen_t,
+            )
+        };
+        if rc != 0 {
+            anyhow::bail!(
+                "set SO_BUSY_POLL failed: {}",
+                std::io::Error::last_os_error()
+            );
+        }
+    }
+    Ok(())
+}
+
+#[cfg(not(target_os = "linux"))]
+fn apply_udp_socket_tuning(
+    _socket: &UdpSocket,
+    _rcvbuf_bytes: Option<usize>,
+    _busy_poll_us: Option<u32>,
+) -> Result<()> {
+    Ok(())
+}
+
+#[cfg(target_os = "linux")]
+fn pin_current_thread(core_id: usize) -> Result<()> {
+    let mut cpuset: libc::cpu_set_t = unsafe { std::mem::zeroed() };
+    unsafe {
+        libc::CPU_ZERO(&mut cpuset);
+        libc::CPU_SET(core_id, &mut cpuset);
+        let rc = libc::pthread_setaffinity_np(
+            libc::pthread_self(),
+            std::mem::size_of::<libc::cpu_set_t>(),
+            &cpuset,
+        );
+        if rc != 0 {
+            anyhow::bail!(
+                "pthread_setaffinity_np(core={core_id}) failed: {}",
+                std::io::Error::from_raw_os_error(rc)
+            );
+        }
+    }
+    Ok(())
+}
+
+#[cfg(not(target_os = "linux"))]
+fn pin_current_thread(_core_id: usize) -> Result<()> {
+    Ok(())
+}
diff --git a/crates/feeder_tokyo/src/bin/sender.rs b/crates/feeder_tokyo/src/bin/sender.rs
new file mode 100644
index 0000000..6a4c30d
--- /dev/null
+++ b/crates/feeder_tokyo/src/bin/sender.rs
@@ -0,0 +1,681 @@
+use anyhow::{Context, Result};
+use futures::StreamExt;
+use poly_wire::{encode_with_mode, now_micros, WireBookTop24, WireMode, WIRE_MAX_PACKET_SIZE};
+use std::collections::HashMap;
+use std::net::{SocketAddr, UdpSocket};
+#[cfg(target_os = "linux")]
+use std::os::fd::AsRawFd;
+use std::time::{Duration, Instant};
+use tokio::time::timeout;
+use tokio_tungstenite::{connect_async, tungstenite::protocol::Message};
+
+const KEY_BID: &[u8] = br#""b":""#;
+const KEY_ASK: &[u8] = br#""a":""#;
+const KEY_EVENT_MS: &[u8] = br#""E":"#;
+
+#[derive(Debug, Clone)]
+struct Route {
+    symbol: String,
+    bind_addr: String,
+    target: String,
+    core_id: Option<usize>,
+}
+
+#[derive(Debug, Clone, Copy)]
+struct SenderTuning {
+    redundancy: u8,
+    sndbuf_bytes: Option<usize>,
+    adaptive_redundancy: bool,
+    adaptive_redundancy_high: u8,
+    adaptive_err_threshold_per_sec: u64,
+    adaptive_cooldown_sec: u64,
+}
+
+fn main() -> Result<()> {
+    let _ = rustls::crypto::ring::default_provider().install_default();
+    let mut routes = resolve_routes();
+    if routes.is_empty() {
+        anyhow::bail!("no sender routes configured");
+    }
+    assign_route_cores(&mut routes);
+    let tuning = load_sender_tuning();
+    eprintln!("sender: routes={routes:?} tuning={tuning:?}");
+
+    let mut handles = Vec::with_capacity(routes.len());
+    for route in routes {
+        let tuning_local = tuning;
+        let name = format!("sender-{}", route.symbol);
+        let handle = std::thread::Builder::new()
+            .name(name.clone())
+            .spawn(move || {
+                if let Some(core_id) = route.core_id {
+                    if let Err(err) = pin_current_thread(core_id) {
+                        eprintln!(
+                            "sender: symbol={} failed to pin thread to core {}: {}",
+                            route.symbol, core_id, err
+                        );
+                    } else {
+                        eprintln!("sender: symbol={} pinned to core {}", route.symbol, core_id);
+                    }
+                }
+
+                let rt = match tokio::runtime::Builder::new_current_thread()
+                    .enable_all()
+                    .build()
+                {
+                    Ok(v) => v,
+                    Err(err) => {
+                        eprintln!(
+                            "sender: symbol={} runtime build failed: {}",
+                            route.symbol, err
+                        );
+                        return;
+                    }
+                };
+
+                rt.block_on(async move {
+                    loop {
+                        if let Err(err) = run_route(&route, tuning_local).await {
+                            eprintln!(
+                                "sender: route symbol={} target={} failed: {}",
+                                route.symbol, route.target, err
+                            );
+                        }
+                        tokio::time::sleep(Duration::from_millis(300)).await;
+                    }
+                });
+            })
+            .with_context(|| format!("spawn thread {name}"))?;
+        handles.push(handle);
+    }
+
+    for h in handles {
+        if let Err(err) = h.join() {
+            eprintln!("sender: worker thread panic: {:?}", err);
+        }
+    }
+    Ok(())
+}
+
+fn load_sender_tuning() -> SenderTuning {
+    let redundancy = std::env::var("POLYEDGE_UDP_REDUNDANCY")
+        .ok()
+        .and_then(|v| v.parse::<u8>().ok())
+        .filter(|v| *v > 0)
+        .unwrap_or(1)
+        .min(8);
+    let sndbuf_bytes = std::env::var("POLYEDGE_UDP_SNDBUF_BYTES")
+        .ok()
+        .and_then(|v| v.parse::<usize>().ok())
+        .filter(|v| *v > 0);
+    let adaptive_redundancy = std::env::var("POLYEDGE_UDP_REDUNDANCY_ADAPTIVE")
+        .ok()
+        .map(|v| matches!(v.as_str(), "1" | "true" | "TRUE" | "True"))
+        .unwrap_or(false);
+    let adaptive_redundancy_high = std::env::var("POLYEDGE_UDP_REDUNDANCY_ADAPTIVE_HIGH")
+        .ok()
+        .and_then(|v| v.parse::<u8>().ok())
+        .filter(|v| *v > 0)
+        .unwrap_or(2)
+        .min(8);
+    let adaptive_err_threshold_per_sec =
+        std::env::var("POLYEDGE_UDP_REDUNDANCY_ERR_THRESHOLD_PER_SEC")
+            .ok()
+            .and_then(|v| v.parse::<u64>().ok())
+            .unwrap_or(2)
+            .max(1);
+    let adaptive_cooldown_sec = std::env::var("POLYEDGE_UDP_REDUNDANCY_COOLDOWN_SEC")
+        .ok()
+        .and_then(|v| v.parse::<u64>().ok())
+        .unwrap_or(10)
+        .max(1);
+    SenderTuning {
+        redundancy,
+        sndbuf_bytes,
+        adaptive_redundancy,
+        adaptive_redundancy_high,
+        adaptive_err_threshold_per_sec,
+        adaptive_cooldown_sec,
+    }
+}
+
+#[derive(Debug, Clone, Copy)]
+struct RedundancyController {
+    base: u8,
+    high: u8,
+    enabled: bool,
+    err_threshold_per_sec: u64,
+    cooldown_sec: u64,
+    current: u8,
+    last_error_window: std::time::Instant,
+    last_error_total: u64,
+    last_error_event: std::time::Instant,
+}
+
+#[derive(Debug, Default, Clone, Copy)]
+struct VelocityEstimator {
+    prev_ts_micros: u64,
+    prev_mid: f64,
+}
+
+impl VelocityEstimator {
+    fn velocity_bps_per_sec(&mut self, packet: &WireBookTop24) -> f64 {
+        let mid = (packet.bid + packet.ask) * 0.5;
+        if !mid.is_finite() || mid <= 0.0 {
+            return 0.0;
+        }
+        if self.prev_ts_micros == 0 || self.prev_mid <= 0.0 || !self.prev_mid.is_finite() {
+            self.prev_ts_micros = packet.ts_micros;
+            self.prev_mid = mid;
+            return 0.0;
+        }
+
+        let dt_micros = packet.ts_micros.saturating_sub(self.prev_ts_micros);
+        if dt_micros == 0 {
+            return 0.0;
+        }
+        let dt_sec = dt_micros as f64 / 1_000_000.0;
+        if dt_sec <= 0.0 {
+            return 0.0;
+        }
+        let ret = (mid - self.prev_mid) / self.prev_mid;
+        let velocity = (ret * 10_000.0) / dt_sec;
+
+        self.prev_ts_micros = packet.ts_micros;
+        self.prev_mid = mid;
+
+        if velocity.is_finite() {
+            velocity
+        } else {
+            0.0
+        }
+    }
+}
+
+impl RedundancyController {
+    fn new(tuning: SenderTuning) -> Self {
+        let base = tuning.redundancy.max(1);
+        let high = tuning.adaptive_redundancy_high.max(base);
+        let now = std::time::Instant::now();
+        Self {
+            base,
+            high,
+            enabled: tuning.adaptive_redundancy,
+            err_threshold_per_sec: tuning.adaptive_err_threshold_per_sec.max(1),
+            cooldown_sec: tuning.adaptive_cooldown_sec.max(1),
+            current: base,
+            last_error_window: now,
+            last_error_total: 0,
+            last_error_event: now,
+        }
+    }
+
+    fn current(&self) -> u8 {
+        self.current
+    }
+
+    fn on_progress(&mut self, total_errors: u64) {
+        if !self.enabled {
+            self.current = self.base;
+            return;
+        }
+        let now = std::time::Instant::now();
+        let elapsed = now.saturating_duration_since(self.last_error_window);
+        if elapsed >= Duration::from_secs(1) {
+            let err_delta = total_errors.saturating_sub(self.last_error_total);
+            if err_delta >= self.err_threshold_per_sec {
+                self.current = self.high;
+                self.last_error_event = now;
+            } else if self.current > self.base
+                && now.saturating_duration_since(self.last_error_event)
+                    >= Duration::from_secs(self.cooldown_sec)
+            {
+                self.current = self.current.saturating_sub(1).max(self.base);
+            }
+            self.last_error_total = total_errors;
+            self.last_error_window = now;
+        }
+    }
+}
+
+fn resolve_routes() -> Vec<Route> {
+    let from_targets = parse_symbol_targets(
+        &std::env::var("SYMBOL_TARGETS").unwrap_or_default(),
+        &std::env::var("BIND_BASE_PORT").unwrap_or_else(|_| "9999".to_string()),
+    );
+    if !from_targets.is_empty() {
+        return from_targets
+            .into_iter()
+            .map(|(symbol, bind_addr, target)| Route {
+                symbol,
+                bind_addr,
+                target,
+                core_id: None,
+            })
+            .collect();
+    }
+    let symbol = std::env::var("SYMBOL").unwrap_or_else(|_| "btcusdt".to_string());
+    let bind_addr = std::env::var("BIND_ADDR").unwrap_or_else(|_| "0.0.0.0:9999".to_string());
+    let target = std::env::var("TARGET").unwrap_or_else(|_| "10.0.3.123:6666".to_string());
+    vec![Route {
+        symbol: symbol.trim().to_ascii_lowercase(),
+        bind_addr,
+        target,
+        core_id: None,
+    }]
+}
+
+fn assign_route_cores(routes: &mut [Route]) {
+    let per_symbol =
+        parse_symbol_core_map(&std::env::var("POLYEDGE_SENDER_PIN_CORES").unwrap_or_default());
+    let fallback = std::env::var("POLYEDGE_SENDER_PIN_CORE")
+        .ok()
+        .and_then(|v| v.parse::<usize>().ok());
+    for route in routes {
+        route.core_id = per_symbol.get(route.symbol.as_str()).copied().or(fallback);
+    }
+}
+
+fn parse_symbol_targets(raw: &str, bind_base_port_raw: &str) -> Vec<(String, String, String)> {
+    let bind_base_port = bind_base_port_raw.parse::<u16>().unwrap_or(9999);
+    let mut routes = Vec::<(String, String, String)>::new();
+    for (idx, token) in raw.split(',').enumerate() {
+        let token = token.trim();
+        if token.is_empty() {
+            continue;
+        }
+        let mut pair = token.split('=');
+        let symbol = pair.next().unwrap_or_default().trim().to_ascii_lowercase();
+        let target = pair.next().unwrap_or_default().trim().to_string();
+        if symbol.is_empty() || target.is_empty() || pair.next().is_some() {
+            continue;
+        }
+        let bind_addr = format!("0.0.0.0:{}", bind_base_port.saturating_add(idx as u16));
+        routes.push((symbol, bind_addr, target));
+    }
+    routes
+}
+
+fn parse_symbol_core_map(raw: &str) -> HashMap<String, usize> {
+    let mut out = HashMap::<String, usize>::new();
+    for item in raw.split(',') {
+        let token = item.trim();
+        if token.is_empty() {
+            continue;
+        }
+        let mut pair = token.split(':');
+        let symbol = pair.next().unwrap_or_default().trim().to_ascii_lowercase();
+        let core = pair.next().unwrap_or_default().trim();
+        if symbol.is_empty() || core.is_empty() || pair.next().is_some() {
+            continue;
+        }
+        if let Ok(core_id) = core.parse::<usize>() {
+            out.insert(symbol, core_id);
+        }
+    }
+    out
+}
+
+async fn run_route(route: &Route, tuning: SenderTuning) -> Result<()> {
+    let target_addr: SocketAddr = route
+        .target
+        .parse()
+        .with_context(|| format!("parse sender target {}", route.target))?;
+    let socket = UdpSocket::bind(&route.bind_addr)
+        .with_context(|| format!("bind sender UDP socket at {}", route.bind_addr))?;
+    apply_udp_sender_socket_tuning(&socket, tuning.sndbuf_bytes)?;
+    socket
+        .set_nonblocking(true)
+        .context("set sender UDP socket nonblocking")?;
+
+    eprintln!(
+        "sender: bind={} target={} symbol={} redundancy={} sndbuf={:?}",
+        route.bind_addr, route.target, route.symbol, tuning.redundancy, tuning.sndbuf_bytes
+    );
+
+    let wire_mode = WireMode::from_env("POLYEDGE_WIRE_MODE");
+    let mut packet_buf = [0u8; WIRE_MAX_PACKET_SIZE];
+    let mut frames: u64 = 0;
+    let mut packets_ok: u64 = 0;
+    let mut dropped_would_block: u64 = 0;
+    let mut dropped_conn_refused: u64 = 0;
+    let mut dropped_other: u64 = 0;
+    let mut redundancy_ctl = RedundancyController::new(tuning);
+    let mut velocity_estimator = VelocityEstimator::default();
+    let mut last_log = std::time::Instant::now();
+
+    loop {
+        let endpoint_candidates = pick_best_fstream_ws_endpoint(fstream_ws_endpoints(&route.symbol)).await;
+        let mut ws_stream = None;
+        let mut last_err: Option<String> = None;
+        for endpoint in endpoint_candidates {
+            match timeout(
+                Duration::from_secs(
+                    std::env::var("POLYEDGE_FSTREAM_WS_CONNECT_TIMEOUT_SEC")
+                        .ok()
+                        .and_then(|v| v.parse::<u64>().ok())
+                        .unwrap_or(3)
+                        .max(1),
+                ),
+                connect_async(&endpoint),
+            )
+            .await
+            {
+                Ok(Ok((socket, _))) => {
+                    ws_stream = Some(socket);
+                    break;
+                }
+                Ok(Err(err)) => {
+                    last_err = Some(format!("{endpoint}: {err}"));
+                    continue;
+                }
+                Err(_) => {
+                    last_err = Some(format!("{endpoint}: connect timeout"));
+                    continue;
+                }
+            }
+        }
+        let Some(mut ws_stream) = ws_stream else {
+            eprintln!(
+                "sender: websocket connect error for symbol={} last={}",
+                route.symbol,
+                last_err.unwrap_or_else(|| "no endpoint available".to_string())
+            );
+            tokio::time::sleep(Duration::from_secs(1)).await;
+            continue;
+        };
+
+        while let Some(frame) = ws_stream.next().await {
+            let Ok(message) = frame else {
+                break;
+            };
+            let Message::Text(text) = message else {
+                continue;
+            };
+
+            if let Some(packet) = parse_book_ticker(&text) {
+                let velocity_bps_per_sec = velocity_estimator.velocity_bps_per_sec(&packet);
+                let packet_len = encode_with_mode(
+                    &packet,
+                    velocity_bps_per_sec,
+                    Some((now_micros() / 1_000) as i64),
+                    wire_mode,
+                    &mut packet_buf,
+                )
+                .context("encode wire packet")?;
+                frames = frames.saturating_add(1);
+
+                for _ in 0..redundancy_ctl.current() {
+                    match socket.send_to(&packet_buf[..packet_len], target_addr) {
+                        Ok(_) => packets_ok = packets_ok.saturating_add(1),
+                        Err(err) if err.kind() == std::io::ErrorKind::WouldBlock => {
+                            dropped_would_block = dropped_would_block.saturating_add(1);
+                        }
+                        Err(err) if err.kind() == std::io::ErrorKind::ConnectionRefused => {
+                            dropped_conn_refused = dropped_conn_refused.saturating_add(1);
+                        }
+                        Err(_) => dropped_other = dropped_other.saturating_add(1),
+                    }
+                }
+            }
+
+            let total_errors = dropped_would_block
+                .saturating_add(dropped_conn_refused)
+                .saturating_add(dropped_other);
+            redundancy_ctl.on_progress(total_errors);
+
+            if last_log.elapsed().as_secs() >= 5 {
+                eprintln!(
+                    "sender: symbol={} wire_mode={:?} frames={} packets_ok={} dropped_would_block={} dropped_conn_refused={} dropped_other={} redundancy={}",
+                    route.symbol,
+                    wire_mode,
+                    frames,
+                    packets_ok,
+                    dropped_would_block,
+                    dropped_conn_refused,
+                    dropped_other,
+                    redundancy_ctl.current()
+                );
+                last_log = std::time::Instant::now();
+            }
+        }
+
+        eprintln!(
+            "sender: websocket disconnected for symbol={}, reconnecting...",
+            route.symbol
+        );
+        tokio::time::sleep(Duration::from_millis(300)).await;
+    }
+}
+
+async fn pick_best_fstream_ws_endpoint(endpoints: Vec<String>) -> Vec<String> {
+    if endpoints.len() <= 1 {
+        return endpoints;
+    }
+    let timeout_dur = Duration::from_secs(
+        std::env::var("POLYEDGE_WS_PROBE_TIMEOUT_SEC")
+            .ok()
+            .and_then(|v| v.parse::<u64>().ok())
+            .unwrap_or(2)
+            .max(1),
+    );
+    let mut join_set = tokio::task::JoinSet::new();
+    for ep in endpoints.iter().cloned() {
+        join_set.spawn(async move {
+            let started = Instant::now();
+            let ok = timeout(timeout_dur, connect_async(&ep)).await;
+            match ok {
+                Ok(Ok((ws, _resp))) => {
+                    drop(ws);
+                    Some((ep, started.elapsed().as_secs_f64() * 1_000.0))
+                }
+                _ => None,
+            }
+        });
+    }
+    let mut results: Vec<(String, f64)> = Vec::new();
+    while let Some(res) = join_set.join_next().await {
+        if let Ok(Some(v)) = res {
+            results.push(v);
+        }
+    }
+    if results.is_empty() {
+        return endpoints;
+    }
+    results.sort_by(|a, b| a.1.total_cmp(&b.1));
+    let best = results[0].0.clone();
+    eprintln!(
+        "sender: symbol endpoint selected={} handshake_ms={:.3} candidates={}",
+        best,
+        results[0].1,
+        endpoints.len()
+    );
+    let mut out = Vec::with_capacity(endpoints.len());
+    out.push(best.clone());
+    for ep in endpoints {
+        if ep != best {
+            out.push(ep);
+        }
+    }
+    out
+}
+
+fn fstream_ws_endpoints(symbol: &str) -> Vec<String> {
+    if let Ok(raw) = std::env::var("POLYEDGE_BINANCE_FSTREAM_WS_BASES") {
+        let out = raw
+            .split(',')
+            .map(str::trim)
+            .filter(|v| v.starts_with("ws://") || v.starts_with("wss://"))
+            .map(|base| format!("{}/ws/{}@bookTicker", base.trim_end_matches('/'), symbol))
+            .collect::<Vec<_>>();
+        if !out.is_empty() {
+            return out;
+        }
+    }
+    if let Ok(base) = std::env::var("POLYEDGE_BINANCE_FSTREAM_WS_BASE") {
+        if base.starts_with("ws://") || base.starts_with("wss://") {
+            return vec![format!(
+                "{}/ws/{}@bookTicker",
+                base.trim_end_matches('/'),
+                symbol
+            )];
+        }
+    }
+    vec![
+        format!("wss://fstream.binance.com/ws/{}@bookTicker", symbol),
+        format!("wss://fstream1.binance.com/ws/{}@bookTicker", symbol),
+        format!("wss://fstream2.binance.com/ws/{}@bookTicker", symbol),
+    ]
+}
+
+#[cfg(target_os = "linux")]
+fn apply_udp_sender_socket_tuning(socket: &UdpSocket, sndbuf_bytes: Option<usize>) -> Result<()> {
+    if let Some(bytes) = sndbuf_bytes {
+        let value: libc::c_int = bytes.try_into().unwrap_or(libc::c_int::MAX);
+        let rc = unsafe {
+            libc::setsockopt(
+                socket.as_raw_fd(),
+                libc::SOL_SOCKET,
+                libc::SO_SNDBUF,
+                (&value as *const libc::c_int).cast(),
+                std::mem::size_of::<libc::c_int>() as libc::socklen_t,
+            )
+        };
+        if rc != 0 {
+            let err = std::io::Error::last_os_error();
+            anyhow::bail!("set SO_SNDBUF={} failed: {}", bytes, err);
+        }
+    }
+    Ok(())
+}
+
+#[cfg(not(target_os = "linux"))]
+fn apply_udp_sender_socket_tuning(_socket: &UdpSocket, _sndbuf_bytes: Option<usize>) -> Result<()> {
+    Ok(())
+}
+
+#[cfg(target_os = "linux")]
+fn pin_current_thread(core_id: usize) -> Result<()> {
+    let mut cpuset: libc::cpu_set_t = unsafe { std::mem::zeroed() };
+    unsafe {
+        libc::CPU_ZERO(&mut cpuset);
+        libc::CPU_SET(core_id, &mut cpuset);
+        let rc = libc::pthread_setaffinity_np(
+            libc::pthread_self(),
+            std::mem::size_of::<libc::cpu_set_t>(),
+            &cpuset,
+        );
+        if rc != 0 {
+            let err = std::io::Error::from_raw_os_error(rc);
+            anyhow::bail!("pthread_setaffinity_np(core={core_id}) failed: {err}");
+        }
+    }
+    Ok(())
+}
+
+#[cfg(not(target_os = "linux"))]
+fn pin_current_thread(_core_id: usize) -> Result<()> {
+    Ok(())
+}
+
+#[inline]
+fn parse_book_ticker(payload: &str) -> Option<WireBookTop24> {
+    let bytes = payload.as_bytes();
+    let bid = extract_quoted_f64(bytes, KEY_BID)?;
+    let ask = extract_quoted_f64(bytes, KEY_ASK)?;
+    let event_ms = extract_u64(bytes, KEY_EVENT_MS)?;
+
+    let ts_micros = if event_ms > 0 {
+        event_ms.saturating_mul(1_000)
+    } else {
+        now_micros()
+    };
+
+    Some(WireBookTop24 {
+        ts_micros,
+        bid,
+        ask,
+    })
+}
+
+#[inline]
+fn extract_quoted_f64(payload: &[u8], key_with_quote: &[u8]) -> Option<f64> {
+    let start = find_subslice(payload, key_with_quote)? + key_with_quote.len();
+    let end_rel = payload.get(start..)?.iter().position(|&b| b == b'"')?;
+    let end = start + end_rel;
+    std::str::from_utf8(payload.get(start..end)?)
+        .ok()?
+        .parse()
+        .ok()
+}
+
+#[inline]
+fn extract_u64(payload: &[u8], key: &[u8]) -> Option<u64> {
+    let start = find_subslice(payload, key)? + key.len();
+    let tail = payload.get(start..)?;
+    let mut end_rel = 0usize;
+    while end_rel < tail.len() && tail[end_rel].is_ascii_digit() {
+        end_rel += 1;
+    }
+    if end_rel == 0 {
+        return None;
+    }
+    std::str::from_utf8(&tail[..end_rel]).ok()?.parse().ok()
+}
+
+#[inline]
+fn find_subslice(haystack: &[u8], needle: &[u8]) -> Option<usize> {
+    if needle.is_empty() || needle.len() > haystack.len() {
+        return None;
+    }
+    haystack
+        .windows(needle.len())
+        .position(|window| window == needle)
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn parse_symbol_targets_accepts_valid_tokens() {
+        let routes =
+            parse_symbol_targets("btcusdt=10.0.3.123:6666,ethusdt=10.0.3.123:6667", "9999");
+        assert_eq!(routes.len(), 2);
+        assert_eq!(routes[0].0, "btcusdt");
+        assert_eq!(routes[0].1, "0.0.0.0:9999");
+        assert_eq!(routes[1].0, "ethusdt");
+        assert_eq!(routes[1].1, "0.0.0.0:10000");
+    }
+
+    #[test]
+    fn parse_symbol_targets_skips_invalid_tokens() {
+        let routes = parse_symbol_targets("bad,btcusdt=10.0.3.123:6666, =x", "9999");
+        assert_eq!(routes.len(), 1);
+        assert_eq!(routes[0].0, "btcusdt");
+    }
+
+    #[test]
+    fn parse_symbol_core_map_accepts_valid_entries() {
+        let map = parse_symbol_core_map("btcusdt:2,ethusdt:3");
+        assert_eq!(map.get("btcusdt"), Some(&2usize));
+        assert_eq!(map.get("ethusdt"), Some(&3usize));
+    }
+
+    #[test]
+    fn adaptive_redundancy_escalates_on_error_spike() {
+        let tuning = SenderTuning {
+            redundancy: 1,
+            sndbuf_bytes: None,
+            adaptive_redundancy: true,
+            adaptive_redundancy_high: 2,
+            adaptive_err_threshold_per_sec: 1,
+            adaptive_cooldown_sec: 1,
+        };
+        let mut ctl = RedundancyController::new(tuning);
+        assert_eq!(ctl.current(), 1);
+        std::thread::sleep(Duration::from_millis(1100));
+        ctl.on_progress(2);
+        assert_eq!(ctl.current(), 2);
+    }
+}
diff --git a/crates/infra_clock/src/lib.rs b/crates/infra_clock/src/lib.rs
index c78ab08..396f7ec 100644
--- a/crates/infra_clock/src/lib.rs
+++ b/crates/infra_clock/src/lib.rs
@@ -23,7 +23,9 @@ impl Default for MonotonicClock {
 impl MonotonicClock {
     pub fn now_ns(&self) -> i64 {
         let elapsed = self.boot.elapsed().as_nanos() as i64;
-        elapsed + self.offset_ns.load(Ordering::Relaxed)
+        // Use SeqCst to ensure proper memory ordering for time synchronization
+        // This guarantees that writes to offset_ns are visible to subsequent reads
+        elapsed + self.offset_ns.load(Ordering::SeqCst)
     }
 
     pub fn now_ms(&self) -> i64 {
@@ -35,11 +37,12 @@ impl MonotonicClock {
     }
 
     pub fn apply_offset_ns(&self, offset_ns: i64) {
-        self.offset_ns.store(offset_ns, Ordering::Relaxed);
+        // Use SeqCst to ensure the offset is properly visible to all threads
+        self.offset_ns.store(offset_ns, Ordering::SeqCst);
     }
 
     pub fn offset_ns(&self) -> i64 {
-        self.offset_ns.load(Ordering::Relaxed)
+        self.offset_ns.load(Ordering::SeqCst)
     }
 }
 
diff --git a/crates/market_discovery/src/lib.rs b/crates/market_discovery/src/lib.rs
index 969d470..6228d25 100644
--- a/crates/market_discovery/src/lib.rs
+++ b/crates/market_discovery/src/lib.rs
@@ -1,4 +1,4 @@
-use anyhow::{Context, Result};
+use anyhow::{anyhow, Context, Result};
 use reqwest::Client;
 use serde::{Deserialize, Serialize};
 
@@ -11,6 +11,8 @@ pub struct MarketDescriptor {
     pub token_id_no: Option<String>,
     pub event_slug: Option<String>,
     pub end_date: Option<String>,
+    pub timeframe: Option<String>,   // "5m" / "15m" / "1h" / "1d"
+    pub market_type: Option<String>, // "updown" / "above_below" / "range"
     pub best_bid: Option<f64>,
     pub best_ask: Option<f64>,
 }
@@ -82,7 +84,7 @@ impl MarketDiscovery {
         for offset in [0_i64, 1000, 2000, 3000] {
             let limit_s = limit.to_string();
             let offset_s = offset.to_string();
-            let markets: Vec<GammaMarket> = self
+            let response = self
                 .http
                 .get(&self.cfg.endpoint)
                 .query(&[
@@ -95,13 +97,34 @@ impl MarketDiscovery {
                     ("ascending", "false"),
                 ])
                 .send()
-                .await
-                .context("discovery request")?
-                .error_for_status()
-                .context("discovery status")?
-                .json()
-                .await
-                .context("discovery json")?;
+                .await;
+            let response = match response {
+                Ok(v) => v,
+                Err(err) => {
+                    if out.is_empty() {
+                        return Err(err).context("discovery request");
+                    }
+                    break;
+                }
+            };
+            let response = match response.error_for_status() {
+                Ok(v) => v,
+                Err(err) => {
+                    if out.is_empty() {
+                        return Err(err).context("discovery status");
+                    }
+                    break;
+                }
+            };
+            let markets: Vec<GammaMarket> = match response.json().await {
+                Ok(v) => v,
+                Err(err) => {
+                    if out.is_empty() {
+                        return Err(err).context("discovery json");
+                    }
+                    break;
+                }
+            };
 
             if markets.is_empty() {
                 break;
@@ -130,15 +153,16 @@ impl MarketDiscovery {
                 {
                     continue;
                 }
+                let timeframe = classify_timeframe(&text);
                 if !self.cfg.timeframes.is_empty() {
-                    let Some(timeframe) = classify_timeframe(&text) else {
+                    let Some(tf) = timeframe else {
                         continue;
                     };
                     if !self
                         .cfg
                         .timeframes
                         .iter()
-                        .any(|t| t.eq_ignore_ascii_case(timeframe))
+                        .any(|t| t.eq_ignore_ascii_case(tf))
                     {
                         continue;
                     }
@@ -155,12 +179,17 @@ impl MarketDiscovery {
                     token_id_no: parse_token_pair(market.clob_token_ids.as_deref()).map(|x| x.1),
                     event_slug: market.event_slug,
                     end_date: market.end_date,
+                    timeframe: timeframe.map(|v| v.to_string()),
+                    market_type: Some(market_type.to_string()),
                     best_bid: market.best_bid,
                     best_ask: market.best_ask,
                 });
             }
         }
 
+        if out.is_empty() {
+            return Err(anyhow!("no markets discovered from gamma"));
+        }
         Ok(out)
     }
 }
diff --git a/crates/observability/Cargo.toml b/crates/observability/Cargo.toml
index 382060a..e5a2281 100644
--- a/crates/observability/Cargo.toml
+++ b/crates/observability/Cargo.toml
@@ -9,3 +9,4 @@ metrics.workspace = true
 metrics-exporter-prometheus.workspace = true
 tracing.workspace = true
 tracing-subscriber.workspace = true
+tracing-appender.workspace = true
diff --git a/crates/observability/src/lib.rs b/crates/observability/src/lib.rs
index 75ae823..57be135 100644
--- a/crates/observability/src/lib.rs
+++ b/crates/observability/src/lib.rs
@@ -5,15 +5,20 @@ use tracing_subscriber::EnvFilter;
 
 static PROM_HANDLE: OnceLock<PrometheusHandle> = OnceLock::new();
 
-pub fn init_tracing(service_name: &str) {
+pub fn init_tracing(service_name: &str) -> Option<tracing_appender::non_blocking::WorkerGuard> {
     let filter = EnvFilter::try_from_default_env()
         .unwrap_or_else(|_| EnvFilter::new(format!("{service_name}=info,info")));
 
+    let (non_blocking, guard) = tracing_appender::non_blocking(std::io::stdout());
+
     let _ = tracing_subscriber::fmt()
         .with_env_filter(filter)
+        .with_writer(non_blocking)
         .with_target(true)
         .with_thread_ids(true)
         .try_init();
+
+    Some(guard)
 }
 
 pub fn init_metrics() -> PrometheusHandle {
diff --git a/crates/paper_executor/src/lib.rs b/crates/paper_executor/src/lib.rs
index 279d8a6..b282753 100644
--- a/crates/paper_executor/src/lib.rs
+++ b/crates/paper_executor/src/lib.rs
@@ -1,13 +1,16 @@
 use std::collections::HashMap;
 
 use chrono::Utc;
-use core_types::{BookTop, FillEvent, OrderAck, OrderSide, QuoteIntent};
+use core_types::{BookTop, ExecutionStyle, FillEvent, OrderAck, OrderSide, QuoteIntent};
 use parking_lot::RwLock;
 
 #[derive(Debug, Clone)]
 pub struct ShadowOrder {
     pub order_id: String,
     pub intent: QuoteIntent,
+    pub style: ExecutionStyle,
+    pub reference_mid: f64,
+    pub fee_rate_bps: f64,
 }
 
 #[derive(Default)]
@@ -16,12 +19,22 @@ pub struct ShadowExecutor {
 }
 
 impl ShadowExecutor {
-    pub fn register_order(&self, ack: &OrderAck, intent: QuoteIntent) {
+    pub fn register_order(
+        &self,
+        ack: &OrderAck,
+        intent: QuoteIntent,
+        style: ExecutionStyle,
+        reference_mid: f64,
+        fee_rate_bps: f64,
+    ) {
         self.orders.write().insert(
             ack.order_id.clone(),
             ShadowOrder {
                 order_id: ack.order_id.clone(),
                 intent,
+                style,
+                reference_mid,
+                fee_rate_bps,
             },
         );
     }
@@ -32,15 +45,14 @@ impl ShadowExecutor {
 
     pub fn on_book(&self, book: &BookTop) -> Vec<FillEvent> {
         let mut fills = Vec::new();
-        let mut to_remove = Vec::new();
-
-        {
-            let orders = self.orders.read();
-            for (id, order) in orders.iter() {
-                if order.intent.market_id != book.market_id {
-                    continue;
-                }
 
+        // Use write lock for entire operation to prevent race condition
+        // between read (matching) and write (removing filled orders)
+        let mut orders = self.orders.write();
+        let to_remove: Vec<String> = orders
+            .iter()
+            .filter(|(_, order)| order.intent.market_id == book.market_id)
+            .filter_map(|(id, order)| {
                 let maybe_fill_price = match order.intent.side {
                     OrderSide::BuyYes if order.intent.price >= book.ask_yes => Some(book.ask_yes),
                     OrderSide::SellYes if order.intent.price <= book.bid_yes => Some(book.bid_yes),
@@ -48,27 +60,49 @@ impl ShadowExecutor {
                     OrderSide::SellNo if order.intent.price <= book.bid_no => Some(book.bid_no),
                     _ => None,
                 };
-
-                if let Some(px) = maybe_fill_price {
+                maybe_fill_price.map(|px| {
+                    let mid_price = mid_for_side(book, &order.intent.side);
+                    let slippage_bps = if mid_price > 0.0 {
+                        Some(((px - mid_price) / mid_price) * 10_000.0)
+                    } else {
+                        None
+                    };
+                    let executed_size_usdc = (px * order.intent.size).max(0.0);
+                    let fee = if order.fee_rate_bps.is_finite() && order.fee_rate_bps != 0.0 {
+                        executed_size_usdc * (order.fee_rate_bps / 10_000.0)
+                    } else {
+                        match order.style {
+                            ExecutionStyle::Maker => 0.0,
+                            ExecutionStyle::Taker | ExecutionStyle::Arb => {
+                                let taker_fee_rate = if !(0.02..=0.98).contains(&px) {
+                                    0.001
+                                } else {
+                                    0.01
+                                };
+                                executed_size_usdc * taker_fee_rate
+                            }
+                        }
+                    };
                     fills.push(FillEvent {
                         order_id: id.clone(),
                         market_id: order.intent.market_id.clone(),
                         side: order.intent.side.clone(),
+                        style: order.style.clone(),
                         price: px,
                         size: order.intent.size,
-                        fee: 0.0,
+                        fee,
+                        mid_price: Some(mid_price.max(0.0)),
+                        slippage_bps,
                         ts_ms: Utc::now().timestamp_millis(),
                     });
-                    to_remove.push(id.clone());
-                }
-            }
-        }
+                    id.clone()
+                })
+            })
+            .collect();
 
-        if !to_remove.is_empty() {
-            let mut orders = self.orders.write();
-            for id in to_remove {
-                orders.remove(&id);
-            }
+        // Remove filled orders within same write lock
+        for id in to_remove {
+            orders.remove(&id);
         }
 
         fills
@@ -79,6 +113,13 @@ impl ShadowExecutor {
     }
 }
 
+fn mid_for_side(book: &BookTop, side: &OrderSide) -> f64 {
+    match side {
+        OrderSide::BuyYes | OrderSide::SellYes => (book.bid_yes + book.ask_yes) * 0.5,
+        OrderSide::BuyNo | OrderSide::SellNo => (book.bid_no + book.ask_no) * 0.5,
+    }
+}
+
 #[cfg(test)]
 mod tests {
     use super::*;
@@ -101,6 +142,9 @@ mod tests {
                 size: 1.0,
                 ttl_ms: 1_000,
             },
+            ExecutionStyle::Maker,
+            0.52,
+            -2.0,
         );
         let fills = shadow.on_book(&BookTop {
             market_id: "m1".to_string(),
@@ -114,5 +158,107 @@ mod tests {
             recv_ts_local_ns: 2_000_000,
         });
         assert_eq!(fills.len(), 1);
+        assert!(fills[0].fee < 0.0);
+    }
+
+    #[test]
+    fn taker_fee_curve_boundaries() {
+        let shadow = ShadowExecutor::default();
+        let book = BookTop {
+            market_id: "m1".to_string(),
+            token_id_yes: "y".to_string(),
+            token_id_no: "n".to_string(),
+            bid_yes: 0.50,
+            ask_yes: 0.50,
+            bid_no: 0.49,
+            ask_no: 0.51,
+            ts_ms: 2,
+            recv_ts_local_ns: 2_000_000,
+        };
+
+        for (idx, px, expected_rate) in [
+            (0, 0.0199, 0.001),
+            (1, 0.02, 0.01),
+            (2, 0.98, 0.01),
+            (3, 0.9801, 0.001),
+        ] {
+            let order_id = format!("o{idx}");
+            let ack = OrderAck {
+                order_id: order_id.clone(),
+                market_id: "m1".to_string(),
+                accepted: true,
+                ts_ms: 1,
+            };
+            let side = OrderSide::BuyYes;
+            shadow.register_order(
+                &ack,
+                QuoteIntent {
+                    market_id: "m1".to_string(),
+                    side,
+                    price: px,
+                    size: 10.0,
+                    ttl_ms: 1000,
+                },
+                ExecutionStyle::Taker,
+                px,
+                expected_rate * 10_000.0,
+            );
+            let mut book_local = book.clone();
+            book_local.ask_yes = px;
+            book_local.bid_yes = px;
+            let fills = shadow.on_book(&book_local);
+            assert_eq!(fills.len(), 1);
+            let expected = px * 10.0 * expected_rate;
+            assert!((fills[0].fee - expected).abs() < 1e-9);
+        }
+    }
+
+    #[test]
+    fn slippage_bps_sign_and_side_formula() {
+        let shadow = ShadowExecutor::default();
+        let book = BookTop {
+            market_id: "m1".to_string(),
+            token_id_yes: "y".to_string(),
+            token_id_no: "n".to_string(),
+            bid_yes: 0.48,
+            ask_yes: 0.52,
+            bid_no: 0.47,
+            ask_no: 0.53,
+            ts_ms: 2,
+            recv_ts_local_ns: 2_000_000,
+        };
+
+        let cases = [
+            ("by", OrderSide::BuyYes, 0.52, 400.0),
+            ("sy", OrderSide::SellYes, 0.48, -400.0),
+            ("bn", OrderSide::BuyNo, 0.53, 600.0),
+            ("sn", OrderSide::SellNo, 0.47, -600.0),
+        ];
+
+        for (suffix, side, px, expected_slippage) in cases {
+            let order_id = format!("o-{suffix}");
+            let ack = OrderAck {
+                order_id: order_id.clone(),
+                market_id: "m1".to_string(),
+                accepted: true,
+                ts_ms: 1,
+            };
+            shadow.register_order(
+                &ack,
+                QuoteIntent {
+                    market_id: "m1".to_string(),
+                    side,
+                    price: px,
+                    size: 1.0,
+                    ttl_ms: 1000,
+                },
+                ExecutionStyle::Taker,
+                0.5,
+                0.0,
+            );
+            let fills = shadow.on_book(&book);
+            assert_eq!(fills.len(), 1);
+            assert!((fills[0].slippage_bps.unwrap_or_default() - expected_slippage).abs() < 1e-9);
+        }
     }
 }
diff --git a/crates/poly_wire/Cargo.toml b/crates/poly_wire/Cargo.toml
new file mode 100644
index 0000000..86eefa9
--- /dev/null
+++ b/crates/poly_wire/Cargo.toml
@@ -0,0 +1,8 @@
+[package]
+name = "poly_wire"
+version = "0.1.0"
+edition = "2021"
+
+[dependencies]
+serde = { workspace = true, features = ["derive"] }
+bincode = { workspace = true }
diff --git a/crates/poly_wire/src/lib.rs b/crates/poly_wire/src/lib.rs
new file mode 100644
index 0000000..0c7b149
--- /dev/null
+++ b/crates/poly_wire/src/lib.rs
@@ -0,0 +1,321 @@
+use bincode::Options;
+use serde::{Deserialize, Serialize};
+use std::io::Cursor;
+
+/// Tight 24-byte quote packet for pure UDP relay hot path.
+/// Layout (Little Endian):
+/// [ts_micros: u64][bid: f64][ask: f64]
+pub const WIRE_BOOK_TOP24_SIZE: usize = 24;
+/// Momentum packet extension.
+/// Layout (Little Endian):
+/// [ts_micros: u64][bid: f64][ask: f64][velocity_bps_per_sec: f64]
+pub const WIRE_MOMENTUM_TICK32_SIZE: usize = 32;
+/// Relay packet extension (first-hop timestamp carried from Tokyo sender).
+/// Layout (Little Endian):
+/// [ts_micros: u64][bid: f64][ask: f64][velocity_bps_per_sec: f64][ts_first_hop_ms: i64]
+pub const WIRE_RELAY_TICK40_SIZE: usize = 40;
+pub const WIRE_MAX_PACKET_SIZE: usize = WIRE_RELAY_TICK40_SIZE;
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq)]
+pub struct WireBookTop24 {
+    pub ts_micros: u64,
+    pub bid: f64,
+    pub ask: f64,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq)]
+pub struct WireMomentumTick32 {
+    pub ts_micros: u64,
+    pub bid: f64,
+    pub ask: f64,
+    pub velocity_bps_per_sec: f64,
+}
+
+#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq)]
+pub struct WireRelayTick40 {
+    pub ts_micros: u64,
+    pub bid: f64,
+    pub ask: f64,
+    pub velocity_bps_per_sec: f64,
+    pub ts_first_hop_ms: i64,
+}
+
+#[derive(Debug, Clone, Copy, PartialEq, Eq)]
+pub enum WireMode {
+    Fixed24,
+    Fixed32,
+    Auto,
+}
+
+impl WireMode {
+    pub fn from_env(var_name: &str) -> Self {
+        let raw = std::env::var(var_name).unwrap_or_else(|_| "auto".to_string());
+        Self::parse(&raw)
+    }
+
+    pub fn parse(raw: &str) -> Self {
+        match raw.trim().to_ascii_lowercase().as_str() {
+            "24" | "book24" | "top24" | "fixed24" => Self::Fixed24,
+            "32" | "momentum32" | "tick32" | "fixed32" => Self::Fixed32,
+            _ => Self::Auto,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Copy, PartialEq)]
+pub enum WirePacket {
+    BookTop24(WireBookTop24),
+    MomentumTick32(WireMomentumTick32),
+    RelayTick40(WireRelayTick40),
+}
+
+#[derive(Debug)]
+pub enum WireDecodeError {
+    UnsupportedSize(usize),
+    Bincode(bincode::Error),
+}
+
+impl std::fmt::Display for WireDecodeError {
+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
+        match self {
+            Self::UnsupportedSize(sz) => write!(f, "unsupported wire packet size: {}", sz),
+            Self::Bincode(err) => write!(f, "wire decode error: {}", err),
+        }
+    }
+}
+
+impl std::error::Error for WireDecodeError {}
+
+/// Explicit little-endian + fixed-width encoding for deterministic wire format.
+#[inline]
+pub fn wire_options() -> impl Options {
+    bincode::DefaultOptions::new()
+        .with_little_endian()
+        .with_fixint_encoding()
+}
+
+#[inline]
+pub fn encode_book_top24(
+    packet: &WireBookTop24,
+    out: &mut [u8; WIRE_BOOK_TOP24_SIZE],
+) -> Result<(), bincode::Error> {
+    let mut cursor = Cursor::new(out.as_mut_slice());
+    wire_options().serialize_into(&mut cursor, packet)
+}
+
+#[inline]
+pub fn decode_book_top24(
+    input: &[u8; WIRE_BOOK_TOP24_SIZE],
+) -> Result<WireBookTop24, bincode::Error> {
+    wire_options().deserialize(input.as_slice())
+}
+
+#[inline]
+pub fn encode_momentum_tick32(
+    packet: &WireMomentumTick32,
+    out: &mut [u8; WIRE_MOMENTUM_TICK32_SIZE],
+) -> Result<(), bincode::Error> {
+    let mut cursor = Cursor::new(out.as_mut_slice());
+    wire_options().serialize_into(&mut cursor, packet)
+}
+
+#[inline]
+pub fn decode_momentum_tick32(
+    input: &[u8; WIRE_MOMENTUM_TICK32_SIZE],
+) -> Result<WireMomentumTick32, bincode::Error> {
+    wire_options().deserialize(input.as_slice())
+}
+
+#[inline]
+pub fn encode_relay_tick40(
+    packet: &WireRelayTick40,
+    out: &mut [u8; WIRE_RELAY_TICK40_SIZE],
+) -> Result<(), bincode::Error> {
+    let mut cursor = Cursor::new(out.as_mut_slice());
+    wire_options().serialize_into(&mut cursor, packet)
+}
+
+#[inline]
+pub fn decode_relay_tick40(
+    input: &[u8; WIRE_RELAY_TICK40_SIZE],
+) -> Result<WireRelayTick40, bincode::Error> {
+    wire_options().deserialize(input.as_slice())
+}
+
+#[inline]
+pub fn decode_auto(input: &[u8]) -> Result<WirePacket, WireDecodeError> {
+    match input.len() {
+        WIRE_BOOK_TOP24_SIZE => {
+            let mut buf = [0u8; WIRE_BOOK_TOP24_SIZE];
+            buf.copy_from_slice(input);
+            decode_book_top24(&buf)
+                .map(WirePacket::BookTop24)
+                .map_err(WireDecodeError::Bincode)
+        }
+        WIRE_MOMENTUM_TICK32_SIZE => {
+            let mut buf = [0u8; WIRE_MOMENTUM_TICK32_SIZE];
+            buf.copy_from_slice(input);
+            decode_momentum_tick32(&buf)
+                .map(WirePacket::MomentumTick32)
+                .map_err(WireDecodeError::Bincode)
+        }
+        WIRE_RELAY_TICK40_SIZE => {
+            let mut buf = [0u8; WIRE_RELAY_TICK40_SIZE];
+            buf.copy_from_slice(input);
+            decode_relay_tick40(&buf)
+                .map(WirePacket::RelayTick40)
+                .map_err(WireDecodeError::Bincode)
+        }
+        other => Err(WireDecodeError::UnsupportedSize(other)),
+    }
+}
+
+#[inline]
+pub fn encode_with_mode(
+    packet24: &WireBookTop24,
+    velocity_bps_per_sec: f64,
+    ts_first_hop_ms: Option<i64>,
+    mode: WireMode,
+    out: &mut [u8; WIRE_MAX_PACKET_SIZE],
+) -> Result<usize, bincode::Error> {
+    match mode {
+        WireMode::Fixed24 => {
+            let mut view = [0u8; WIRE_BOOK_TOP24_SIZE];
+            encode_book_top24(packet24, &mut view)?;
+            out[..WIRE_BOOK_TOP24_SIZE].copy_from_slice(&view);
+            Ok(WIRE_BOOK_TOP24_SIZE)
+        }
+        WireMode::Fixed32 => {
+            let mut view = [0u8; WIRE_MOMENTUM_TICK32_SIZE];
+            let packet32 = WireMomentumTick32 {
+                ts_micros: packet24.ts_micros,
+                bid: packet24.bid,
+                ask: packet24.ask,
+                velocity_bps_per_sec,
+            };
+            encode_momentum_tick32(&packet32, &mut view)?;
+            out[..WIRE_MOMENTUM_TICK32_SIZE].copy_from_slice(&view);
+            Ok(WIRE_MOMENTUM_TICK32_SIZE)
+        }
+        WireMode::Auto => {
+            // Auto prefers the richer relay packet while receivers stay backward-compatible.
+            let mut view = [0u8; WIRE_RELAY_TICK40_SIZE];
+            let packet40 = WireRelayTick40 {
+                ts_micros: packet24.ts_micros,
+                bid: packet24.bid,
+                ask: packet24.ask,
+                velocity_bps_per_sec,
+                ts_first_hop_ms: ts_first_hop_ms
+                    .unwrap_or_else(|| (packet24.ts_micros / 1_000) as i64),
+            };
+            encode_relay_tick40(&packet40, &mut view)?;
+            out[..WIRE_RELAY_TICK40_SIZE].copy_from_slice(&view);
+            Ok(WIRE_RELAY_TICK40_SIZE)
+        }
+    }
+}
+
+/// Helper to get current micros
+pub fn now_micros() -> u64 {
+    std::time::SystemTime::now()
+        .duration_since(std::time::UNIX_EPOCH)
+        .unwrap_or_default()
+        .as_micros() as u64
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn wire_24_size_is_stable() {
+        let sample = WireBookTop24 {
+            ts_micros: 1,
+            bid: 100.25,
+            ask: 100.75,
+        };
+        let bytes = wire_options()
+            .serialize(&sample)
+            .expect("serialize WireBookTop24");
+        assert_eq!(bytes.len(), WIRE_BOOK_TOP24_SIZE);
+    }
+
+    #[test]
+    fn wire_24_roundtrip() {
+        let sample = WireBookTop24 {
+            ts_micros: 42,
+            bid: 61321.5,
+            ask: 61322.0,
+        };
+        let mut out = [0u8; WIRE_BOOK_TOP24_SIZE];
+        encode_book_top24(&sample, &mut out).expect("encode");
+        let decoded = decode_book_top24(&out).expect("decode");
+        assert_eq!(decoded, sample);
+    }
+
+    #[test]
+    fn wire_32_roundtrip() {
+        let sample = WireMomentumTick32 {
+            ts_micros: 42,
+            bid: 61321.5,
+            ask: 61322.0,
+            velocity_bps_per_sec: 7.5,
+        };
+        let mut out = [0u8; WIRE_MOMENTUM_TICK32_SIZE];
+        encode_momentum_tick32(&sample, &mut out).expect("encode 32");
+        let decoded = decode_momentum_tick32(&out).expect("decode 32");
+        assert_eq!(decoded, sample);
+    }
+
+    #[test]
+    fn wire_decode_auto_handles_24_and_32() {
+        let book24 = WireBookTop24 {
+            ts_micros: 10,
+            bid: 100.1,
+            ask: 100.2,
+        };
+        let mut raw24 = [0u8; WIRE_BOOK_TOP24_SIZE];
+        encode_book_top24(&book24, &mut raw24).expect("encode 24");
+        match decode_auto(&raw24).expect("decode auto 24") {
+            WirePacket::BookTop24(v) => assert_eq!(v, book24),
+            _ => panic!("expected WirePacket::BookTop24"),
+        }
+
+        let mut raw32 = [0u8; WIRE_MAX_PACKET_SIZE];
+        let n = encode_with_mode(&book24, 3.2, None, WireMode::Fixed32, &mut raw32)
+            .expect("encode mode");
+        assert_eq!(n, WIRE_MOMENTUM_TICK32_SIZE);
+        match decode_auto(&raw32[..n]).expect("decode auto 32") {
+            WirePacket::MomentumTick32(v) => {
+                assert_eq!(v.ts_micros, book24.ts_micros);
+                assert_eq!(v.bid, book24.bid);
+                assert_eq!(v.ask, book24.ask);
+                assert_eq!(v.velocity_bps_per_sec, 3.2);
+            }
+            _ => panic!("expected WirePacket::MomentumTick32"),
+        }
+
+        let mut raw40 = [0u8; WIRE_MAX_PACKET_SIZE];
+        let n = encode_with_mode(&book24, 5.4, Some(123456), WireMode::Auto, &mut raw40)
+            .expect("encode mode auto");
+        assert_eq!(n, WIRE_RELAY_TICK40_SIZE);
+        match decode_auto(&raw40[..n]).expect("decode auto 40") {
+            WirePacket::RelayTick40(v) => {
+                assert_eq!(v.ts_micros, book24.ts_micros);
+                assert_eq!(v.bid, book24.bid);
+                assert_eq!(v.ask, book24.ask);
+                assert_eq!(v.velocity_bps_per_sec, 5.4);
+                assert_eq!(v.ts_first_hop_ms, 123456);
+            }
+            _ => panic!("expected WirePacket::RelayTick40"),
+        }
+    }
+
+    #[test]
+    fn wire_mode_parse_default_auto() {
+        assert_eq!(WireMode::parse("24"), WireMode::Fixed24);
+        assert_eq!(WireMode::parse("32"), WireMode::Fixed32);
+        assert_eq!(WireMode::parse("auto"), WireMode::Auto);
+        assert_eq!(WireMode::parse("unknown"), WireMode::Auto);
+    }
+}
diff --git a/crates/portfolio/src/lib.rs b/crates/portfolio/src/lib.rs
index 05bcd6c..a69e40e 100644
--- a/crates/portfolio/src/lib.rs
+++ b/crates/portfolio/src/lib.rs
@@ -37,18 +37,22 @@ impl PortfolioBook {
                 pos.yes += fill.size;
             }
             OrderSide::SellYes => {
+                // Use min to prevent negative position: only close up to existing position
                 let closed = fill.size.min(pos.yes);
                 *self.realized.write() += (fill.price - pos.avg_yes) * closed - fill.fee;
-                pos.yes -= fill.size;
+                // Only reduce by actual closed amount, not full fill size
+                pos.yes = (pos.yes - closed).max(0.0);
             }
             OrderSide::BuyNo => {
                 pos.avg_no = weighted_avg(pos.avg_no, pos.no, fill.price, fill.size);
                 pos.no += fill.size;
             }
             OrderSide::SellNo => {
+                // Use min to prevent negative position: only close up to existing position
                 let closed = fill.size.min(pos.no);
                 *self.realized.write() += (fill.price - pos.avg_no) * closed - fill.fee;
-                pos.no -= fill.size;
+                // Only reduce by actual closed amount, not full fill size
+                pos.no = (pos.no - closed).max(0.0);
             }
         }
     }
@@ -57,9 +61,25 @@ impl PortfolioBook {
         self.positions.read().clone()
     }
 
-    pub fn snapshot(&self) -> PnLSnapshot {
+    /// Calculate unrealized PnL based on current market prices
+    /// If no prices provided, unrealized is treated as 0
+    pub fn snapshot_with_prices(&self, prices: &HashMap<String, f64>) -> PnLSnapshot {
         let realized = *self.realized.read();
-        let unrealized = 0.0;
+
+        // Calculate unrealized PnL using current market prices
+        let positions = self.positions.read();
+        let mut unrealized = 0.0;
+        for (market_id, pos) in positions.iter() {
+            if let Some(&current_price) = prices.get(market_id) {
+                // Unrealized = (current_price - avg_price) * position_size
+                // For yes position: (current - avg_yes) * yes
+                // For no position: (current - (1-avg_no)) * no = (avg_no - (1-current)) * no
+                unrealized += (current_price - pos.avg_yes).max(0.0) * pos.yes;
+                unrealized += ((1.0 - pos.avg_no) - (1.0 - current_price)).max(0.0) * pos.no;
+            }
+        }
+        drop(positions);
+
         let equity = realized + unrealized;
 
         let mut peak = self.equity_peak.write();
@@ -80,6 +100,11 @@ impl PortfolioBook {
             daily_pnl: equity,
         }
     }
+
+    /// Legacy snapshot without price info (unrealized = 0)
+    pub fn snapshot(&self) -> PnLSnapshot {
+        self.snapshot_with_prices(&HashMap::new())
+    }
 }
 
 fn weighted_avg(current_avg: f64, current_qty: f64, px: f64, qty: f64) -> f64 {
diff --git a/crates/probability_engine/Cargo.toml b/crates/probability_engine/Cargo.toml
new file mode 100644
index 0000000..7328ec1
--- /dev/null
+++ b/crates/probability_engine/Cargo.toml
@@ -0,0 +1,10 @@
+[package]
+name = "probability_engine"
+version.workspace = true
+edition.workspace = true
+license.workspace = true
+
+[dependencies]
+core_types = { path = "../core_types" }
+serde.workspace = true
+
diff --git a/crates/probability_engine/src/lib.rs b/crates/probability_engine/src/lib.rs
new file mode 100644
index 0000000..ee866f5
--- /dev/null
+++ b/crates/probability_engine/src/lib.rs
@@ -0,0 +1,208 @@
+use core_types::{Direction, DirectionSignal, ProbabilityEstimate, Signal};
+use serde::{Deserialize, Serialize};
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct ProbabilityEngineConfig {
+    pub momentum_gain: f64,
+    pub lag_penalty_per_ms: f64,
+    pub confidence_floor: f64,
+    /// Black-Scholes/GBM annualized sigma.
+    pub sigma_annual: f64,
+    /// Horizon for near-term digital direction probability.
+    pub horizon_sec: f64,
+    /// Base annualized drift component.
+    pub drift_annual: f64,
+    /// Scale from velocity (bps/s) to annualized drift component.
+    pub velocity_drift_gain: f64,
+    /// Scale from acceleration ((bps/s)/s) to annualized drift component.
+    pub acceleration_drift_gain: f64,
+    /// Blend weight for fair-value prior (0..1). Remaining weight uses BS/GBM model.
+    pub fair_blend_weight: f64,
+}
+
+impl Default for ProbabilityEngineConfig {
+    fn default() -> Self {
+        Self {
+            momentum_gain: 2.0,
+            lag_penalty_per_ms: 0.0002,
+            confidence_floor: 0.05,
+            sigma_annual: 0.90,
+            horizon_sec: 30.0,
+            drift_annual: 0.0,
+            velocity_drift_gain: 0.35,
+            acceleration_drift_gain: 0.02,
+            fair_blend_weight: 0.35,
+        }
+    }
+}
+
+#[derive(Debug, Clone)]
+pub struct ProbabilityEngine {
+    cfg: ProbabilityEngineConfig,
+}
+
+impl Default for ProbabilityEngine {
+    fn default() -> Self {
+        Self::new(ProbabilityEngineConfig::default())
+    }
+}
+
+impl ProbabilityEngine {
+    pub fn new(cfg: ProbabilityEngineConfig) -> Self {
+        Self { cfg }
+    }
+
+    pub fn cfg(&self) -> &ProbabilityEngineConfig {
+        &self.cfg
+    }
+
+    pub fn set_cfg(&mut self, cfg: ProbabilityEngineConfig) {
+        self.cfg = cfg;
+    }
+
+    pub fn estimate(
+        &self,
+        signal: &Signal,
+        direction_signal: &DirectionSignal,
+        settlement_prob_yes: Option<f64>,
+        book_top_lag_ms: f64,
+        now_ms: i64,
+    ) -> ProbabilityEstimate {
+        let base_fast = signal.fair_yes.clamp(0.0, 1.0);
+        let p_bs = bs_directional_probability(direction_signal, &self.cfg);
+        let blend_w = self.cfg.fair_blend_weight.clamp(0.0, 1.0);
+        let p_fast = ((base_fast * blend_w) + (p_bs * (1.0 - blend_w))).clamp(0.0, 1.0);
+        let p_settle = settlement_prob_yes.unwrap_or(p_fast).clamp(0.0, 1.0);
+
+        let lag_penalty = (book_top_lag_ms.max(0.0) * self.cfg.lag_penalty_per_ms).clamp(0.0, 0.60);
+        let settle_alignment = 1.0 - (p_fast - p_settle).abs().min(1.0);
+        let confidence = (direction_signal.confidence * settle_alignment - lag_penalty)
+            .clamp(self.cfg.confidence_floor, 1.0);
+
+        ProbabilityEstimate {
+            p_fast,
+            p_settle,
+            confidence,
+            settlement_source_degraded: settlement_prob_yes.is_none(),
+            ts_ms: now_ms,
+        }
+    }
+}
+
+#[inline]
+fn bs_directional_probability(
+    direction_signal: &DirectionSignal,
+    cfg: &ProbabilityEngineConfig,
+) -> f64 {
+    const SEC_PER_YEAR: f64 = 31_536_000.0;
+    let t = (cfg.horizon_sec.max(0.1) / SEC_PER_YEAR).clamp(1e-9, 1.0);
+    let sigma = cfg.sigma_annual.max(1e-6);
+    let sign = match direction_signal.direction {
+        Direction::Up => 1.0,
+        Direction::Down => -1.0,
+        Direction::Neutral => 0.0,
+    };
+    let momentum_component =
+        sign * (direction_signal.magnitude_pct.abs() / 100.0) * cfg.momentum_gain * 0.25;
+    let velocity_component =
+        sign * (direction_signal.velocity_bps_per_sec / 10_000.0) * cfg.velocity_drift_gain;
+    let acceleration_component =
+        sign * (direction_signal.acceleration / 10_000.0) * cfg.acceleration_drift_gain;
+    let drift = cfg.drift_annual + momentum_component + velocity_component + acceleration_component;
+    let denom = sigma * t.sqrt();
+    let d2 = ((drift - 0.5 * sigma * sigma) * t) / denom.max(1e-9);
+    normal_cdf(d2)
+}
+
+#[inline]
+fn normal_cdf(x: f64) -> f64 {
+    0.5 * (1.0 + erf_approx(x / std::f64::consts::SQRT_2))
+}
+
+// Abramowitz and Stegun 7.1.26 approximation, sufficient for strategy gating.
+#[inline]
+fn erf_approx(x: f64) -> f64 {
+    let sign = if x < 0.0 { -1.0 } else { 1.0 };
+    let x = x.abs();
+    let t = 1.0 / (1.0 + 0.327_591_1 * x);
+    let a1 = 0.254_829_592;
+    let a2 = -0.284_496_736;
+    let a3 = 1.421_413_741;
+    let a4 = -1.453_152_027;
+    let a5 = 1.061_405_429;
+    let y = 1.0 - (((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t * (-x * x).exp());
+    sign * y
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use core_types::{Direction, TimeframeClass};
+
+    fn signal() -> Signal {
+        Signal {
+            market_id: "m1".to_string(),
+            fair_yes: 0.52,
+            edge_bps_bid: 0.0,
+            edge_bps_ask: 0.0,
+            confidence: 0.7,
+        }
+    }
+
+    fn direction(up: bool) -> DirectionSignal {
+        DirectionSignal {
+            symbol: "BTCUSDT".to_string(),
+            direction: if up { Direction::Up } else { Direction::Down },
+            magnitude_pct: 0.40,
+            confidence: 0.9,
+            recommended_tf: TimeframeClass::Tf15m,
+            velocity_bps_per_sec: 6.0,
+            acceleration: 0.7,
+            tick_consistency: 3,
+            triple_confirm: true,
+            momentum_spike: false,
+            ts_ns: 1,
+        }
+    }
+
+    #[test]
+    fn estimate_marks_degraded_when_settlement_missing() {
+        let engine = ProbabilityEngine::default();
+        let p = engine.estimate(&signal(), &direction(true), None, 10.0, 123);
+        assert!(p.settlement_source_degraded);
+        assert!((0.0..=1.0).contains(&p.p_fast));
+        assert!((0.0..=1.0).contains(&p.p_settle));
+    }
+
+    #[test]
+    fn estimate_uses_settlement_when_provided() {
+        let engine = ProbabilityEngine::default();
+        let p = engine.estimate(&signal(), &direction(true), Some(0.61), 5.0, 123);
+        assert!(!p.settlement_source_degraded);
+        assert!((p.p_settle - 0.61).abs() < 1e-9);
+    }
+
+    #[test]
+    fn lag_penalty_reduces_confidence() {
+        let engine = ProbabilityEngine::default();
+        let p_low = engine.estimate(&signal(), &direction(true), None, 2.0, 123);
+        let p_high = engine.estimate(&signal(), &direction(true), None, 200.0, 123);
+        assert!(p_high.confidence < p_low.confidence);
+    }
+
+    #[test]
+    fn bs_probability_respects_direction() {
+        let engine = ProbabilityEngine::default();
+        let p_up = engine.estimate(&signal(), &direction(true), None, 5.0, 123);
+        let p_dn = engine.estimate(&signal(), &direction(false), None, 5.0, 123);
+        assert!(p_up.p_fast > p_dn.p_fast);
+    }
+
+    #[test]
+    fn confidence_penalized_when_settlement_diverges() {
+        let engine = ProbabilityEngine::default();
+        let aligned = engine.estimate(&signal(), &direction(true), Some(0.60), 5.0, 123);
+        let diverged = engine.estimate(&signal(), &direction(true), Some(0.10), 5.0, 123);
+        assert!(diverged.confidence < aligned.confidence);
+    }
+}
diff --git a/crates/replay_engine/src/lib.rs b/crates/replay_engine/src/lib.rs
index e98e921..1ceb453 100644
--- a/crates/replay_engine/src/lib.rs
+++ b/crates/replay_engine/src/lib.rs
@@ -99,8 +99,11 @@ mod tests {
                     symbol: "BTCUSDT".to_string(),
                     event_ts_ms: 1,
                     recv_ts_ms: 1,
+                    source_seq: 0,
                     event_ts_exchange_ms: 1,
                     recv_ts_local_ns: 1_000_000,
+                    ingest_ts_local_ns: 1_000_000,
+                    ts_first_hop_ms: None,
                     price: 1.0,
                 }),
             })
diff --git a/crates/risk_engine/src/lib.rs b/crates/risk_engine/src/lib.rs
index 4414f7e..67d2fe9 100644
--- a/crates/risk_engine/src/lib.rs
+++ b/crates/risk_engine/src/lib.rs
@@ -11,6 +11,11 @@ pub struct RiskLimits {
     pub max_drawdown_pct: f64,
     pub max_loss_streak: u32,
     pub cooldown_sec: u64,
+    pub progressive_enabled: bool,
+    pub drawdown_tier1_ratio: f64,
+    pub drawdown_tier2_ratio: f64,
+    pub tier1_size_scale: f64,
+    pub tier2_size_scale: f64,
 }
 
 impl Default for RiskLimits {
@@ -22,6 +27,11 @@ impl Default for RiskLimits {
             max_drawdown_pct: 0.015,
             max_loss_streak: 5,
             cooldown_sec: 60,
+            progressive_enabled: true,
+            drawdown_tier1_ratio: 0.50,
+            drawdown_tier2_ratio: 0.80,
+            tier1_size_scale: 0.70,
+            tier2_size_scale: 0.40,
         }
     }
 }
@@ -47,40 +57,68 @@ impl DefaultRiskManager {
 
 impl RiskManager for DefaultRiskManager {
     fn evaluate(&self, ctx: &RiskContext) -> RiskDecision {
-        let limits = self
-            .limits
-            .read()
-            .map(|g| g.clone())
-            .unwrap_or_else(|_| RiskLimits::default());
-
-        let now_ms = ctx.now_ms;
-
-        // Cooldown gate (e.g. after a loss streak trigger).
-        if let Ok(st) = self.state.lock() {
-            if now_ms > 0 && now_ms < st.cooldown_until_ms {
+        let limits = match self.limits.read() {
+            Ok(guard) => guard.clone(),
+            Err(_) => {
+                // Lock poisoned - fail closed for safety
                 return RiskDecision {
                     allow: false,
-                    reason: "cooldown".to_string(),
+                    reason: "risk_lock_poisoned".to_string(),
                     capped_size: 0.0,
                 };
             }
+        };
+
+        let now_ms = ctx.now_ms;
+
+        // Cooldown gate (e.g. after a loss streak trigger).
+        let cooldown_active = self
+            .state
+            .lock()
+            .map(|st| now_ms > 0 && now_ms < st.cooldown_until_ms)
+            .unwrap_or(false); // Fail closed if lock fails
+
+        if cooldown_active {
+            return RiskDecision {
+                allow: false,
+                reason: "cooldown".to_string(),
+                capped_size: 0.0,
+            };
         }
 
-        // Hard drawdown stop.
-        if ctx.drawdown_pct >= limits.max_drawdown_pct {
+        let drawdown_abs = ctx.drawdown_pct.abs();
+        // Hard drawdown stop - use abs to handle negative drawdown values
+        if drawdown_abs >= limits.max_drawdown_pct {
             return RiskDecision {
                 allow: false,
                 reason: "drawdown_stop".to_string(),
                 capped_size: 0.0,
             };
         }
+        let mut progressive_scale: f64 = 1.0;
+        let mut progressive_reason: Option<&'static str> = None;
+        if limits.progressive_enabled && limits.max_drawdown_pct > 0.0 {
+            let tier1 = limits.max_drawdown_pct * limits.drawdown_tier1_ratio.clamp(0.05, 0.99);
+            let tier2 = limits.max_drawdown_pct
+                * limits
+                    .drawdown_tier2_ratio
+                    .clamp(limits.drawdown_tier1_ratio.clamp(0.05, 0.99), 0.999);
+            if drawdown_abs >= tier2 {
+                progressive_scale = progressive_scale.min(limits.tier2_size_scale.clamp(0.01, 1.0));
+                progressive_reason = Some("drawdown_tier2");
+            } else if drawdown_abs >= tier1 {
+                progressive_scale = progressive_scale.min(limits.tier1_size_scale.clamp(0.01, 1.0));
+                progressive_reason = Some("drawdown_tier1");
+            }
+        }
 
         // Loss streak stop: once tripped, enter cooldown window.
         if ctx.loss_streak >= limits.max_loss_streak && limits.max_loss_streak > 0 {
             if let Ok(mut st) = self.state.lock() {
                 if now_ms > 0 {
+                    // Start cooldown window from "now", not from previous value.
                     st.cooldown_until_ms =
-                        st.cooldown_until_ms.max(now_ms + (limits.cooldown_sec as i64) * 1_000);
+                        now_ms.saturating_add((limits.cooldown_sec as i64).saturating_mul(1_000));
                 }
             }
             return RiskDecision {
@@ -102,23 +140,28 @@ impl RiskManager for DefaultRiskManager {
         // Notional caps. RiskContext carries precomputed notional in USDC.
         let proposed_notional = ctx.proposed_notional_usdc.max(0.0);
 
-        if ctx.market_notional + proposed_notional > limits.max_market_notional {
-            let remaining = (limits.max_market_notional - ctx.market_notional).max(0.0);
+        // Normalize existing notional to handle potential negative values
+        let market_notional = ctx.market_notional.max(0.0);
+        let asset_notional = ctx.asset_notional.max(0.0);
+
+        if market_notional + proposed_notional > limits.max_market_notional {
+            let remaining = (limits.max_market_notional - market_notional).max(0.0);
             let capped_size = if proposed_notional <= 0.0 {
                 0.0
             } else {
                 // Scale down size proportionally; caller uses it as a cap.
+                // Use epsilon to prevent division by zero
                 (ctx.proposed_size * (remaining / proposed_notional)).max(0.0)
             };
             return RiskDecision {
                 allow: capped_size > 0.0,
                 reason: "market_notional_limit".to_string(),
-                capped_size,
+                capped_size: (capped_size * progressive_scale).max(0.0),
             };
         }
 
-        if ctx.asset_notional + proposed_notional > limits.max_asset_notional {
-            let remaining = (limits.max_asset_notional - ctx.asset_notional).max(0.0);
+        if asset_notional + proposed_notional > limits.max_asset_notional {
+            let remaining = (limits.max_asset_notional - asset_notional).max(0.0);
             let capped_size = if proposed_notional <= 0.0 {
                 0.0
             } else {
@@ -127,15 +170,106 @@ impl RiskManager for DefaultRiskManager {
             return RiskDecision {
                 allow: capped_size > 0.0,
                 reason: "asset_notional_limit".to_string(),
-                capped_size,
+                capped_size: (capped_size * progressive_scale).max(0.0),
             };
         }
 
+        let capped = (ctx.proposed_size.max(0.0) * progressive_scale).max(0.0);
         RiskDecision {
-            allow: true,
-            reason: "ok".to_string(),
-            capped_size: ctx.proposed_size.max(0.0),
+            allow: capped > 0.0,
+            reason: progressive_reason.unwrap_or("ok").to_string(),
+            capped_size: capped,
         }
     }
 }
 
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    fn ctx(now_ms: i64) -> RiskContext {
+        RiskContext {
+            market_id: "m1".to_string(),
+            symbol: "BTCUSDT".to_string(),
+            order_count: 0,
+            proposed_size: 1.0,
+            proposed_notional_usdc: 1.0,
+            market_notional: 0.0,
+            asset_notional: 0.0,
+            drawdown_pct: 0.0,
+            loss_streak: 0,
+            now_ms,
+        }
+    }
+
+    #[test]
+    fn loss_streak_sets_cooldown_from_current_time() {
+        let limits = Arc::new(RwLock::new(RiskLimits {
+            max_loss_streak: 1,
+            cooldown_sec: 60,
+            ..RiskLimits::default()
+        }));
+        let rm = DefaultRiskManager::new(limits);
+
+        let mut tripped = ctx(1_000_000);
+        tripped.loss_streak = 1;
+        let d = rm.evaluate(&tripped);
+        assert!(!d.allow);
+        assert_eq!(d.reason, "loss_streak");
+
+        // Should be blocked by cooldown at +59s.
+        let d = rm.evaluate(&ctx(1_059_000));
+        assert!(!d.allow);
+        assert_eq!(d.reason, "cooldown");
+
+        // Cooldown should end at +60s.
+        let d = rm.evaluate(&ctx(1_060_000));
+        assert!(d.allow);
+        assert_eq!(d.reason, "ok");
+    }
+
+    #[test]
+    fn notional_cap_scales_size_proportionally() {
+        let limits = Arc::new(RwLock::new(RiskLimits {
+            max_market_notional: 10.0,
+            ..RiskLimits::default()
+        }));
+        let rm = DefaultRiskManager::new(limits);
+        let d = rm.evaluate(&RiskContext {
+            market_notional: 8.0,
+            proposed_notional_usdc: 4.0,
+            proposed_size: 2.0,
+            ..ctx(1_000_000)
+        });
+        assert!(d.allow);
+        // Remaining notional is 2.0 out of requested 4.0 => 50% size cap.
+        assert!((d.capped_size - 1.0).abs() < 1e-9);
+    }
+
+    #[test]
+    fn progressive_drawdown_scales_size_before_hard_stop() {
+        let limits = Arc::new(RwLock::new(RiskLimits {
+            max_drawdown_pct: 0.20,
+            drawdown_tier1_ratio: 0.50,
+            drawdown_tier2_ratio: 0.80,
+            tier1_size_scale: 0.70,
+            tier2_size_scale: 0.40,
+            progressive_enabled: true,
+            ..RiskLimits::default()
+        }));
+        let rm = DefaultRiskManager::new(limits);
+        let mut low = ctx(1_000_000);
+        low.drawdown_pct = 0.11;
+        let d_low = rm.evaluate(&low);
+        assert!(d_low.allow);
+        assert_eq!(d_low.reason, "drawdown_tier1");
+        assert!((d_low.capped_size - 0.70).abs() < 1e-9);
+
+        let mut high = ctx(1_000_100);
+        high.drawdown_pct = 0.17;
+        let d_high = rm.evaluate(&high);
+        assert!(d_high.allow);
+        assert_eq!(d_high.reason, "drawdown_tier2");
+        assert!((d_high.capped_size - 0.40).abs() < 1e-9);
+    }
+}
diff --git a/crates/settlement_compounder/Cargo.toml b/crates/settlement_compounder/Cargo.toml
new file mode 100644
index 0000000..730072c
--- /dev/null
+++ b/crates/settlement_compounder/Cargo.toml
@@ -0,0 +1,10 @@
+[package]
+name = "settlement_compounder"
+version.workspace = true
+edition.workspace = true
+license.workspace = true
+
+[dependencies]
+core_types = { path = "../core_types" }
+serde.workspace = true
+
diff --git a/crates/settlement_compounder/src/lib.rs b/crates/settlement_compounder/src/lib.rs
new file mode 100644
index 0000000..13615ef
--- /dev/null
+++ b/crates/settlement_compounder/src/lib.rs
@@ -0,0 +1,274 @@
+use core_types::CapitalUpdate;
+use serde::{Deserialize, Serialize};
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct CompounderConfig {
+    pub enabled: bool,
+    pub initial_capital_usdc: f64,
+    /// Share of profits to compound (1.0 = 100%).
+    pub compound_ratio: f64,
+    /// Recommended per-order notional = available * position_fraction (bounded by min_quote_size).
+    pub position_fraction: f64,
+    /// Minimum per-order notional in USDC.
+    pub min_quote_size: f64,
+    /// Hard-stop threshold (USDC). If daily_pnl <= -cap, compounder marks halted.
+    pub daily_loss_cap_usdc: f64,
+}
+
+impl Default for CompounderConfig {
+    fn default() -> Self {
+        Self {
+            enabled: false,
+            initial_capital_usdc: 100.0,
+            compound_ratio: 1.0,
+            position_fraction: 0.15,
+            min_quote_size: 1.0,
+            daily_loss_cap_usdc: 1.0,
+        }
+    }
+}
+
+#[derive(Debug)]
+pub struct SettlementCompounder {
+    cfg: CompounderConfig,
+    available_usdc: f64,
+    initial_usdc: f64,
+    total_pnl: f64,
+    daily_pnl: f64,
+    daily_epoch_day: i64,
+    win_count: u64,
+    loss_count: u64,
+    halted: bool,
+}
+
+impl SettlementCompounder {
+    pub fn new(cfg: CompounderConfig) -> Self {
+        let initial = cfg.initial_capital_usdc.max(0.0);
+        let now = now_ms();
+        Self {
+            cfg,
+            available_usdc: initial,
+            initial_usdc: initial,
+            total_pnl: 0.0,
+            daily_pnl: 0.0,
+            daily_epoch_day: epoch_day_from_ms(now),
+            win_count: 0,
+            loss_count: 0,
+            halted: false,
+        }
+    }
+
+    pub fn cfg(&self) -> &CompounderConfig {
+        &self.cfg
+    }
+
+    pub fn set_cfg(&mut self, mut cfg: CompounderConfig) {
+        // Validate and clamp config values to valid ranges
+        cfg.compound_ratio = cfg.compound_ratio.clamp(0.0, 1.0);
+        cfg.position_fraction = cfg.position_fraction.clamp(0.0, 1.0);
+        cfg.min_quote_size = cfg.min_quote_size.max(0.0);
+        cfg.daily_loss_cap_usdc = cfg.daily_loss_cap_usdc.max(0.0);
+        self.cfg = cfg;
+        if self.initial_usdc <= 0.0 {
+            self.initial_usdc = self.cfg.initial_capital_usdc.max(0.0);
+        }
+    }
+
+    pub fn available(&self) -> f64 {
+        self.available_usdc
+    }
+
+    pub fn total_pnl(&self) -> f64 {
+        self.total_pnl
+    }
+
+    pub fn daily_pnl(&self) -> f64 {
+        self.daily_pnl
+    }
+
+    pub fn win_rate(&self) -> f64 {
+        let total = self.win_count + self.loss_count;
+        if total == 0 {
+            0.0
+        } else {
+            (self.win_count as f64 / total as f64).clamp(0.0, 1.0)
+        }
+    }
+
+    pub fn halted(&self) -> bool {
+        self.halted
+    }
+
+    pub fn recommended_quote_notional_usdc(&self) -> f64 {
+        if !self.cfg.enabled {
+            return 0.0;
+        }
+        (self.available_usdc.max(0.0) * self.cfg.position_fraction.clamp(0.0, 1.0))
+            .max(self.cfg.min_quote_size.max(0.0))
+    }
+
+    pub fn on_markout(&mut self, pnl_usdc: f64) -> CapitalUpdate {
+        let ts_ms = now_ms();
+        self.on_markout_at(pnl_usdc, ts_ms)
+    }
+
+    fn on_markout_at(&mut self, pnl_usdc: f64, ts_ms: i64) -> CapitalUpdate {
+        self.rollover_day_if_needed(ts_ms);
+        if !self.cfg.enabled {
+            return CapitalUpdate {
+                available_usdc: self.available_usdc,
+                base_quote_size: 0.0,
+                ts_ms,
+            };
+        }
+
+        self.total_pnl += pnl_usdc;
+        self.daily_pnl += pnl_usdc;
+
+        if pnl_usdc > 0.0 {
+            self.win_count = self.win_count.saturating_add(1);
+            self.available_usdc += pnl_usdc * self.cfg.compound_ratio.clamp(0.0, 1.0);
+        } else if pnl_usdc < 0.0 {
+            self.loss_count = self.loss_count.saturating_add(1);
+            self.available_usdc += pnl_usdc;
+        }
+
+        if self.available_usdc < 0.0 {
+            self.available_usdc = 0.0;
+        }
+
+        if self.cfg.daily_loss_cap_usdc > 0.0 && self.daily_pnl <= -self.cfg.daily_loss_cap_usdc {
+            self.halted = true;
+        }
+
+        CapitalUpdate {
+            available_usdc: self.available_usdc,
+            base_quote_size: self.recommended_quote_notional_usdc(),
+            ts_ms,
+        }
+    }
+
+    pub fn reset_daily(&mut self) {
+        self.daily_pnl = 0.0;
+        self.halted = false;
+        self.daily_epoch_day = epoch_day_from_ms(now_ms());
+    }
+
+    fn rollover_day_if_needed(&mut self, ts_ms: i64) {
+        let day = epoch_day_from_ms(ts_ms);
+        if day != self.daily_epoch_day {
+            self.daily_pnl = 0.0;
+            self.halted = false;
+            self.daily_epoch_day = day;
+        }
+    }
+}
+
+fn now_ms() -> i64 {
+    use std::time::{SystemTime, UNIX_EPOCH};
+    SystemTime::now()
+        .duration_since(UNIX_EPOCH)
+        .ok()
+        .map(|d| d.as_millis() as i64)
+        .unwrap_or(0)
+}
+
+#[inline]
+fn epoch_day_from_ms(ts_ms: i64) -> i64 {
+    ts_ms.div_euclid(86_400_000)
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn compound_increases_available() {
+        let mut c = SettlementCompounder::new(CompounderConfig {
+            enabled: true,
+            initial_capital_usdc: 100.0,
+            compound_ratio: 1.0,
+            position_fraction: 0.15,
+            min_quote_size: 1.0,
+            daily_loss_cap_usdc: 0.0,
+        });
+        let u = c.on_markout(10.0);
+        assert!((u.available_usdc - 110.0).abs() < 1e-9);
+    }
+
+    #[test]
+    fn loss_decreases_available() {
+        let mut c = SettlementCompounder::new(CompounderConfig {
+            enabled: true,
+            initial_capital_usdc: 100.0,
+            compound_ratio: 1.0,
+            position_fraction: 0.15,
+            min_quote_size: 1.0,
+            daily_loss_cap_usdc: 0.0,
+        });
+        let u = c.on_markout(-20.0);
+        assert!((u.available_usdc - 80.0).abs() < 1e-9);
+    }
+
+    #[test]
+    fn quote_notional_scales_with_capital() {
+        let c = SettlementCompounder::new(CompounderConfig {
+            enabled: true,
+            initial_capital_usdc: 200.0,
+            compound_ratio: 1.0,
+            position_fraction: 0.15,
+            min_quote_size: 1.0,
+            daily_loss_cap_usdc: 0.0,
+        });
+        assert!((c.recommended_quote_notional_usdc() - 30.0).abs() < 1e-9);
+    }
+
+    #[test]
+    fn halt_on_daily_cap() {
+        let mut c = SettlementCompounder::new(CompounderConfig {
+            enabled: true,
+            initial_capital_usdc: 100.0,
+            compound_ratio: 1.0,
+            position_fraction: 0.15,
+            min_quote_size: 1.0,
+            daily_loss_cap_usdc: 10.0,
+        });
+        c.on_markout(-11.0);
+        assert!(c.halted());
+    }
+
+    #[test]
+    fn never_negative_available() {
+        let mut c = SettlementCompounder::new(CompounderConfig {
+            enabled: true,
+            initial_capital_usdc: 5.0,
+            compound_ratio: 1.0,
+            position_fraction: 0.15,
+            min_quote_size: 1.0,
+            daily_loss_cap_usdc: 0.0,
+        });
+        c.on_markout(-20.0);
+        assert!(c.available() >= 0.0);
+    }
+
+    #[test]
+    fn daily_halt_auto_recovers_after_day_rollover() {
+        let mut c = SettlementCompounder::new(CompounderConfig {
+            enabled: true,
+            initial_capital_usdc: 100.0,
+            compound_ratio: 1.0,
+            position_fraction: 0.15,
+            min_quote_size: 1.0,
+            daily_loss_cap_usdc: 10.0,
+        });
+
+        // Day 0: trigger halt.
+        let _ = c.on_markout_at(-11.0, 1_000);
+        assert!(c.halted());
+
+        // Day 1: a new markout should roll daily state and clear halt.
+        let _ = c.on_markout_at(1.0, 86_400_000 + 2_000);
+        assert!(!c.halted());
+        assert!(c.daily_pnl() > 0.0);
+    }
+}
diff --git a/crates/strategy_maker/src/lib.rs b/crates/strategy_maker/src/lib.rs
index 94a5407..7144c61 100644
--- a/crates/strategy_maker/src/lib.rs
+++ b/crates/strategy_maker/src/lib.rs
@@ -30,7 +30,8 @@ impl Default for MakerConfig {
             ttl_ms: 400,
             taker_trigger_bps: 8.0,
             taker_max_slippage_bps: 25.0,
-            stale_tick_filter_ms: 2_000.0,
+            // SEAT Latency Fabric v1.0: æ›´æ¿€è¿›çš„è¿‡æœŸè¿‡æ»¤
+            stale_tick_filter_ms: 120.0, // ä»Ž 2000ms é™åˆ° 120ms
             market_tier_profile: "balanced".to_string(),
             capital_fraction_kelly: 0.35,
             variance_penalty_lambda: 0.25,
diff --git a/crates/taker_sniper/Cargo.toml b/crates/taker_sniper/Cargo.toml
new file mode 100644
index 0000000..a7327ed
--- /dev/null
+++ b/crates/taker_sniper/Cargo.toml
@@ -0,0 +1,10 @@
+[package]
+name = "taker_sniper"
+version.workspace = true
+edition.workspace = true
+license.workspace = true
+
+[dependencies]
+core_types = { path = "../core_types" }
+serde.workspace = true
+
diff --git a/crates/taker_sniper/src/lib.rs b/crates/taker_sniper/src/lib.rs
new file mode 100644
index 0000000..5af4a4e
--- /dev/null
+++ b/crates/taker_sniper/src/lib.rs
@@ -0,0 +1,754 @@
+use std::collections::HashMap;
+
+use core_types::{Direction, DirectionSignal, TimeframeClass, TimeframeOpp};
+use serde::{Deserialize, Serialize};
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]
+pub struct SymbolGatlingConfig {
+    #[serde(default)]
+    pub enabled: Option<bool>,
+    #[serde(default)]
+    pub chunk_notional_usdc: Option<f64>,
+    #[serde(default)]
+    pub min_chunks: Option<usize>,
+    #[serde(default)]
+    pub max_chunks: Option<usize>,
+    #[serde(default)]
+    pub spacing_ms: Option<u64>,
+    #[serde(default)]
+    pub stop_on_reject: Option<bool>,
+}
+
+#[derive(Debug, Clone, Copy)]
+struct GatlingResolved {
+    enabled: bool,
+    chunk_notional_usdc: f64,
+    min_chunks: usize,
+    max_chunks: usize,
+    spacing_ms: u64,
+    stop_on_reject: bool,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct TakerSniperConfig {
+    pub min_direction_confidence: f64,
+    pub min_edge_net_bps: f64,
+    pub max_spread: f64,
+    pub cooldown_ms_per_market: u64,
+    pub gatling_enabled: bool,
+    pub gatling_chunk_notional_usdc: f64,
+    pub gatling_min_chunks: usize,
+    pub gatling_max_chunks: usize,
+    pub gatling_spacing_ms: u64,
+    pub gatling_stop_on_reject: bool,
+    #[serde(default)]
+    pub gatling_by_symbol: HashMap<String, SymbolGatlingConfig>,
+    /// Minimum quality score (0..100) required to fire.
+    /// Score = signal (0..40) + market (0..35) + timing (0..25).
+    #[serde(default = "default_min_win_rate_score")]
+    pub min_win_rate_score: f64,
+}
+
+fn default_min_win_rate_score() -> f64 {
+    55.0
+}
+
+impl Default for TakerSniperConfig {
+    fn default() -> Self {
+        Self {
+            min_direction_confidence: 0.60,
+            // Conservative default for taker path; config can override this.
+            min_edge_net_bps: 200.0,
+            max_spread: 0.08,
+            cooldown_ms_per_market: 800,
+            gatling_enabled: true,
+            gatling_chunk_notional_usdc: 5.0,
+            gatling_min_chunks: 1,
+            gatling_max_chunks: 4,
+            gatling_spacing_ms: 12,
+            gatling_stop_on_reject: true,
+            gatling_by_symbol: HashMap::new(),
+            min_win_rate_score: 55.0,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub enum TakerAction {
+    Fire,
+    Skip,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct FireChunk {
+    pub size: f64,
+    pub send_delay_ms: u64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct FirePlan {
+    pub opportunity: TimeframeOpp,
+    pub chunks: Vec<FireChunk>,
+    pub stop_on_reject: bool,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct TakerDecision {
+    pub action: TakerAction,
+    pub fire_plan: Option<FirePlan>,
+    pub reason: String,
+}
+
+// Inputs for a single taker decision.
+#[derive(Debug, Clone)]
+pub struct EvaluateCtx<'a> {
+    pub market_id: &'a str,
+    pub symbol: &'a str,
+    pub timeframe: TimeframeClass,
+    pub direction_signal: &'a DirectionSignal,
+    pub entry_price: f64,
+    pub spread: f64,
+    pub fee_bps: f64,
+    pub edge_gross_bps: f64,
+    pub edge_net_bps: f64,
+    pub size: f64,
+    pub now_ms: i64,
+}
+
+#[derive(Debug)]
+pub struct TakerSniper {
+    cfg: TakerSniperConfig,
+    last_fire_ms_by_market: HashMap<String, i64>,
+}
+
+impl TakerSniper {
+    pub fn new(cfg: TakerSniperConfig) -> Self {
+        Self {
+            cfg,
+            last_fire_ms_by_market: HashMap::new(),
+        }
+    }
+
+    pub fn cfg(&self) -> &TakerSniperConfig {
+        &self.cfg
+    }
+
+    pub fn set_cfg(&mut self, cfg: TakerSniperConfig) {
+        self.cfg = cfg;
+    }
+
+    pub fn evaluate(&mut self, ctx: &EvaluateCtx<'_>) -> TakerDecision {
+        if matches!(ctx.direction_signal.direction, Direction::Neutral) {
+            return skip_static("neutral_direction");
+        }
+        if ctx.direction_signal.confidence < self.cfg.min_direction_confidence {
+            return skip_static("low_confidence");
+        }
+        if ctx.entry_price <= 0.0 {
+            return skip_static("bad_price");
+        }
+        if ctx.spread > self.cfg.max_spread {
+            return skip_static("spread_too_wide");
+        }
+        let dynamic_min_edge =
+            dynamic_fee_gate_min_edge_bps(ctx.entry_price, ctx.direction_signal.confidence);
+        let min_edge_required = self.cfg.min_edge_net_bps.max(dynamic_min_edge);
+        if ctx.edge_net_bps < min_edge_required {
+            return skip_static("fee_gate_too_expensive");
+        }
+        if ctx.size <= 0.0 {
+            return skip_static("size_zero");
+        }
+        if self.cfg.cooldown_ms_per_market > 0 {
+            if let Some(last) = self.last_fire_ms_by_market.get(ctx.market_id) {
+                let age = ctx.now_ms.saturating_sub(*last);
+                if (age as u64) < self.cfg.cooldown_ms_per_market {
+                    return skip_static("cooldown_active");
+                }
+            }
+        }
+
+        // Quality gate: skip weak opportunities.
+        if self.cfg.min_win_rate_score > 0.0 {
+            let score = compute_win_rate_score(ctx);
+            if score < self.cfg.min_win_rate_score {
+                return skip_dynamic(format!("win_rate_score_too_low:{score:.1}"));
+            }
+        }
+
+        let lock_minutes = lock_minutes_for_timeframe(&ctx.timeframe);
+        let notional_usdc = (ctx.entry_price.max(0.0) * ctx.size.max(0.0)).max(0.0);
+        let edge_net_usdc = (ctx.edge_net_bps / 10_000.0) * notional_usdc;
+        let density = if lock_minutes <= 0.0 {
+            0.0
+        } else {
+            edge_net_usdc / lock_minutes
+        };
+        let opp = TimeframeOpp {
+            timeframe: ctx.timeframe.clone(),
+            market_id: ctx.market_id.to_string(),
+            symbol: ctx.symbol.to_string(),
+            direction: ctx.direction_signal.direction.clone(),
+            side: direction_to_side(&ctx.direction_signal.direction),
+            entry_price: ctx.entry_price,
+            size: ctx.size,
+            edge_gross_bps: ctx.edge_gross_bps,
+            edge_net_bps: ctx.edge_net_bps,
+            edge_net_usdc,
+            fee_bps: ctx.fee_bps,
+            lock_minutes,
+            density,
+            confidence: ctx.direction_signal.confidence,
+            ts_ms: ctx.now_ms,
+        };
+        self.last_fire_ms_by_market
+            .insert(ctx.market_id.to_string(), ctx.now_ms);
+        let gatling = self.cfg.gatling_for_symbol(ctx.symbol);
+        let fire_plan = build_fire_plan(&gatling, opp);
+        TakerDecision {
+            action: TakerAction::Fire,
+            fire_plan: Some(fire_plan),
+            reason: "fire".to_string(),
+        }
+    }
+}
+
+// ============================================================
+// skip è¾…åŠ©å‡½æ•° â€” ä¸¤ä¸ªç‰ˆæœ¬æ¶ˆé™¤ä¸å¿…è¦çš„å †åˆ†é…
+//   skip_static: å›ºå®šåŽŸå› ï¼Œé›¶åˆ†é…ï¼ˆçƒ­è·¯å¾„ä¸“ç”¨ï¼‰
+//   skip_dynamic: åŠ¨æ€åŽŸå› ï¼Œåªåœ¨å¿…è¦æ—¶åˆ†é…
+// ============================================================
+#[inline]
+fn skip_static(reason: &'static str) -> TakerDecision {
+    TakerDecision {
+        action: TakerAction::Skip,
+        fire_plan: None,
+        reason: reason.to_string(),
+    }
+}
+
+#[inline]
+fn skip_dynamic(reason: String) -> TakerDecision {
+    TakerDecision {
+        action: TakerAction::Skip,
+        fire_plan: None,
+        reason,
+    }
+}
+
+// ============================================================
+// èƒœçŽ‡è¯„åˆ†ç³»ç»Ÿ (0-100åˆ†)
+// ä¸‰ä¸ªç»´åº¦åˆ†åˆ«è¯„ä¼°ä¿¡å·ã€å¸‚åœºã€æ—¶åºè´¨é‡
+// åªæœ‰æ€»åˆ† â‰¥ min_win_rate_score æ‰è§¦å‘ï¼Œå…¶ä½™è·³è¿‡
+// ============================================================
+fn compute_win_rate_score(ctx: &EvaluateCtx<'_>) -> f64 {
+    let sig = ctx.direction_signal;
+
+    // --- ä¿¡å·è´¨é‡ (0-40åˆ†) ---
+    // velocity: åŠ¨é‡è¶Šå¼ºï¼Œä¿¡å·è¶Šå¯é 
+    let velocity_score = match sig.velocity_bps_per_sec.abs() {
+        v if v >= 100.0 => 20.0,
+        v if v >= 50.0 => 14.0,
+        v if v >= 20.0 => 8.0,
+        v if v >= 5.0 => 3.0,
+        _ => 0.0,
+    };
+    // acceleration: è¶‹åŠ¿åŠ å¼ºä¸­ï¼Œä¸æ˜¯å‡é€Ÿ
+    let accel_score = if sig.acceleration > 0.0 { 10.0 } else { 0.0 };
+    // tick_consistency: è¿žç»­åŒå‘ Tick è¶Šå¤šï¼Œæ–¹å‘è¶Šç¡®å®š
+    let tick_score = match sig.tick_consistency {
+        t if t >= 3 => 10.0,
+        2 => 5.0,
+        1 => 2.0,
+        _ => 0.0,
+    };
+    let signal_quality = velocity_score + accel_score + tick_score;
+
+    // --- å¸‚åœºè´¨é‡ (0-35åˆ†) ---
+    // price_zone: æžç«¯ä»·æ ¼åŒº Gamma æœ€é«˜ï¼Œè´¹çŽ‡æœ€ä½Žï¼Œæœ€å®¹æ˜“ç›ˆåˆ©
+    let p = ctx.entry_price.clamp(0.0, 1.0);
+    let dist = (p - 0.5).abs(); // 0=ä¸­é—´, 0.5=æžç«¯
+    let zone_score = match dist {
+        d if d >= 0.42 => 20.0, // >0.92 æˆ– <0.08: æœ€é«˜ Gamma
+        d if d >= 0.35 => 13.0, // 0.85-0.92
+        d if d >= 0.25 => 6.0,  // 0.75-0.85
+        _ => 0.0,               // ä¸­é—´åŒºé—´: è´¹çŽ‡å¤ªé«˜
+    };
+    // spread: ç›˜å£è¶Šç´§ï¼Œæ»‘ç‚¹è¶Šå°
+    let spread_score = match ctx.spread {
+        s if s < 0.01 => 10.0,
+        s if s < 0.03 => 5.0,
+        s if s < 0.05 => 2.0,
+        _ => 0.0,
+    };
+    // triple_confirm: ä¸‰é‡ç¡®è®¤é€šè¿‡æ˜¯é«˜è´¨é‡ä¿¡å·çš„æ ‡å¿—
+    let confirm_score = if sig.triple_confirm { 5.0 } else { 0.0 };
+    let market_quality = zone_score + spread_score + confirm_score;
+
+    // --- æ—¶åºè´¨é‡ (0-25åˆ†) ---
+    // momentum_spike: åŠ¨é‡çªåˆºæ˜¯æœ€å¼ºçš„å…¥åœºä¿¡å·
+    let spike_score = if sig.momentum_spike { 15.0 } else { 0.0 };
+    // edge: é¢„æœŸç›ˆåˆ©è¶Šé«˜ï¼Œæ—¶åºä»·å€¼è¶Šå¤§
+    let edge_score = match ctx.edge_net_bps {
+        e if e >= 200.0 => 10.0,
+        e if e >= 100.0 => 7.0,
+        e if e >= 50.0 => 4.0,
+        e if e >= 30.0 => 2.0,
+        _ => 0.0,
+    };
+    let timing_quality = spike_score + edge_score;
+
+    signal_quality + market_quality + timing_quality
+}
+
+fn build_fire_plan(gatling: &GatlingResolved, opportunity: TimeframeOpp) -> FirePlan {
+    let total_size = opportunity.size.max(0.0);
+    let notional = (opportunity.entry_price.max(0.0) * total_size).max(0.0);
+    let min_chunks = gatling.min_chunks.max(1);
+    let max_chunks = gatling.max_chunks.max(min_chunks);
+    let desired_chunks = if gatling.enabled && gatling.chunk_notional_usdc > 0.0 {
+        ((notional / gatling.chunk_notional_usdc).ceil() as usize).clamp(min_chunks, max_chunks)
+    } else {
+        1
+    };
+
+    let mut chunks = Vec::with_capacity(desired_chunks);
+    if desired_chunks == 1 {
+        chunks.push(FireChunk {
+            size: total_size,
+            send_delay_ms: 0,
+        });
+    } else {
+        let mut remain = total_size;
+        let base = total_size / desired_chunks as f64;
+        for idx in 0..desired_chunks {
+            let mut size = if idx + 1 == desired_chunks {
+                remain
+            } else {
+                base
+            };
+            if idx + 1 != desired_chunks {
+                size = size.max(0.01);
+                remain = (remain - size).max(0.0);
+            }
+            chunks.push(FireChunk {
+                size,
+                send_delay_ms: if idx == 0 { 0 } else { gatling.spacing_ms },
+            });
+        }
+    }
+
+    FirePlan {
+        opportunity,
+        chunks,
+        stop_on_reject: gatling.stop_on_reject,
+    }
+}
+
+impl TakerSniperConfig {
+    fn gatling_for_symbol(&self, symbol: &str) -> GatlingResolved {
+        let mut resolved = GatlingResolved {
+            enabled: self.gatling_enabled,
+            chunk_notional_usdc: self.gatling_chunk_notional_usdc,
+            min_chunks: self.gatling_min_chunks.max(1),
+            max_chunks: self.gatling_max_chunks.max(self.gatling_min_chunks.max(1)),
+            spacing_ms: self.gatling_spacing_ms,
+            stop_on_reject: self.gatling_stop_on_reject,
+        };
+        let key = symbol.to_ascii_uppercase();
+        if let Some(override_cfg) = self.gatling_by_symbol.get(&key) {
+            if let Some(v) = override_cfg.enabled {
+                resolved.enabled = v;
+            }
+            if let Some(v) = override_cfg.chunk_notional_usdc {
+                resolved.chunk_notional_usdc = v.max(0.01);
+            }
+            if let Some(v) = override_cfg.min_chunks {
+                resolved.min_chunks = v.max(1);
+            }
+            if let Some(v) = override_cfg.max_chunks {
+                resolved.max_chunks = v.max(resolved.min_chunks);
+            }
+            if let Some(v) = override_cfg.spacing_ms {
+                resolved.spacing_ms = v.min(1_000);
+            }
+            if let Some(v) = override_cfg.stop_on_reject {
+                resolved.stop_on_reject = v;
+            }
+        }
+        resolved
+    }
+}
+
+fn lock_minutes_for_timeframe(tf: &TimeframeClass) -> f64 {
+    match tf {
+        TimeframeClass::Tf5m => 5.0,
+        TimeframeClass::Tf15m => 15.0,
+        TimeframeClass::Tf1h => 60.0,
+        TimeframeClass::Tf1d => 1440.0,
+    }
+}
+
+fn direction_to_side(dir: &Direction) -> core_types::OrderSide {
+    match dir {
+        Direction::Up => core_types::OrderSide::BuyYes,
+        Direction::Down => core_types::OrderSide::BuyNo,
+        Direction::Neutral => core_types::OrderSide::BuyYes,
+    }
+}
+
+/// Dynamic edge gate by entry price bucket.
+/// Near 0.50 prices require much larger edge due fee drag and toxicity.
+#[inline]
+fn dynamic_fee_gate_min_edge_bps(entry_price: f64, confidence: f64) -> f64 {
+    let p = entry_price.clamp(0.0, 1.0);
+    // Fee behavior is approximately symmetric around 0.50.
+    let base_gate = if p >= 0.92 || p <= 0.08 {
+        80.0
+    } else if p >= 0.85 || p <= 0.15 {
+        150.0
+    } else if p >= 0.75 || p <= 0.25 {
+        300.0
+    } else if p >= 0.60 || p <= 0.40 {
+        600.0
+    } else {
+        // Around 0.50, require a much larger edge.
+        1200.0
+    };
+    // High confidence can relax at most 25%.
+    let confidence_relax =
+        (1.0 - (confidence.clamp(0.0, 1.0) - 0.5).max(0.0) * 0.4).clamp(0.75, 1.0);
+    base_gate * confidence_relax
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use core_types::{Direction, DirectionSignal, TimeframeClass};
+
+    fn up_signal(confidence: f64) -> DirectionSignal {
+        DirectionSignal {
+            symbol: "BTCUSDT".to_string(),
+            direction: Direction::Up,
+            magnitude_pct: 0.20,
+            confidence,
+            recommended_tf: TimeframeClass::Tf15m,
+            velocity_bps_per_sec: 7.5,
+            acceleration: 0.8,
+            tick_consistency: 3,
+            triple_confirm: true,
+            momentum_spike: false,
+            ts_ns: 1,
+        }
+    }
+
+    #[test]
+    fn fires_on_strong_signal() {
+        let mut sniper = TakerSniper::new(TakerSniperConfig {
+            min_direction_confidence: 0.7,
+            min_edge_net_bps: 5.0,
+            max_spread: 0.08,
+            cooldown_ms_per_market: 0,
+            ..TakerSniperConfig::default()
+        });
+        let sig = up_signal(0.9);
+        let d = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.95,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 80.0,
+            edge_net_bps: 80.0, // 0.95 åŒºé—´éœ€è¦ > 67.2 bps (80*0.84)
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d.action, TakerAction::Fire));
+        assert!(d.fire_plan.is_some());
+    }
+
+    #[test]
+    fn skips_low_confidence() {
+        let mut sniper = TakerSniper::new(TakerSniperConfig::default());
+        let sig = up_signal(0.5);
+        let d = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.52,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 30.0,
+            edge_net_bps: 32.0,
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d.action, TakerAction::Skip));
+        assert_eq!(d.reason, "low_confidence");
+    }
+
+    #[test]
+    fn skips_edge_below_threshold() {
+        let mut sniper = TakerSniper::new(TakerSniperConfig {
+            min_edge_net_bps: 25.0,
+            ..TakerSniperConfig::default()
+        });
+        let sig = up_signal(0.9);
+        let d = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.52,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 30.0,
+            edge_net_bps: 24.0,
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d.action, TakerAction::Skip));
+        assert_eq!(d.reason, "fee_gate_too_expensive");
+    }
+
+    #[test]
+    fn cooldown_blocks_repeated_fire() {
+        let mut sniper = TakerSniper::new(TakerSniperConfig {
+            min_edge_net_bps: 5.0,
+            cooldown_ms_per_market: 1_000,
+            ..TakerSniperConfig::default()
+        });
+        let sig = up_signal(0.9);
+        let d1 = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.95,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 80.0,
+            edge_net_bps: 80.0, // 0.95 åŒºé—´éœ€è¦ > 67.2 bps
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d1.action, TakerAction::Fire));
+        let d2 = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.95,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 80.0,
+            edge_net_bps: 80.0,
+            size: 10.0,
+            now_ms: 1_000_500,
+        });
+        assert!(matches!(d2.action, TakerAction::Skip));
+        assert_eq!(d2.reason, "cooldown_active");
+    }
+
+    #[test]
+    fn dynamic_fee_gate_blocks_mid_price_without_large_edge() {
+        // 50Â¢ åŒºé—´éœ€è¦ 800 bps (ç½®ä¿¡åº¦ 0.9 æ”¾å®½ 25% â†’ 600 bps)
+        // ä¼ å…¥ edge_net_bps=95 è¿œä½ŽäºŽ 600 bps, åº”è¯¥è¢«æ‹¦æˆª
+        let mut sniper = TakerSniper::new(TakerSniperConfig {
+            min_edge_net_bps: 10.0,
+            ..TakerSniperConfig::default()
+        });
+        let sig = up_signal(0.9);
+        let d = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.50,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 60.0,
+            edge_net_bps: 95.0,
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d.action, TakerAction::Skip));
+        assert_eq!(d.reason, "fee_gate_too_expensive");
+    }
+
+    #[test]
+    fn dynamic_fee_gate_blocks_mid_price_even_with_moderate_edge() {
+        // å³ä½¿ edge=500 bps, 50Â¢ åŒºé—´ (éœ€è¦ ~600 bps) ä¹Ÿåº”è¢«æ‹¦æˆª
+        let mut sniper = TakerSniper::new(TakerSniperConfig {
+            min_edge_net_bps: 10.0,
+            ..TakerSniperConfig::default()
+        });
+        let sig = up_signal(0.9);
+        let d = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.50,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 500.0,
+            edge_net_bps: 500.0,
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d.action, TakerAction::Skip));
+        assert_eq!(d.reason, "fee_gate_too_expensive");
+    }
+
+    #[test]
+    fn dynamic_fee_gate_allows_extreme_price_with_small_edge() {
+        // 0.95 åŒºé—´: 80 bps base * 0.84 (confidence=0.9 æ”¾å®½) = 67.2 bps
+        // edge_net_bps=80 > 67.2, åº”è¯¥ Fire
+        let mut sniper = TakerSniper::new(TakerSniperConfig {
+            min_edge_net_bps: 10.0,
+            min_win_rate_score: 0.0, // åªæµ‹è¯• fee gate è¡Œä¸º
+            ..TakerSniperConfig::default()
+        });
+        let sig = up_signal(0.9);
+        let d = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.95,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 80.0,
+            edge_net_bps: 80.0, // 80 > 67.2 bps â†’ Fire
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d.action, TakerAction::Fire));
+    }
+
+    #[test]
+    fn dynamic_fee_gate_relaxes_with_higher_confidence() {
+        // éªŒè¯é«˜ç½®ä¿¡åº¦ç¡®å®žèƒ½æ”¾å®½é—¨æ§› (åœ¨æžç«¯ä»·æ ¼åŒºé—´)
+        // 0.85 åŒºé—´: 150 bps base
+        //   confidence=0.55: relax = 1 - (0.55-0.5)*0.4 = 0.98 â†’ éœ€è¦ 147 bps
+        //   confidence=0.95: relax = 1 - (0.95-0.5)*0.4 = 0.82 â†’ éœ€è¦ 123 bps
+        let mut sniper = TakerSniper::new(TakerSniperConfig {
+            min_edge_net_bps: 10.0,
+            min_win_rate_score: 0.0, // åªæµ‹è¯• fee gate è¡Œä¸ºï¼Œç¦ç”¨èƒœçŽ‡è¿‡æ»¤
+            ..TakerSniperConfig::default()
+        });
+        let low = up_signal(0.55);
+        let high = up_signal(0.95);
+        // ä½Žç½®ä¿¡åº¦: edge=130 bps < 147 bps â†’ Skip
+        let d_low = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &low,
+            entry_price: 0.85,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 130.0,
+            edge_net_bps: 130.0,
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d_low.action, TakerAction::Skip));
+        // é«˜ç½®ä¿¡åº¦: edge=130 bps > 123 bps â†’ Fire
+        let d_high = sniper.evaluate(&EvaluateCtx {
+            market_id: "m2",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &high,
+            entry_price: 0.85,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 130.0,
+            edge_net_bps: 130.0,
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d_high.action, TakerAction::Fire));
+    }
+
+    #[test]
+    fn gatling_plan_splits_into_chunks() {
+        let mut sniper = TakerSniper::new(TakerSniperConfig {
+            gatling_enabled: true,
+            gatling_chunk_notional_usdc: 2.0,
+            gatling_min_chunks: 2,
+            gatling_max_chunks: 5,
+            ..TakerSniperConfig::default()
+        });
+        let sig = up_signal(0.9);
+        let d = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.90,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 200.0,
+            edge_net_bps: 200.0, // 0.90 åŒºé—´éœ€è¦ > 150 bps
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d.action, TakerAction::Fire));
+        let Some(plan) = d.fire_plan else {
+            panic!("expected fire plan");
+        };
+        assert!(plan.chunks.len() >= 2);
+        assert!(plan.stop_on_reject);
+        let total: f64 = plan.chunks.iter().map(|c| c.size).sum();
+        assert!((total - 10.0).abs() < 1e-6);
+    }
+
+    #[test]
+    fn symbol_level_gatling_override_applied() {
+        let mut sniper = TakerSniper::new(TakerSniperConfig {
+            min_edge_net_bps: 5.0, // æµ‹è¯• gatling è¡Œä¸ºï¼Œä¸æµ‹è¯• edge é—¨æ§›
+            gatling_enabled: false,
+            gatling_chunk_notional_usdc: 10.0,
+            gatling_min_chunks: 1,
+            gatling_max_chunks: 2,
+            gatling_by_symbol: HashMap::from([(
+                "BTCUSDT".to_string(),
+                SymbolGatlingConfig {
+                    enabled: Some(true),
+                    chunk_notional_usdc: Some(2.0),
+                    min_chunks: Some(2),
+                    max_chunks: Some(4),
+                    spacing_ms: Some(7),
+                    stop_on_reject: Some(false),
+                },
+            )]),
+            ..TakerSniperConfig::default()
+        });
+        let sig = up_signal(0.9);
+        let d = sniper.evaluate(&EvaluateCtx {
+            market_id: "m1",
+            symbol: "BTCUSDT",
+            timeframe: TimeframeClass::Tf15m,
+            direction_signal: &sig,
+            entry_price: 0.90,
+            spread: 0.01,
+            fee_bps: 2.0,
+            edge_gross_bps: 200.0,
+            edge_net_bps: 200.0, // 0.90 åŒºé—´éœ€è¦ > 150 bps
+            size: 10.0,
+            now_ms: 1_000_000,
+        });
+        assert!(matches!(d.action, TakerAction::Fire));
+        let Some(plan) = d.fire_plan else {
+            panic!("expected fire plan");
+        };
+        assert!(plan.chunks.len() >= 2);
+        assert_eq!(plan.chunks[1].send_delay_ms, 7);
+        assert!(!plan.stop_on_reject);
+    }
+}
diff --git a/crates/timeframe_router/Cargo.toml b/crates/timeframe_router/Cargo.toml
new file mode 100644
index 0000000..055bd09
--- /dev/null
+++ b/crates/timeframe_router/Cargo.toml
@@ -0,0 +1,10 @@
+[package]
+name = "timeframe_router"
+version.workspace = true
+edition.workspace = true
+license.workspace = true
+
+[dependencies]
+core_types = { path = "../core_types" }
+serde.workspace = true
+
diff --git a/crates/timeframe_router/src/lib.rs b/crates/timeframe_router/src/lib.rs
new file mode 100644
index 0000000..75e806f
--- /dev/null
+++ b/crates/timeframe_router/src/lib.rs
@@ -0,0 +1,334 @@
+use std::collections::HashMap;
+
+use core_types::{TimeframeClass, TimeframeOpp};
+use serde::{Deserialize, Serialize};
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct RouterConfig {
+    pub max_locked_pct_5m: f64,
+    pub max_locked_pct_15m: f64,
+    pub max_locked_pct_1h: f64,
+    pub max_locked_pct_1d: f64,
+    pub max_concurrent_positions: usize,
+    pub liquidity_reserve_pct: f64,
+    /// Hard caps for micro-live and safety. Defaults are permissive for paper/shadow.
+    pub max_order_notional_usdc: f64,
+    pub max_total_notional_usdc: f64,
+}
+
+impl Default for RouterConfig {
+    fn default() -> Self {
+        Self {
+            max_locked_pct_5m: 0.30,
+            max_locked_pct_15m: 0.40,
+            max_locked_pct_1h: 0.50,
+            max_locked_pct_1d: 0.30,
+            max_concurrent_positions: 8,
+            liquidity_reserve_pct: 0.20,
+            max_order_notional_usdc: 1_000_000.0,
+            max_total_notional_usdc: 1_000_000.0,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct RouterLock {
+    pub market_id: String,
+    pub timeframe: TimeframeClass,
+    pub notional_usdc: f64,
+    pub locked_at_ms: i64,
+    pub unlock_at_ms: i64,
+}
+
+#[derive(Debug)]
+pub struct TimeframeRouter {
+    cfg: RouterConfig,
+    locks_by_market: HashMap<String, RouterLock>,
+}
+
+impl TimeframeRouter {
+    pub fn new(cfg: RouterConfig) -> Self {
+        Self {
+            cfg,
+            locks_by_market: HashMap::new(),
+        }
+    }
+
+    pub fn cfg(&self) -> &RouterConfig {
+        &self.cfg
+    }
+
+    pub fn set_cfg(&mut self, cfg: RouterConfig) {
+        self.cfg = cfg;
+    }
+
+    pub fn prune_expired(&mut self, now_ms: i64) {
+        self.locks_by_market.retain(|_, l| l.unlock_at_ms > now_ms);
+    }
+
+    pub fn active_positions(&mut self, now_ms: i64) -> usize {
+        self.prune_expired(now_ms);
+        self.locks_by_market.len()
+    }
+
+    pub fn locked_total_usdc(&mut self, now_ms: i64) -> f64 {
+        self.prune_expired(now_ms);
+        self.locks_by_market.values().map(|l| l.notional_usdc).sum()
+    }
+
+    pub fn locked_by_tf_usdc(&mut self, now_ms: i64) -> HashMap<TimeframeClass, f64> {
+        self.prune_expired(now_ms);
+        let mut out: HashMap<TimeframeClass, f64> = HashMap::new();
+        for l in self.locks_by_market.values() {
+            *out.entry(l.timeframe.clone()).or_insert(0.0) += l.notional_usdc;
+        }
+        out
+    }
+
+    pub fn snapshot_locks(&mut self, now_ms: i64) -> Vec<RouterLock> {
+        self.prune_expired(now_ms);
+        self.locks_by_market.values().cloned().collect()
+    }
+
+    pub fn route(
+        &mut self,
+        mut candidates: Vec<TimeframeOpp>,
+        total_capital_usdc: f64,
+        now_ms: i64,
+    ) -> Vec<TimeframeOpp> {
+        self.prune_expired(now_ms);
+
+        if candidates.is_empty() {
+            return Vec::new();
+        }
+        if total_capital_usdc <= 0.0 {
+            return Vec::new();
+        }
+
+        if self.locks_by_market.len() >= self.cfg.max_concurrent_positions {
+            return Vec::new();
+        }
+
+        let locked_total = self
+            .locks_by_market
+            .values()
+            .map(|l| l.notional_usdc)
+            .sum::<f64>();
+        let reserve =
+            (total_capital_usdc * self.cfg.liquidity_reserve_pct.clamp(0.0, 0.95)).max(0.0);
+        let mut deployable = (total_capital_usdc - reserve - locked_total).max(0.0);
+        if deployable < 1e-9 {
+            return Vec::new();
+        }
+
+        // Highest density first.
+        candidates.sort_by(|a, b| b.density.total_cmp(&a.density));
+
+        let mut out: Vec<TimeframeOpp> = Vec::new();
+        let max_new = self
+            .cfg
+            .max_concurrent_positions
+            .saturating_sub(self.locks_by_market.len())
+            .max(0);
+
+        let locked_by_tf = self.locked_by_tf_usdc(now_ms);
+
+        for opp in candidates {
+            if out.len() >= max_new {
+                break;
+            }
+            if self.locks_by_market.contains_key(&opp.market_id) {
+                continue;
+            }
+            let notional = (opp.entry_price.max(0.0) * opp.size.max(0.0)).max(0.0);
+            if notional <= 0.0 {
+                continue;
+            }
+            if notional > self.cfg.max_order_notional_usdc.max(0.0) {
+                continue;
+            }
+            if locked_total
+                + out
+                    .iter()
+                    .map(|o| (o.entry_price * o.size).max(0.0))
+                    .sum::<f64>()
+                + notional
+                > self.cfg.max_total_notional_usdc.max(0.0)
+            {
+                continue;
+            }
+
+            let tf_limit =
+                (self.max_locked_pct(&opp.timeframe).clamp(0.0, 1.0) * total_capital_usdc).max(0.0);
+            let tf_locked = *locked_by_tf.get(&opp.timeframe).unwrap_or(&0.0);
+            if tf_locked + notional > tf_limit {
+                continue;
+            }
+            if notional > deployable {
+                continue;
+            }
+
+            deployable -= notional;
+            out.push(opp);
+        }
+
+        out
+    }
+
+    pub fn lock(&mut self, opp: &TimeframeOpp, now_ms: i64) -> bool {
+        self.prune_expired(now_ms);
+        if self.locks_by_market.contains_key(&opp.market_id) {
+            return false;
+        }
+        let notional = (opp.entry_price.max(0.0) * opp.size.max(0.0)).max(0.0);
+        if notional <= 0.0 {
+            return false;
+        }
+        let lock_ms = (opp.lock_minutes.max(0.0) * 60_000.0).round() as i64;
+        let unlock_at = now_ms.saturating_add(lock_ms.max(0));
+        self.locks_by_market.insert(
+            opp.market_id.clone(),
+            RouterLock {
+                market_id: opp.market_id.clone(),
+                timeframe: opp.timeframe.clone(),
+                notional_usdc: notional,
+                locked_at_ms: now_ms,
+                unlock_at_ms: unlock_at,
+            },
+        );
+        true
+    }
+
+    pub fn unlock_market(&mut self, market_id: &str) -> bool {
+        self.locks_by_market.remove(market_id).is_some()
+    }
+
+    fn max_locked_pct(&self, tf: &TimeframeClass) -> f64 {
+        match tf {
+            TimeframeClass::Tf5m => self.cfg.max_locked_pct_5m,
+            TimeframeClass::Tf15m => self.cfg.max_locked_pct_15m,
+            TimeframeClass::Tf1h => self.cfg.max_locked_pct_1h,
+            TimeframeClass::Tf1d => self.cfg.max_locked_pct_1d,
+        }
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use core_types::{Direction, OrderSide};
+
+    fn opp(
+        tf: TimeframeClass,
+        density: f64,
+        market_id: &str,
+        entry_price: f64,
+        size: f64,
+    ) -> TimeframeOpp {
+        TimeframeOpp {
+            timeframe: tf,
+            market_id: market_id.to_string(),
+            symbol: "BTCUSDT".to_string(),
+            direction: Direction::Up,
+            side: OrderSide::BuyYes,
+            entry_price,
+            size,
+            edge_gross_bps: 20.0,
+            edge_net_bps: 10.0,
+            edge_net_usdc: 0.1,
+            fee_bps: 2.0,
+            lock_minutes: 15.0,
+            density,
+            confidence: 0.9,
+            ts_ms: 0,
+        }
+    }
+
+    #[test]
+    fn sorts_by_density_desc() {
+        let mut router = TimeframeRouter::new(RouterConfig {
+            max_concurrent_positions: 8,
+            liquidity_reserve_pct: 0.0,
+            ..RouterConfig::default()
+        });
+        let routed = router.route(
+            vec![
+                opp(TimeframeClass::Tf15m, 0.1, "m1", 0.5, 10.0),
+                opp(TimeframeClass::Tf15m, 0.2, "m2", 0.5, 10.0),
+            ],
+            100.0,
+            1_000,
+        );
+        assert_eq!(routed.len(), 2);
+        assert_eq!(routed[0].market_id, "m2");
+    }
+
+    #[test]
+    fn respects_max_positions() {
+        let mut router = TimeframeRouter::new(RouterConfig {
+            max_concurrent_positions: 1,
+            liquidity_reserve_pct: 0.0,
+            ..RouterConfig::default()
+        });
+        // Pre-lock one market.
+        router.locks_by_market.insert(
+            "m0".to_string(),
+            RouterLock {
+                market_id: "m0".to_string(),
+                timeframe: TimeframeClass::Tf15m,
+                notional_usdc: 10.0,
+                locked_at_ms: 0,
+                unlock_at_ms: 10_000,
+            },
+        );
+        let routed = router.route(
+            vec![opp(TimeframeClass::Tf15m, 0.2, "m1", 0.5, 10.0)],
+            100.0,
+            1_000,
+        );
+        assert!(routed.is_empty());
+    }
+
+    #[test]
+    fn respects_liquidity_reserve() {
+        let mut router = TimeframeRouter::new(RouterConfig {
+            max_concurrent_positions: 8,
+            liquidity_reserve_pct: 0.20,
+            ..RouterConfig::default()
+        });
+        // total=10, reserve=2 => deployable=8; order notional=9 => should skip.
+        let routed = router.route(
+            vec![opp(TimeframeClass::Tf15m, 0.2, "m1", 0.9, 10.0)],
+            10.0,
+            1_000,
+        );
+        assert!(routed.is_empty());
+    }
+
+    #[test]
+    fn respects_timeframe_lock_limit() {
+        let mut router = TimeframeRouter::new(RouterConfig {
+            max_locked_pct_5m: 0.30,
+            max_concurrent_positions: 8,
+            liquidity_reserve_pct: 0.0,
+            ..RouterConfig::default()
+        });
+        // 5m lock already 3 out of 10 => 30% cap reached.
+        router.locks_by_market.insert(
+            "m0".to_string(),
+            RouterLock {
+                market_id: "m0".to_string(),
+                timeframe: TimeframeClass::Tf5m,
+                notional_usdc: 3.0,
+                locked_at_ms: 0,
+                unlock_at_ms: 10_000,
+            },
+        );
+        let routed = router.route(
+            vec![opp(TimeframeClass::Tf5m, 0.2, "m1", 0.5, 10.0)],
+            10.0,
+            1_000,
+        );
+        assert!(routed.is_empty());
+    }
+}
diff --git a/docs/runtime_state_machines.md b/docs/runtime_state_machines.md
new file mode 100644
index 0000000..9d906e0
--- /dev/null
+++ b/docs/runtime_state_machines.md
@@ -0,0 +1,86 @@
+# Runtime State Machines
+
+This document captures the runtime control-state transitions that matter for remote operations and transport A/B testing.
+
+## 1) Execution Arming State
+
+The runtime decides between `paper` and `live` in `crates/app_runner/src/bootstrap.rs`.
+
+### Inputs
+
+- `configs/execution.toml` -> `execution.mode`
+- env: `POLYEDGE_LIVE_ARMED`
+- `configs/settlement.toml` -> settlement gate (`required_for_live`, `endpoint`)
+
+### Transition Rules
+
+1. If `execution.mode != "live"` -> run in `paper`.
+2. If `execution.mode == "live"` but `POLYEDGE_LIVE_ARMED` is false/missing -> force `paper`.
+3. If `execution.mode == "live"` and armed, but settlement gate is not ready -> force `paper`.
+4. Only when all three are satisfied (`live` mode, armed, settlement gate ready) -> run `live`.
+
+### Operational Implications
+
+- `/control/arm_live` changes arming intent but does not hot-swap execution mode if process booted in `paper`.
+- `restart_required: true` in arm response means process restart is needed to actually enter `live`.
+
+## 2) Fusion Mode State
+
+Managed by `/control/reload_fusion` and evaluated in `crates/app_runner/src/feed_runtime.rs`.
+
+### Modes
+
+- `direct_only`
+- `active_active`
+- `udp_only`
+- `websocket_primary`
+
+### Common Guards
+
+- `udp_share_cap`
+- `jitter_threshold_ms`
+- `fallback_arm_duration_ms`
+- `fallback_cooldown_sec`
+- `udp_local_only`
+
+### WebSocket-Primary Fallback Lifecycle
+
+This applies only when `mode == websocket_primary`.
+
+1. **ws_primary**: default state while WS freshness is healthy.
+2. **armed**: WS freshness breach started but persistence window not met yet.
+3. **udp_fallback**: breach persisted for `fallback_arm_duration_ms`; UDP fallback is activated.
+4. **cooldown**: WS recovered but still inside cooldown window (`fallback_cooldown_sec`).
+5. Back to **ws_primary** after cooldown expiry.
+
+Reported in `/report/shadow/live` via:
+
+- `fallback_state`
+- `fallback_trigger_reason_distribution`
+- `udp_share_effective`
+- `source_mix_ratio`
+
+## 3) Shadow Metrics Window State
+
+Managed by `/control/reset_shadow`.
+
+### Reset Effects
+
+- Shadow stats window is reset (`window_id` increments).
+- Toxicity state is cleared.
+- Router/sniper/compounder runtime objects are reinitialized from current configs.
+- Fallback reason counters and short-horizon tallies restart from the new window baseline.
+
+### Why This Matters
+
+- Any regression comparison across runs must treat `window_id` reset boundaries as new baselines.
+- Scripts that compare deltas should use run-local deltas, not absolute totals across resets.
+
+## 4) Recommended Remote Test Order
+
+1. `POST /control/reload_fusion` with target mode and guard values.
+2. `POST /control/reset_shadow`.
+3. Warmup interval (5s+).
+4. Run `scripts/full_latency_sweep.py`.
+5. Run `scripts/storm_test.py` (or `scripts/seat_transport_guard.py` for A/B and rollback).
+6. Read `/report/shadow/live` and verify mode-specific counters and fallback state.
diff --git a/docs/seat_transport_ab_runbook.md b/docs/seat_transport_ab_runbook.md
new file mode 100644
index 0000000..851496a
--- /dev/null
+++ b/docs/seat_transport_ab_runbook.md
@@ -0,0 +1,98 @@
+# SEAT Transport Guard Runbook
+
+## Scope
+- Guard rollback is runtime config rollback (`/control/reload_fusion`), not git rollback.
+- A/B baseline is `direct_only`, candidate is `websocket_primary`.
+
+## Reboot Safety (must-have)
+Install a persistent service so reboot does not leave `127.0.0.1:8080` down:
+```bash
+bash scripts/setup_app_runner_systemd.sh
+```
+
+After reboot:
+```bash
+systemctl status polyedge.service --no-pager
+curl -fsS http://127.0.0.1:8080/health
+```
+
+## Quick Validation (60s)
+```bash
+python scripts/seat_transport_guard.py \
+  --run-id seat-final-ab-20260219-quick \
+  --profile quick_60s \
+  --base-url http://127.0.0.1:8080 \
+  --dedupe-window-ms 8 \
+  --udp-share-cap 0.35 \
+  --jitter-threshold-ms 25 \
+  --fallback-arm-duration-ms 8000 \
+  --fallback-cooldown-sec 300 \
+  --udp-local-only true \
+  --warmup-sec 5
+```
+
+## Background Mode (heartbeat every 5s)
+```bash
+python scripts/run_guard_background.py \
+  --run-id seat-final-ab-20260219-quick-bg \
+  --profile quick_60s \
+  --base-url http://127.0.0.1:8080 \
+  --udp-share-cap 0.35 \
+  --jitter-threshold-ms 25 \
+  --fallback-arm-duration-ms 8000 \
+  --fallback-cooldown-sec 300 \
+  --udp-local-only true
+```
+
+## Deep + Storm (120s storm)
+```bash
+python scripts/seat_transport_guard.py \
+  --run-id seat-final-ab-20260219-deep \
+  --profile deep \
+  --storm-duration-sec 120 \
+  --base-url http://127.0.0.1:8080 \
+  --dedupe-window-ms 8 \
+  --udp-share-cap 0.35 \
+  --jitter-threshold-ms 25 \
+  --fallback-arm-duration-ms 8000 \
+  --fallback-cooldown-sec 300 \
+  --udp-local-only true \
+  --warmup-sec 5
+```
+
+## Infra Path Probe (GA / PrivateLink / Direct)
+```bash
+python scripts/transport_path_probe.py \
+  --targets "direct=http://127.0.0.1:8080,ga=http://<ga-endpoint>:8080,pl=http://<privatelink-endpoint>:8080" \
+  --path /health/latency \
+  --samples 120 \
+  --interval-ms 50 \
+  --run-id seat-final-ab-20260219-path
+```
+
+Read `p50/p99/errors` for each target. If `ga/pl` p99 is worse than `direct`, infra path is not healthy yet.
+
+## One-Shot SEAT Fabric Verify
+```bash
+python scripts/verify_seat_fabric.py \
+  --base-url http://127.0.0.1:8080 \
+  --ga-url http://a2ea6e068a4cd04af.awsglobalaccelerator.com:8080 \
+  --privatelink-url http://<privatelink-endpoint>:8080 \
+  --run-id seat-final-ab-20260219-verify
+```
+
+This verifies runtime control plane, required live-report fields, static transport/execution config,
+and transport path readiness (direct/GA/PrivateLink) in a single JSON artifact.
+
+## Output Files
+- `datasets/reports/<utc-day>/runs/<run-id>-baseline/full_latency_sweep_*.json`
+- `datasets/reports/<utc-day>/runs/<run-id>-candidate/full_latency_sweep_*.json`
+- `datasets/reports/<utc-day>/runs/<run-id>/seat_transport_guard_summary.json`
+- Background wrapper log: `datasets/reports/<utc-day>/runs/<run-id>/seat_transport_guard_live.log`
+
+## Passing Gates
+- `candidate_udp_share <= 0.35`
+- `policy_block_ratio <= 0.20`
+- `tick_to_decision_p99_ms <= 0.45`
+- `source_latency_p99_ms <= 100`
+- Guard did not rollback, or rollback restored stable baseline in next window
diff --git a/docs/seat_v23_runbook.md b/docs/seat_v23_runbook.md
new file mode 100644
index 0000000..1841c7d
--- /dev/null
+++ b/docs/seat_v23_runbook.md
@@ -0,0 +1,76 @@
+# SEAT v2.3 Runtime + Acceptance Runbook
+
+## Local Service Layout
+
+- `app_runner` control API: `http://127.0.0.1:${POLYEDGE_CONTROL_PORT:-8080}`
+- optimizer service: `http://127.0.0.1:${POLYEDGE_SEAT_OPTIMIZER_PORT:-8091}`
+- seat config: `configs/seat.toml`
+- seat state files:
+  - `datasets/reports/seat/seat_state.json`
+  - `datasets/reports/seat/seat_decisions.jsonl`
+  - `datasets/reports/seat/reports/seat_tune_*.json`
+
+## Runtime Controls
+
+```bash
+curl -X POST http://127.0.0.1:8080/control/seat/pause
+curl -X POST http://127.0.0.1:8080/control/seat/resume
+curl -X POST http://127.0.0.1:8080/control/seat/force_layer -H 'content-type: application/json' -d '{"layer":"layer2"}'
+curl -X POST http://127.0.0.1:8080/control/seat/manual_override -H 'content-type: application/json' -d '{"params":{"position_fraction":0.12}}'
+curl -X POST http://127.0.0.1:8080/control/seat/clear_override
+```
+
+## Runtime Reports
+
+```bash
+curl -fsSL http://127.0.0.1:8080/report/seat/status | jq
+curl -fsSL 'http://127.0.0.1:8080/report/seat/history?limit=200' | jq
+```
+
+## Optimizer Service
+
+Install and start on target host:
+
+```bash
+bash scripts/setup_seat_optimizer_systemd.sh
+systemctl status polyedge-seat-optimizer.service --no-pager
+```
+
+Health check:
+
+```bash
+curl -fsSL http://127.0.0.1:8091/health | jq
+```
+
+## Ireland 72h Acceptance Validation
+
+Single-shot check:
+
+```bash
+python scripts/seat_remote_acceptance.py \
+  --host 54.77.232.166 \
+  --user ubuntu \
+  --key C:\\Users\\Shini\\Documents\\PolyEdge.pem \
+  --run-id seat-ireland-check
+```
+
+Watch mode (poll until accepted or timeout):
+
+```bash
+python scripts/seat_remote_acceptance.py \
+  --host 54.77.232.166 \
+  --user ubuntu \
+  --key C:\\Users\\Shini\\Documents\\PolyEdge.pem \
+  --watch-sec 28800 \
+  --poll-sec 60 \
+  --run-id seat-ireland-watch
+```
+
+Acceptance criteria:
+
+1. `current_layer` is `layer2` or `layer3`
+2. `trade_count >= 800`
+3. uptime `>= 72h`
+4. decision history includes challenger cycle (`shadow_started` + `monitor_pass` or `shadow_reject`)
+
+Output JSON: `datasets/reports/<day>/runs/<run-id>/seat_remote_acceptance.json`
diff --git a/docs/v52_atomic_commit_map.md b/docs/v52_atomic_commit_map.md
new file mode 100644
index 0000000..27cfd13
--- /dev/null
+++ b/docs/v52_atomic_commit_map.md
@@ -0,0 +1,20 @@
+# PolyEdge v5.2 Atomic Commit Audit Map
+
+This file maps the plan template names to concrete commits on `feat/p1-wire-dual`.
+It is intended for audit and traceability when commit history spans multiple refinement rounds.
+
+## Template -> Commit Mapping
+
+| Plan template name | Implemented commit(s) | Notes |
+|---|---|---|
+| `chore/baseline-snapshot` | `cedf2c2`, `3acb902` | Remote deploy/tuning baseline hardening and sync robustness. |
+| `feat/v52-single-flow-core` | `f9c9ad8`, `ce68b68` | Single v5.2 route path and convergence/fee gate consolidation. |
+| `feat/v52-exit-and-fallback` | `30e93d5`, `a499802`, `ce68b68` | Exit lifecycle, reversal handling, and fallback behavior. |
+| `feat/v52-live-gates` | `f9c9ad8`, `6f07242` | Settlement/live hard gate and degraded-source guard. |
+| `feat/v52-reporting-fallback-metric` | `f9c9ad8`, `2ac06ea` | Live report continuity, fallback counter, and queue-focused reporting. |
+| `feat/v52-reversal-switch-integration` | `019315d` | End-to-end reversal flatten + opposite maker re-entry integration test. |
+| `feat/v52-queue-opt` | `53d612a`, `24b8bfe`, `6282bc8`, `2ac06ea` | Queue wait tail optimization and hot-loop stall removal. |
+
+## Working Tree Hygiene
+
+- `scripts/convergence_analysis.py` is intentionally tracked as a reproducible convergence analysis utility used in latency-window studies.
diff --git a/latency_report.csv b/latency_report.csv
new file mode 100644
index 0000000..611573e
--- /dev/null
+++ b/latency_report.csv
@@ -0,0 +1,1919 @@
+update_id,udp_ts,ws_ts,delta_ms,faster_source
+88094243346,1771262520894368,1771262520893987,0.381,WS
+88094243396,1771262521040341,1771262521040340,0.001,WS
+88094243399,1771262521041741,1771262521040345,1.396,WS
+88094243402,1771262521041772,1771262521040346,1.426,WS
+88094243403,1771262521042842,1771262521041662,1.180,WS
+88094243405,1771262521042848,1771262521041666,1.182,WS
+88094243418,1771262521076682,1771262521074900,1.782,WS
+88094243422,1771262521085602,1771262521087269,-1.667,UDP
+88094243427,1771262521115911,1771262521115373,0.538,WS
+88094243431,1771262521122004,1771262521121113,0.891,WS
+88094243464,1771262521232528,1771262521232438,0.090,WS
+88094243521,1771262521336927,1771262521336662,0.265,WS
+88094243524,1771262521336953,1771262521336666,0.287,WS
+88094243525,1771262521336958,1771262521336847,0.111,WS
+88094243526,1771262521337935,1771262521338408,-0.473,UDP
+88094243527,1771262521337936,1771262521338417,-0.481,UDP
+88094243552,1771262521437154,1771262521436816,0.338,WS
+88094243554,1771262521437192,1771262521437111,0.081,WS
+88094243557,1771262521437198,1771262521438133,-0.935,UDP
+88094243558,1771262521439068,1771262521438142,0.926,WS
+88094243566,1771262521488638,1771262521486714,1.924,WS
+88094243570,1771262521543319,1771262521543259,0.060,WS
+88094243573,1771262521555093,1771262521554395,0.698,WS
+88094243574,1771262521565437,1771262521567401,-1.964,UDP
+88094243575,1771262521583009,1771262521582973,0.036,WS
+88094243585,1771262521634613,1771262521634552,0.061,WS
+88094243586,1771262521634640,1771262521635210,-0.570,UDP
+88094243609,1771262521645955,1771262521645182,0.773,WS
+88094243629,1771262521713425,1771262521713433,-0.008,UDP
+88094243674,1771262521743349,1771262521744476,-1.127,UDP
+88094243675,1771262521743374,1771262521744488,-1.114,UDP
+88094243677,1771262521747749,1771262521747693,0.056,WS
+88094243679,1771262521748930,1771262521748164,0.766,WS
+88094243680,1771262521750996,1771262521750962,0.034,WS
+88094243681,1771262521755640,1771262521754896,0.744,WS
+88094243683,1771262521765690,1771262521764584,1.106,WS
+88094243684,1771262521772409,1771262521771569,0.840,WS
+88094243685,1771262521781890,1771262521780810,1.080,WS
+88094243688,1771262521785232,1771262521786368,-1.136,UDP
+88094243693,1771262521790791,1771262521791138,-0.347,UDP
+88094243694,1771262521795982,1771262521791930,4.052,WS
+88094243696,1771262521799330,1771262521800021,-0.691,UDP
+88094243698,1771262521807543,1771262521807059,0.484,WS
+88094243699,1771262521819189,1771262521820097,-0.908,UDP
+88094243703,1771262521825306,1771262521825902,-0.596,UDP
+88094243704,1771262521835415,1771262521834895,0.520,WS
+88094243709,1771262521835940,1771262521836918,-0.978,UDP
+88094243716,1771262521843574,1771262521842872,0.702,WS
+88094243718,1771262521848280,1771262521847588,0.692,WS
+88094243719,1771262521850935,1771262521850863,0.072,WS
+88094243722,1771262521857149,1771262521857682,-0.533,UDP
+88094243726,1771262521864131,1771262521864084,0.047,WS
+88094243727,1771262521872572,1771262521871966,0.606,WS
+88094243735,1771262521908222,1771262521907961,0.261,WS
+88094243736,1771262521908251,1771262521907967,0.284,WS
+88094243737,1771262521908252,1771262521907968,0.284,WS
+88094243738,1771262521909819,1771262521909117,0.702,WS
+88094243739,1771262521909824,1771262521912801,-2.977,UDP
+88094243740,1771262521909837,1771262521912813,-2.976,UDP
+88094243741,1771262521913132,1771262521912814,0.318,WS
+88094243742,1771262521913138,1771262521912815,0.323,WS
+88094243743,1771262521913139,1771262521912816,0.323,WS
+88094243757,1771262521935054,1771262521935978,-0.924,UDP
+88094243772,1771262521937275,1771262521936929,0.346,WS
+88094243782,1771262521951270,1771262521949795,1.475,WS
+88094243793,1771262522034888,1771262522034855,0.033,WS
+88094243832,1771262522100869,1771262522100799,0.070,WS
+88094243840,1771262522136683,1771262522136016,0.667,WS
+88094243849,1771262522136710,1771262522136022,0.688,WS
+88094243860,1771262522137500,1771262522137474,0.026,WS
+88094243863,1771262522137522,1771262522137479,0.043,WS
+88094243873,1771262522138781,1771262522138221,0.560,WS
+88094243875,1771262522138800,1771262522142676,-3.876,UDP
+88094243879,1771262522143312,1771262522142687,0.625,WS
+88094243887,1771262522167777,1771262522166997,0.780,WS
+88094243890,1771262522178234,1771262522178153,0.081,WS
+88094243897,1771262522226504,1771262522226416,0.088,WS
+88094243907,1771262522239428,1771262522239210,0.218,WS
+88094243943,1771262522307159,1771262522306678,0.481,WS
+88094243955,1771262522336984,1771262522335678,1.306,WS
+88094243956,1771262522337030,1771262522337769,-0.739,UDP
+88094243959,1771262522339418,1771262522340181,-0.763,UDP
+88094243962,1771262522340982,1771262522340189,0.793,WS
+88094243970,1771262522387497,1771262522387512,-0.015,UDP
+88094244024,1771262522569077,1771262522568811,0.266,WS
+88094244031,1771262522588107,1771262522588320,-0.213,UDP
+88094244046,1771262522637426,1771262522637310,0.116,WS
+88094244049,1771262522637470,1771262522637314,0.156,WS
+88094244053,1771262522637484,1771262522638755,-1.271,UDP
+88094244060,1771262522638776,1771262522638780,-0.004,UDP
+88094244061,1771262522638813,1771262522638781,0.032,WS
+88094244062,1771262522638814,1771262522638782,0.032,WS
+88094244070,1771262522668844,1771262522668008,0.836,WS
+88094244072,1771262522670716,1771262522670695,0.021,WS
+88094244077,1771262522686116,1771262522685311,0.805,WS
+88094244143,1771262522916202,1771262522916181,0.021,WS
+88094244148,1771262522973128,1771262522973081,0.047,WS
+88094244151,1771262522981454,1771262522981461,-0.007,UDP
+88094244153,1771262522994764,1771262522994638,0.126,WS
+88094244159,1771262523054722,1771262523054630,0.092,WS
+88094244160,1771262523054758,1771262523054634,0.124,WS
+88094244161,1771262523054759,1771262523054638,0.121,WS
+88094244162,1771262523054760,1771262523054638,0.122,WS
+88094244163,1771262523054761,1771262523054639,0.122,WS
+88094244164,1771262523054762,1771262523054642,0.120,WS
+88094244167,1771262523059567,1771262523054645,4.922,WS
+88094244168,1771262523059600,1771262523059518,0.082,WS
+88094244188,1771262523235824,1771262523235065,0.759,WS
+88094244189,1771262523239660,1771262523238230,1.430,WS
+88094244246,1771262523528081,1771262523526841,1.240,WS
+88094244290,1771262523593604,1771262523594010,-0.406,UDP
+88094244298,1771262523627994,1771262523627097,0.897,WS
+88094244314,1771262523703529,1771262523703022,0.507,WS
+88094244322,1771262523738605,1771262523738519,0.086,WS
+88094244324,1771262523740434,1771262523739367,1.067,WS
+88094244325,1771262523740455,1771262523741845,-1.390,UDP
+88094244326,1771262523740455,1771262523741859,-1.404,UDP
+88094244327,1771262523747439,1771262523745985,1.454,WS
+88094244328,1771262523747445,1771262523745988,1.457,WS
+88094244329,1771262523749461,1771262523750118,-0.657,UDP
+88094244330,1771262523750090,1771262523750130,-0.040,UDP
+88094244359,1771262523810870,1771262523810879,-0.009,UDP
+88094244377,1771262523859183,1771262523859154,0.029,WS
+88094244397,1771262523980455,1771262523979930,0.525,WS
+88094244458,1771262524312960,1771262524308924,4.036,WS
+88094244459,1771262524312987,1771262524313844,-0.857,UDP
+88094244469,1771262524387470,1771262524387895,-0.425,UDP
+88094244471,1771262524395573,1771262524396117,-0.544,UDP
+88094244478,1771262524441348,1771262524444301,-2.953,UDP
+88094244488,1771262524447992,1771262524448672,-0.680,UDP
+88094244505,1771262524519669,1771262524519610,0.059,WS
+88094244511,1771262524540463,1771262524540542,-0.079,UDP
+88094244539,1771262524563528,1771262524563377,0.151,WS
+88094244544,1771262524572069,1771262524572546,-0.477,UDP
+88094244554,1771262524614306,1771262524614255,0.051,WS
+88094244559,1771262524631098,1771262524631775,-0.677,UDP
+88094244564,1771262524632676,1771262524632900,-0.224,UDP
+88094244569,1771262524633525,1771262524632911,0.614,WS
+88094244572,1771262524633546,1771262524635486,-1.940,UDP
+88094244584,1771262524637153,1771262524636957,0.196,WS
+88094244585,1771262524637172,1771262524636958,0.214,WS
+88094244613,1771262524639182,1771262524639081,0.101,WS
+88094244615,1771262524639222,1771262524639089,0.133,WS
+88094244635,1771262524641063,1771262524640642,0.421,WS
+88094244643,1771262524641084,1771262524641036,0.048,WS
+88094244646,1771262524642718,1771262524642725,-0.007,UDP
+88094244653,1771262524646015,1771262524646616,-0.601,UDP
+88094244685,1771262524662201,1771262524662862,-0.661,UDP
+88094244688,1771262524666441,1771262524666035,0.406,WS
+88094244722,1771262524686306,1771262524686995,-0.689,UDP
+88094244724,1771262524687912,1771262524687009,0.903,WS
+88094244732,1771262524689661,1771262524687979,1.682,WS
+88094244764,1771262524735312,1771262524736199,-0.887,UDP
+88094244772,1771262524736546,1771262524736241,0.305,WS
+88094244804,1771262524738820,1771262524738565,0.255,WS
+88094244818,1771262524738847,1771262524738740,0.107,WS
+88094244831,1771262524760301,1771262524759887,0.414,WS
+88094244842,1771262524786094,1771262524785537,0.557,WS
+88094244855,1771262524788093,1771262524787829,0.264,WS
+88094244868,1771262524826735,1771262524827098,-0.363,UDP
+88094244876,1771262524834996,1771262524835732,-0.736,UDP
+88094244902,1771262524837612,1771262524837966,-0.354,UDP
+88094244943,1771262524886294,1771262524885831,0.463,WS
+88094244945,1771262524886335,1771262524885835,0.500,WS
+88094244947,1771262524887215,1771262524887091,0.124,WS
+88094244968,1771262524936896,1771262524936648,0.248,WS
+88094245001,1771262524985255,1771262524985605,-0.350,UDP
+88094245002,1771262524988256,1771262524985617,2.639,WS
+88094245005,1771262524988261,1771262524988270,-0.009,UDP
+88094245019,1771262525028582,1771262525028530,0.052,WS
+88094245020,1771262525028787,1771262525029940,-1.153,UDP
+88094245026,1771262525039675,1771262525039400,0.275,WS
+88094245063,1771262525050322,1771262525048874,1.448,WS
+88094245069,1771262525105882,1771262525105741,0.141,WS
+88094245071,1771262525110047,1771262525109447,0.600,WS
+88094245126,1771262525138257,1771262525137649,0.608,WS
+88094245135,1771262525138284,1771262525137653,0.631,WS
+88094245155,1771262525153019,1771262525152267,0.752,WS
+88094245165,1771262525165744,1771262525165862,-0.118,UDP
+88094245174,1771262525186800,1771262525186108,0.692,WS
+88094245175,1771262525186826,1771262525186112,0.714,WS
+88094245193,1771262525188787,1771262525188401,0.386,WS
+88094245213,1771262525229065,1771262525228411,0.654,WS
+88094245214,1771262525230008,1771262525229826,0.182,WS
+88094245215,1771262525230012,1771262525229829,0.183,WS
+88094245216,1771262525230013,1771262525229830,0.183,WS
+88094245217,1771262525230016,1771262525231692,-1.676,UDP
+88094245218,1771262525232017,1771262525231706,0.311,WS
+88094245219,1771262525232024,1771262525231707,0.317,WS
+88094245229,1771262525234942,1771262525235862,-0.920,UDP
+88094245262,1771262525236057,1771262525237989,-1.932,UDP
+88094245316,1771262525285137,1771262525285587,-0.450,UDP
+88094245320,1771262525285162,1771262525285595,-0.433,UDP
+88094245341,1771262525336946,1771262525336815,0.131,WS
+88094245385,1771262525348109,1771262525346917,1.192,WS
+88094245386,1771262525349681,1771262525349563,0.118,WS
+88094245387,1771262525355313,1771262525355249,0.064,WS
+88094245389,1771262525369203,1771262525369861,-0.658,UDP
+88094245509,1771262525585904,1771262525585860,0.044,WS
+88094245518,1771262525635135,1771262525635639,-0.504,UDP
+88094245523,1771262525636907,1771262525635646,1.261,WS
+88094245571,1771262525961195,1771262525960687,0.508,WS
+88094245579,1771262526016257,1771262526014464,1.793,WS
+88094245586,1771262526037655,1771262526037156,0.499,WS
+88094245642,1771262526254098,1771262526255431,-1.333,UDP
+88094245663,1771262526294471,1771262526294565,-0.094,UDP
+88094245695,1771262526336789,1771262526336745,0.044,WS
+88094245700,1771262526336824,1771262526336751,0.073,WS
+88094245701,1771262526336833,1771262526336752,0.081,WS
+88094245706,1771262526336835,1771262526336752,0.083,WS
+88094245732,1771262526343752,1771262526337882,5.870,WS
+88094245733,1771262526343790,1771262526337886,5.904,WS
+88094245759,1771262526385657,1771262526385801,-0.144,UDP
+88094245770,1771262526442480,1771262526442962,-0.482,UDP
+88094245771,1771262526442515,1771262526442970,-0.455,UDP
+88094245790,1771262526515446,1771262526515385,0.061,WS
+88094245793,1771262526523082,1771262526523792,-0.710,UDP
+88094245809,1771262526536246,1771262526536782,-0.536,UDP
+88094245874,1771262526922930,1771262526923569,-0.639,UDP
+88094245904,1771262526947028,1771262526946563,0.465,WS
+88094245919,1771262527063409,1771262527063030,0.379,WS
+88094245935,1771262527200305,1771262527200693,-0.388,UDP
+88094245941,1771262527232706,1771262527231867,0.839,WS
+88094245943,1771262527241200,1771262527241827,-0.627,UDP
+88094245960,1771262527335272,1771262527334806,0.466,WS
+88094246016,1771262527697525,1771262527698297,-0.772,UDP
+88094246034,1771262527824799,1771262527824636,0.163,WS
+88094246036,1771262527824825,1771262527825624,-0.799,UDP
+88094246037,1771262527824830,1771262527825630,-0.800,UDP
+88094246052,1771262527852132,1771262527851103,1.029,WS
+88094246055,1771262527861357,1771262527861074,0.283,WS
+88094246058,1771262527886235,1771262527885919,0.316,WS
+88094246060,1771262527888300,1771262527888047,0.253,WS
+88094246176,1771262528235923,1771262528236762,-0.839,UDP
+88094246177,1771262528235947,1771262528236770,-0.823,UDP
+88094246186,1771262528235948,1771262528236771,-0.823,UDP
+88094246188,1771262528238799,1771262528238579,0.220,WS
+88094246205,1771262528285105,1771262528285656,-0.551,UDP
+88094246210,1771262528336480,1771262528336508,-0.028,UDP
+88094246289,1771262528486154,1771262528486063,0.091,WS
+88094246292,1771262528494136,1771262528493351,0.785,WS
+88094246298,1771262528497176,1771262528496336,0.840,WS
+88094246300,1771262528503503,1771262528503448,0.055,WS
+88094246324,1771262528536301,1771262528536869,-0.568,UDP
+88094246325,1771262528537771,1771262528536877,0.894,WS
+88094246329,1771262528537775,1771262528536878,0.897,WS
+88094246334,1771262528537788,1771262528536879,0.909,WS
+88094246336,1771262528538799,1771262528538154,0.645,WS
+88094246374,1771262528586424,1771262528585712,0.712,WS
+88094246381,1771262528635203,1771262528634473,0.730,WS
+88094246391,1771262528686380,1771262528685923,0.457,WS
+88094246421,1771262528793658,1771262528793498,0.160,WS
+88094246436,1771262528836834,1771262528836804,0.030,WS
+88094246446,1771262528836859,1771262528837494,-0.635,UDP
+88094246461,1771262528885105,1771262528885888,-0.783,UDP
+88094246462,1771262528885128,1771262528885901,-0.773,UDP
+88094246463,1771262528887312,1771262528886554,0.758,WS
+88094246468,1771262528925104,1771262528924657,0.447,WS
+88094246490,1771262528958748,1771262528947698,11.050,WS
+88094246496,1771262528959448,1771262528958755,0.693,WS
+88094246502,1771262528985255,1771262528985975,-0.720,UDP
+88094246507,1771262528989894,1771262528986655,3.239,WS
+88094246657,1771262529585074,1771262529585479,-0.405,UDP
+88094246665,1771262529665769,1771262529665970,-0.201,UDP
+88094246667,1771262529672680,1771262529671569,1.111,WS
+88094246673,1771262529681269,1771262529680849,0.420,WS
+88094246698,1771262529736421,1771262529735603,0.818,WS
+88094246722,1771262529785462,1771262529784860,0.602,WS
+88094246724,1771262529789402,1771262529785639,3.763,WS
+88094246753,1771262529836981,1771262529837918,-0.937,UDP
+88094246768,1771262529861263,1771262529862040,-0.777,UDP
+88094246812,1771262529964885,1771262529965564,-0.679,UDP
+88094246825,1771262529985359,1771262529985760,-0.401,UDP
+88094246857,1771262530051235,1771262530051251,-0.016,UDP
+88094246862,1771262530053401,1771262530052817,0.584,WS
+88094246872,1771262530086908,1771262530086134,0.774,WS
+88094246934,1771262530199475,1771262530202054,-2.579,UDP
+88094246935,1771262530199500,1771262530202069,-2.569,UDP
+88094246936,1771262530199501,1771262530202070,-2.569,UDP
+88094246937,1771262530199502,1771262530202072,-2.570,UDP
+88094246938,1771262530199503,1771262530202073,-2.570,UDP
+88094246939,1771262530202126,1771262530202073,0.053,WS
+88094246940,1771262530202131,1771262530202074,0.057,WS
+88094246941,1771262530202132,1771262530202075,0.057,WS
+88094246943,1771262530202143,1771262530202076,0.067,WS
+88094246944,1771262530202165,1771262530202076,0.089,WS
+88094246945,1771262530202166,1771262530202077,0.089,WS
+88094246946,1771262530202168,1771262530202078,0.090,WS
+88094246947,1771262530202169,1771262530202079,0.090,WS
+88094246948,1771262530202170,1771262530202080,0.090,WS
+88094246949,1771262530202170,1771262530202080,0.090,WS
+88094246950,1771262530202171,1771262530202081,0.090,WS
+88094246951,1771262530202172,1771262530202082,0.090,WS
+88094246952,1771262530202173,1771262530202083,0.090,WS
+88094246954,1771262530202179,1771262530202083,0.096,WS
+88094246962,1771262530202188,1771262530202089,0.099,WS
+88094246973,1771262530202191,1771262530202090,0.101,WS
+88094246978,1771262530202194,1771262530202091,0.103,WS
+88094246979,1771262530202197,1771262530202091,0.106,WS
+88094246989,1771262530202205,1771262530202092,0.113,WS
+88094247000,1771262530202208,1771262530203850,-1.642,UDP
+88094247002,1771262530202211,1771262530203858,-1.647,UDP
+88094247006,1771262530202214,1771262530203859,-1.645,UDP
+88094247009,1771262530202221,1771262530203860,-1.639,UDP
+88094247022,1771262530202224,1771262530203860,-1.636,UDP
+88094247025,1771262530202227,1771262530203861,-1.634,UDP
+88094247034,1771262530202234,1771262530203861,-1.627,UDP
+88094247035,1771262530202237,1771262530203862,-1.625,UDP
+88094247037,1771262530202242,1771262530203862,-1.620,UDP
+88094247038,1771262530202245,1771262530203863,-1.618,UDP
+88094247044,1771262530202249,1771262530203864,-1.615,UDP
+88094247046,1771262530202252,1771262530203865,-1.613,UDP
+88094247051,1771262530202260,1771262530203865,-1.605,UDP
+88094247059,1771262530203848,1771262530203866,-0.018,UDP
+88094247060,1771262530203901,1771262530203866,0.035,WS
+88094247061,1771262530203902,1771262530203867,0.035,WS
+88094247085,1771262530203903,1771262530203869,0.034,WS
+88094247097,1771262530203927,1771262530203870,0.057,WS
+88094247098,1771262530203931,1771262530203870,0.061,WS
+88094247117,1771262530203932,1771262530203872,0.060,WS
+88094247122,1771262530203935,1771262530203873,0.062,WS
+88094247164,1771262530204827,1771262530204158,0.669,WS
+88094247165,1771262530204844,1771262530204162,0.682,WS
+88094247168,1771262530204845,1771262530204163,0.682,WS
+88094247180,1771262530204850,1771262530204164,0.686,WS
+88094247188,1771262530204853,1771262530204165,0.688,WS
+88094247189,1771262530204857,1771262530204165,0.692,WS
+88094247194,1771262530204858,1771262530205597,-0.739,UDP
+88094247203,1771262530204860,1771262530205603,-0.743,UDP
+88094247206,1771262530204864,1771262530205604,-0.740,UDP
+88094247207,1771262530206332,1771262530205604,0.728,WS
+88094247208,1771262530206343,1771262530205605,0.738,WS
+88094247209,1771262530206352,1771262530205605,0.747,WS
+88094247210,1771262530206373,1771262530205606,0.767,WS
+88094247212,1771262530206376,1771262530205606,0.770,WS
+88094247215,1771262530206386,1771262530205607,0.779,WS
+88094247216,1771262530206390,1771262530205607,0.783,WS
+88094247217,1771262530206392,1771262530205607,0.785,WS
+88094247218,1771262530206393,1771262530205608,0.785,WS
+88094247219,1771262530206394,1771262530205608,0.786,WS
+88094247220,1771262530206395,1771262530205608,0.787,WS
+88094247221,1771262530206397,1771262530205609,0.788,WS
+88094247222,1771262530206403,1771262530205609,0.794,WS
+88094247223,1771262530206405,1771262530205610,0.795,WS
+88094247225,1771262530206406,1771262530205610,0.796,WS
+88094247226,1771262530206410,1771262530205610,0.800,WS
+88094247261,1771262530206411,1771262530206238,0.173,WS
+88094247268,1771262530206414,1771262530206238,0.176,WS
+88094247325,1771262530208018,1771262530208489,-0.471,UDP
+88094247353,1771262530209927,1771262530210416,-0.489,UDP
+88094247410,1771262530216004,1771262530212978,3.026,WS
+88094247417,1771262530216030,1771262530212982,3.048,WS
+88094247419,1771262530216036,1771262530212982,3.054,WS
+88094247428,1771262530216039,1771262530212983,3.056,WS
+88094247441,1771262530216042,1771262530215897,0.145,WS
+88094247442,1771262530216045,1771262530215901,0.144,WS
+88094247444,1771262530216047,1771262530215901,0.146,WS
+88094247445,1771262530216052,1771262530215902,0.150,WS
+88094247446,1771262530216053,1771262530215902,0.151,WS
+88094247447,1771262530216054,1771262530215903,0.151,WS
+88094247449,1771262530216055,1771262530215903,0.152,WS
+88094247450,1771262530216058,1771262530215904,0.154,WS
+88094247463,1771262530216059,1771262530215904,0.155,WS
+88094247479,1771262530216061,1771262530215904,0.157,WS
+88094247510,1771262530216064,1771262530215905,0.159,WS
+88094247516,1771262530216072,1771262530215905,0.167,WS
+88094247520,1771262530216076,1771262530215907,0.169,WS
+88094247521,1771262530216080,1771262530215907,0.173,WS
+88094247524,1771262530216082,1771262530215907,0.175,WS
+88094247531,1771262530216088,1771262530215908,0.180,WS
+88094247537,1771262530217080,1771262530215908,1.172,WS
+88094247542,1771262530217098,1771262530215908,1.190,WS
+88094247544,1771262530217104,1771262530215909,1.195,WS
+88094247549,1771262530217107,1771262530215909,1.198,WS
+88094247570,1771262530217110,1771262530217059,0.051,WS
+88094247573,1771262530217113,1771262530217061,0.052,WS
+88094247576,1771262530217117,1771262530217062,0.055,WS
+88094247578,1771262530217123,1771262530217063,0.060,WS
+88094247583,1771262530217127,1771262530217063,0.064,WS
+88094247600,1771262530217130,1771262530217065,0.065,WS
+88094247605,1771262530217138,1771262530217065,0.073,WS
+88094247617,1771262530217492,1771262530217067,0.425,WS
+88094247645,1771262530220567,1771262530218064,2.503,WS
+88094247648,1771262530220589,1771262530218066,2.523,WS
+88094247649,1771262530220593,1771262530218067,2.526,WS
+88094247652,1771262530220594,1771262530218067,2.527,WS
+88094247654,1771262530220598,1771262530218068,2.530,WS
+88094247656,1771262530220601,1771262530218068,2.533,WS
+88094247657,1771262530220616,1771262530218068,2.548,WS
+88094247658,1771262530220619,1771262530218069,2.550,WS
+88094247663,1771262530220627,1771262530218069,2.558,WS
+88094247665,1771262530220634,1771262530218070,2.564,WS
+88094247678,1771262530220638,1771262530220537,0.101,WS
+88094247680,1771262530220649,1771262530220541,0.108,WS
+88094247690,1771262530220656,1771262530220541,0.115,WS
+88094247692,1771262530220659,1771262530220542,0.117,WS
+88094247696,1771262530220669,1771262530220542,0.127,WS
+88094247704,1771262530220680,1771262530220543,0.137,WS
+88094247705,1771262530220687,1771262530220543,0.144,WS
+88094247712,1771262530220694,1771262530220544,0.150,WS
+88094247713,1771262530220699,1771262530220544,0.155,WS
+88094247715,1771262530220732,1771262530220545,0.187,WS
+88094247722,1771262530220756,1771262530223750,-2.994,UDP
+88094247732,1771262530224145,1771262530223757,0.388,WS
+88094247736,1771262530224159,1771262530223757,0.402,WS
+88094247740,1771262530224164,1771262530224060,0.104,WS
+88094247745,1771262530224167,1771262530224062,0.105,WS
+88094247756,1771262530224746,1771262530224063,0.683,WS
+88094247767,1771262530224761,1771262530224667,0.094,WS
+88094247776,1771262530224766,1771262530224669,0.097,WS
+88094247801,1771262530224769,1771262530224671,0.098,WS
+88094247805,1771262530224779,1771262530224672,0.107,WS
+88094247825,1771262530225245,1771262530225217,0.028,WS
+88094247833,1771262530227545,1771262530226160,1.385,WS
+88094247845,1771262530227814,1771262530227785,0.029,WS
+88094247876,1771262530233526,1771262530232691,0.835,WS
+88094247877,1771262530233553,1771262530232695,0.858,WS
+88094247895,1771262530236965,1771262530236972,-0.007,UDP
+88094247896,1771262530236991,1771262530236974,0.017,WS
+88094247898,1771262530236993,1771262530236975,0.018,WS
+88094247899,1771262530237005,1771262530236975,0.030,WS
+88094247900,1771262530237007,1771262530236976,0.031,WS
+88094247910,1771262530237008,1771262530236976,0.032,WS
+88094247938,1771262530237018,1771262530236977,0.041,WS
+88094247946,1771262530237026,1771262530236977,0.049,WS
+88094247957,1771262530237033,1771262530236978,0.055,WS
+88094248029,1771262530239452,1771262530237926,1.526,WS
+88094248032,1771262530239476,1771262530237930,1.546,WS
+88094248035,1771262530239481,1771262530237930,1.551,WS
+88094248095,1771262530243583,1771262530243103,0.480,WS
+88094248096,1771262530243605,1771262530243107,0.498,WS
+88094248097,1771262530243607,1771262530243108,0.499,WS
+88094248098,1771262530243608,1771262530243108,0.500,WS
+88094248101,1771262530243616,1771262530243109,0.507,WS
+88094248106,1771262530243622,1771262530243109,0.513,WS
+88094248108,1771262530243626,1771262530243110,0.516,WS
+88094248109,1771262530243637,1771262530243110,0.527,WS
+88094248111,1771262530243645,1771262530243111,0.534,WS
+88094248113,1771262530243652,1771262530243111,0.541,WS
+88094248114,1771262530243659,1771262530243111,0.548,WS
+88094248164,1771262530243685,1771262530243400,0.285,WS
+88094248173,1771262530243717,1771262530243405,0.312,WS
+88094248179,1771262530243722,1771262530243406,0.316,WS
+88094248183,1771262530243725,1771262530243406,0.319,WS
+88094248193,1771262530243729,1771262530243407,0.322,WS
+88094248196,1771262530244263,1771262530243407,0.856,WS
+88094248197,1771262530244294,1771262530243408,0.886,WS
+88094248205,1771262530244297,1771262530243408,0.889,WS
+88094248206,1771262530244312,1771262530243409,0.903,WS
+88094248207,1771262530244313,1771262530243410,0.903,WS
+88094248208,1771262530244314,1771262530243410,0.904,WS
+88094248213,1771262530244316,1771262530243411,0.905,WS
+88094248219,1771262530244329,1771262530243411,0.918,WS
+88094248221,1771262530244336,1771262530243412,0.924,WS
+88094248222,1771262530244346,1771262530243413,0.933,WS
+88094248250,1771262530244348,1771262530243413,0.935,WS
+88094248262,1771262530244354,1771262530243414,0.940,WS
+88094248265,1771262530244361,1771262530243414,0.947,WS
+88094248269,1771262530244370,1771262530243415,0.955,WS
+88094248279,1771262530244378,1771262530244113,0.265,WS
+88094248284,1771262530244389,1771262530244118,0.271,WS
+88094248287,1771262530244395,1771262530244119,0.276,WS
+88094248296,1771262530244404,1771262530244119,0.285,WS
+88094248299,1771262530244411,1771262530244120,0.291,WS
+88094248303,1771262530244417,1771262530244121,0.296,WS
+88094248310,1771262530244428,1771262530244121,0.307,WS
+88094248315,1771262530244434,1771262530244122,0.312,WS
+88094248316,1771262530244442,1771262530244123,0.319,WS
+88094248318,1771262530244444,1771262530244124,0.320,WS
+88094248322,1771262530244453,1771262530244124,0.329,WS
+88094248323,1771262530244465,1771262530244125,0.340,WS
+88094248325,1771262530244470,1771262530244126,0.344,WS
+88094248330,1771262530244477,1771262530244126,0.351,WS
+88094248331,1771262530244484,1771262530244127,0.357,WS
+88094248336,1771262530244487,1771262530244128,0.359,WS
+88094248339,1771262530244500,1771262530244128,0.372,WS
+88094248341,1771262530244509,1771262530244129,0.380,WS
+88094248347,1771262530244516,1771262530244133,0.383,WS
+88094248349,1771262530244526,1771262530244133,0.393,WS
+88094248351,1771262530245254,1771262530244134,1.120,WS
+88094248356,1771262530245274,1771262530244135,1.139,WS
+88094248364,1771262530245279,1771262530244135,1.144,WS
+88094248366,1771262530245283,1771262530244136,1.147,WS
+88094248370,1771262530245289,1771262530245219,0.070,WS
+88094248373,1771262530245564,1771262530245223,0.341,WS
+88094248389,1771262530247776,1771262530246377,1.399,WS
+88094248390,1771262530247801,1771262530247700,0.101,WS
+88094248391,1771262530247802,1771262530247704,0.098,WS
+88094248396,1771262530250817,1771262530251333,-0.516,UDP
+88094248397,1771262530250838,1771262530251343,-0.505,UDP
+88094248398,1771262530250839,1771262530251344,-0.505,UDP
+88094248399,1771262530250840,1771262530251345,-0.505,UDP
+88094248400,1771262530250841,1771262530251346,-0.505,UDP
+88094248401,1771262530250842,1771262530251347,-0.505,UDP
+88094248402,1771262530250843,1771262530251348,-0.505,UDP
+88094248403,1771262530250843,1771262530251349,-0.506,UDP
+88094248417,1771262530251320,1771262530251353,-0.033,UDP
+88094248418,1771262530251335,1771262530252124,-0.789,UDP
+88094248421,1771262530251336,1771262530252131,-0.795,UDP
+88094248425,1771262530252166,1771262530252132,0.034,WS
+88094248426,1771262530252181,1771262530252133,0.048,WS
+88094248429,1771262530252182,1771262530252133,0.049,WS
+88094248432,1771262530252202,1771262530252134,0.068,WS
+88094248433,1771262530252208,1771262530252135,0.073,WS
+88094248434,1771262530252209,1771262530252135,0.074,WS
+88094248435,1771262530252219,1771262530252136,0.083,WS
+88094248436,1771262530252228,1771262530252137,0.091,WS
+88094248437,1771262530252231,1771262530252137,0.094,WS
+88094248438,1771262530252247,1771262530252138,0.109,WS
+88094248439,1771262530252251,1771262530252139,0.112,WS
+88094248441,1771262530252260,1771262530252139,0.121,WS
+88094248442,1771262530252268,1771262530252140,0.128,WS
+88094248444,1771262530252276,1771262530252141,0.135,WS
+88094248448,1771262530252281,1771262530252141,0.140,WS
+88094248462,1771262530252287,1771262530252142,0.145,WS
+88094248463,1771262530252295,1771262530252143,0.152,WS
+88094248471,1771262530252302,1771262530252143,0.159,WS
+88094248473,1771262530252309,1771262530252144,0.165,WS
+88094248475,1771262530252317,1771262530252145,0.172,WS
+88094248478,1771262530252322,1771262530252145,0.177,WS
+88094248481,1771262530252333,1771262530252146,0.187,WS
+88094248486,1771262530252337,1771262530252147,0.190,WS
+88094248489,1771262530252345,1771262530252147,0.198,WS
+88094248490,1771262530252350,1771262530253499,-1.149,UDP
+88094248491,1771262530252366,1771262530253505,-1.139,UDP
+88094248492,1771262530252372,1771262530253505,-1.133,UDP
+88094248493,1771262530252379,1771262530253506,-1.127,UDP
+88094248494,1771262530252384,1771262530253507,-1.123,UDP
+88094248495,1771262530252392,1771262530253507,-1.115,UDP
+88094248496,1771262530252399,1771262530253508,-1.109,UDP
+88094248509,1771262530252407,1771262530253508,-1.101,UDP
+88094248513,1771262530252411,1771262530253509,-1.098,UDP
+88094248535,1771262530253490,1771262530253509,-0.019,UDP
+88094248553,1771262530254373,1771262530253511,0.862,WS
+88094248556,1771262530254390,1771262530253511,0.879,WS
+88094248558,1771262530254395,1771262530253512,0.883,WS
+88094248560,1771262530254398,1771262530253512,0.886,WS
+88094248561,1771262530254401,1771262530253513,0.888,WS
+88094248563,1771262530254402,1771262530253513,0.889,WS
+88094248564,1771262530254406,1771262530253513,0.893,WS
+88094248565,1771262530254407,1771262530253514,0.893,WS
+88094248566,1771262530254407,1771262530253514,0.893,WS
+88094248570,1771262530254408,1771262530253515,0.893,WS
+88094248571,1771262530254413,1771262530253515,0.898,WS
+88094248572,1771262530254413,1771262530253515,0.898,WS
+88094248575,1771262530254414,1771262530256750,-2.336,UDP
+88094248582,1771262530254417,1771262530256756,-2.339,UDP
+88094248587,1771262530254421,1771262530256757,-2.336,UDP
+88094248588,1771262530254426,1771262530256758,-2.332,UDP
+88094248591,1771262530254427,1771262530256758,-2.331,UDP
+88094248592,1771262530254431,1771262530256759,-2.328,UDP
+88094248594,1771262530254432,1771262530256759,-2.327,UDP
+88094248597,1771262530254434,1771262530256760,-2.326,UDP
+88094248602,1771262530257366,1771262530256760,0.606,WS
+88094248604,1771262530257397,1771262530256761,0.636,WS
+88094248615,1771262530257406,1771262530256761,0.645,WS
+88094248617,1771262530257417,1771262530257372,0.045,WS
+88094248620,1771262530257425,1771262530257375,0.050,WS
+88094248627,1771262530257436,1771262530257376,0.060,WS
+88094248629,1771262530257443,1771262530257376,0.067,WS
+88094248631,1771262530257453,1771262530257377,0.076,WS
+88094248632,1771262530257460,1771262530257377,0.083,WS
+88094248635,1771262530257462,1771262530257377,0.085,WS
+88094248636,1771262530257472,1771262530257378,0.094,WS
+88094248638,1771262530257473,1771262530257378,0.095,WS
+88094248639,1771262530257483,1771262530257379,0.104,WS
+88094248642,1771262530257485,1771262530257379,0.106,WS
+88094248646,1771262530257495,1771262530257381,0.114,WS
+88094248647,1771262530257504,1771262530257381,0.123,WS
+88094248648,1771262530257506,1771262530257382,0.124,WS
+88094248651,1771262530257508,1771262530257383,0.125,WS
+88094248656,1771262530257518,1771262530257384,0.134,WS
+88094248657,1771262530257527,1771262530257384,0.143,WS
+88094248659,1771262530257529,1771262530257385,0.144,WS
+88094248671,1771262530258337,1771262530263811,-5.474,UDP
+88094248685,1771262530264503,1771262530264387,0.116,WS
+88094248686,1771262530264529,1771262530264388,0.141,WS
+88094248687,1771262530264530,1771262530264389,0.141,WS
+88094248694,1771262530264531,1771262530264390,0.141,WS
+88094248700,1771262530267520,1771262530267421,0.099,WS
+88094248711,1771262530269311,1771262530270661,-1.350,UDP
+88094248752,1771262530280519,1771262530279558,0.961,WS
+88094248756,1771262530282435,1771262530282086,0.349,WS
+88094248804,1771262530286487,1771262530287358,-0.871,UDP
+88094248805,1771262530286504,1771262530287364,-0.860,UDP
+88094248818,1771262530287345,1771262530287365,-0.020,UDP
+88094248819,1771262530287361,1771262530287366,-0.005,UDP
+88094248820,1771262530287364,1771262530287367,-0.003,UDP
+88094248821,1771262530287365,1771262530287367,-0.002,UDP
+88094248824,1771262530287366,1771262530287368,-0.002,UDP
+88094248825,1771262530287371,1771262530287369,0.002,WS
+88094248828,1771262530287372,1771262530287369,0.003,WS
+88094248829,1771262530287375,1771262530287370,0.005,WS
+88094248832,1771262530287376,1771262530287370,0.006,WS
+88094248833,1771262530287379,1771262530287371,0.008,WS
+88094248858,1771262530287380,1771262530287372,0.008,WS
+88094248867,1771262530287383,1771262530287704,-0.321,UDP
+88094248905,1771262530290873,1771262530291736,-0.863,UDP
+88094248918,1771262530290894,1771262530291744,-0.850,UDP
+88094248920,1771262530290898,1771262530291745,-0.847,UDP
+88094248922,1771262530290901,1771262530291746,-0.845,UDP
+88094248933,1771262530291992,1771262530291746,0.246,WS
+88094248965,1771262530292025,1771262530291747,0.278,WS
+88094248966,1771262530292035,1771262530291747,0.288,WS
+88094248967,1771262530292036,1771262530291748,0.288,WS
+88094248968,1771262530292037,1771262530291748,0.289,WS
+88094248969,1771262530292040,1771262530291748,0.292,WS
+88094248981,1771262530292042,1771262530291749,0.293,WS
+88094248982,1771262530292053,1771262530291749,0.304,WS
+88094248983,1771262530292055,1771262530291750,0.305,WS
+88094248993,1771262530292056,1771262530291750,0.306,WS
+88094249010,1771262530292069,1771262530291750,0.319,WS
+88094249014,1771262530292077,1771262530291824,0.253,WS
+88094249015,1771262530292087,1771262530291825,0.262,WS
+88094249016,1771262530292088,1771262530291825,0.263,WS
+88094249019,1771262530292089,1771262530291826,0.263,WS
+88094249038,1771262530292100,1771262530291826,0.274,WS
+88094249061,1771262530292107,1771262530291827,0.280,WS
+88094249066,1771262530292117,1771262530291827,0.290,WS
+88094249084,1771262530292132,1771262530291927,0.205,WS
+88094249092,1771262530292144,1771262530291931,0.213,WS
+88094249099,1771262530292158,1771262530291932,0.226,WS
+88094249145,1771262530293019,1771262530291935,1.084,WS
+88094249156,1771262530293054,1771262530294133,-1.079,UDP
+88094249172,1771262530294410,1771262530294141,0.269,WS
+88094249173,1771262530294432,1771262530294141,0.291,WS
+88094249177,1771262530294433,1771262530294142,0.291,WS
+88094249207,1771262530294438,1771262530294142,0.296,WS
+88094249214,1771262530294445,1771262530294143,0.302,WS
+88094249221,1771262530294449,1771262530294363,0.086,WS
+88094249224,1771262530294452,1771262530294366,0.086,WS
+88094249232,1771262530295135,1771262530294366,0.769,WS
+88094249234,1771262530295151,1771262530294367,0.784,WS
+88094249239,1771262530295164,1771262530294368,0.796,WS
+88094249251,1771262530295170,1771262530294368,0.802,WS
+88094249265,1771262530295175,1771262530294369,0.806,WS
+88094249267,1771262530295179,1771262530294369,0.810,WS
+88094249272,1771262530295183,1771262530294370,0.813,WS
+88094249275,1771262530295187,1771262530294370,0.817,WS
+88094249276,1771262530295195,1771262530294371,0.824,WS
+88094249277,1771262530295196,1771262530294371,0.825,WS
+88094249279,1771262530295197,1771262530294372,0.825,WS
+88094249281,1771262530295202,1771262530294372,0.830,WS
+88094249303,1771262530295206,1771262530297291,-2.085,UDP
+88094249307,1771262530295210,1771262530297299,-2.089,UDP
+88094249313,1771262530297601,1771262530297300,0.301,WS
+88094249314,1771262530297622,1771262530297300,0.322,WS
+88094249331,1771262530297623,1771262530297513,0.110,WS
+88094249332,1771262530297628,1771262530297515,0.113,WS
+88094249333,1771262530297629,1771262530297516,0.113,WS
+88094249341,1771262530297630,1771262530297516,0.114,WS
+88094249351,1771262530297634,1771262530297517,0.117,WS
+88094249417,1771262530300842,1771262530300674,0.168,WS
+88094249419,1771262530300866,1771262530300678,0.188,WS
+88094249448,1771262530300871,1771262530300822,0.049,WS
+88094249468,1771262530305980,1771262530300825,5.155,WS
+88094249469,1771262530306017,1771262530300826,5.191,WS
+88094249470,1771262530306019,1771262530300827,5.192,WS
+88094249471,1771262530306020,1771262530300827,5.193,WS
+88094249472,1771262530306021,1771262530300828,5.193,WS
+88094249473,1771262530306023,1771262530300828,5.195,WS
+88094249501,1771262530306024,1771262530306185,-0.161,UDP
+88094249502,1771262530306068,1771262530306197,-0.129,UDP
+88094249504,1771262530306069,1771262530306198,-0.129,UDP
+88094249530,1771262530306081,1771262530306198,-0.117,UDP
+88094249547,1771262530306114,1771262530306201,-0.087,UDP
+88094249587,1771262530306124,1771262530306204,-0.080,UDP
+88094249594,1771262530306130,1771262530306206,-0.076,UDP
+88094249602,1771262530306137,1771262530306207,-0.070,UDP
+88094249603,1771262530306143,1771262530306208,-0.065,UDP
+88094249607,1771262530306144,1771262530306209,-0.065,UDP
+88094249686,1771262530309128,1771262530308910,0.218,WS
+88094249700,1771262530309147,1771262530308917,0.230,WS
+88094249701,1771262530309151,1771262530308918,0.233,WS
+88094249767,1771262530313831,1771262530310575,3.256,WS
+88094249768,1771262530313859,1771262530310578,3.281,WS
+88094249771,1771262530313860,1771262530310579,3.281,WS
+88094249772,1771262530313866,1771262530310579,3.287,WS
+88094249773,1771262530313867,1771262530310579,3.288,WS
+88094249774,1771262530313868,1771262530310580,3.288,WS
+88094249775,1771262530313869,1771262530310580,3.289,WS
+88094249776,1771262530313870,1771262530310581,3.289,WS
+88094249805,1771262530313874,1771262530314177,-0.303,UDP
+88094249807,1771262530314194,1771262530314188,0.006,WS
+88094249818,1771262530314214,1771262530314189,0.025,WS
+88094249828,1771262530314219,1771262530314190,0.029,WS
+88094249858,1771262530314223,1771262530314193,0.030,WS
+88094249874,1771262530314227,1771262530314952,-0.725,UDP
+88094249886,1771262530314981,1771262530314960,0.021,WS
+88094249888,1771262530315009,1771262530314961,0.048,WS
+88094249905,1771262530315018,1771262530314962,0.056,WS
+88094249921,1771262530315164,1771262530314965,0.199,WS
+88094249962,1771262530318968,1771262530319661,-0.693,UDP
+88094249964,1771262530318988,1771262530319669,-0.681,UDP
+88094249969,1771262530320393,1771262530319670,0.723,WS
+88094249974,1771262530320404,1771262530319671,0.733,WS
+88094249977,1771262530320408,1771262530319671,0.737,WS
+88094249978,1771262530320411,1771262530319672,0.739,WS
+88094249980,1771262530320412,1771262530319672,0.740,WS
+88094249982,1771262530320416,1771262530319673,0.743,WS
+88094249983,1771262530320419,1771262530319673,0.746,WS
+88094249988,1771262530320420,1771262530323323,-2.903,UDP
+88094249990,1771262530320422,1771262530323335,-2.913,UDP
+88094249994,1771262530320425,1771262530323337,-2.912,UDP
+88094250002,1771262530320428,1771262530323338,-2.910,UDP
+88094250005,1771262530320431,1771262530323339,-2.908,UDP
+88094250011,1771262530323588,1771262530323339,0.249,WS
+88094250015,1771262530323619,1771262530323340,0.279,WS
+88094250018,1771262530323627,1771262530323341,0.286,WS
+88094250020,1771262530323637,1771262530323342,0.295,WS
+88094250022,1771262530323644,1771262530323342,0.302,WS
+88094250023,1771262530323654,1771262530323343,0.311,WS
+88094250024,1771262530323656,1771262530323344,0.312,WS
+88094250030,1771262530323659,1771262530323344,0.315,WS
+88094250032,1771262530323669,1771262530323345,0.324,WS
+88094250033,1771262530323679,1771262530324164,-0.485,UDP
+88094250034,1771262530323680,1771262530324169,-0.489,UDP
+88094250042,1771262530323682,1771262530324170,-0.488,UDP
+88094250043,1771262530324164,1771262530324170,-0.006,UDP
+88094250046,1771262530324166,1771262530324171,-0.005,UDP
+88094250048,1771262530324192,1771262530324171,0.021,WS
+88094250057,1771262530324204,1771262530324173,0.031,WS
+88094250064,1771262530324215,1771262530324173,0.042,WS
+88094250071,1771262530324225,1771262530324173,0.052,WS
+88094250075,1771262530324234,1771262530324174,0.060,WS
+88094250077,1771262530324245,1771262530324175,0.070,WS
+88094250087,1771262530324257,1771262530324175,0.082,WS
+88094250112,1771262530326540,1771262530324909,1.631,WS
+88094250121,1771262530326556,1771262530326798,-0.242,UDP
+88094250122,1771262530326561,1771262530326803,-0.242,UDP
+88094250129,1771262530327070,1771262530326804,0.266,WS
+88094250149,1771262530328667,1771262530327806,0.861,WS
+88094250161,1771262530328695,1771262530327808,0.887,WS
+88094250165,1771262530328701,1771262530327809,0.892,WS
+88094250197,1771262530332526,1771262530331669,0.857,WS
+88094250209,1771262530332557,1771262530333100,-0.543,UDP
+88094250225,1771262530336190,1771262530336899,-0.709,UDP
+88094250230,1771262530337670,1771262530336907,0.763,WS
+88094250252,1771262530337691,1771262530336908,0.783,WS
+88094250266,1771262530337696,1771262530336908,0.788,WS
+88094250268,1771262530337699,1771262530336909,0.790,WS
+88094250274,1771262530337702,1771262530336909,0.793,WS
+88094250285,1771262530337705,1771262530336910,0.795,WS
+88094250289,1771262530338759,1771262530338374,0.385,WS
+88094250290,1771262530338773,1771262530338377,0.396,WS
+88094250291,1771262530338774,1771262530338377,0.397,WS
+88094250298,1771262530338775,1771262530338378,0.397,WS
+88094250302,1771262530338779,1771262530338378,0.401,WS
+88094250304,1771262530338782,1771262530338379,0.403,WS
+88094250309,1771262530338786,1771262530338379,0.407,WS
+88094250310,1771262530338789,1771262530338380,0.409,WS
+88094250311,1771262530338789,1771262530338380,0.409,WS
+88094250312,1771262530338790,1771262530338380,0.410,WS
+88094250313,1771262530338791,1771262530338381,0.410,WS
+88094250319,1771262530338792,1771262530338381,0.411,WS
+88094250320,1771262530338795,1771262530338382,0.413,WS
+88094250321,1771262530338801,1771262530338382,0.419,WS
+88094250322,1771262530338802,1771262530338382,0.420,WS
+88094250330,1771262530338803,1771262530338383,0.420,WS
+88094250359,1771262530338806,1771262530338383,0.423,WS
+88094250366,1771262530338809,1771262530338384,0.425,WS
+88094250394,1771262530342822,1771262530342542,0.280,WS
+88094250400,1771262530342847,1771262530342546,0.301,WS
+88094250405,1771262530342851,1771262530342547,0.304,WS
+88094250434,1771262530342855,1771262530344354,-1.499,UDP
+88094250438,1771262530342858,1771262530344360,-1.502,UDP
+88094250439,1771262530342861,1771262530344362,-1.501,UDP
+88094250440,1771262530342862,1771262530344363,-1.501,UDP
+88094250441,1771262530342863,1771262530344363,-1.500,UDP
+88094250442,1771262530342863,1771262530344364,-1.501,UDP
+88094250449,1771262530342864,1771262530344365,-1.501,UDP
+88094250454,1771262530342867,1771262530344365,-1.498,UDP
+88094250455,1771262530342870,1771262530344366,-1.496,UDP
+88094250470,1771262530344398,1771262530344367,0.031,WS
+88094250471,1771262530344411,1771262530344367,0.044,WS
+88094250476,1771262530344413,1771262530344368,0.045,WS
+88094250479,1771262530344418,1771262530344369,0.049,WS
+88094250487,1771262530344423,1771262530344369,0.054,WS
+88094250514,1771262530344427,1771262530344369,0.058,WS
+88094250519,1771262530344435,1771262530344370,0.065,WS
+88094250526,1771262530344439,1771262530344371,0.068,WS
+88094250527,1771262530344442,1771262530344371,0.071,WS
+88094250528,1771262530344443,1771262530344372,0.071,WS
+88094250530,1771262530344443,1771262530344373,0.070,WS
+88094250531,1771262530344447,1771262530344373,0.074,WS
+88094250533,1771262530344448,1771262530344374,0.074,WS
+88094250534,1771262530344453,1771262530344375,0.078,WS
+88094250535,1771262530344465,1771262530344375,0.090,WS
+88094250537,1771262530344468,1771262530344376,0.092,WS
+88094250545,1771262530344474,1771262530344376,0.098,WS
+88094250547,1771262530344479,1771262530344376,0.103,WS
+88094250548,1771262530344483,1771262530344377,0.106,WS
+88094250549,1771262530344492,1771262530344378,0.114,WS
+88094250552,1771262530344495,1771262530344378,0.117,WS
+88094250558,1771262530344500,1771262530344379,0.121,WS
+88094250569,1771262530344504,1771262530344384,0.120,WS
+88094250570,1771262530344510,1771262530344385,0.125,WS
+88094250571,1771262530344521,1771262530344386,0.135,WS
+88094250572,1771262530344524,1771262530344386,0.138,WS
+88094250575,1771262530344530,1771262530344387,0.143,WS
+88094250577,1771262530344537,1771262530344387,0.150,WS
+88094250579,1771262530344546,1771262530344388,0.158,WS
+88094250583,1771262530344549,1771262530344389,0.160,WS
+88094250585,1771262530344554,1771262530344389,0.165,WS
+88094250593,1771262530344563,1771262530344390,0.173,WS
+88094250595,1771262530344571,1771262530344390,0.181,WS
+88094250602,1771262530344576,1771262530344392,0.184,WS
+88094250605,1771262530344580,1771262530344392,0.188,WS
+88094250626,1771262530344594,1771262530344393,0.201,WS
+88094250632,1771262530344834,1771262530344395,0.439,WS
+88094250638,1771262530346093,1771262530345950,0.143,WS
+88094250639,1771262530346105,1771262530345952,0.153,WS
+88094250640,1771262530346106,1771262530345952,0.154,WS
+88094250643,1771262530349318,1771262530349220,0.098,WS
+88094250748,1771262530369937,1771262530368746,1.191,WS
+88094250766,1771262530372204,1771262530372338,-0.134,UDP
+88094250772,1771262530372566,1771262530373487,-0.921,UDP
+88094250797,1771262530385113,1771262530384430,0.683,WS
+88094250824,1771262530386605,1771262530385836,0.769,WS
+88094250825,1771262530386618,1771262530385838,0.780,WS
+88094250865,1771262530390085,1771262530389926,0.159,WS
+88094250884,1771262530390119,1771262530389930,0.189,WS
+88094250895,1771262530393426,1771262530392622,0.804,WS
+88094250923,1771262530408810,1771262530407627,1.183,WS
+88094250928,1771262530411467,1771262530411391,0.076,WS
+88094250937,1771262530414537,1771262530413757,0.780,WS
+88094250968,1771262530436599,1771262530435719,0.880,WS
+88094250978,1771262530436624,1771262530435723,0.901,WS
+88094250979,1771262530436629,1771262530435724,0.905,WS
+88094250980,1771262530436630,1771262530435724,0.906,WS
+88094250982,1771262530436631,1771262530435725,0.906,WS
+88094250985,1771262530436634,1771262530435725,0.909,WS
+88094250990,1771262530436637,1771262530436502,0.135,WS
+88094251003,1771262530439502,1771262530436504,2.998,WS
+88094251010,1771262530439526,1771262530436505,3.021,WS
+88094251015,1771262530439530,1771262530436505,3.025,WS
+88094251029,1771262530439534,1771262530439507,0.027,WS
+88094251031,1771262530439538,1771262530439511,0.027,WS
+88094251039,1771262530439541,1771262530440233,-0.692,UDP
+88094251049,1771262530445420,1771262530444584,0.836,WS
+88094251058,1771262530455490,1771262530456092,-0.602,UDP
+88094251061,1771262530463169,1771262530462554,0.615,WS
+88094251064,1771262530469129,1771262530468423,0.706,WS
+88094251069,1771262530474212,1771262530474737,-0.525,UDP
+88094251073,1771262530480192,1771262530479461,0.731,WS
+88094251075,1771262530482818,1771262530482509,0.309,WS
+88094251078,1771262530486244,1771262530485586,0.658,WS
+88094251079,1771262530486267,1771262530485589,0.678,WS
+88094251085,1771262530486268,1771262530485590,0.678,WS
+88094251097,1771262530536140,1771262530536095,0.045,WS
+88094251102,1771262530544202,1771262530543555,0.647,WS
+88094251209,1771262530636350,1771262530635600,0.750,WS
+88094251210,1771262530636377,1771262530635604,0.773,WS
+88094251216,1771262530636378,1771262530637170,-0.792,UDP
+88094251217,1771262530636383,1771262530637175,-0.792,UDP
+88094251218,1771262530636384,1771262530637176,-0.792,UDP
+88094251226,1771262530636385,1771262530637177,-0.792,UDP
+88094251234,1771262530637269,1771262530639199,-1.930,UDP
+88094251235,1771262530637295,1771262530639211,-1.916,UDP
+88094251243,1771262530639292,1771262530639216,0.076,WS
+88094251254,1771262530658952,1771262530657913,1.039,WS
+88094251255,1771262530658977,1771262530657918,1.059,WS
+88094251256,1771262530661320,1771262530661616,-0.296,UDP
+88094251257,1771262530661610,1771262530661620,-0.010,UDP
+88094251266,1771262530686383,1771262530685644,0.739,WS
+88094251274,1771262530688958,1771262530689215,-0.257,UDP
+88094251275,1771262530704358,1771262530704408,-0.050,UDP
+88094251293,1771262530735055,1771262530736783,-1.728,UDP
+88094251299,1771262530736948,1771262530736795,0.153,WS
+88094251415,1771262530940374,1771262530939610,0.764,WS
+88094251435,1771262530967489,1771262530967781,-0.292,UDP
+88094251456,1771262530998908,1771262530998723,0.185,WS
+88094251479,1771262531028150,1771262531028130,0.020,WS
+88094251480,1771262531030597,1771262531030659,-0.062,UDP
+88094251543,1771262531088073,1771262531085813,2.260,WS
+88094251548,1771262531088100,1771262531085818,2.282,WS
+88094251611,1771262531101956,1771262531101778,0.178,WS
+88094251612,1771262531103454,1771262531103282,0.172,WS
+88094251613,1771262531103458,1771262531103288,0.170,WS
+88094251614,1771262531103459,1771262531103289,0.170,WS
+88094251615,1771262531103466,1771262531103290,0.176,WS
+88094251617,1771262531103466,1771262531103290,0.176,WS
+88094251621,1771262531103478,1771262531103291,0.187,WS
+88094251622,1771262531103483,1771262531103291,0.192,WS
+88094251623,1771262531103484,1771262531103292,0.192,WS
+88094251636,1771262531107853,1771262531107764,0.089,WS
+88094251640,1771262531107874,1771262531107767,0.107,WS
+88094251641,1771262531107878,1771262531107768,0.110,WS
+88094251642,1771262531107879,1771262531107769,0.110,WS
+88094251643,1771262531107880,1771262531107769,0.111,WS
+88094251644,1771262531107888,1771262531107770,0.118,WS
+88094251645,1771262531107895,1771262531107770,0.125,WS
+88094251646,1771262531107900,1771262531107771,0.129,WS
+88094251647,1771262531107908,1771262531107771,0.137,WS
+88094251648,1771262531107915,1771262531107772,0.143,WS
+88094251649,1771262531107923,1771262531107772,0.151,WS
+88094251650,1771262531107928,1771262531107772,0.156,WS
+88094251651,1771262531107935,1771262531107773,0.162,WS
+88094251657,1771262531107943,1771262531107773,0.170,WS
+88094251658,1771262531107950,1771262531107774,0.176,WS
+88094251663,1771262531107958,1771262531107775,0.183,WS
+88094251667,1771262531107961,1771262531107775,0.186,WS
+88094251687,1771262531107972,1771262531107776,0.196,WS
+88094251688,1771262531107976,1771262531107776,0.200,WS
+88094251689,1771262531107984,1771262531107776,0.208,WS
+88094251709,1771262531107992,1771262531107777,0.215,WS
+88094251710,1771262531108739,1771262531107777,0.962,WS
+88094251727,1771262531108751,1771262531107778,0.973,WS
+88094251741,1771262531108758,1771262531107778,0.980,WS
+88094251742,1771262531108762,1771262531108599,0.163,WS
+88094251743,1771262531108771,1771262531108602,0.169,WS
+88094251744,1771262531108779,1771262531108602,0.177,WS
+88094251746,1771262531108783,1771262531108603,0.180,WS
+88094251747,1771262531108789,1771262531108603,0.186,WS
+88094251750,1771262531108801,1771262531108604,0.197,WS
+88094251758,1771262531108807,1771262531108604,0.203,WS
+88094251762,1771262531108814,1771262531108605,0.209,WS
+88094251793,1771262531108822,1771262531108605,0.217,WS
+88094251797,1771262531108827,1771262531108605,0.222,WS
+88094251805,1771262531108835,1771262531108606,0.229,WS
+88094251823,1771262531108846,1771262531108607,0.239,WS
+88094251874,1771262531108862,1771262531108607,0.255,WS
+88094251875,1771262531108868,1771262531108608,0.260,WS
+88094251877,1771262531108958,1771262531108608,0.350,WS
+88094251908,1771262531108985,1771262531108608,0.377,WS
+88094251916,1771262531108994,1771262531108609,0.385,WS
+88094251917,1771262531109007,1771262531108609,0.398,WS
+88094251919,1771262531109008,1771262531108610,0.398,WS
+88094251920,1771262531109020,1771262531108610,0.410,WS
+88094251921,1771262531109022,1771262531108610,0.412,WS
+88094251939,1771262531109025,1771262531108847,0.178,WS
+88094251957,1771262531111969,1771262531108850,3.119,WS
+88094251959,1771262531111996,1771262531108852,3.144,WS
+88094251972,1771262531112001,1771262531108853,3.148,WS
+88094251986,1771262531112004,1771262531112089,-0.085,UDP
+88094251988,1771262531112007,1771262531112100,-0.093,UDP
+88094251989,1771262531112010,1771262531112101,-0.091,UDP
+88094251990,1771262531112011,1771262531112102,-0.091,UDP
+88094251992,1771262531112011,1771262531112103,-0.092,UDP
+88094251993,1771262531112014,1771262531112104,-0.090,UDP
+88094251997,1771262531112015,1771262531112104,-0.089,UDP
+88094252019,1771262531112078,1771262531112105,-0.027,UDP
+88094252055,1771262531112103,1771262531112107,-0.004,UDP
+88094252075,1771262531112116,1771262531112108,0.008,WS
+88094252077,1771262531112123,1771262531112108,0.015,WS
+88094252082,1771262531112136,1771262531112110,0.026,WS
+88094252084,1771262531112149,1771262531112115,0.034,WS
+88094252087,1771262531112161,1771262531112116,0.045,WS
+88094252093,1771262531112618,1771262531112116,0.502,WS
+88094252105,1771262531112630,1771262531112117,0.513,WS
+88094252106,1771262531112635,1771262531112118,0.517,WS
+88094252117,1771262531112636,1771262531112119,0.517,WS
+88094252149,1771262531113114,1771262531112901,0.213,WS
+88094252183,1771262531115370,1771262531115049,0.321,WS
+88094252187,1771262531115396,1771262531115051,0.345,WS
+88094252190,1771262531115400,1771262531115288,0.112,WS
+88094252194,1771262531115403,1771262531115289,0.114,WS
+88094252202,1771262531115408,1771262531115289,0.119,WS
+88094252205,1771262531115412,1771262531115290,0.122,WS
+88094252218,1771262531115424,1771262531115290,0.134,WS
+88094252226,1771262531115427,1771262531115291,0.136,WS
+88094252230,1771262531115432,1771262531116304,-0.872,UDP
+88094252235,1771262531115435,1771262531116310,-0.875,UDP
+88094252241,1771262531117128,1771262531116310,0.818,WS
+88094252242,1771262531117148,1771262531116311,0.837,WS
+88094252243,1771262531117149,1771262531116311,0.838,WS
+88094252244,1771262531117150,1771262531116312,0.838,WS
+88094252245,1771262531117151,1771262531116312,0.839,WS
+88094252246,1771262531117152,1771262531116313,0.839,WS
+88094252247,1771262531117153,1771262531116313,0.840,WS
+88094252248,1771262531117154,1771262531116313,0.841,WS
+88094252249,1771262531117155,1771262531116314,0.841,WS
+88094252250,1771262531117156,1771262531116314,0.842,WS
+88094252251,1771262531117157,1771262531116315,0.842,WS
+88094252252,1771262531117158,1771262531116315,0.843,WS
+88094252257,1771262531117159,1771262531116315,0.844,WS
+88094252320,1771262531118499,1771262531118282,0.217,WS
+88094252378,1771262531122240,1771262531122200,0.040,WS
+88094252385,1771262531122274,1771262531122205,0.069,WS
+88094252386,1771262531122284,1771262531122206,0.078,WS
+88094252387,1771262531122286,1771262531122207,0.079,WS
+88094252388,1771262531122288,1771262531122208,0.080,WS
+88094252389,1771262531122290,1771262531122209,0.081,WS
+88094252391,1771262531122292,1771262531122209,0.083,WS
+88094252392,1771262531122303,1771262531122210,0.093,WS
+88094252393,1771262531122304,1771262531122211,0.093,WS
+88094252394,1771262531122306,1771262531122211,0.095,WS
+88094252398,1771262531122307,1771262531122212,0.095,WS
+88094252400,1771262531122315,1771262531122213,0.102,WS
+88094252401,1771262531122325,1771262531122214,0.111,WS
+88094252407,1771262531122326,1771262531122844,-0.518,UDP
+88094252409,1771262531122334,1771262531122852,-0.518,UDP
+88094252410,1771262531122341,1771262531122853,-0.512,UDP
+88094252415,1771262531122342,1771262531122854,-0.512,UDP
+88094252433,1771262531122348,1771262531122854,-0.506,UDP
+88094252451,1771262531123880,1771262531122855,1.025,WS
+88094252453,1771262531123911,1771262531122855,1.056,WS
+88094252457,1771262531123920,1771262531122856,1.064,WS
+88094252460,1771262531123930,1771262531122856,1.074,WS
+88094252462,1771262531123937,1771262531122857,1.080,WS
+88094252464,1771262531123947,1771262531122857,1.090,WS
+88094252465,1771262531123960,1771262531122858,1.102,WS
+88094252471,1771262531123961,1771262531122858,1.103,WS
+88094252481,1771262531123968,1771262531123811,0.157,WS
+88094252500,1771262531126486,1771262531126058,0.428,WS
+88094252518,1771262531126521,1771262531126712,-0.191,UDP
+88094252521,1771262531126525,1771262531126718,-0.193,UDP
+88094252522,1771262531126529,1771262531126719,-0.190,UDP
+88094252523,1771262531126529,1771262531126720,-0.191,UDP
+88094252528,1771262531126530,1771262531126721,-0.191,UDP
+88094252531,1771262531126534,1771262531126721,-0.187,UDP
+88094252534,1771262531126537,1771262531126722,-0.185,UDP
+88094252539,1771262531126539,1771262531126722,-0.183,UDP
+88094252540,1771262531126542,1771262531126723,-0.181,UDP
+88094252543,1771262531126543,1771262531126723,-0.180,UDP
+88094252545,1771262531126546,1771262531126723,-0.177,UDP
+88094252552,1771262531127483,1771262531126724,0.759,WS
+88094252553,1771262531127495,1771262531126724,0.771,WS
+88094252555,1771262531127503,1771262531126725,0.778,WS
+88094252557,1771262531127509,1771262531126725,0.784,WS
+88094252558,1771262531127520,1771262531126725,0.795,WS
+88094252559,1771262531127528,1771262531126726,0.802,WS
+88094252560,1771262531127600,1771262531126726,0.874,WS
+88094252561,1771262531127604,1771262531126727,0.877,WS
+88094252564,1771262531127605,1771262531126727,0.878,WS
+88094252566,1771262531127621,1771262531126728,0.893,WS
+88094252571,1771262531127626,1771262531126728,0.898,WS
+88094252580,1771262531127629,1771262531127380,0.249,WS
+88094252582,1771262531127632,1771262531127382,0.250,WS
+88094252584,1771262531127636,1771262531127382,0.254,WS
+88094252587,1771262531127643,1771262531127383,0.260,WS
+88094252610,1771262531130714,1771262531128075,2.639,WS
+88094252629,1771262531131150,1771262531130937,0.213,WS
+88094252630,1771262531131165,1771262531130942,0.223,WS
+88094252632,1771262531131166,1771262531130943,0.223,WS
+88094252633,1771262531131177,1771262531130944,0.233,WS
+88094252634,1771262531131185,1771262531130945,0.240,WS
+88094252638,1771262531131191,1771262531130946,0.245,WS
+88094252640,1771262531131203,1771262531130946,0.257,WS
+88094252641,1771262531131206,1771262531130947,0.259,WS
+88094252643,1771262531131216,1771262531130948,0.268,WS
+88094252644,1771262531131224,1771262531130949,0.275,WS
+88094252645,1771262531131231,1771262531130949,0.282,WS
+88094252648,1771262531131239,1771262531130950,0.289,WS
+88094252662,1771262531131246,1771262531131770,-0.524,UDP
+88094252667,1771262531131254,1771262531131779,-0.525,UDP
+88094252670,1771262531131261,1771262531131780,-0.519,UDP
+88094252671,1771262531132407,1771262531131781,0.626,WS
+88094252678,1771262531132411,1771262531131782,0.629,WS
+88094252679,1771262531132428,1771262531131783,0.645,WS
+88094252680,1771262531132429,1771262531131783,0.646,WS
+88094252681,1771262531132430,1771262531131784,0.646,WS
+88094252682,1771262531132431,1771262531131785,0.646,WS
+88094252683,1771262531132432,1771262531131785,0.647,WS
+88094252684,1771262531132433,1771262531131786,0.647,WS
+88094252685,1771262531132434,1771262531131787,0.647,WS
+88094252688,1771262531132435,1771262531131787,0.648,WS
+88094252690,1771262531132440,1771262531131788,0.652,WS
+88094252691,1771262531132444,1771262531131789,0.655,WS
+88094252692,1771262531132445,1771262531131789,0.656,WS
+88094252693,1771262531132453,1771262531131790,0.663,WS
+88094252709,1771262531132456,1771262531131791,0.665,WS
+88094252712,1771262531132462,1771262531131792,0.670,WS
+88094252718,1771262531132466,1771262531131792,0.674,WS
+88094252720,1771262531132469,1771262531131793,0.676,WS
+88094252729,1771262531132472,1771262531131794,0.678,WS
+88094252741,1771262531132475,1771262531131794,0.681,WS
+88094252745,1771262531132478,1771262531131795,0.683,WS
+88094252748,1771262531132481,1771262531132375,0.106,WS
+88094252750,1771262531132484,1771262531132379,0.105,WS
+88094252752,1771262531132490,1771262531132380,0.110,WS
+88094252760,1771262531132950,1771262531132380,0.570,WS
+88094252770,1771262531132959,1771262531132381,0.578,WS
+88094252771,1771262531132963,1771262531132382,0.581,WS
+88094252773,1771262531132964,1771262531132382,0.582,WS
+88094252777,1771262531132967,1771262531132383,0.584,WS
+88094252779,1771262531132970,1771262531132384,0.586,WS
+88094252780,1771262531132972,1771262531132384,0.588,WS
+88094252781,1771262531132973,1771262531135527,-2.554,UDP
+88094252783,1771262531132974,1771262531135536,-2.562,UDP
+88094252785,1771262531132977,1771262531135537,-2.560,UDP
+88094252787,1771262531132981,1771262531135538,-2.557,UDP
+88094252792,1771262531132986,1771262531135538,-2.552,UDP
+88094252793,1771262531132989,1771262531135539,-2.550,UDP
+88094252797,1771262531136187,1771262531135539,0.648,WS
+88094252798,1771262531136212,1771262531135540,0.672,WS
+88094252801,1771262531136213,1771262531135540,0.673,WS
+88094252802,1771262531136218,1771262531135540,0.678,WS
+88094252805,1771262531136232,1771262531135541,0.691,WS
+88094252809,1771262531136237,1771262531135541,0.696,WS
+88094252820,1771262531136241,1771262531136152,0.089,WS
+88094252822,1771262531136250,1771262531136155,0.095,WS
+88094252836,1771262531136257,1771262531136156,0.101,WS
+88094252837,1771262531136265,1771262531136157,0.108,WS
+88094252847,1771262531136270,1771262531136158,0.112,WS
+88094252850,1771262531136277,1771262531136159,0.118,WS
+88094252857,1771262531136321,1771262531136160,0.161,WS
+88094252878,1771262531136328,1771262531136161,0.167,WS
+88094252931,1771262531136331,1771262531136161,0.170,WS
+88094252933,1771262531136335,1771262531136162,0.173,WS
+88094252936,1771262531136338,1771262531136163,0.175,WS
+88094252940,1771262531136343,1771262531136163,0.180,WS
+88094252941,1771262531136347,1771262531136889,-0.542,UDP
+88094252942,1771262531136347,1771262531136894,-0.547,UDP
+88094252943,1771262531136349,1771262531136895,-0.546,UDP
+88094252952,1771262531136372,1771262531136896,-0.524,UDP
+88094252954,1771262531136387,1771262531136896,-0.509,UDP
+88094252968,1771262531137652,1771262531136897,0.755,WS
+88094252990,1771262531137666,1771262531136897,0.769,WS
+88094253005,1771262531137670,1771262531136897,0.773,WS
+88094253010,1771262531137673,1771262531136898,0.775,WS
+88094253022,1771262531137676,1771262531136898,0.778,WS
+88094253042,1771262531137681,1771262531140543,-2.862,UDP
+88094253043,1771262531137685,1771262531140553,-2.868,UDP
+88094253059,1771262531140901,1771262531140554,0.347,WS
+88094253064,1771262531140929,1771262531140554,0.375,WS
+88094253065,1771262531140939,1771262531140555,0.384,WS
+88094253066,1771262531140941,1771262531140556,0.385,WS
+88094253091,1771262531140942,1771262531140854,0.088,WS
+88094253105,1771262531146666,1771262531146150,0.516,WS
+88094253110,1771262531146705,1771262531146560,0.145,WS
+88094253118,1771262531147506,1771262531149443,-1.937,UDP
+88094253134,1771262531157667,1771262531158149,-0.482,UDP
+88094253150,1771262531162280,1771262531161618,0.662,WS
+88094253162,1771262531164992,1771262531165545,-0.553,UDP
+88094253163,1771262531165015,1771262531165559,-0.544,UDP
+88094253164,1771262531165016,1771262531165560,-0.544,UDP
+88094253165,1771262531165018,1771262531165561,-0.543,UDP
+88094253168,1771262531165019,1771262531165562,-0.543,UDP
+88094253173,1771262531165023,1771262531165563,-0.540,UDP
+88094253174,1771262531165026,1771262531165577,-0.551,UDP
+88094253175,1771262531165038,1771262531165582,-0.544,UDP
+88094253177,1771262531165043,1771262531165583,-0.540,UDP
+88094253178,1771262531165050,1771262531165584,-0.534,UDP
+88094253180,1771262531165058,1771262531165584,-0.526,UDP
+88094253182,1771262531165062,1771262531165585,-0.523,UDP
+88094253183,1771262531165072,1771262531165586,-0.514,UDP
+88094253184,1771262531165080,1771262531165587,-0.507,UDP
+88094253185,1771262531165087,1771262531165587,-0.500,UDP
+88094253186,1771262531165095,1771262531165588,-0.493,UDP
+88094253201,1771262531166634,1771262531166638,-0.004,UDP
+88094253205,1771262531168105,1771262531166643,1.462,WS
+88094253206,1771262531168127,1771262531166644,1.483,WS
+88094253207,1771262531168129,1771262531166644,1.485,WS
+88094253211,1771262531168129,1771262531166645,1.484,WS
+88094253212,1771262531168134,1771262531166645,1.489,WS
+88094253213,1771262531168145,1771262531166646,1.499,WS
+88094253214,1771262531168150,1771262531166646,1.504,WS
+88094253215,1771262531168151,1771262531166647,1.504,WS
+88094253216,1771262531168162,1771262531166647,1.515,WS
+88094253226,1771262531168171,1771262531166648,1.523,WS
+88094253230,1771262531168178,1771262531166648,1.530,WS
+88094253231,1771262531168186,1771262531166648,1.538,WS
+88094253232,1771262531168194,1771262531166649,1.545,WS
+88094253244,1771262531168203,1771262531166649,1.554,WS
+88094253246,1771262531168209,1771262531166650,1.559,WS
+88094253249,1771262531168215,1771262531166650,1.565,WS
+88094253251,1771262531168227,1771262531166650,1.577,WS
+88094253259,1771262531168236,1771262531168291,-0.055,UDP
+88094253262,1771262531168240,1771262531168302,-0.062,UDP
+88094253270,1771262531168254,1771262531168303,-0.049,UDP
+88094253272,1771262531168259,1771262531168304,-0.045,UDP
+88094253274,1771262531168264,1771262531168305,-0.041,UDP
+88094253275,1771262531168268,1771262531168306,-0.038,UDP
+88094253277,1771262531168280,1771262531168307,-0.027,UDP
+88094253278,1771262531168286,1771262531168308,-0.022,UDP
+88094253279,1771262531168292,1771262531168309,-0.017,UDP
+88094253281,1771262531168301,1771262531168310,-0.009,UDP
+88094253288,1771262531168306,1771262531168310,-0.004,UDP
+88094253293,1771262531168314,1771262531168311,0.003,WS
+88094253295,1771262531168351,1771262531168312,0.039,WS
+88094253296,1771262531168387,1771262531168313,0.074,WS
+88094253298,1771262531168388,1771262531168313,0.075,WS
+88094253303,1771262531168393,1771262531168314,0.079,WS
+88094253305,1771262531168397,1771262531168315,0.082,WS
+88094253308,1771262531168400,1771262531168316,0.084,WS
+88094253314,1771262531171007,1771262531168324,2.683,WS
+88094253320,1771262531171037,1771262531168325,2.712,WS
+88094253325,1771262531171044,1771262531168325,2.719,WS
+88094253329,1771262531171047,1771262531171216,-0.169,UDP
+88094253331,1771262531171050,1771262531171227,-0.177,UDP
+88094253333,1771262531171053,1771262531171228,-0.175,UDP
+88094253339,1771262531171152,1771262531171229,-0.077,UDP
+88094253347,1771262531172009,1771262531171236,0.773,WS
+88094253349,1771262531172049,1771262531172742,-0.693,UDP
+88094253355,1771262531172729,1771262531172754,-0.025,UDP
+88094253384,1771262531186228,1771262531185530,0.698,WS
+88094253409,1771262531186254,1771262531185535,0.719,WS
+88094253420,1771262531186259,1771262531186789,-0.530,UDP
+88094253421,1771262531186262,1771262531186795,-0.533,UDP
+88094253460,1771262531190426,1771262531190437,-0.011,UDP
+88094253472,1771262531190457,1771262531190441,0.016,WS
+88094253478,1771262531194471,1771262531193621,0.850,WS
+88094253481,1771262531194494,1771262531193624,0.870,WS
+88094253484,1771262531202870,1771262531202421,0.449,WS
+88094253486,1771262531202897,1771262531202675,0.222,WS
+88094253493,1771262531205458,1771262531205447,0.011,WS
+88094253500,1771262531205478,1771262531205452,0.026,WS
+88094253512,1771262531211971,1771262531213117,-1.146,UDP
+88094253522,1771262531218055,1771262531218066,-0.011,UDP
+88094253525,1771262531218406,1771262531219314,-0.908,UDP
+88094253534,1771262531223118,1771262531223080,0.038,WS
+88094253536,1771262531223822,1771262531223755,0.067,WS
+88094253537,1771262531225867,1771262531225615,0.252,WS
+88094253551,1771262531236255,1771262531235117,1.138,WS
+88094253564,1771262531236282,1771262531235122,1.160,WS
+88094253565,1771262531236286,1771262531235123,1.163,WS
+88094253579,1771262531236287,1771262531236548,-0.261,UDP
+88094253601,1771262531238341,1771262531237457,0.884,WS
+88094253618,1771262531251609,1771262531251865,-0.256,UDP
+88094253619,1771262531253250,1771262531252417,0.833,WS
+88094253623,1771262531263307,1771262531257498,5.809,WS
+88094253632,1771262531264385,1771262531263594,0.791,WS
+88094253638,1771262531268980,1771262531268873,0.107,WS
+88094253653,1771262531286428,1771262531286337,0.091,WS
+88094253659,1771262531286466,1771262531286343,0.123,WS
+88094253665,1771262531286474,1771262531286344,0.130,WS
+88094253699,1771262531314540,1771262531314373,0.167,WS
+88094253700,1771262531315331,1771262531315247,0.084,WS
+88094253774,1771262531386431,1771262531385767,0.664,WS
+88094253777,1771262531386456,1771262531385772,0.684,WS
+88094253778,1771262531386461,1771262531385773,0.688,WS
+88094253833,1771262531447233,1771262531446858,0.375,WS
+88094253842,1771262531486509,1771262531486248,0.261,WS
+88094253862,1771262531524615,1771262531523864,0.751,WS
+88094253863,1771262531524641,1771262531523868,0.773,WS
+88094253881,1771262531537333,1771262531536642,0.691,WS
+88094253948,1771262531629742,1771262531630572,-0.830,UDP
+88094253949,1771262531629768,1771262531630587,-0.819,UDP
+88094253950,1771262531629769,1771262531630588,-0.819,UDP
+88094253951,1771262531629770,1771262531630589,-0.819,UDP
+88094253952,1771262531629770,1771262531630589,-0.819,UDP
+88094253953,1771262531629771,1771262531630590,-0.819,UDP
+88094253954,1771262531629772,1771262531630591,-0.819,UDP
+88094253955,1771262531629773,1771262531630592,-0.819,UDP
+88094253956,1771262531629774,1771262531630593,-0.819,UDP
+88094253957,1771262531629774,1771262531630593,-0.819,UDP
+88094253958,1771262531629775,1771262531630595,-0.820,UDP
+88094253961,1771262531630521,1771262531631722,-1.201,UDP
+88094253963,1771262531633545,1771262531631733,1.812,WS
+88094253966,1771262531633572,1771262531631734,1.838,WS
+88094253976,1771262531633577,1771262531631734,1.843,WS
+88094253979,1771262531633580,1771262531631735,1.845,WS
+88094253980,1771262531633583,1771262531631735,1.848,WS
+88094253989,1771262531633584,1771262531631736,1.848,WS
+88094253990,1771262531633588,1771262531631736,1.852,WS
+88094253991,1771262531633589,1771262531631737,1.852,WS
+88094253993,1771262531633590,1771262531631738,1.852,WS
+88094253994,1771262531633596,1771262531631738,1.858,WS
+88094253995,1771262531633596,1771262531631739,1.857,WS
+88094254015,1771262531633597,1771262531631739,1.858,WS
+88094254021,1771262531633600,1771262531631740,1.860,WS
+88094254025,1771262531633603,1771262531631740,1.863,WS
+88094254026,1771262531633606,1771262531631741,1.865,WS
+88094254028,1771262531633607,1771262531631741,1.866,WS
+88094254029,1771262531633610,1771262531631742,1.868,WS
+88094254030,1771262531633612,1771262531631742,1.870,WS
+88094254037,1771262531633613,1771262531631743,1.870,WS
+88094254038,1771262531633618,1771262531631743,1.875,WS
+88094254043,1771262531633618,1771262531633520,0.098,WS
+88094254044,1771262531633622,1771262531633526,0.096,WS
+88094254050,1771262531633623,1771262531633527,0.096,WS
+88094254052,1771262531633626,1771262531633528,0.098,WS
+88094254054,1771262531633630,1771262531633528,0.102,WS
+88094254055,1771262531633633,1771262531633529,0.104,WS
+88094254056,1771262531633634,1771262531633530,0.104,WS
+88094254059,1771262531633634,1771262531633531,0.103,WS
+88094254060,1771262531633637,1771262531633532,0.105,WS
+88094254061,1771262531633638,1771262531633532,0.106,WS
+88094254067,1771262531633639,1771262531633533,0.106,WS
+88094254069,1771262531634532,1771262531633534,0.998,WS
+88094254073,1771262531634551,1771262531633534,1.017,WS
+88094254074,1771262531634556,1771262531633535,1.021,WS
+88094254077,1771262531634557,1771262531633536,1.021,WS
+88094254079,1771262531634561,1771262531634476,0.085,WS
+88094254080,1771262531634565,1771262531634479,0.086,WS
+88094254084,1771262531634566,1771262531634480,0.086,WS
+88094254086,1771262531634763,1771262531634480,0.283,WS
+88094254087,1771262531634788,1771262531634481,0.307,WS
+88094254091,1771262531634789,1771262531634751,0.038,WS
+88094254103,1771262531637553,1771262531636627,0.926,WS
+88094254104,1771262531637574,1771262531636629,0.945,WS
+88094254111,1771262531637575,1771262531637462,0.113,WS
+88094254117,1771262531637579,1771262531637466,0.113,WS
+88094254128,1771262531638938,1771262531637467,1.471,WS
+88094254129,1771262531638973,1771262531637468,1.505,WS
+88094254135,1771262531638974,1771262531638936,0.038,WS
+88094254137,1771262531638983,1771262531638940,0.043,WS
+88094254157,1771262531677245,1771262531677838,-0.593,UDP
+88094254159,1771262531680283,1771262531678410,1.873,WS
+88094254162,1771262531685054,1771262531684308,0.746,WS
+88094254171,1771262531693021,1771262531693097,-0.076,UDP
+88094254172,1771262531703893,1771262531703095,0.798,WS
+88094254192,1771262531738180,1771262531738720,-0.540,UDP
+88094254193,1771262531742658,1771262531742659,-0.001,UDP
+88094254227,1771262531785719,1771262531785665,0.054,WS
+88094254262,1771262531802184,1771262531802140,0.044,WS
+88094254274,1771262531819582,1771262531818821,0.761,WS
+88094254275,1771262531819621,1771262531818826,0.795,WS
+88094254276,1771262531819623,1771262531818827,0.796,WS
+88094254277,1771262531819624,1771262531818828,0.796,WS
+88094254281,1771262531819626,1771262531818829,0.797,WS
+88094254282,1771262531819641,1771262531818830,0.811,WS
+88094254283,1771262531819642,1771262531818830,0.812,WS
+88094254284,1771262531819643,1771262531820285,-0.642,UDP
+88094254285,1771262531819645,1771262531820295,-0.650,UDP
+88094254286,1771262531819646,1771262531820296,-0.650,UDP
+88094254288,1771262531819647,1771262531820297,-0.650,UDP
+88094254289,1771262531819656,1771262531820297,-0.641,UDP
+88094254298,1771262531820566,1771262531824652,-4.086,UDP
+88094254322,1771262531825736,1771262531824660,1.076,WS
+88094254336,1771262531825756,1771262531824661,1.095,WS
+88094254341,1771262531825761,1771262531824661,1.100,WS
+88094254344,1771262531825766,1771262531824662,1.104,WS
+88094254359,1771262531825770,1771262531824662,1.108,WS
+88094254360,1771262531825774,1771262531824663,1.111,WS
+88094254361,1771262531825775,1771262531824663,1.112,WS
+88094254362,1771262531825776,1771262531824664,1.112,WS
+88094254363,1771262531825777,1771262531824664,1.113,WS
+88094254377,1771262531825778,1771262531824665,1.113,WS
+88094254378,1771262531825793,1771262531824665,1.128,WS
+88094254380,1771262531825797,1771262531824665,1.132,WS
+88094254382,1771262531825801,1771262531824666,1.135,WS
+88094254383,1771262531825805,1771262531824666,1.139,WS
+88094254401,1771262531825806,1771262531825823,-0.017,UDP
+88094254407,1771262531825810,1771262531825834,-0.024,UDP
+88094254413,1771262531825815,1771262531825835,-0.020,UDP
+88094254414,1771262531825818,1771262531825836,-0.018,UDP
+88094254416,1771262531825819,1771262531825837,-0.018,UDP
+88094254418,1771262531825823,1771262531825838,-0.015,UDP
+88094254419,1771262531825834,1771262531825838,-0.004,UDP
+88094254433,1771262531825842,1771262531825839,0.003,WS
+88094254438,1771262531825846,1771262531825840,0.006,WS
+88094254446,1771262531825852,1771262531825840,0.012,WS
+88094254451,1771262531825858,1771262531825841,0.017,WS
+88094254456,1771262531825862,1771262531825842,0.020,WS
+88094254458,1771262531825866,1771262531825843,0.023,WS
+88094254459,1771262531825869,1771262531825843,0.026,WS
+88094254461,1771262531825870,1771262531825844,0.026,WS
+88094254462,1771262531825874,1771262531825845,0.029,WS
+88094254463,1771262531825875,1771262531825845,0.030,WS
+88094254464,1771262531825884,1771262531825846,0.038,WS
+88094254466,1771262531825885,1771262531825847,0.038,WS
+88094254467,1771262531825893,1771262531825848,0.045,WS
+88094254469,1771262531825894,1771262531825848,0.046,WS
+88094254475,1771262531825898,1771262531825849,0.049,WS
+88094254480,1771262531825902,1771262531826001,-0.099,UDP
+88094254481,1771262531825905,1771262531826008,-0.103,UDP
+88094254482,1771262531825906,1771262531826009,-0.103,UDP
+88094254485,1771262531825914,1771262531826009,-0.095,UDP
+88094254486,1771262531825918,1771262531826010,-0.092,UDP
+88094254488,1771262531825919,1771262531826011,-0.092,UDP
+88094254490,1771262531825922,1771262531826011,-0.089,UDP
+88094254491,1771262531825932,1771262531826012,-0.080,UDP
+88094254494,1771262531825933,1771262531826012,-0.079,UDP
+88094254495,1771262531825945,1771262531826013,-0.068,UDP
+88094254497,1771262531825946,1771262531826013,-0.067,UDP
+88094254500,1771262531825950,1771262531826014,-0.064,UDP
+88094254510,1771262531825958,1771262531826014,-0.056,UDP
+88094254531,1771262531825962,1771262531826015,-0.053,UDP
+88094254534,1771262531825966,1771262531826015,-0.049,UDP
+88094254535,1771262531825969,1771262531826016,-0.047,UDP
+88094254538,1771262531825983,1771262531826016,-0.033,UDP
+88094254545,1771262531825989,1771262531826017,-0.028,UDP
+88094254547,1771262531825993,1771262531826019,-0.026,UDP
+88094254548,1771262531825997,1771262531826020,-0.023,UDP
+88094254555,1771262531825998,1771262531826021,-0.023,UDP
+88094254561,1771262531826001,1771262531826021,-0.020,UDP
+88094254565,1771262531826070,1771262531826022,0.048,WS
+88094254575,1771262531826086,1771262531826024,0.062,WS
+88094254581,1771262531826091,1771262531826024,0.067,WS
+88094254597,1771262531827079,1771262531827199,-0.120,UDP
+88094254600,1771262531827201,1771262531827204,-0.003,UDP
+88094254617,1771262531830198,1771262531830116,0.082,WS
+88094254677,1771262531833108,1771262531832778,0.330,WS
+88094254718,1771262531836342,1771262531836000,0.342,WS
+88094254721,1771262531836358,1771262531836002,0.356,WS
+88094254732,1771262531837964,1771262531837616,0.348,WS
+88094254733,1771262531837985,1771262531837619,0.366,WS
+88094254735,1771262531837987,1771262531837620,0.367,WS
+88094254740,1771262531837993,1771262531837620,0.373,WS
+88094254742,1771262531837997,1771262531837621,0.376,WS
+88094254744,1771262531838003,1771262531837621,0.382,WS
+88094254746,1771262531838007,1771262531837622,0.385,WS
+88094254747,1771262531838011,1771262531837622,0.389,WS
+88094254752,1771262531838023,1771262531837623,0.400,WS
+88094254753,1771262531838033,1771262531837623,0.410,WS
+88094254764,1771262531838033,1771262531837623,0.410,WS
+88094254765,1771262531838038,1771262531837624,0.414,WS
+88094254775,1771262531838048,1771262531837624,0.424,WS
+88094254807,1771262531838053,1771262531837625,0.428,WS
+88094254817,1771262531838064,1771262531837813,0.251,WS
+88094254823,1771262531841416,1771262531837816,3.600,WS
+88094254833,1771262531841442,1771262531837817,3.625,WS
+88094254863,1771262531841450,1771262531841426,0.024,WS
+88094254864,1771262531841459,1771262531841429,0.030,WS
+88094254866,1771262531841460,1771262531841429,0.031,WS
+88094254867,1771262531841470,1771262531841430,0.040,WS
+88094254868,1771262531841472,1771262531841430,0.042,WS
+88094254869,1771262531841473,1771262531841431,0.042,WS
+88094254875,1771262531841474,1771262531841431,0.043,WS
+88094254879,1771262531841481,1771262531841432,0.049,WS
+88094254880,1771262531841487,1771262531841432,0.055,WS
+88094254881,1771262531841488,1771262531841432,0.056,WS
+88094254883,1771262531841490,1771262531841433,0.057,WS
+88094254884,1771262531841500,1771262531841433,0.067,WS
+88094254888,1771262531841502,1771262531841434,0.068,WS
+88094254890,1771262531841514,1771262531841434,0.080,WS
+88094254891,1771262531841527,1771262531841434,0.093,WS
+88094254894,1771262531841528,1771262531841440,0.088,WS
+88094254898,1771262531841537,1771262531841441,0.096,WS
+88094254899,1771262531841547,1771262531841441,0.106,WS
+88094254901,1771262531841548,1771262531841442,0.106,WS
+88094254902,1771262531841558,1771262531841442,0.116,WS
+88094254904,1771262531841559,1771262531841442,0.117,WS
+88094254911,1771262531842271,1771262531841443,0.828,WS
+88094254912,1771262531842298,1771262531841443,0.855,WS
+88094254916,1771262531842299,1771262531841443,0.856,WS
+88094254927,1771262531842308,1771262531841444,0.864,WS
+88094254929,1771262531842319,1771262531841444,0.875,WS
+88094254941,1771262531842326,1771262531841445,0.881,WS
+88094254954,1771262531842336,1771262531841445,0.891,WS
+88094254962,1771262531842345,1771262531841445,0.900,WS
+88094254964,1771262531842355,1771262531841446,0.909,WS
+88094254973,1771262531842364,1771262531841446,0.918,WS
+88094254974,1771262531842375,1771262531841446,0.929,WS
+88094254975,1771262531842378,1771262531841447,0.931,WS
+88094254978,1771262531842380,1771262531841447,0.933,WS
+88094254979,1771262531842388,1771262531841448,0.940,WS
+88094254980,1771262531842390,1771262531841448,0.942,WS
+88094254982,1771262531842391,1771262531841449,0.942,WS
+88094254983,1771262531842401,1771262531841449,0.952,WS
+88094254986,1771262531842402,1771262531841450,0.952,WS
+88094254989,1771262531842409,1771262531841450,0.959,WS
+88094254994,1771262531842419,1771262531841451,0.968,WS
+88094254998,1771262531842428,1771262531841451,0.977,WS
+88094254999,1771262531842438,1771262531841451,0.987,WS
+88094255000,1771262531842439,1771262531842187,0.252,WS
+88094255002,1771262531842440,1771262531842190,0.250,WS
+88094255008,1771262531842452,1771262531842191,0.261,WS
+88094255010,1771262531842459,1771262531842192,0.267,WS
+88094255012,1771262531842468,1771262531842192,0.276,WS
+88094255016,1771262531842478,1771262531842193,0.285,WS
+88094255020,1771262531842487,1771262531842197,0.290,WS
+88094255024,1771262531842496,1771262531842198,0.298,WS
+88094255033,1771262531842507,1771262531842199,0.308,WS
+88094255036,1771262531842514,1771262531842199,0.315,WS
+88094255059,1771262531842523,1771262531842203,0.320,WS
+88094255076,1771262531845614,1771262531845296,0.318,WS
+88094255077,1771262531845641,1771262531845302,0.339,WS
+88094255078,1771262531845642,1771262531845303,0.339,WS
+88094255141,1771262531870284,1771262531869651,0.633,WS
+88094255144,1771262531873344,1771262531872647,0.697,WS
+88094255149,1771262531879056,1771262531879867,-0.811,UDP
+88094255151,1771262531880223,1771262531880764,-0.541,UDP
+88094255153,1771262531885200,1771262531885896,-0.696,UDP
+88094255180,1771262531886895,1771262531885909,0.986,WS
+88094255208,1771262531889697,1771262531889902,-0.205,UDP
+88094255210,1771262531889712,1771262531889911,-0.199,UDP
+88094255227,1771262531894031,1771262531894533,-0.502,UDP
+88094255238,1771262531909090,1771262531908761,0.329,WS
+88094255240,1771262531910150,1771262531911060,-0.910,UDP
+88094255286,1771262531930270,1771262531930429,-0.159,UDP
+88094255287,1771262531935033,1771262531934730,0.303,WS
+88094255288,1771262531935055,1771262531935020,0.035,WS
+88094255289,1771262531935058,1771262531935024,0.034,WS
+88094255301,1771262531938225,1771262531938050,0.175,WS
+88094255308,1771262531938249,1771262531938054,0.195,WS
+88094255310,1771262531938254,1771262531938055,0.199,WS
+88094255311,1771262531938257,1771262531938056,0.201,WS
+88094255323,1771262531938258,1771262531938056,0.202,WS
+88094255325,1771262531938261,1771262531938056,0.205,WS
+88094255326,1771262531938264,1771262531938057,0.207,WS
+88094255327,1771262531938264,1771262531938712,-0.448,UDP
+88094255374,1771262531938705,1771262531938718,-0.013,UDP
+88094255377,1771262531938731,1771262531938718,0.013,WS
+88094255388,1771262531939298,1771262531939215,0.083,WS
+88094255391,1771262531944211,1771262531943272,0.939,WS
+88094255392,1771262531944245,1771262531943276,0.969,WS
+88094255393,1771262531944247,1771262531943277,0.970,WS
+88094255394,1771262531944248,1771262531943277,0.971,WS
+88094255395,1771262531944249,1771262531943278,0.971,WS
+88094255397,1771262531944251,1771262531943278,0.973,WS
+88094255398,1771262531944263,1771262531943279,0.984,WS
+88094255403,1771262531944264,1771262531943279,0.985,WS
+88094255404,1771262531944271,1771262531943279,0.992,WS
+88094255405,1771262531944273,1771262531943280,0.993,WS
+88094255412,1771262531944424,1771262531944172,0.252,WS
+88094255416,1771262531944444,1771262531944172,0.272,WS
+88094255420,1771262531944449,1771262531944409,0.040,WS
+88094255422,1771262531944452,1771262531944413,0.039,WS
+88094255431,1771262531944455,1771262531944414,0.041,WS
+88094255437,1771262531944467,1771262531944414,0.053,WS
+88094255451,1771262531944472,1771262531944415,0.057,WS
+88094255452,1771262531944475,1771262531944416,0.059,WS
+88094255453,1771262531944487,1771262531944416,0.071,WS
+88094255454,1771262531944489,1771262531944417,0.072,WS
+88094255455,1771262531944504,1771262531944418,0.086,WS
+88094255456,1771262531944511,1771262531944419,0.092,WS
+88094255457,1771262531944520,1771262531944419,0.101,WS
+88094255459,1771262531944527,1771262531944420,0.107,WS
+88094255466,1771262531945037,1771262531944421,0.616,WS
+88094255470,1771262531945054,1771262531944421,0.633,WS
+88094255476,1771262531945059,1771262531944422,0.637,WS
+88094255477,1771262531945062,1771262531944423,0.639,WS
+88094255482,1771262531945063,1771262531944423,0.640,WS
+88094255487,1771262531945068,1771262531944424,0.644,WS
+88094255488,1771262531945072,1771262531944425,0.647,WS
+88094255496,1771262531945073,1771262531945025,0.048,WS
+88094255500,1771262531945076,1771262531945027,0.049,WS
+88094255501,1771262531945079,1771262531945030,0.049,WS
+88094255502,1771262531945079,1771262531945036,0.043,WS
+88094255503,1771262531945080,1771262531945040,0.040,WS
+88094255504,1771262531945081,1771262531945044,0.037,WS
+88094255505,1771262531945082,1771262531945048,0.034,WS
+88094255507,1771262531945084,1771262531945052,0.032,WS
+88094255511,1771262531945091,1771262531945056,0.035,WS
+88094255512,1771262531945095,1771262531945058,0.037,WS
+88094255514,1771262531945096,1771262531945059,0.037,WS
+88094255517,1771262531945100,1771262531945059,0.041,WS
+88094255518,1771262531945104,1771262531945059,0.045,WS
+88094255521,1771262531945105,1771262531945060,0.045,WS
+88094255522,1771262531945108,1771262531945060,0.048,WS
+88094255523,1771262531945109,1771262531945061,0.048,WS
+88094255524,1771262531945110,1771262531945061,0.049,WS
+88094255525,1771262531945111,1771262531945062,0.049,WS
+88094255526,1771262531945120,1771262531945062,0.058,WS
+88094255532,1771262531945123,1771262531945062,0.061,WS
+88094255538,1771262531945129,1771262531945063,0.066,WS
+88094255539,1771262531945133,1771262531945063,0.070,WS
+88094255541,1771262531945134,1771262531945064,0.070,WS
+88094255546,1771262531945137,1771262531945064,0.073,WS
+88094255549,1771262531945140,1771262531945064,0.076,WS
+88094255552,1771262531945143,1771262531945067,0.076,WS
+88094255553,1771262531945146,1771262531945068,0.078,WS
+88094255561,1771262531947884,1771262531945068,2.816,WS
+88094255562,1771262531947918,1771262531945069,2.849,WS
+88094255563,1771262531947919,1771262531945069,2.850,WS
+88094255564,1771262531947920,1771262531945070,2.850,WS
+88094255567,1771262531947921,1771262531947976,-0.055,UDP
+88094255572,1771262531948001,1771262531947992,0.009,WS
+88094255573,1771262531948031,1771262531947994,0.037,WS
+88094255577,1771262531949568,1771262531948596,0.972,WS
+88094255578,1771262531949585,1771262531949589,-0.004,UDP
+88094255582,1771262531953169,1771262531953352,-0.183,UDP
+88094255627,1771262531986194,1771262531985505,0.689,WS
+88094255629,1771262531986220,1771262531985509,0.711,WS
+88094255645,1771262531988758,1771262531987896,0.862,WS
+88094255646,1771262531988791,1771262531987898,0.893,WS
+88094255655,1771262532000045,1771262531999568,0.477,WS
+88094255658,1771262532003016,1771262532002433,0.583,WS
+88094255659,1771262532004142,1771262532003135,1.007,WS
+88094255660,1771262532007386,1771262532004490,2.896,WS
+88094255661,1771262532008493,1771262532007604,0.889,WS
+88094255681,1771262532036352,1771262532035650,0.702,WS
+88094255683,1771262532036379,1771262532035654,0.725,WS
+88094255711,1771262532038266,1771262532036314,1.952,WS
+88094255718,1771262532038288,1771262532038483,-0.195,UDP
+88094255723,1771262532038553,1771262532038493,0.060,WS
+88094255726,1771262532038572,1771262532038498,0.074,WS
+88094255747,1771262532085839,1771262532085538,0.301,WS
+88094255749,1771262532086645,1771262532087158,-0.513,UDP
+88094255752,1771262532089107,1771262532087165,1.942,WS
+88094255778,1771262532100185,1771262532099757,0.428,WS
+88094255815,1771262532185699,1771262532185648,0.051,WS
+88094255844,1771262532235988,1771262532235924,0.064,WS
+88094255850,1771262532236015,1771262532235929,0.086,WS
+88094255853,1771262532236019,1771262532236733,-0.714,UDP
+88094255865,1771262532236708,1771262532236741,-0.033,UDP
+88094255866,1771262532236716,1771262532238111,-1.395,UDP
+88094255868,1771262532238180,1771262532238117,0.063,WS
+88094255894,1771262532285799,1771262532285574,0.225,WS
+88094255930,1771262532336098,1771262532335254,0.844,WS
+88094255940,1771262532336125,1771262532336301,-0.176,UDP
+88094255949,1771262532338340,1771262532337276,1.064,WS
+88094255952,1771262532340050,1771262532339683,0.367,WS
+88094255953,1771262532340073,1771262532340050,0.023,WS
+88094255955,1771262532343640,1771262532340879,2.761,WS
+88094255957,1771262532343949,1771262532343931,0.018,WS
+88094255964,1771262532386157,1771262532386167,-0.010,UDP
+88094255965,1771262532386193,1771262532386171,0.022,WS
+88094255966,1771262532386495,1771262532386470,0.025,WS
+88094255971,1771262532397461,1771262532398199,-0.738,UDP
+88094255977,1771262532416821,1771262532416444,0.377,WS
+88094255989,1771262532457550,1771262532456791,0.759,WS
+88094255997,1771262532492281,1771262532492790,-0.509,UDP
+88094256076,1771262532536348,1771262532536419,-0.071,UDP
+88094256092,1771262532536373,1771262532536432,-0.059,UDP
+88094256116,1771262532536984,1771262532536711,0.273,WS
+88094256151,1771262532557312,1771262532556458,0.854,WS
+88094256152,1771262532559924,1771262532557593,2.331,WS
+88094256153,1771262532559930,1771262532559837,0.093,WS
+88094256155,1771262532559949,1771262532559842,0.107,WS
+88094256156,1771262532560765,1771262532559846,0.919,WS
+88094256157,1771262532560776,1771262532559847,0.929,WS
+88094256160,1771262532561298,1771262532560677,0.621,WS
+88094256161,1771262532561317,1771262532560679,0.638,WS
+88094256183,1771262532565223,1771262532564377,0.846,WS
+88094256194,1771262532571855,1771262532571410,0.445,WS
+88094256207,1771262532583370,1771262532582586,0.784,WS
+88094256211,1771262532584397,1771262532583623,0.774,WS
+88094256215,1771262532586026,1771262532585818,0.208,WS
+88094256222,1771262532586038,1771262532586018,0.020,WS
+88094256227,1771262532586043,1771262532586021,0.022,WS
+88094256232,1771262532586046,1771262532586022,0.024,WS
+88094256236,1771262532586050,1771262532586022,0.028,WS
+88094256243,1771262532586054,1771262532586023,0.031,WS
+88094256245,1771262532586057,1771262532586023,0.034,WS
+88094256261,1771262532586677,1771262532586025,0.652,WS
+88094256281,1771262532589125,1771262532587059,2.066,WS
+88094256290,1771262532589146,1771262532589319,-0.173,UDP
+88094256292,1771262532589150,1771262532589332,-0.182,UDP
+88094256305,1771262532591597,1771262532591843,-0.246,UDP
+88094256330,1771262532594506,1771262532594372,0.134,WS
+88094256345,1771262532594727,1771262532594470,0.257,WS
+88094256364,1771262532615059,1771262532615023,0.036,WS
+88094256376,1771262532618891,1771262532618687,0.204,WS
+88094256377,1771262532618918,1771262532618692,0.226,WS
+88094256383,1771262532619935,1771262532619486,0.449,WS
+88094256385,1771262532619968,1771262532625741,-5.773,UDP
+88094256391,1771262532619977,1771262532625756,-5.779,UDP
+88094256394,1771262532619985,1771262532625757,-5.772,UDP
+88094256412,1771262532625915,1771262532625769,0.146,WS
+88094256417,1771262532625943,1771262532625773,0.170,WS
+88094256427,1771262532626407,1771262532626303,0.104,WS
+88094256430,1771262532626910,1771262532626307,0.603,WS
+88094256432,1771262532626929,1771262532627532,-0.603,UDP
+88094256436,1771262532626934,1771262532627546,-0.612,UDP
+88094256437,1771262532627576,1771262532627548,0.028,WS
+88094256438,1771262532627581,1771262532627549,0.032,WS
+88094256441,1771262532629314,1771262532629134,0.180,WS
+88094256443,1771262532629335,1771262532629137,0.198,WS
+88094256446,1771262532629340,1771262532629301,0.039,WS
+88094256448,1771262532629344,1771262532629304,0.040,WS
+88094256451,1771262532629348,1771262532629304,0.044,WS
+88094256458,1771262532629354,1771262532631001,-1.647,UDP
+88094256465,1771262532631272,1771262532631230,0.042,WS
+88094256489,1771262532635854,1771262532635858,-0.004,UDP
+88094256505,1771262532636022,1771262532635863,0.159,WS
+88094256515,1771262532636051,1771262532635864,0.187,WS
+88094256517,1771262532636061,1771262532638106,-2.045,UDP
+88094256528,1771262532636070,1771262532638118,-2.048,UDP
+88094256529,1771262532636080,1771262532638120,-2.040,UDP
+88094256561,1771262532638103,1771262532638122,-0.019,UDP
+88094256576,1771262532638127,1771262532638123,0.004,WS
+88094256586,1771262532638132,1771262532638127,0.005,WS
+88094256596,1771262532638135,1771262532638128,0.007,WS
+88094256603,1771262532638139,1771262532638129,0.010,WS
+88094256609,1771262532638142,1771262532639529,-1.387,UDP
+88094256620,1771262532640016,1771262532639537,0.479,WS
+88094256653,1771262532644571,1771262532643633,0.938,WS
+88094256654,1771262532644605,1771262532644857,-0.252,UDP
+88094256665,1771262532653928,1771262532653556,0.372,WS
+88094256681,1771262532666505,1771262532665755,0.750,WS
+88094256684,1771262532669154,1771262532668835,0.319,WS
+88094256687,1771262532669178,1771262532668839,0.339,WS
+88094256688,1771262532669183,1771262532669807,-0.624,UDP
+88094256691,1771262532670794,1771262532669815,0.979,WS
+88094256692,1771262532670808,1771262532669815,0.993,WS
+88094256693,1771262532670809,1771262532669816,0.993,WS
+88094256694,1771262532670809,1771262532669817,0.992,WS
+88094256695,1771262532670810,1771262532669817,0.993,WS
+88094256696,1771262532670811,1771262532669817,0.994,WS
+88094256697,1771262532670812,1771262532669818,0.994,WS
+88094256698,1771262532670813,1771262532669818,0.995,WS
+88094256699,1771262532670813,1771262532669819,0.994,WS
+88094256700,1771262532670821,1771262532669819,1.002,WS
+88094256702,1771262532672444,1771262532672181,0.263,WS
+88094256706,1771262532674322,1771262532674336,-0.014,UDP
+88094256714,1771262532677298,1771262532677106,0.192,WS
+88094256718,1771262532678706,1771262532677882,0.824,WS
+88094256721,1771262532678723,1771262532678923,-0.200,UDP
+88094256722,1771262532678727,1771262532678928,-0.201,UDP
+88094256723,1771262532678728,1771262532678929,-0.201,UDP
+88094256724,1771262532680499,1771262532678930,1.569,WS
+88094256736,1771262532686016,1771262532685152,0.864,WS
+88094256740,1771262532686058,1771262532685156,0.902,WS
+88094256743,1771262532686070,1771262532685157,0.913,WS
+88094256821,1771262532698182,1771262532699194,-1.012,UDP
+88094256829,1771262532700884,1771262532700723,0.161,WS
+88094256834,1771262532700912,1771262532700727,0.185,WS
+88094256840,1771262532700916,1771262532700728,0.188,WS
+88094256842,1771262532701902,1771262532702095,-0.193,UDP
+88094256848,1771262532711375,1771262532711339,0.036,WS
+88094256850,1771262532714449,1771262532714282,0.167,WS
+88094256852,1771262532719618,1771262532719524,0.094,WS
+88094256857,1771262532721941,1771262532723162,-1.221,UDP
+88094256858,1771262532721957,1771262532723173,-1.216,UDP
+88094256861,1771262532721958,1771262532723174,-1.216,UDP
+88094256862,1771262532723204,1771262532723175,0.029,WS
+88094256863,1771262532723208,1771262532723176,0.032,WS
+88094256864,1771262532723223,1771262532723177,0.046,WS
+88094256865,1771262532723225,1771262532723178,0.047,WS
+88094256872,1771262532726678,1771262532723461,3.217,WS
+88094256875,1771262532726841,1771262532726734,0.107,WS
+88094256879,1771262532729284,1771262532729212,0.072,WS
+88094256913,1771262532736227,1771262532735385,0.842,WS
+88094256915,1771262532736253,1771262532735389,0.864,WS
+88094256916,1771262532736258,1771262532735390,0.868,WS
+88094256917,1771262532736259,1771262532735391,0.868,WS
+88094256923,1771262532736260,1771262532735391,0.869,WS
+88094256927,1771262532736263,1771262532735392,0.871,WS
+88094256928,1771262532736267,1771262532735392,0.875,WS
+88094256948,1771262532740118,1771262532739758,0.360,WS
+88094256951,1771262532740136,1771262532739760,0.376,WS
+88094256962,1771262532740143,1771262532739761,0.382,WS
+88094256971,1771262532740146,1771262532739762,0.384,WS
+88094256982,1771262532740150,1771262532740022,0.128,WS
+88094256999,1771262532743774,1771262532743576,0.198,WS
+88094257006,1771262532751127,1771262532751646,-0.519,UDP
+88094257007,1771262532754493,1771262532752595,1.898,WS
+88094257011,1771262532754696,1771262532754682,0.014,WS
+88094257015,1771262532755750,1771262532755746,0.004,WS
+88094257020,1771262532759742,1771262532759286,0.456,WS
+88094257021,1771262532759784,1771262532759290,0.494,WS
+88094257038,1771262532761170,1771262532760678,0.492,WS
+88094257040,1771262532763462,1771262532763072,0.390,WS
+88094257043,1771262532763486,1771262532763075,0.411,WS
+88094257050,1771262532763491,1771262532763076,0.415,WS
+88094257057,1771262532763494,1771262532763076,0.418,WS
+88094257058,1771262532763498,1771262532763077,0.421,WS
+88094257063,1771262532763499,1771262532763077,0.422,WS
+88094257064,1771262532763504,1771262532763078,0.426,WS
+88094257070,1771262532763505,1771262532763078,0.427,WS
+88094257075,1771262532763508,1771262532763079,0.429,WS
+88094257088,1771262532764024,1771262532763377,0.647,WS
+88094257089,1771262532764040,1771262532763393,0.647,WS
+88094257091,1771262532764041,1771262532763394,0.647,WS
+88094257092,1771262532764046,1771262532763394,0.652,WS
+88094257094,1771262532764047,1771262532763395,0.652,WS
+88094257095,1771262532764050,1771262532763395,0.655,WS
+88094257100,1771262532764051,1771262532763396,0.655,WS
+88094257109,1771262532764598,1771262532763396,1.202,WS
+88094257111,1771262532764625,1771262532764013,0.612,WS
+88094257112,1771262532764633,1771262532764016,0.617,WS
+88094257126,1771262532766382,1771262532764016,2.366,WS
+88094257139,1771262532766410,1771262532766058,0.352,WS
+88094257141,1771262532766415,1771262532766063,0.352,WS
+88094257154,1771262532766418,1771262532766064,0.354,WS
+88094257156,1771262532766421,1771262532766065,0.356,WS
+88094257157,1771262532766424,1771262532766066,0.358,WS
+88094257159,1771262532768278,1771262532766067,2.211,WS
+88094257161,1771262532768298,1771262532766067,2.231,WS
+88094257162,1771262532768302,1771262532766068,2.234,WS
+88094257169,1771262532768303,1771262532766069,2.234,WS
+88094257172,1771262532768306,1771262532766069,2.237,WS
+88094257176,1771262532768321,1771262532766280,2.041,WS
+88094257177,1771262532768325,1771262532766283,2.042,WS
+88094257180,1771262532768326,1771262532766284,2.042,WS
+88094257181,1771262532768341,1771262532766285,2.056,WS
+88094257182,1771262532768341,1771262532766286,2.055,WS
+88094257183,1771262532768349,1771262532766287,2.062,WS
+88094257184,1771262532768357,1771262532766287,2.070,WS
+88094257196,1771262532768364,1771262532766288,2.076,WS
+88094257198,1771262532768372,1771262532766289,2.083,WS
+88094257203,1771262532768382,1771262532768266,0.116,WS
+88094257214,1771262532768389,1771262532768268,0.121,WS
+88094257216,1771262532768396,1771262532768269,0.127,WS
+88094257217,1771262532768403,1771262532768269,0.134,WS
+88094257219,1771262532768411,1771262532768270,0.141,WS
+88094257220,1771262532768417,1771262532768271,0.146,WS
+88094257239,1771262532769798,1771262532769521,0.277,WS
+88094257257,1771262532771603,1771262532769747,1.856,WS
+88094257267,1771262532771642,1771262532769750,1.892,WS
+88094257268,1771262532771651,1771262532769751,1.900,WS
+88094257274,1771262532771982,1771262532771961,0.021,WS
+88094257277,1771262532772002,1771262532771966,0.036,WS
+88094257278,1771262532772008,1771262532771967,0.041,WS
+88094257280,1771262532773312,1771262532771970,1.342,WS
+88094257282,1771262532773339,1771262532771970,1.369,WS
+88094257290,1771262532775396,1771262532775193,0.203,WS
+88094257297,1771262532775871,1771262532775869,0.002,WS
+88094257314,1771262532779804,1771262532780501,-0.697,UDP
+88094257325,1771262532783881,1771262532783713,0.168,WS
+88094257397,1771262532787428,1771262532787672,-0.244,UDP
+88094257422,1771262532797791,1771262532796920,0.871,WS
+88094257423,1771262532797818,1771262532796924,0.894,WS
+88094257424,1771262532797819,1771262532796925,0.894,WS
+88094257425,1771262532797820,1771262532796925,0.895,WS
+88094257426,1771262532797820,1771262532796926,0.894,WS
+88094257427,1771262532797821,1771262532796926,0.895,WS
+88094257428,1771262532797822,1771262532796927,0.895,WS
+88094257429,1771262532797823,1771262532796927,0.896,WS
+88094257439,1771262532800401,1771262532800352,0.049,WS
+88094257443,1771262532800423,1771262532800356,0.067,WS
+88094257445,1771262532800427,1771262532800356,0.071,WS
+88094257446,1771262532800431,1771262532800357,0.074,WS
+88094257449,1771262532800432,1771262532800357,0.075,WS
+88094257451,1771262532800435,1771262532800358,0.077,WS
+88094257455,1771262532800439,1771262532800359,0.080,WS
+88094257456,1771262532800444,1771262532800359,0.085,WS
+88094257458,1771262532800445,1771262532800359,0.086,WS
+88094257462,1771262532800448,1771262532800360,0.088,WS
+88094257467,1771262532800453,1771262532800360,0.093,WS
+88094257471,1771262532800456,1771262532800361,0.095,WS
+88094257478,1771262532800459,1771262532800361,0.098,WS
+88094257481,1771262532800462,1771262532800361,0.101,WS
+88094257482,1771262532800466,1771262532800362,0.104,WS
+88094257483,1771262532800468,1771262532800362,0.106,WS
+88094257488,1771262532800469,1771262532800363,0.106,WS
+88094257489,1771262532800473,1771262532800363,0.110,WS
+88094257492,1771262532800474,1771262532800363,0.111,WS
+88094257494,1771262532800477,1771262532800364,0.113,WS
+88094257497,1771262532800480,1771262532800364,0.116,WS
+88094257499,1771262532800484,1771262532800365,0.119,WS
+88094257500,1771262532800488,1771262532800365,0.123,WS
+88094257502,1771262532800489,1771262532800365,0.124,WS
+88094257509,1771262532800495,1771262532800366,0.129,WS
+88094257510,1771262532800500,1771262532801941,-1.441,UDP
+88094257513,1771262532800501,1771262532801952,-1.451,UDP
+88094257516,1771262532800505,1771262532801953,-1.448,UDP
+88094257517,1771262532800507,1771262532801954,-1.447,UDP
+88094257520,1771262532800508,1771262532801955,-1.447,UDP
+88094257521,1771262532800511,1771262532801956,-1.445,UDP
+88094257525,1771262532800512,1771262532801957,-1.445,UDP
+88094257527,1771262532802017,1771262532801957,0.060,WS
+88094257528,1771262532802212,1771262532801958,0.254,WS
+88094257529,1771262532802214,1771262532801959,0.255,WS
+88094257536,1771262532802215,1771262532801962,0.253,WS
+88094257538,1771262532802225,1771262532801962,0.263,WS
+88094257544,1771262532803467,1771262532803252,0.215,WS
+88094257547,1771262532803494,1771262532803472,0.022,WS
+88094257549,1771262532803506,1771262532803474,0.032,WS
+88094257555,1771262532803517,1771262532803476,0.041,WS
+88094257559,1771262532805117,1771262532803476,1.641,WS
+88094257560,1771262532805138,1771262532803477,1.661,WS
+88094257565,1771262532805305,1771262532805193,0.112,WS
+88094257567,1771262532805329,1771262532806845,-1.516,UDP
+88094257593,1771262532814972,1771262532814713,0.259,WS
+88094257615,1771262532823661,1771262532824421,-0.760,UDP
+88094257616,1771262532825348,1771262532824429,0.919,WS
+88094257617,1771262532826978,1771262532827840,-0.862,UDP
+88094257620,1771262532827841,1771262532827846,-0.005,UDP
+88094257625,1771262532828957,1771262532828926,0.031,WS
+88094257663,1771262532836033,1771262532837326,-1.293,UDP
+88094257666,1771262532836057,1771262532837341,-1.284,UDP
+88094257668,1771262532836061,1771262532837342,-1.281,UDP
+88094257671,1771262532836064,1771262532837343,-1.279,UDP
+88094257682,1771262532836067,1771262532837344,-1.277,UDP
+88094257684,1771262532836070,1771262532837345,-1.275,UDP
+88094257690,1771262532836073,1771262532837345,-1.272,UDP
+88094257709,1771262532837263,1771262532837346,-0.083,UDP
+88094257721,1771262532838527,1771262532837766,0.761,WS
+88094257736,1771262532838588,1771262532838503,0.085,WS
+88094257758,1771262532849129,1771262532847663,1.466,WS
+88094257774,1771262532858562,1771262532858376,0.186,WS
+88094257788,1771262532871883,1771262532870119,1.764,WS
+88094257789,1771262532871910,1771262532871861,0.049,WS
+88094257790,1771262532871911,1771262532871863,0.048,WS
+88094257793,1771262532871911,1771262532871864,0.047,WS
+88094257797,1771262532874113,1771262532872156,1.957,WS
+88094257803,1771262532874543,1771262532874460,0.083,WS
+88094257811,1771262532876724,1771262532875322,1.402,WS
+88094257882,1771262532913981,1771262532913815,0.166,WS
+88094257885,1771262532914280,1771262532914256,0.024,WS
+88094257889,1771262532914298,1771262532914991,-0.693,UDP
+88094257899,1771262532925031,1771262532924260,0.771,WS
+88094257901,1771262532928551,1771262532925499,3.052,WS
+88094257902,1771262532928573,1771262532929091,-0.518,UDP
+88094257934,1771262532935922,1771262532935521,0.401,WS
+88094257940,1771262532935951,1771262532936494,-0.543,UDP
+88094257974,1771262532938582,1771262532938274,0.308,WS
+88094257982,1771262532938858,1771262532938591,0.267,WS
+88094257984,1771262532938868,1771262532938594,0.274,WS
+88094257991,1771262532943175,1771262532939873,3.302,WS
+88094258000,1771262532946667,1771262532946509,0.158,WS
+88094258005,1771262532953594,1771262532953507,0.087,WS
+88094258012,1771262532953635,1771262532953515,0.120,WS
+88094258014,1771262532953647,1771262532953516,0.131,WS
+88094258017,1771262532954189,1771262532953517,0.672,WS
+88094258019,1771262532954207,1771262532953517,0.690,WS
+88094258021,1771262532954212,1771262532953518,0.694,WS
+88094258023,1771262532954215,1771262532955922,-1.707,UDP
+88094258031,1771262532956043,1771262532955929,0.114,WS
+88094258036,1771262532956056,1771262532955929,0.127,WS
+88094258041,1771262532956060,1771262532955930,0.130,WS
+88094258048,1771262532956738,1771262532956695,0.043,WS
+88094258050,1771262532956752,1771262532956696,0.056,WS
+88094258052,1771262532956756,1771262532956697,0.059,WS
+88094258053,1771262532956759,1771262532956697,0.062,WS
+88094258055,1771262532956760,1771262532956698,0.062,WS
+88094258059,1771262532957366,1771262532956699,0.667,WS
+88094258062,1771262532957376,1771262532956699,0.677,WS
+88094258063,1771262532957380,1771262532956699,0.681,WS
+88094258065,1771262532965793,1771262532957369,8.424,WS
+88094258067,1771262532965828,1771262532965743,0.085,WS
+88094258070,1771262532965837,1771262532965750,0.087,WS
+88094258072,1771262532965848,1771262532965751,0.097,WS
+88094258074,1771262532965855,1771262532965753,0.102,WS
+88094258076,1771262532965865,1771262532965756,0.109,WS
+88094258077,1771262532966079,1771262532965757,0.322,WS
+88094258084,1771262532966086,1771262532966024,0.062,WS
+88094258105,1771262532985851,1771262532984988,0.863,WS
+88094258112,1771262532985880,1771262532984993,0.887,WS
+88094258126,1771262532985885,1771262532984993,0.892,WS
+88094258170,1771262532992907,1771262532992662,0.245,WS
+88094258171,1771262532997952,1771262532997703,0.249,WS
+88094258179,1771262533003756,1771262533003311,0.445,WS
+88094258192,1771262533012102,1771262533011124,0.978,WS
+88094258196,1771262533017923,1771262533017402,0.521,WS
+88094258229,1771262533036149,1771262533035533,0.616,WS
+88094258236,1771262533036176,1771262533035537,0.639,WS
+88094258243,1771262533036181,1771262533036350,-0.169,UDP
+88094258269,1771262533037412,1771262533036359,1.053,WS
+88094258282,1771262533040517,1771262533037582,2.935,WS
+88094258297,1771262533040538,1771262533037585,2.953,WS
+88094258309,1771262533065048,1771262533064957,0.091,WS
+88094258316,1771262533074995,1771262533074182,0.813,WS
+88094258317,1771262533079876,1771262533079053,0.823,WS
+88094258318,1771262533082753,1771262533082375,0.378,WS
+88094258350,1771262533117055,1771262533117011,0.044,WS
+88094258386,1771262533136226,1771262533136058,0.168,WS
+88094258441,1771262533214935,1771262533214667,0.268,WS
+88094258457,1771262533257782,1771262533257299,0.483,WS
+88094258467,1771262533283077,1771262533282226,0.851,WS
+88094258469,1771262533284742,1771262533284580,0.162,WS
+88094258471,1771262533289682,1771262533289246,0.436,WS
+88094258488,1771262533347728,1771262533347090,0.638,WS
diff --git a/ops/clob_gateway/.gitignore b/ops/clob_gateway/.gitignore
new file mode 100644
index 0000000..cff5543
--- /dev/null
+++ b/ops/clob_gateway/.gitignore
@@ -0,0 +1,3 @@
+.env
+__pycache__/
+*.pyc
diff --git a/ops/clob_gateway/README.md b/ops/clob_gateway/README.md
new file mode 100644
index 0000000..ba6d4b8
--- /dev/null
+++ b/ops/clob_gateway/README.md
@@ -0,0 +1,47 @@
+# clob_gateway
+
+Local (127.0.0.1) HTTP gateway that signs/orders via `py-clob-client`, so the Rust
+engine does not need to implement EIP-712 signing + CLOB auth.
+
+## Endpoints
+
+- `GET /health`
+- `POST /orders`
+- `DELETE /orders/{order_id}`
+- `POST /flatten`
+
+## Environment Variables (required)
+
+- `CLOB_HOST` (default: `https://clob.polymarket.com`)
+- `CLOB_CHAIN_ID` (default: `137`)
+- `CLOB_PRIVATE_KEY`
+
+API creds (recommended; if missing we try to derive on startup):
+
+- `CLOB_API_KEY`
+- `CLOB_API_SECRET`
+- `CLOB_API_PASSPHRASE`
+
+## Run (dev)
+
+```bash
+python3 -m pip install -r ops/clob_gateway/requirements.txt
+
+# export env vars first...
+python3 ops/clob_gateway/app.py --host 127.0.0.1 --port 9001
+```
+
+## systemd
+
+Use `ops/systemd/clob_gateway.service` and provide an env file at:
+
+- `/etc/polyedge/clob_gateway.env`
+
+Then:
+
+```bash
+sudo systemctl daemon-reload
+sudo systemctl enable --now clob_gateway.service
+curl -fsS http://127.0.0.1:9001/health
+```
+
diff --git a/ops/clob_gateway/app.py b/ops/clob_gateway/app.py
new file mode 100644
index 0000000..f007a3d
--- /dev/null
+++ b/ops/clob_gateway/app.py
@@ -0,0 +1,368 @@
+#!/usr/bin/env python3
+"""Local CLOB order gateway for PolyEdge (py-clob-client).
+
+Why this exists:
+- Keep Rust free of EIP-712 signing / API key auth details.
+- Provide a small, auditable localhost surface: /orders, /flatten, /health.
+
+This service is meant to run on the *remote* box, bound to 127.0.0.1.
+Secrets MUST be provided via environment variables (e.g. systemd EnvironmentFile).
+"""
+
+from __future__ import annotations
+
+import math
+import os
+import threading
+import time
+from typing import Any, Dict, Optional, Tuple
+
+from fastapi import Body, FastAPI
+from fastapi.responses import JSONResponse
+
+from py_clob_client.client import ClobClient
+from py_clob_client.clob_types import ApiCreds, OrderArgs, OrderType
+from py_clob_client.order_builder.constants import BUY, SELL
+
+
+ZERO_ADDRESS = "0x0000000000000000000000000000000000000000"
+
+# Polymarket CLOB enforces probability bounds for order prices.
+# Using a strict clamp here makes the gateway resilient to small slippage widening and
+# prevents avoidable "price out of range" rejects during canaries / micro-live.
+#
+# Note: CLOB books commonly show prices as low as 0.001 and as high as 0.999.
+MIN_PRICE = 0.001
+MAX_PRICE = 0.999
+
+
+def _env(name: str, default: Optional[str] = None) -> Optional[str]:
+    v = os.environ.get(name)
+    if v is None:
+        return default
+    v = str(v).strip()
+    return v if v else default
+
+
+def _env_required(name: str) -> str:
+    v = _env(name)
+    if not v:
+        raise RuntimeError(f"missing required env: {name}")
+    return v
+
+
+def _parse_bool(v: Optional[str]) -> bool:
+    if v is None:
+        return False
+    return str(v).strip().lower() in ("1", "true", "yes", "y", "on")
+
+
+def _ms_now() -> int:
+    return int(time.time() * 1000)
+
+
+def _clamp(v: float, lo: float, hi: float) -> float:
+    return max(lo, min(hi, v))
+
+
+def _map_side(side: str) -> Tuple[str, Optional[str]]:
+    s = str(side or "").strip().lower()
+    if s in ("buy_yes", "buy_no"):
+        return BUY, None
+    if s in ("sell_yes", "sell_no"):
+        return SELL, None
+    return BUY, f"invalid_side:{side}"
+
+
+def _map_tif_to_order_type(tif: str, ttl_ms: int) -> Tuple[OrderType, Optional[str]]:
+    t = str(tif or "").strip().upper()
+    if t == "FAK":
+        return OrderType.FAK, None
+    if t == "FOK":
+        return OrderType.FOK, None
+    if t == "GTC":
+        return OrderType.GTC, None
+    if t == "POST_ONLY":
+        # Polymarket CLOB does not expose a strict "post-only" on this client surface.
+        # We approximate with a resting order; use GTD to respect (coarse) ttl.
+        if ttl_ms > 0:
+            return OrderType.GTD, None
+        return OrderType.GTC, None
+    # Unknown -> be conservative.
+    return OrderType.FAK, f"invalid_tif:{tif}"
+
+
+def _coarse_expiration_s(ttl_ms: int) -> int:
+    # CLOB expiration is second-granularity (sub-second TTLs become 1s).
+    ttl_s = max(1, int(math.ceil(max(0.0, float(ttl_ms)) / 1000.0)))
+    return int(time.time()) + ttl_s
+
+
+def _safe_reject_code(exc: BaseException) -> str:
+    msg = str(exc).replace("\n", " ").strip()
+    msg = msg[:160]
+    return f"exception:{exc.__class__.__name__}:{msg}"
+
+
+class GatewayState:
+    def __init__(self) -> None:
+        self.client: Optional[ClobClient] = None
+        self.client_lock = threading.Lock()
+        self.tracked_orders: set[str] = set()
+        self.tracked_lock = threading.Lock()
+
+        # For debugging readiness without leaking secrets.
+        self.ready: bool = False
+        self.ready_error: str = ""
+
+
+STATE = GatewayState()
+
+app = FastAPI(title="PolyEdge CLOB Gateway", version="0.1.0")
+
+
+@app.on_event("startup")
+def _startup() -> None:
+    host = _env("CLOB_HOST", "https://clob.polymarket.com")
+    chain_id = int(_env("CLOB_CHAIN_ID", "137") or "137")
+    private_key = _env_required("CLOB_PRIVATE_KEY")
+
+    api_key = _env("CLOB_API_KEY")
+    api_secret = _env("CLOB_API_SECRET")
+    api_passphrase = _env("CLOB_API_PASSPHRASE")
+
+    try:
+        creds: Optional[ApiCreds] = None
+        if api_key and api_secret and api_passphrase:
+            creds = ApiCreds(
+                api_key=api_key,
+                api_secret=api_secret,
+                api_passphrase=api_passphrase,
+            )
+
+        client = ClobClient(host=host, chain_id=chain_id, key=private_key, creds=creds)
+        if creds is None:
+            # Prefer deriving first to avoid creating a new API key on every restart.
+            # If none exists yet, fall back to creating one.
+            derived = None
+            try:
+                derived = client.derive_api_key()
+            except Exception:
+                derived = None
+            if derived is None:
+                derived = client.create_api_key()
+            if derived is None:
+                raise RuntimeError("failed to derive/create api creds (got None)")
+            client.set_api_creds(derived)
+
+        STATE.client = client
+        STATE.ready = True
+        STATE.ready_error = ""
+    except Exception as exc:  # noqa: BLE001
+        # Keep the process up so /health is useful, but mark as not-ready.
+        # (systemd can still restart-loop if you prefer; set Restart=always)
+        STATE.client = None
+        STATE.ready = False
+        STATE.ready_error = _safe_reject_code(exc)
+
+
+@app.get("/health")
+def health() -> Dict[str, Any]:
+    client = STATE.client
+    addr = None
+    if client is not None:
+        try:
+            addr = client.get_address()
+        except Exception:
+            addr = None
+    return {
+        "status": "ok",
+        "ready": bool(STATE.ready and client is not None),
+        "ready_error": STATE.ready_error,
+        "ts_ms": _ms_now(),
+        "address": addr,
+    }
+
+
+@app.post("/orders")
+def post_order(payload: Dict[str, Any] = Body(...)) -> JSONResponse:
+    started = time.perf_counter()
+
+    def respond(
+        accepted: bool,
+        order_id: str = "",
+        accepted_size: float = 0.0,
+        reject_code: Optional[str] = None,
+        extra: Optional[Dict[str, Any]] = None,
+    ) -> JSONResponse:
+        exchange_latency_ms = (time.perf_counter() - started) * 1000.0
+        body: Dict[str, Any] = {
+            "accepted": bool(accepted),
+            "order_id": order_id,
+            "accepted_size": float(accepted_size),
+            "reject_code": reject_code,
+            "exchange_latency_ms": float(exchange_latency_ms),
+            "ts_ms": _ms_now(),
+        }
+        if extra:
+            body.update(extra)
+        return JSONResponse(status_code=200, content=body)
+
+    client = STATE.client
+    if client is None or not STATE.ready:
+        return respond(False, reject_code="gateway_not_ready")
+
+    token_id = str(payload.get("token_id") or "").strip()
+    if not token_id:
+        return respond(False, reject_code="missing_token_id")
+
+    side_raw = payload.get("side")
+    side, side_err = _map_side(str(side_raw or ""))
+    if side_err:
+        return respond(False, reject_code=side_err)
+
+    try:
+        price = float(payload.get("price"))
+        size = float(payload.get("size"))
+    except Exception:
+        return respond(False, reject_code="invalid_price_or_size")
+
+    if not (MIN_PRICE <= price <= MAX_PRICE):
+        return respond(False, reject_code="price_out_of_range")
+    if not (size > 0.0):
+        return respond(False, reject_code="size_non_positive")
+
+    ttl_ms = int(payload.get("ttl_ms") or 0)
+    tif_raw = str(payload.get("tif") or "").strip()
+    order_type, tif_err = _map_tif_to_order_type(tif_raw, ttl_ms)
+    if tif_err:
+        return respond(False, reject_code=tif_err)
+
+    # Optional slippage widening (kept conservative).
+    try:
+        max_slippage_bps = float(payload.get("max_slippage_bps") or 0.0)
+    except Exception:
+        max_slippage_bps = 0.0
+    max_slippage_bps = max(0.0, max_slippage_bps)
+    if max_slippage_bps > 0:
+        slip = max_slippage_bps / 10_000.0
+        if side == BUY:
+            price = _clamp(price * (1.0 + slip), MIN_PRICE, MAX_PRICE)
+        else:
+            price = _clamp(price * (1.0 - slip), MIN_PRICE, MAX_PRICE)
+
+    try:
+        fee_rate_bps = float(payload.get("fee_rate_bps") or 0.0)
+    except Exception:
+        fee_rate_bps = 0.0
+    fee_rate_bps_i = int(round(max(0.0, fee_rate_bps)))
+
+    expiration_s = _coarse_expiration_s(ttl_ms)
+
+    # Use a high-entropy nonce to prevent accidental duplicates.
+    nonce = time.time_ns()
+
+    try:
+        with STATE.client_lock:
+            signed = client.create_order(
+                OrderArgs(
+                    token_id=token_id,
+                    price=price,
+                    size=size,
+                    side=side,
+                    fee_rate_bps=fee_rate_bps_i,
+                    nonce=nonce,
+                    expiration=expiration_s,
+                    taker=ZERO_ADDRESS,
+                )
+            )
+            res = client.post_order(signed, orderType=order_type)
+    except Exception as exc:  # noqa: BLE001
+        return respond(False, reject_code=_safe_reject_code(exc))
+
+    # Best-effort parsing; different gateways/clients sometimes vary the field names.
+    order_id = ""
+    try:
+        if isinstance(res, dict):
+            order_id = (
+                (res.get("order_id") or res.get("id") or res.get("orderID") or res.get("orderId") or "")
+            )
+    except Exception:
+        order_id = ""
+
+    # Some responses include a filled size; if absent assume requested (engine will cap later anyway).
+    accepted_size = None
+    if isinstance(res, dict):
+        for k in ("accepted_size", "size", "sizeMatched", "matched_size", "filled_size", "filledSize"):
+            v = res.get(k)
+            try:
+                if v is not None:
+                    accepted_size = float(v)
+                    break
+            except Exception:
+                continue
+        # Some responses include explicit error/success.
+        if res.get("error") or res.get("errors"):
+            return respond(False, order_id=order_id or "", accepted_size=0.0, reject_code=str(res.get("error") or "exchange_error")[:160])
+
+    if accepted_size is None:
+        accepted_size = float(size)
+
+    if order_id:
+        with STATE.tracked_lock:
+            STATE.tracked_orders.add(str(order_id))
+
+    # If the venue returns 0 fill for taker orders, treat as reject so the engine can account for it.
+    accepted = accepted_size > 0.0
+    reject_code = None if accepted else "zero_fill"
+    return respond(accepted, order_id=order_id or "", accepted_size=accepted_size, reject_code=reject_code)
+
+
+@app.delete("/orders/{order_id}")
+def cancel_order(order_id: str) -> JSONResponse:
+    client = STATE.client
+    if client is None or not STATE.ready:
+        return JSONResponse(status_code=503, content={"ok": False, "error": "gateway_not_ready"})
+    try:
+        with STATE.client_lock:
+            _ = client.cancel(order_id)
+        with STATE.tracked_lock:
+            STATE.tracked_orders.discard(order_id)
+        return JSONResponse(status_code=200, content={"ok": True})
+    except Exception as exc:  # noqa: BLE001
+        return JSONResponse(status_code=500, content={"ok": False, "error": _safe_reject_code(exc)})
+
+
+@app.post("/flatten")
+def flatten() -> JSONResponse:
+    client = STATE.client
+    if client is None or not STATE.ready:
+        return JSONResponse(status_code=503, content={"ok": False, "error": "gateway_not_ready"})
+    try:
+        # Hard safety: cancel everything for the API key.
+        with STATE.client_lock:
+            _ = client.cancel_all()
+        with STATE.tracked_lock:
+            STATE.tracked_orders.clear()
+        return JSONResponse(status_code=200, content={"ok": True})
+    except Exception as exc:  # noqa: BLE001
+        return JSONResponse(status_code=500, content={"ok": False, "error": _safe_reject_code(exc)})
+
+
+def _main() -> int:
+    import argparse
+
+    p = argparse.ArgumentParser(description="PolyEdge local CLOB gateway (FastAPI)")
+    p.add_argument("--host", default=_env("GATEWAY_HOST", "127.0.0.1"))
+    p.add_argument("--port", type=int, default=int(_env("GATEWAY_PORT", "9001") or "9001"))
+    p.add_argument("--log-level", default=_env("GATEWAY_LOG_LEVEL", "info"))
+    args = p.parse_args()
+
+    import uvicorn
+
+    uvicorn.run("app:app", host=args.host, port=args.port, log_level=args.log_level, workers=1)
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(_main())
diff --git a/ops/clob_gateway/requirements.txt b/ops/clob_gateway/requirements.txt
new file mode 100644
index 0000000..47b4430
--- /dev/null
+++ b/ops/clob_gateway/requirements.txt
@@ -0,0 +1,3 @@
+fastapi
+uvicorn
+py-clob-client
diff --git a/ops/systemd/clob_gateway.service b/ops/systemd/clob_gateway.service
new file mode 100644
index 0000000..577ad59
--- /dev/null
+++ b/ops/systemd/clob_gateway.service
@@ -0,0 +1,30 @@
+[Unit]
+Description=PolyEdge CLOB gateway (py-clob-client)
+After=network-online.target
+Wants=network-online.target
+
+[Service]
+Type=simple
+User=ubuntu
+WorkingDirectory=/home/ubuntu/PolyEdge/ops/clob_gateway
+Environment=PYTHONUNBUFFERED=1
+# Secrets must live outside the repo. Example file:
+#   /etc/polyedge/clob_gateway.env
+# containing:
+#   CLOB_HOST=https://clob.polymarket.com
+#   CLOB_CHAIN_ID=137
+#   CLOB_PRIVATE_KEY=...
+#   CLOB_API_KEY=...
+#   CLOB_API_SECRET=...
+#   CLOB_API_PASSPHRASE=...
+EnvironmentFile=-/etc/polyedge/clob_gateway.env
+ExecStart=/usr/bin/python3 -m uvicorn app:app --host 127.0.0.1 --port 9001 --workers 1
+Restart=always
+RestartSec=3
+LimitNOFILE=1048576
+StandardOutput=append:/var/log/polyedge/clob_gateway.log
+StandardError=append:/var/log/polyedge/clob_gateway.err.log
+
+[Install]
+WantedBy=multi-user.target
+
diff --git a/ops/systemd/polyedge.service b/ops/systemd/polyedge.service
index 8637664..d8799d3 100644
--- a/ops/systemd/polyedge.service
+++ b/ops/systemd/polyedge.service
@@ -8,6 +8,9 @@ Type=simple
 User=ubuntu
 WorkingDirectory=/home/ubuntu/PolyEdge
 Environment=RUST_LOG=info
+# Optional feed toggles (defaults are enabled in code). We disable Chainlink anchor input on
+# servers by default to avoid slow ticks impacting data validity and latency tails.
+Environment=POLYEDGE_ENABLE_CHAINLINK_ANCHOR=false
 # Run the built binary directly (faster restarts, avoids cargo spawning/port races).
 ExecStart=/home/ubuntu/PolyEdge/target/release/app_runner
 Restart=always
diff --git a/scripts/TIME_ARBITRAGE_NETWORK.md b/scripts/TIME_ARBITRAGE_NETWORK.md
new file mode 100644
index 0000000..6572ee8
--- /dev/null
+++ b/scripts/TIME_ARBITRAGE_NETWORK.md
@@ -0,0 +1,194 @@
+# PolyEdge æ—¶é—´å¥—åˆ©ç½‘ç»œæž¶æž„
+
+## æ¦‚è¿°
+
+æœ¬æ–‡æ¡£æè¿° PolyEdge çš„æ­£ç¡®æ—¶é—´å¥—åˆ©ç½‘ç»œæž¶æž„ã€‚
+
+**é‡è¦æ¾„æ¸…**ï¼š
+- Polymarket æœåŠ¡å™¨ä½äºŽ **è‹±å›½ä¼¦æ•¦ (AWS eu-west-2)**
+- Binance å­˜åœ¨æ–°åŠ å¡èŠ‚ç‚¹
+- ä¸œäº¬åˆ°ä¼¦æ•¦ç‰©ç†è·ç¦»çº¦ 9600 å…¬é‡Œï¼Œå»¶è¿Ÿçº¦ 200ms
+
+## ç½‘ç»œæ‹“æ‰‘
+
+```
+â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+â”‚                         AWS å…¨çƒéª¨å¹²ç½‘                                    â”‚
+â”‚                                                                         â”‚
+â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
+â”‚  â”‚   ä¸œäº¬ VPC       â”‚          â”‚         çˆ±å°”å…° VPC                   â”‚ â”‚
+â”‚  â”‚   ap-northeast-1 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚         eu-west-1                   â”‚ â”‚
+â”‚  â”‚                  â”‚  VPC     â”‚                                      â”‚ â”‚
+â”‚  â”‚                  â”‚  ~206ms  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
+â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚          â”‚  â”‚  PolyEdge  â”‚ â”‚  Polymarket    â”‚ â”‚ â”‚
+â”‚  â”‚  â”‚  Binance   â”‚â”€â”€â”¤          â”‚  â”‚  Engine    â”‚ â”‚  (ä¼¦æ•¦ eu-west-2)â”‚ â”‚
+â”‚  â”‚  â”‚  (æ–°åŠ å¡)   â”‚  5ms       â”‚  â”‚  (çˆ±å°”å…°)   â”‚ â”‚    ~5ms        â”‚ â”‚ â”‚
+â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚          â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
+â”‚  â”‚        â†“         â”‚          â”‚        â”‚                            â”‚ â”‚
+â”‚  â”‚   ~5ms å»¶è¿Ÿ      â”‚          â”‚   ~5ms å»¶è¿Ÿ                        â”‚ â”‚
+â”‚  â”‚                  â”‚          â”‚                                      â”‚ â”‚
+â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚          â”‚                                      â”‚ â”‚
+â”‚  â”‚  â”‚  Feeder    â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ â”‚
+â”‚  â”‚  â”‚  (UDP)     â”‚  â”‚          â”‚                                      â”‚ â”‚
+â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚          â”‚                                      â”‚ â”‚
+â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
+â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+```
+
+## æœåŠ¡å™¨ä¿¡æ¯
+
+| æœåŠ¡å™¨ | å†…ç½‘ IP | å…¬ç½‘ IP | è§’è‰² |
+|--------|---------|---------|------|
+| ä¸œäº¬ | 172.31.44.26 | 57.180.89.145 | Binance æ•°æ®æº |
+| çˆ±å°”å…° | 10.0.3.123 | 54.77.232.166 | æ‰§è¡Œå¼•æ“Ž |
+
+## å»¶è¿Ÿåˆ†æž (å®žæµ‹æ•°æ®)
+
+### é“¾è·¯å»¶è¿Ÿ (å®žæµ‹)
+
+| é“¾è·¯ | å»¶è¿Ÿ | è¯´æ˜Ž |
+|------|------|------|
+| Binance (æ–°åŠ å¡) â†’ ä¸œäº¬ | ~5ms | WebSocket æœ¬åœ°è¿žæŽ¥ |
+| ä¸œäº¬ â†’ çˆ±å°”å…° (VPC) | **~206ms** | AWS å†…ç½‘éª¨å¹²ç½‘ |
+| çˆ±å°”å…° â†’ Polymarket (ä¼¦æ•¦) | ~5ms | éš”å£ region |
+| **æ€»å‚è€ƒå»¶è¿Ÿ** | **~216ms** | æ•°æ®ä¼ è¾“ |
+
+### æ–¹æ¡ˆå¯¹æ¯”
+
+| æ–¹æ¡ˆ | æ•°æ®å»¶è¿Ÿ | æ‰§è¡Œå»¶è¿Ÿ | æ€»å»¶è¿Ÿ | ç¨³å®šæ€§ |
+|------|----------|----------|--------|--------|
+| **ä¸œäº¬ä¸­ç»§ (æŽ¨è)** | ~216ms | ~5ms | ~221ms | æžé«˜ (0.265msæŠ–åŠ¨) |
+| çˆ±å°”å…°ç›´è¿ž | ~250ms | ~5ms | ~255ms | ä¸€èˆ¬ (å…¬ç½‘æŠ–åŠ¨) |
+
+**ç»“è®º**: ä¸œäº¬ä¸­ç»§æ¯”ç›´è¿žå¿« **~40ms**ï¼Œä¸”ç¨³å®šæ€§æ›´é«˜ï¼
+
+## ä¸ºä»€ä¹ˆ"çœ‹åˆ°æ…¢"æ²¡å…³ç³»ï¼Ÿ
+
+å…³é”®åœ¨äºŽ**ä¸‹å•é€Ÿåº¦**å’Œ**ç¡®å®šæ€§**ï¼š
+
+### æ–¹æ¡ˆ A: éƒ¨ç½²åœ¨ä¸œäº¬ (é”™è¯¯)
+- çœ‹åˆ°ä»·æ ¼: 0ms (æœ¬åœ°)
+- ä¸‹å•åˆ°ä¼¦æ•¦: ~220ms (è·¨åŒºåŸŸ)
+- é—®é¢˜: å­å¼¹é£žè¡Œçš„ 220ms é‡Œï¼Œä¼¦æ•¦ç›˜å£å·²å˜åŒ–å¤šæ¬¡
+
+### æ–¹æ¡ˆ B: éƒ¨ç½²åœ¨çˆ±å°”å…° + ä¸œäº¬ä¸­ç»§ (æ­£ç¡®)
+- çœ‹åˆ°ä»·æ ¼: ~216ms (ä¸­ç»§æ•°æ®)
+- ä¸‹å•åˆ°ä¼¦æ•¦: ~5ms (éš”å£)
+- ä¼˜åŠ¿: è™½ç„¶çœ‹åˆ°çš„æ˜¯ 216ms å‰çš„ä»·æ ¼ï¼Œä½†å¯¹æ‰‹çœ‹åˆ°çš„ä¹Ÿæ˜¯
+- ç¡®å®šæ€§: ä¸‹å•åªéœ€ 5ms å°±èƒ½ç¡®è®¤æˆäº¤
+
+**æ ¸å¿ƒ**: è·¨å¸‚åœºå¥—åˆ©ä¸­ï¼Œ**æ‰§è¡Œç«¯ä½Žå»¶è¿Ÿ**è¿œæ¯”**æ•°æ®ç«¯ä½Žå»¶è¿Ÿ**é‡è¦ï¼
+
+## æŠ€æœ¯å®žçŽ°
+
+### 1. æ•°æ®æ ¼å¼ (Wire Protocol)
+
+24 å­—èŠ‚/æ¶ˆæ¯ï¼š
+```rust
+struct WireBookTop {
+    bid: f64,    // 8 å­—èŠ‚
+    ask: f64,    // 8 å­—èŠ‚
+    ts: u64,     // 8 å­—èŠ‚ (å¾®ç§’)
+}
+```
+
+### 2. ä¸œäº¬ç«¯: Binance è½¬å‘å™¨
+
+ä¼˜åŒ–ç‰¹æ€§:
+- **16MB UDP å‘é€ç¼“å†²åŒº**
+- **DSCP ä¼˜å…ˆçº§** (EF, 46)
+- **é¢„åˆ†é…ç¼–ç  buffer**
+- **äºŒè¿›åˆ¶åºåˆ—åŒ–** (bincode)
+
+### 3. çˆ±å°”å…°ç«¯: UDP æŽ¥æ”¶å™¨
+
+ä¼˜åŒ–ç‰¹æ€§:
+- **32MB UDP æŽ¥æ”¶ç¼“å†²åŒº**
+- **ç«¯å£å¤ç”¨** (å¿«é€Ÿé‡å¯)
+- **Gap æ£€æµ‹**
+- **è¯¦ç»†ç»Ÿè®¡**
+
+## æµ‹è¯•æ•°æ®
+
+### VPC è¿žé€šæ€§æµ‹è¯•
+
+```
+--- 172.31.44.26 ping statistics ---
+20 packets transmitted, 20 received, 0% packet loss
+rtt min/avg/max/mdev = 206.230/206.331/207.477/0.265 ms
+```
+
+å…³é”®æŒ‡æ ‡:
+- å»¶è¿Ÿ: ~206ms (ç¨³å®š)
+- ä¸¢åŒ…çŽ‡: 0%
+- æŠ–åŠ¨ (mdev): 0.265ms (æžä½Ž)
+
+### å…¬ç½‘ç›´è¿žå¯¹æ¯”
+
+```
+# çˆ±å°”å…° â†’ Binance (å…¬ç½‘)
+time_connect: 0.203006
+time_appconnect: 0.609011
+
+# çˆ±å°”å…° â†’ Polymarket
+time_connect: 0.002833
+time_appconnect: 0.022545
+```
+
+## éƒ¨ç½²æ­¥éª¤
+
+### 1. éªŒè¯ VPC Peering
+
+```bash
+# åœ¨çˆ±å°”å…°æµ‹è¯•
+ping -c 10 172.31.44.26
+
+# é¢„æœŸ: ~206ms, 0% ä¸¢åŒ…
+```
+
+### 2. å¯åŠ¨ä¸œäº¬è½¬å‘å™¨
+
+```bash
+ssh -i dongjing.pem ubuntu@57.180.89.145
+
+# ç¼–è¯‘
+cd /opt/PolyEdge
+cargo build -p feeder_tokyo --release --bin sender
+
+# å¯åŠ¨
+export TARGET=10.0.3.123:6666
+nohup ./target/release/sender > feeder.log 2>&1 &
+```
+
+### 3. å¯åŠ¨çˆ±å°”å…°å¼•æ“Ž
+
+```bash
+ssh -i PolyEdge.pem ubuntu@54.77.232.166
+
+# ç¼–è¯‘
+cargo build -p app_runner --release
+
+# å¯åŠ¨
+cargo run -p app_runner
+```
+
+## ç›‘æŽ§æŒ‡æ ‡
+
+å»ºè®®ç›‘æŽ§:
+- æ•°æ®å»¶è¿Ÿ: ~216ms (P99 < 250ms)
+- ä¸‹å•å»¶è¿Ÿ: ~5ms (P99 < 10ms)
+- ä¸¢åŒ…çŽ‡: < 0.01%
+- æŠ–åŠ¨: < 1ms
+
+## æ•…éšœæŽ’æŸ¥
+
+### é—®é¢˜: å»¶è¿Ÿè¿‡é«˜
+
+1. æ£€æŸ¥ VPC è·¯ç”±è¡¨æ˜¯å¦æ­£ç¡®é…ç½®
+2. ç¡®è®¤å®‰å…¨ç»„å…è®¸ UDP 6666 ç«¯å£
+3. æµ‹è¯• VPC è¿žé€šæ€§: `ping 172.31.44.26`
+
+### é—®é¢˜: ä¸¢åŒ…
+
+1. æ£€æŸ¥ç½‘å¡é”™è¯¯: `ethtool -S eth0`
+2. å¢žåŠ  ring buffer: `ethtool -G eth0 rx 4096 tx 4096`
diff --git a/scripts/ab_region_compare.py b/scripts/ab_region_compare.py
index e3d861f..36312f8 100644
--- a/scripts/ab_region_compare.py
+++ b/scripts/ab_region_compare.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 from __future__ import annotations
 
+import atexit
 import argparse
 import json
 import os
@@ -57,6 +58,7 @@ def collect(
     fail_fast_threshold: int,
 ) -> RegionStats:
     session = requests.Session()
+    atexit.register(session.close)
     deadline = time.time() + max(1, seconds)
     tick_ack: List[float] = []
     tick_decision: List[float] = []
diff --git a/scripts/analyze_fullchain_run.py b/scripts/analyze_fullchain_run.py
new file mode 100644
index 0000000..b658fe9
--- /dev/null
+++ b/scripts/analyze_fullchain_run.py
@@ -0,0 +1,408 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import json
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Any, Dict, List, Optional
+
+
+def read_json(path: Path) -> Any:
+    return json.loads(path.read_text(encoding="utf-8"))
+
+
+def fmt(x: Any, digits: int = 3) -> str:
+    try:
+        if x is None:
+            return "NA"
+        if isinstance(x, bool):
+            return "true" if x else "false"
+        if isinstance(x, (int, float)):
+            return f"{float(x):.{digits}f}"
+        return str(x)
+    except Exception:
+        return "NA"
+
+
+@dataclass
+class SweepRow:
+    ts_ms: int
+    path: Path
+    stats: Dict[str, Dict[str, float]]
+    last: Dict[str, Any]
+
+
+@dataclass
+class MetricSpec:
+    key: str
+    stat: str
+    direction: str  # lower|higher
+    abs_tolerance: float
+    rel_tolerance: float
+
+
+def collect_sweeps(run_dir: Path) -> List[SweepRow]:
+    rows: List[SweepRow] = []
+    for p in sorted(run_dir.glob("full_latency_sweep_*.json")):
+        try:
+            d = read_json(p)
+            meta = d.get("meta") or {}
+            ts_ms = int(meta.get("ts_ms") or 0)
+            engine = d.get("engine") or {}
+            stats = engine.get("stats") or {}
+            last = engine.get("last") or {}
+            if isinstance(stats, dict) and isinstance(last, dict):
+                rows.append(SweepRow(ts_ms=ts_ms, path=p, stats=stats, last=last))
+        except Exception:
+            continue
+    return rows
+
+
+def pick_stat(stats: Dict[str, Dict[str, float]], key: str, which: str) -> Optional[float]:
+    try:
+        st = stats.get(key) or {}
+        if not isinstance(st, dict):
+            return None
+        val = st.get(which)
+        return float(val) if val is not None else None
+    except Exception:
+        return None
+
+
+def print_sweep_table(rows: List[SweepRow]) -> None:
+    if not rows:
+        print("no full_latency_sweep_*.json found")
+        return
+
+    cols = [
+        ("tick_to_ack_p99_ms", "p99"),
+        ("tick_to_decision_p99_ms", "p99"),
+        ("decision_queue_wait_p99_ms", "p99"),
+        ("decision_compute_p99_ms", "p99"),
+        ("source_latency_p99_ms", "p99"),
+        ("exchange_lag_p99_ms", "p99"),
+        ("path_lag_p99_ms", "p99"),
+        ("local_backlog_p99_ms", "p99"),
+        ("quote_block_ratio", "p99"),
+        ("policy_block_ratio", "p99"),
+        ("gate_block_ratio", "p99"),
+        ("executed_over_eligible", "p50"),
+        ("ev_net_usdc_p50", "p50"),
+        ("window_outcomes", "p99"),
+    ]
+    header = ["ts_ms", "window_id"] + [f"{k}.{w}" for k, w in cols] + ["file"]
+    print("\t".join(header))
+    for row in rows:
+        values = [str(row.ts_ms), str(row.last.get("window_id"))]
+        for key, which in cols:
+            values.append(fmt(pick_stat(row.stats, key, which)))
+        values.append(row.path.name)
+        print("\t".join(values))
+
+
+def print_storm(run_dir: Path) -> None:
+    p = run_dir / "storm_test_summary.json"
+    if not p.exists():
+        print("no storm_test_summary.json found")
+        return
+    d = read_json(p)
+    lat = d.get("latency_ms") or {}
+    print("storm_test_summary")
+    print(f"- error_count: {d.get('error_count')}")
+    print(f"- consecutive_failures: {d.get('consecutive_failures')}")
+    print(f"- latency_p50_ms: {fmt(lat.get('p50'))}")
+    print(f"- latency_p99_ms: {fmt(lat.get('p99'))}")
+    print(f"- latency_max_ms: {fmt(lat.get('max'))}")
+
+
+def _snapshot_live(run_dir: Path, name: str) -> Optional[Dict[str, Any]]:
+    path = run_dir / "snapshots" / name
+    if not path.exists():
+        return None
+    try:
+        data = read_json(path)
+        return data if isinstance(data, dict) else None
+    except Exception:
+        return None
+
+
+def print_snapshot_diffs(run_dir: Path) -> None:
+    pre = _snapshot_live(run_dir, "shadow_live_pre.json")
+    post = _snapshot_live(run_dir, "shadow_live_after_storm.json") or _snapshot_live(
+        run_dir, "shadow_live_after_sweeps.json"
+    )
+    if not pre or not post:
+        return
+
+    keys = [
+        "tick_to_ack_p99_ms",
+        "tick_to_decision_p99_ms",
+        "decision_queue_wait_p99_ms",
+        "decision_compute_p99_ms",
+        "source_latency_p99_ms",
+        "exchange_lag_p99_ms",
+        "path_lag_p99_ms",
+        "local_backlog_p99_ms",
+        "window_outcomes",
+        "quote_block_ratio",
+        "policy_block_ratio",
+        "gate_block_ratio",
+        "executed_over_eligible",
+        "ev_net_usdc_p50",
+        "ev_positive_ratio",
+        "data_valid_ratio",
+    ]
+    print("shadow_live_pre_vs_post")
+    for key in keys:
+        print(f"- {key}: {fmt(pre.get(key))} -> {fmt(post.get(key))}")
+
+
+def print_missing_endpoints(run_dir: Path) -> None:
+    snap = run_dir / "snapshots"
+    if not snap.exists():
+        return
+    errs = sorted(snap.glob("*.err.txt"))
+    if not errs:
+        return
+    print("snapshot_errors")
+    for p in errs:
+        msg = p.read_text(encoding="utf-8", errors="replace").strip()
+        print(f"- {p.name}: {msg}")
+
+
+def latest_metrics(rows: List[SweepRow]) -> Dict[str, float]:
+    if not rows:
+        return {}
+    row = rows[-1]
+    metrics: Dict[str, float] = {}
+    for key, stat in (
+        ("tick_to_ack_p99_ms", "p99"),
+        ("tick_to_decision_p99_ms", "p99"),
+        ("decision_queue_wait_p99_ms", "p99"),
+        ("decision_compute_p99_ms", "p99"),
+        ("source_latency_p99_ms", "p99"),
+        ("exchange_lag_p99_ms", "p99"),
+        ("path_lag_p99_ms", "p99"),
+        ("local_backlog_p99_ms", "p99"),
+        ("feed_in_p99_ms", "p99"),
+        ("quote_block_ratio", "p99"),
+        ("policy_block_ratio", "p99"),
+        ("gate_block_ratio", "p99"),
+        ("executed_over_eligible", "p50"),
+        ("ev_positive_ratio", "p50"),
+        ("ev_net_usdc_p50", "p50"),
+    ):
+        val = pick_stat(row.stats, key, stat)
+        if val is not None:
+            metrics[key] = val
+    return metrics
+
+
+def regression_specs() -> List[MetricSpec]:
+    return [
+        MetricSpec("tick_to_ack_p99_ms", "p99", "lower", 0.10, 0.08),
+        MetricSpec("tick_to_decision_p99_ms", "p99", "lower", 0.10, 0.08),
+        MetricSpec("decision_queue_wait_p99_ms", "p99", "lower", 0.08, 0.10),
+        MetricSpec("decision_compute_p99_ms", "p99", "lower", 0.08, 0.10),
+        MetricSpec("source_latency_p99_ms", "p99", "lower", 5.00, 0.12),
+        MetricSpec("exchange_lag_p99_ms", "p99", "lower", 5.00, 0.12),
+        MetricSpec("path_lag_p99_ms", "p99", "lower", 0.25, 0.20),
+        MetricSpec("local_backlog_p99_ms", "p99", "lower", 0.15, 0.15),
+        MetricSpec("feed_in_p99_ms", "p99", "lower", 0.15, 0.15),
+        MetricSpec("quote_block_ratio", "p99", "lower", 0.01, 0.20),
+        MetricSpec("policy_block_ratio", "p99", "lower", 0.01, 0.20),
+        MetricSpec("gate_block_ratio", "p99", "lower", 0.01, 0.20),
+        MetricSpec("executed_over_eligible", "p50", "higher", 0.02, 0.10),
+        MetricSpec("ev_positive_ratio", "p50", "higher", 0.02, 0.10),
+        MetricSpec("ev_net_usdc_p50", "p50", "higher", 0.0001, 0.15),
+    ]
+
+
+def compare_metrics(
+    candidate_rows: List[SweepRow], baseline_rows: List[SweepRow]
+) -> Dict[str, Any]:
+    candidate = latest_metrics(candidate_rows)
+    baseline = latest_metrics(baseline_rows)
+
+    metrics: Dict[str, Dict[str, Any]] = {}
+    regressed: List[str] = []
+    improved: List[str] = []
+    missing: List[str] = []
+
+    for spec in regression_specs():
+        c = candidate.get(spec.key)
+        b = baseline.get(spec.key)
+        if c is None or b is None:
+            missing.append(spec.key)
+            continue
+        delta = c - b
+        rel = 0.0 if abs(b) < 1e-9 else delta / abs(b)
+        if spec.direction == "lower":
+            threshold = max(spec.abs_tolerance, abs(b) * spec.rel_tolerance)
+            is_regressed = delta > threshold
+            is_improved = delta < -threshold
+        else:
+            threshold = max(spec.abs_tolerance, abs(b) * spec.rel_tolerance)
+            is_regressed = -delta > threshold
+            is_improved = delta > threshold
+
+        status = "flat"
+        if is_regressed:
+            status = "regressed"
+            regressed.append(spec.key)
+        elif is_improved:
+            status = "improved"
+            improved.append(spec.key)
+
+        metrics[spec.key] = {
+            "baseline": b,
+            "candidate": c,
+            "delta": delta,
+            "rel_delta": rel,
+            "status": status,
+            "direction": spec.direction,
+        }
+
+    attributions = infer_regression_attributions(metrics)
+    return {
+        "candidate": candidate,
+        "baseline": baseline,
+        "metrics": metrics,
+        "regressed_metrics": regressed,
+        "improved_metrics": improved,
+        "missing_metrics": missing,
+        "pass": len(regressed) == 0,
+        "attributions": attributions,
+    }
+
+
+def infer_regression_attributions(metrics: Dict[str, Dict[str, Any]]) -> List[str]:
+    reasons: List[str] = []
+
+    def is_regressed(key: str) -> bool:
+        return (metrics.get(key) or {}).get("status") == "regressed"
+
+    if is_regressed("source_latency_p99_ms") or is_regressed("exchange_lag_p99_ms"):
+        reasons.append(
+            "upstream source latency regressed (exchange/ingest); prioritize exchange feed stability and timestamp alignment"
+        )
+    if is_regressed("path_lag_p99_ms") and not is_regressed("exchange_lag_p99_ms"):
+        reasons.append(
+            "Tokyo->Ireland relay path regressed independently; inspect UDP relay host/network path and irq/core pinning"
+        )
+    if is_regressed("decision_queue_wait_p99_ms"):
+        if is_regressed("local_backlog_p99_ms") or is_regressed("feed_in_p99_ms"):
+            reasons.append(
+                "ingress queue pressure increased (queue wait + backlog/feed-in moved together); tune merge capacity/coalescing"
+            )
+        elif is_regressed("decision_compute_p99_ms"):
+            reasons.append(
+                "compute-bound decision loop (queue wait grew with compute p99); reduce hot-path work or increase consumer parallelism"
+            )
+        else:
+            reasons.append(
+                "scheduler/dispatch jitter likely (queue wait regressed without matching backlog/compute growth)"
+            )
+    if is_regressed("quote_block_ratio") or is_regressed("policy_block_ratio"):
+        reasons.append(
+            "execution gate blocking rose; inspect policy thresholds and eligibility drift"
+        )
+    if is_regressed("executed_over_eligible") and not (
+        is_regressed("quote_block_ratio") or is_regressed("policy_block_ratio")
+    ):
+        reasons.append(
+            "execution conversion fell without explicit gate rise; check order path, ack handling, and venue responsiveness"
+        )
+
+    if not reasons:
+        reasons.append("no dominant bottleneck inferred; run targeted stage-by-stage profiling for next iteration")
+    return reasons
+
+
+def print_regression_report(result: Dict[str, Any], baseline_dir: Path) -> None:
+    print(f"baseline_run_dir={baseline_dir}")
+    print(f"regression_gate_pass={'true' if result['pass'] else 'false'}")
+    if result["missing_metrics"]:
+        print(f"missing_metrics={','.join(result['missing_metrics'])}")
+
+    print("regression_scorecard")
+    ordered = sorted(
+        result["metrics"].items(),
+        key=lambda kv: (0 if kv[1]["status"] == "regressed" else 1, kv[0]),
+    )
+    for key, row in ordered:
+        print(
+            f"- {key}: {fmt(row['baseline'])} -> {fmt(row['candidate'])} "
+            f"(delta={fmt(row['delta'])}, rel={fmt(row['rel_delta'], 4)}, status={row['status']})"
+        )
+
+    print("likely_causes")
+    for item in result["attributions"]:
+        print(f"- {item}")
+
+
+def parse_args() -> argparse.Namespace:
+    p = argparse.ArgumentParser(description="Analyze a fullchain benchmark run directory.")
+    p.add_argument("--run-dir", required=True, help="path to datasets/reports/<day>/runs/<run_id>")
+    p.add_argument(
+        "--baseline-run-dir",
+        default="",
+        help="optional baseline run directory for regression comparison",
+    )
+    p.add_argument("--json-out", default="", help="optional path to write analysis json")
+    p.add_argument(
+        "--fail-on-regression",
+        action="store_true",
+        help="exit non-zero when regression gate does not pass",
+    )
+    return p.parse_args()
+
+
+def main() -> int:
+    args = parse_args()
+    run_dir = Path(args.run_dir)
+    if not run_dir.exists():
+        print(f"run dir not found: {run_dir}")
+        return 2
+
+    rows = collect_sweeps(run_dir)
+    print_sweep_table(rows)
+    print()
+    print_storm(run_dir)
+    print()
+    print_snapshot_diffs(run_dir)
+    print()
+    print_missing_endpoints(run_dir)
+
+    regression_result: Optional[Dict[str, Any]] = None
+    if args.baseline_run_dir:
+        baseline_dir = Path(args.baseline_run_dir)
+        baseline_rows = collect_sweeps(baseline_dir)
+        print()
+        if not baseline_rows:
+            print(f"baseline has no full_latency_sweep_*.json: {baseline_dir}")
+        elif not rows:
+            print("candidate has no full_latency_sweep_*.json; regression analysis skipped")
+        else:
+            regression_result = compare_metrics(rows, baseline_rows)
+            print_regression_report(regression_result, baseline_dir)
+
+    if args.json_out:
+        output = {
+            "run_dir": str(run_dir),
+            "sweep_files": [str(r.path) for r in rows],
+            "regression": regression_result,
+        }
+        out_path = Path(args.json_out)
+        out_path.parent.mkdir(parents=True, exist_ok=True)
+        out_path.write_text(json.dumps(output, ensure_ascii=True, indent=2), encoding="utf-8")
+        print(f"wrote_json={out_path}")
+
+    if args.fail_on_regression and regression_result is not None and not regression_result["pass"]:
+        return 10
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/scripts/convergence_analysis.py b/scripts/convergence_analysis.py
new file mode 100644
index 0000000..f3713ec
--- /dev/null
+++ b/scripts/convergence_analysis.py
@@ -0,0 +1,493 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import asyncio
+import json
+import math
+import time
+from dataclasses import dataclass
+from collections import deque
+from pathlib import Path
+from typing import Any, Dict, List, Optional, Tuple
+
+import requests
+import websockets
+
+
+def percentile(values: List[float], q: float) -> Optional[float]:
+    if not values:
+        return None
+    arr = sorted(values)
+    if len(arr) == 1:
+        return float(arr[0])
+    idx = (len(arr) - 1) * q
+    lo = int(math.floor(idx))
+    hi = int(math.ceil(idx))
+    if lo == hi:
+        return float(arr[lo])
+    w = idx - lo
+    return float(arr[lo] * (1.0 - w) + arr[hi] * w)
+
+
+def to_bps(delta: float, base: float) -> Optional[float]:
+    if not math.isfinite(delta) or not math.isfinite(base) or base == 0:
+        return None
+    return (delta / base) * 10_000.0
+
+
+@dataclass
+class PricePoint:
+    ts_ms: int
+    px: float
+
+
+class SharedState:
+    def __init__(self, symbols: List[str]) -> None:
+        self.symbols = symbols
+        self.binance: Dict[str, PricePoint] = {}
+        self.pm: Dict[str, PricePoint] = {}
+        self.last_trigger_ms: Dict[str, int] = {s: 0 for s in symbols}
+        self.events: List[Dict[str, Any]] = []
+        self.lock = asyncio.Lock()
+        self.trigger_count: int = 0
+        self.trigger_skip_no_pm: int = 0
+
+
+def normalize_symbol(s: str) -> str:
+    s = s.strip().upper()
+    return s if s.endswith("USDT") else f"{s}USDT"
+
+
+def symbol_to_pm(s: str) -> str:
+    return normalize_symbol(s).replace("USDT", "").lower()
+
+
+async def run_binance_feed(state: SharedState, end_ts: float) -> None:
+    streams = "/".join([f"{normalize_symbol(s).lower()}@bookTicker" for s in state.symbols])
+    url = f"wss://stream.binance.com:9443/stream?streams={streams}"
+    while time.time() < end_ts:
+        try:
+            async with websockets.connect(url, ping_interval=20, ping_timeout=20, max_size=2**22) as ws:
+                while time.time() < end_ts:
+                    raw = await asyncio.wait_for(ws.recv(), timeout=3.0)
+                    recv_ms = int(time.time() * 1000)
+                    msg = json.loads(raw)
+                    payload = msg.get("data", msg)
+                    symbol = normalize_symbol(str(payload.get("s", "")))
+                    bid = float(payload.get("b", 0.0))
+                    ask = float(payload.get("a", 0.0))
+                    if symbol not in state.symbols or bid <= 0 or ask <= 0:
+                        continue
+                    px = (bid + ask) * 0.5
+                    async with state.lock:
+                        prev = state.binance.get(symbol)
+                        state.binance[symbol] = PricePoint(ts_ms=recv_ms, px=px)
+                    if prev is None:
+                        continue
+                    dt_ms = max(1, recv_ms - prev.ts_ms)
+                    ret = (px - prev.px) / prev.px
+                    velocity_bps_per_sec = (ret * 10_000.0) / (dt_ms / 1000.0)
+                    if abs(velocity_bps_per_sec) > 5.0:
+                        await maybe_trigger_event(
+                            state,
+                            symbol,
+                            recv_ms,
+                            velocity_bps_per_sec,
+                            binance_change_bps=ret * 10_000.0,
+                        )
+        except Exception:
+            await asyncio.sleep(0.5)
+
+
+async def run_pm_feed(state: SharedState, end_ts: float) -> None:
+    url = "wss://ws-live-data.polymarket.com"
+    subscriptions = [
+        {
+            "topic": "crypto_prices",
+            "type": "update",
+            "filters": json.dumps({"symbol": symbol_to_pm(s)}),
+        }
+        for s in state.symbols
+    ]
+    sub_payload = {"action": "subscribe", "subscriptions": subscriptions}
+    while time.time() < end_ts:
+        try:
+            async with websockets.connect(url, ping_interval=20, ping_timeout=20, max_size=2**22) as ws:
+                await ws.send(json.dumps(sub_payload))
+                while time.time() < end_ts:
+                    raw = await asyncio.wait_for(ws.recv(), timeout=3.0)
+                    recv_ms = int(time.time() * 1000)
+                    msg = json.loads(raw)
+                    if msg.get("topic") != "crypto_prices" or msg.get("type") != "update":
+                        continue
+                    payload = msg.get("payload") or {}
+                    symbol = normalize_symbol(f"{str(payload.get('symbol', '')).upper()}USDT")
+                    price = payload.get("price")
+                    if symbol not in state.symbols or price is None:
+                        continue
+                    px = float(price)
+                    if not math.isfinite(px) or px <= 0:
+                        continue
+                    async with state.lock:
+                        state.pm[symbol] = PricePoint(ts_ms=recv_ms, px=px)
+        except Exception:
+            await asyncio.sleep(0.5)
+
+
+def fetch_token_symbol_map(symbols: List[str]) -> Dict[Tuple[str, str], str]:
+    symbols = [normalize_symbol(s) for s in symbols]
+    allowed = set(symbols)
+    out: Dict[Tuple[str, str], str] = {}
+    endpoint = "https://gamma-api.polymarket.com/markets"
+    client = requests.Session()
+    for offset in (0, 1000, 2000, 3000):
+        try:
+            resp = client.get(
+                endpoint,
+                params={
+                    "closed": "false",
+                    "archived": "false",
+                    "active": "true",
+                    "limit": 1000,
+                    "offset": offset,
+                    "order": "volume",
+                    "ascending": "false",
+                },
+                timeout=10,
+            )
+            resp.raise_for_status()
+            rows = resp.json()
+        except Exception:
+            continue
+        if not isinstance(rows, list) or not rows:
+            break
+        for m in rows:
+            question = str(m.get("question") or "").upper()
+            slug = str(m.get("slug") or "").upper()
+            text = f"{question} {slug}"
+            symbol = None
+            for s in allowed:
+                base = s.replace("USDT", "")
+                if base in text:
+                    symbol = s
+                    break
+            if symbol is None:
+                continue
+            token_raw = m.get("clobTokenIds")
+            if not token_raw:
+                continue
+            try:
+                token_ids = json.loads(token_raw)
+            except Exception:
+                continue
+            if not isinstance(token_ids, list) or len(token_ids) < 2:
+                continue
+            yes = str(token_ids[0])
+            no = str(token_ids[1])
+            out[(yes, no)] = symbol
+    return out
+
+
+async def run_pm_file_feed(
+    state: SharedState,
+    end_ts: float,
+    raw_root: str,
+) -> None:
+    token_map = fetch_token_symbol_map(state.symbols)
+    if not token_map:
+        return
+    book_file = Path(raw_root) / time.strftime("%Y-%m-%d", time.gmtime()) / "book_tops.jsonl"
+    # wait up to 15s for file creation
+    for _ in range(150):
+        if book_file.exists():
+            break
+        await asyncio.sleep(0.1)
+    if not book_file.exists():
+        return
+
+    # Bootstrap latest PM mid by symbol from recent file tail so triggers don't wait for fresh lines.
+    bootstrap_latest_pm(state, book_file, token_map)
+
+    with book_file.open("r", encoding="utf-8") as f:
+        f.seek(0, 2)
+        while time.time() < end_ts:
+            line = f.readline()
+            if not line:
+                await asyncio.sleep(0.01)
+                continue
+            try:
+                msg = json.loads(line)
+                book = msg.get("book") or {}
+                yes = str(book.get("token_id_yes") or "")
+                no = str(book.get("token_id_no") or "")
+                symbol = token_map.get((yes, no))
+                if symbol is None:
+                    continue
+                bid_yes = float(book.get("bid_yes"))
+                ask_yes = float(book.get("ask_yes"))
+                if bid_yes <= 0 or ask_yes <= 0:
+                    continue
+                px = (bid_yes + ask_yes) * 0.5
+                recv_ns = int(book.get("recv_ts_local_ns") or 0)
+                recv_ms = recv_ns // 1_000_000 if recv_ns > 0 else int(time.time() * 1000)
+                async with state.lock:
+                    state.pm[symbol] = PricePoint(ts_ms=recv_ms, px=px)
+            except Exception:
+                continue
+
+
+def bootstrap_latest_pm(state: SharedState, book_file: Path, token_map: Dict[Tuple[str, str], str]) -> None:
+    latest: Dict[str, PricePoint] = {}
+    try:
+        with book_file.open("r", encoding="utf-8") as f:
+            tail_lines = deque(f, maxlen=30_000)
+        for line in tail_lines:
+            try:
+                msg = json.loads(line)
+                book = msg.get("book") or {}
+                yes = str(book.get("token_id_yes") or "")
+                no = str(book.get("token_id_no") or "")
+                symbol = token_map.get((yes, no))
+                if symbol is None:
+                    continue
+                bid_yes = float(book.get("bid_yes"))
+                ask_yes = float(book.get("ask_yes"))
+                if bid_yes <= 0 or ask_yes <= 0:
+                    continue
+                px = (bid_yes + ask_yes) * 0.5
+                recv_ns = int(book.get("recv_ts_local_ns") or 0)
+                recv_ms = recv_ns // 1_000_000 if recv_ns > 0 else int(time.time() * 1000)
+                latest[symbol] = PricePoint(ts_ms=recv_ms, px=px)
+            except Exception:
+                continue
+    except Exception:
+        return
+    if latest:
+        state.pm.update(latest)
+
+
+async def maybe_trigger_event(
+    state: SharedState,
+    symbol: str,
+    t0_ms: int,
+    velocity_bps_per_sec: float,
+    binance_change_bps: float,
+) -> None:
+    async with state.lock:
+        state.trigger_count += 1
+        last = state.last_trigger_ms.get(symbol, 0)
+        # Keep events independent but avoid over-trigger flooding.
+        if t0_ms - last < 200:
+            return
+        pm0 = state.pm.get(symbol)
+        if pm0 is None:
+            state.trigger_skip_no_pm += 1
+            return
+        state.last_trigger_ms[symbol] = t0_ms
+    event: Dict[str, Any] = {
+        "symbol": symbol,
+        "t0_ms": t0_ms,
+        "velocity_bps_per_sec": velocity_bps_per_sec,
+        "binance_price_change_bps": binance_change_bps,
+        "pm_book_mid_at_t0": pm0.px,
+    }
+    await capture_event_samples(state, event)
+    async with state.lock:
+        state.events.append(event)
+
+
+async def read_pm_price(state: SharedState, symbol: str) -> Optional[float]:
+    async with state.lock:
+        point = state.pm.get(symbol)
+        return None if point is None else point.px
+
+
+async def capture_event_samples(state: SharedState, event: Dict[str, Any]) -> None:
+    symbol = str(event["symbol"])
+    t_start = time.time()
+    schedule_ms = {
+        "pm_book_mid_at_t0_plus_20ms": 20,
+        "pm_book_mid_at_t0_plus_50ms": 50,
+        "pm_book_mid_at_t0_plus_100ms": 100,
+        "pm_book_mid_at_t0_plus_200ms": 200,
+        "pm_book_mid_at_t0_plus_500ms": 500,
+        "pm_book_mid_at_t0_plus_1000ms": 1000,
+        "pm_price_at_t1_plus_1s": 1020,
+        "pm_price_at_t1_plus_3s": 3020,
+        "pm_price_at_t1_plus_5s": 5020,
+        "pm_price_at_t1_plus_10s": 10020,
+    }
+    for key, delay_ms in schedule_ms.items():
+        now_elapsed_ms = int((time.time() - t_start) * 1000)
+        sleep_ms = max(0, delay_ms - now_elapsed_ms)
+        await asyncio.sleep(sleep_ms / 1000.0)
+        event[key] = await read_pm_price(state, symbol)
+    finalize_event_metrics(event)
+
+
+def finalize_event_metrics(event: Dict[str, Any]) -> None:
+    t0 = float(event.get("pm_book_mid_at_t0") or 0.0)
+    p20 = event.get("pm_book_mid_at_t0_plus_20ms")
+    p50 = event.get("pm_book_mid_at_t0_plus_50ms")
+    p100 = event.get("pm_book_mid_at_t0_plus_100ms")
+    p200 = event.get("pm_book_mid_at_t0_plus_200ms")
+    p500 = event.get("pm_book_mid_at_t0_plus_500ms")
+    p1000 = event.get("pm_book_mid_at_t0_plus_1000ms")
+
+    if not all(isinstance(v, (int, float)) for v in [p20, p50, p100, p200, p500, p1000]) or t0 <= 0:
+        event["convergence_time_ms"] = None
+        event["price_gap_at_t1_bps"] = None
+        event["max_profit_time_ms"] = None
+        event["max_profit_bps"] = None
+        event["profit_at_3s_bps"] = None
+        event["entry_price"] = p20
+        return
+
+    sign = 1.0 if float(event.get("binance_price_change_bps", 0.0)) >= 0 else -1.0
+    delta_target = sign * (float(p1000) - t0)
+    event["entry_price"] = float(p20)
+
+    if abs(delta_target) < 1e-12:
+        event["convergence_time_ms"] = None
+    else:
+        checkpoints = [(50, p50), (100, p100), (200, p200), (500, p500), (1000, p1000)]
+        conv = None
+        for ms, val in checkpoints:
+            progress = sign * (float(val) - t0)
+            if progress >= 0.9 * delta_target:
+                conv = ms
+                break
+        event["convergence_time_ms"] = conv
+
+    gap = sign * (float(p1000) - float(p20))
+    event["price_gap_at_t1_bps"] = to_bps(gap, float(p20))
+
+    future_points = [
+        (1000, event.get("pm_price_at_t1_plus_1s")),
+        (3000, event.get("pm_price_at_t1_plus_3s")),
+        (5000, event.get("pm_price_at_t1_plus_5s")),
+        (10000, event.get("pm_price_at_t1_plus_10s")),
+    ]
+    profits: List[tuple[int, float]] = []
+    for ms, px in future_points:
+        if isinstance(px, (int, float)):
+            pnl = sign * (float(px) - float(p20))
+            bps = to_bps(pnl, float(p20))
+            if bps is not None:
+                profits.append((ms, bps))
+    if not profits:
+        event["max_profit_time_ms"] = None
+        event["max_profit_bps"] = None
+        event["profit_at_3s_bps"] = None
+        return
+    best = max(profits, key=lambda x: x[1])
+    event["max_profit_time_ms"] = best[0]
+    event["max_profit_bps"] = best[1]
+    profit_3s = next((bps for ms, bps in profits if ms == 3000), None)
+    event["profit_at_3s_bps"] = profit_3s
+
+
+def build_summary(events: List[Dict[str, Any]]) -> Dict[str, Any]:
+    convergence_vals = [float(e["convergence_time_ms"]) for e in events if isinstance(e.get("convergence_time_ms"), (int, float))]
+    gap_vals = [float(e["price_gap_at_t1_bps"]) for e in events if isinstance(e.get("price_gap_at_t1_bps"), (int, float))]
+    max_profit_vals = [float(e["max_profit_bps"]) for e in events if isinstance(e.get("max_profit_bps"), (int, float))]
+    profit_3s_vals = [float(e["profit_at_3s_bps"]) for e in events if isinstance(e.get("profit_at_3s_bps"), (int, float))]
+    best_time_vals = [float(e["max_profit_time_ms"]) for e in events if isinstance(e.get("max_profit_time_ms"), (int, float))]
+
+    by_symbol: Dict[str, Dict[str, Any]] = {}
+    for symbol in sorted(set(str(e["symbol"]) for e in events)):
+        rows = [e for e in events if e["symbol"] == symbol]
+        conv = [float(e["convergence_time_ms"]) for e in rows if isinstance(e.get("convergence_time_ms"), (int, float))]
+        gap = [float(e["price_gap_at_t1_bps"]) for e in rows if isinstance(e.get("price_gap_at_t1_bps"), (int, float))]
+        by_symbol[symbol] = {
+            "events": len(rows),
+            "convergence_time_ms": {
+                "p50": percentile(conv, 0.5),
+                "p90": percentile(conv, 0.9),
+                "p99": percentile(conv, 0.99),
+            },
+            "price_gap_at_t1_bps": {
+                "p50": percentile(gap, 0.5),
+                "p90": percentile(gap, 0.9),
+                "p99": percentile(gap, 0.99),
+            },
+        }
+
+    return {
+        "event_count": len(events),
+        "convergence_time_ms": {
+            "p50": percentile(convergence_vals, 0.5),
+            "p90": percentile(convergence_vals, 0.9),
+            "p99": percentile(convergence_vals, 0.99),
+        },
+        "price_gap_at_t1_bps": {
+            "p50": percentile(gap_vals, 0.5),
+            "p90": percentile(gap_vals, 0.9),
+            "p99": percentile(gap_vals, 0.99),
+        },
+        "max_profit_bps": {
+            "p50": percentile(max_profit_vals, 0.5),
+            "p90": percentile(max_profit_vals, 0.9),
+            "p99": percentile(max_profit_vals, 0.99),
+        },
+        "profit_at_3s_bps": {
+            "p50": percentile(profit_3s_vals, 0.5),
+            "p90": percentile(profit_3s_vals, 0.9),
+            "p99": percentile(profit_3s_vals, 0.99),
+        },
+        "best_exit_time_ms": {
+            "p50": percentile(best_time_vals, 0.5),
+            "p90": percentile(best_time_vals, 0.9),
+            "p99": percentile(best_time_vals, 0.99),
+        },
+        "by_symbol": by_symbol,
+    }
+
+
+async def run_measurement(symbols: List[str], duration_sec: int, pm_source: str, raw_root: str) -> Dict[str, Any]:
+    symbols = [normalize_symbol(s) for s in symbols]
+    state = SharedState(symbols)
+    end_ts = time.time() + duration_sec
+    pm_task = run_pm_feed(state, end_ts) if pm_source == "ws_live_data" else run_pm_file_feed(state, end_ts, raw_root)
+    await asyncio.gather(run_binance_feed(state, end_ts), pm_task)
+    events = state.events
+    return {
+        "meta": {
+            "started_at_ms": int((end_ts - duration_sec) * 1000),
+            "finished_at_ms": int(time.time() * 1000),
+            "duration_sec": duration_sec,
+            "symbols": symbols,
+            "velocity_trigger_bps_per_sec": 5.0,
+            "t1_assumed_ms": 20,
+            "pm_mid_source": pm_source,
+            "raw_root": raw_root,
+            "trigger_count": state.trigger_count,
+            "trigger_skip_no_pm": state.trigger_skip_no_pm,
+        },
+        "summary": build_summary(events),
+        "events": events,
+    }
+
+
+def main() -> None:
+    parser = argparse.ArgumentParser(description="Convergence and exit-timing analysis")
+    parser.add_argument("--duration-sec", type=int, default=120)
+    parser.add_argument("--symbols", default="BTCUSDT,ETHUSDT,SOLUSDT")
+    parser.add_argument("--pm-source", choices=["raw_file", "ws_live_data"], default="raw_file")
+    parser.add_argument("--raw-root", default="datasets/raw")
+    parser.add_argument("--out", required=True)
+    args = parser.parse_args()
+
+    symbols = [s.strip() for s in args.symbols.split(",") if s.strip()]
+    out_path = Path(args.out)
+    out_path.parent.mkdir(parents=True, exist_ok=True)
+
+    result = asyncio.run(run_measurement(symbols, args.duration_sec, args.pm_source, args.raw_root))
+    out_path.write_text(json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
+    print(out_path.as_posix())
+    print(json.dumps(result["summary"], ensure_ascii=False))
+
+
+if __name__ == "__main__":
+    main()
diff --git a/scripts/deploy_vpc.sh b/scripts/deploy_vpc.sh
new file mode 100644
index 0000000..dba2e47
--- /dev/null
+++ b/scripts/deploy_vpc.sh
@@ -0,0 +1,262 @@
+#!/bin/bash
+# ============================================================
+# PolyEdge VPC éƒ¨ç½²è„šæœ¬
+# ç”¨äºŽä¸œäº¬å’Œçˆ±å°”å…°æœåŠ¡å™¨çš„éƒ¨ç½²
+#
+# ä½¿ç”¨:
+#   # ä¸œäº¬æœåŠ¡å™¨ (æ•°æ®æº)
+#   ./deploy_vpc.sh tokyo
+#
+#   # çˆ±å°”å…°æœåŠ¡å™¨ (æ‰§è¡Œå¼•æ“Ž)
+#   ./deploy_vpc.sh ireland
+# ============================================================
+
+set -e
+
+# é¢œè‰²å®šä¹‰
+RED='\033[0;31m'
+GREEN='\033[0;32m'
+YELLOW='\033[1;33m'
+BLUE='\033[0;34m'
+NC='\033[0m' # No Color
+
+# é…ç½®
+TOKYO_IP="172.31.44.26"
+IRELAND_IP="10.0.3.123"
+TARGET_PORT=6666
+FEEDER_PORT=9999
+
+log_info() {
+    echo -e "${BLUE}[INFO]${NC} $1"
+}
+
+log_success() {
+    echo -e "${GREEN}[SUCCESS]${NC} $1"
+}
+
+log_warn() {
+    echo -e "${YELLOW}[WARN]${NC} $1"
+}
+
+log_error() {
+    echo -e "${RED}[ERROR]${NC} $1"
+}
+
+# æ£€æŸ¥ä¾èµ–
+check_dependencies() {
+    log_info "æ£€æŸ¥ä¾èµ–..."
+
+    if ! command -v cargo &> /dev/null; then
+        log_error "Rust æœªå®‰è£…"
+        exit 1
+    fi
+
+    if ! command -v python3 &> /dev/null; then
+        log_error "Python3 æœªå®‰è£…"
+        exit 1
+    fi
+
+    log_success "ä¾èµ–æ£€æŸ¥å®Œæˆ"
+}
+
+# éƒ¨ç½²ä¸œäº¬æœåŠ¡å™¨
+deploy_tokyo() {
+    log_info "éƒ¨ç½²ä¸œäº¬æœåŠ¡å™¨..."
+
+    # ç¼–è¯‘ release ç‰ˆæœ¬
+    log_info "ç¼–è¯‘ feeder_tokyo..."
+    cargo build -p feeder_tokyo --release
+
+    # åˆ›å»ºå¯åŠ¨è„šæœ¬
+    cat > /tmp/feeder_tokyo.sh << 'EOF'
+#!/bin/bash
+export SYMBOL_TARGETS="btcusdt=10.0.3.123:6666,ethusdt=10.0.3.123:6667,solusdt=10.0.3.123:6668,xrpusdt=10.0.3.123:6669"
+export BIND_BASE_PORT="9999"
+export POLYEDGE_UDP_REDUNDANCY="2"
+export POLYEDGE_UDP_SNDBUF_BYTES="16777216"
+export POLYEDGE_SENDER_PIN_CORES="btcusdt:0,ethusdt:0,solusdt:1,xrpusdt:1"
+export POLYEDGE_UDP_REDUNDANCY_ADAPTIVE="true"
+export POLYEDGE_UDP_REDUNDANCY_ADAPTIVE_HIGH="2"
+export POLYEDGE_UDP_REDUNDANCY_ERR_THRESHOLD_PER_SEC="2"
+export POLYEDGE_UDP_REDUNDANCY_COOLDOWN_SEC="10"
+
+cd /opt/PolyEdge
+./target/release/sender >> /var/log/feeder_tokyo.log 2>&1
+EOF
+
+    chmod +x /tmp/feeder_tokyo.sh
+
+    log_success "ä¸œäº¬æœåŠ¡å™¨éƒ¨ç½²å®Œæˆ"
+    log_info "å¯åŠ¨å‘½ä»¤: export SYMBOL_TARGETS='btcusdt=10.0.3.123:6666,ethusdt=10.0.3.123:6667,solusdt=10.0.3.123:6668,xrpusdt=10.0.3.123:6669' && export POLYEDGE_UDP_REDUNDANCY=2 && cargo run -p feeder_tokyo --bin sender --release"
+}
+
+# éƒ¨ç½²çˆ±å°”å…°æœåŠ¡å™¨
+deploy_ireland() {
+    log_info "éƒ¨ç½²çˆ±å°”å…°æœåŠ¡å™¨..."
+
+    # ç¡®ä¿ç«¯å£å¼€æ”¾
+    log_info "æ£€æŸ¥ç«¯å£ $TARGET_PORT ..."
+
+    # ç¼–è¯‘ release ç‰ˆæœ¬
+    log_info "ç¼–è¯‘ PolyEdge..."
+    cargo build -p app_runner --release
+
+    log_success "çˆ±å°”å…°æœåŠ¡å™¨éƒ¨ç½²å®Œæˆ"
+    log_info "å¯åŠ¨å‘½ä»¤: cargo run -p app_runner --release"
+
+    # è®¾ç½®çŽ¯å¢ƒå˜é‡
+    cat > /tmp/polyedge.env << EOF
+# PolyEdge çŽ¯å¢ƒå˜é‡
+export POLYEDGE_BINANCE_RELAY=true
+export POLYEDGE_BINANCE_RELAY_HOST=127.0.0.1
+export POLYEDGE_BINANCE_RELAY_PORT=6666
+export POLYEDGE_UDP_SYMBOL_PORTS="BTCUSDT:6666,ETHUSDT:6667,SOLUSDT:6668,XRPUSDT:6669"
+export POLYEDGE_UDP_RCVBUF_BYTES=26214400
+export POLYEDGE_UDP_BUSY_POLL_US=50
+export POLYEDGE_UDP_PIN_CORES="6666:1,6667:2,6668:2,6669:3"
+export POLYEDGE_UDP_DROP_ON_FULL=true
+export POLYEDGE_UDP_RX_QUEUE_CAP=4096
+export POLYEDGE_BUS_CAPACITY=65536
+export POLYEDGE_REF_TICK_QUEUE_CAP=16384
+export POLYEDGE_REF_MERGE_QUEUE_CAP=16384
+export POLYEDGE_REF_MERGE_DROP_ON_FULL=true
+export POLYEDGE_STRATEGY_MAX_COALESCE=2048
+export POLYEDGE_STRATEGY_MIN_COALESCE=256
+export POLYEDGE_STRATEGY_DROP_STALE_BOOK_MS=800
+export POLYEDGE_REF_TICK_BUS_ENABLED=false
+export POLYEDGE_FUSION_STALENESS_BUDGET_US=600
+EOF
+
+    log_info "çŽ¯å¢ƒé…ç½®å·²ä¿å­˜åˆ° /tmp/polyedge.env"
+}
+
+# æµ‹è¯•ç½‘ç»œè¿žé€šæ€§
+test_connectivity() {
+    local target=$1
+    local port=$2
+
+    log_info "æµ‹è¯•è¿žé€šæ€§: $target:$port"
+
+    if command -v nc &> /dev/null; then
+        if nc -zv -w 5 $target $port 2>&1 | grep -q "succeeded"; then
+            log_success "è¿žæŽ¥æˆåŠŸ"
+            return 0
+        else
+            log_error "è¿žæŽ¥å¤±è´¥"
+            return 1
+        fi
+    elif command -v timeout &> /dev/null; then
+        if timeout 5 bash -c "echo > /dev/tcp/$target/$port" 2>/dev/null; then
+            log_success "è¿žæŽ¥æˆåŠŸ"
+            return 0
+        else
+            log_error "è¿žæŽ¥å¤±è´¥"
+            return 1
+        fi
+    else
+        log_warn "æ— æ³•æµ‹è¯•è¿žé€šæ€§ (nc/timeout æœªå®‰è£…)"
+        return 0
+    fi
+}
+
+# æµ‹è¯•å»¶è¿Ÿ
+test_latency() {
+    local target=$1
+
+    log_info "æµ‹è¯•å»¶è¿Ÿåˆ° $target..."
+
+    if command -v ping &> /dev/null; then
+        ping -c 5 $target | tail -1
+    fi
+
+    if command -v nc &> /dev/null; then
+        log_info "ä½¿ç”¨ nc æµ‹è¯• TCP å»¶è¿Ÿ..."
+        time nc -zv $target $TARGET_PORT 2>&1 | grep -E "time|connected"
+    fi
+}
+
+# å¯åŠ¨ systemd æœåŠ¡ (å¯é€‰)
+setup_systemd() {
+    local service_name=$1
+    local user=$(whoami)
+
+    log_info "åˆ›å»º systemd æœåŠ¡: $service_name"
+
+    cat > /tmp/${service_name}.service << EOF
+[Unit]
+Description=PolyEdge $service_name
+After=network.target
+
+[Service]
+Type=simple
+User=$user
+WorkingDirectory=/opt/PolyEdge
+Environment=TARGET=10.0.3.123:6666
+Environment=SYMBOL_TARGETS=btcusdt=10.0.3.123:6666,ethusdt=10.0.3.123:6667,solusdt=10.0.3.123:6668,xrpusdt=10.0.3.123:6669
+Environment=POLYEDGE_UDP_REDUNDANCY=2
+Environment=POLYEDGE_UDP_SNDBUF_BYTES=16777216
+Environment=POLYEDGE_SENDER_PIN_CORES=btcusdt:0,ethusdt:0,solusdt:1,xrpusdt:1
+ExecStart=/opt/PolyEdge/target/release/sender
+Restart=always
+RestartSec=5
+
+[Install]
+WantedBy=multi-user.target
+EOF
+
+    log_success "systemd æœåŠ¡æ–‡ä»¶å·²åˆ›å»º: /tmp/${service_name}.service"
+    log_info "å®‰è£…: sudo cp /tmp/${service_name}.service /etc/systemd/system/"
+    log_info "å¯åŠ¨: sudo systemctl start $service_name"
+}
+
+# ä¸»èœå•
+show_menu() {
+    echo ""
+    echo "=========================================="
+    echo "  PolyEdge VPC éƒ¨ç½²å·¥å…·"
+    echo "=========================================="
+    echo ""
+    echo "é€‰æ‹©æœåŠ¡å™¨:"
+    echo "  1) ä¸œäº¬æœåŠ¡å™¨ (æ•°æ®æº)"
+    echo "  2) çˆ±å°”å…°æœåŠ¡å™¨ (æ‰§è¡Œå¼•æ“Ž)"
+    echo "  3) æµ‹è¯•è¿žé€šæ€§ (ä¸œäº¬ -> çˆ±å°”å…°)"
+    echo "  4) æµ‹è¯•å»¶è¿Ÿ"
+    echo "  5) åˆ›å»º systemd æœåŠ¡"
+    echo "  0) é€€å‡º"
+    echo ""
+    echo -n "é€‰æ‹©: "
+}
+
+# ä¸»å‡½æ•°
+main() {
+    local mode=${1:-menu}
+
+    check_dependencies
+
+    case $mode in
+        tokyo)
+            deploy_tokyo
+            ;;
+        ireland)
+            deploy_ireland
+            ;;
+        test)
+            test_connectivity $TOKYO_IP $TARGET_PORT
+            ;;
+        latency)
+            test_latency $TOKYO_IP
+            ;;
+        systemd)
+            setup_systemd "polyedge-feeder"
+            ;;
+        menu)
+            show_menu
+            ;;
+        *)
+            echo "ç”¨æ³•: $0 {tokyo|ireland|test|latency|systemd|menu}"
+            exit 1
+            ;;
+    esac
+}
+
+main "$@"
diff --git a/scripts/e2e_latency_test.py b/scripts/e2e_latency_test.py
index 3124d7e..b59ea3d 100644
--- a/scripts/e2e_latency_test.py
+++ b/scripts/e2e_latency_test.py
@@ -3,8 +3,10 @@
 
 from __future__ import annotations
 
+import atexit
 import argparse
 import asyncio
+import concurrent.futures
 import json
 import math
 import time
@@ -23,9 +25,64 @@ PROFILE_DEFAULTS: Dict[str, Dict[str, float]] = {
     "deep": {"seconds": 300, "poll_interval": 2.0},
 }
 
+ENGINE_SERIES_KEYS = [
+    "tick_to_decision_p99_ms",
+    "decision_queue_wait_p99_ms",
+    "decision_compute_p99_ms",
+    "tick_to_ack_p99_ms",
+    "ack_only_p99_ms",
+    "feed_in_p50_ms",
+    "source_latency_p99_ms",
+    "local_backlog_p99_ms",
+    "data_valid_ratio",
+    "seq_gap_rate",
+    "ts_inversion_rate",
+    "stale_tick_drop_ratio",
+    "quote_block_ratio",
+    "policy_block_ratio",
+    "queue_depth_p99",
+    "event_backlog_p99",
+    "pnl_10s_p50_bps_raw",
+    "pnl_10s_p50_bps_robust",
+    "ev_net_usdc_p50",
+    "ev_net_usdc_p10",
+    "ev_positive_ratio",
+    "eligible_count",
+    "executed_count",
+    "executed_over_eligible",
+    "net_markout_10s_usdc_p50",
+    "roi_notional_10s_bps_p50",
+    "pnl_10s_outlier_ratio",
+    "window_outcomes",
+    "gate_ready_ratio",
+    "gate_ready_ratio_strict",
+    "gate_ready_ratio_effective",
+]
+
+
+def empty_engine_result(failures: int = 1) -> Dict[str, Any]:
+    return {
+        "samples": 0,
+        "failures": failures,
+        "stats": {k: summarize([]) for k in ENGINE_SERIES_KEYS},
+    }
+
+
+def empty_ws_result() -> Dict[str, Any]:
+    empty_stat = summarize([])
+    return {
+        "pm_lag_ms": empty_stat,
+        "chainlink_lag_ms": empty_stat,
+        "bin_lag_ms": empty_stat,
+        "delta_pm_minus_bin_p50_ms": float("nan"),
+        "delta_chainlink_minus_bin_p50_ms": float("nan"),
+        "delta_pm_minus_chainlink_p50_ms": float("nan"),
+    }
+
 
 def collect_engine_metrics(base_url: str, seconds: int, poll_interval: float) -> Dict[str, Any]:
     session = requests.Session()
+    atexit.register(session.close)
     deadline = time.time() + max(1, seconds)
     samples = 0
     failures = 0
@@ -59,6 +116,8 @@ def collect_engine_metrics(base_url: str, seconds: int, poll_interval: float) ->
         "roi_notional_10s_bps_p50": [],
         "pnl_10s_outlier_ratio": [],
         "gate_ready_ratio": [],
+        "gate_ready_ratio_strict": [],
+        "gate_ready_ratio_effective": [],
         "window_outcomes": [],
     }
 
@@ -100,7 +159,12 @@ def collect_engine_metrics(base_url: str, seconds: int, poll_interval: float) ->
                 value = live.get(key)
                 if isinstance(value, (int, float)):
                     series[key].append(float(value))
-            series["gate_ready_ratio"].append(1.0 if bool(live.get("gate_ready", False)) else 0.0)
+            gate_ready_strict = bool(live.get("gate_ready_strict", live.get("gate_ready", False)))
+            gate_ready_effective = bool(live.get("gate_ready_effective", gate_ready_strict))
+            series["gate_ready_ratio_strict"].append(1.0 if gate_ready_strict else 0.0)
+            series["gate_ready_ratio_effective"].append(1.0 if gate_ready_effective else 0.0)
+            # Backward-compatible key: keep this tied to effective semantics for downstream summaries.
+            series["gate_ready_ratio"].append(1.0 if gate_ready_effective else 0.0)
             feed_p50 = latency.get("feed_in_p50_ms")
             if isinstance(feed_p50, (int, float)):
                 series["feed_in_p50_ms"].append(float(feed_p50))
@@ -124,6 +188,7 @@ def main() -> None:
     parser.add_argument("--base-url", default="http://127.0.0.1:8080")
     parser.add_argument("--seconds", type=int, default=None)
     parser.add_argument("--poll-interval", type=float, default=None)
+    parser.add_argument("--hard-timeout-sec", type=int, default=None)
     parser.add_argument("--json-out", default="")
     args = parser.parse_args()
     profile_defaults = PROFILE_DEFAULTS[args.profile]
@@ -131,12 +196,34 @@ def main() -> None:
         args.seconds = int(profile_defaults["seconds"])
     if args.poll_interval is None:
         args.poll_interval = float(profile_defaults["poll_interval"])
+    if args.hard_timeout_sec is None:
+        # Run-time guard for stalled endpoints; benchmark should stop close to target window.
+        args.hard_timeout_sec = int(max(args.seconds + 25, args.seconds * 1.35))
     print(
-        f"[profile] {args.profile} seconds={args.seconds} poll_interval={args.poll_interval}"
+        f"[profile] {args.profile} seconds={args.seconds} poll_interval={args.poll_interval} hard_timeout={args.hard_timeout_sec}"
     )
 
     print("=== ENGINE WS-FIRST METRICS ===")
-    engine = collect_engine_metrics(args.base_url, args.seconds, args.poll_interval)
+    ws: Dict[str, Any]
+    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as pool:
+        engine_future = pool.submit(
+            collect_engine_metrics, args.base_url, args.seconds, args.poll_interval
+        )
+        try:
+            ws = asyncio.run(
+                asyncio.wait_for(
+                    run_ws_latency(args.seconds, args.symbol), timeout=args.hard_timeout_sec
+                )
+            )
+        except Exception:
+            print("[warn] ws probe timeout/error; fallback to empty ws stats")
+            ws = empty_ws_result()
+        try:
+            engine = engine_future.result(timeout=args.hard_timeout_sec)
+        except concurrent.futures.TimeoutError:
+            print("[warn] engine probe timeout; fallback to empty engine stats")
+            engine = empty_engine_result(failures=1)
+
     print(f"base_url={args.base_url} symbol={args.symbol} mode={args.mode}")
     print(f"samples={engine['samples']} failures={engine['failures']}")
     print_stat_block("tick_to_decision_p99", engine["stats"]["tick_to_decision_p99_ms"], "ms")
@@ -177,10 +264,11 @@ def main() -> None:
     )
     print_stat_block("pnl_10s_outlier_ratio", engine["stats"]["pnl_10s_outlier_ratio"], "")
     print_stat_block("gate_ready_ratio", engine["stats"]["gate_ready_ratio"], "")
+    print_stat_block("gate_ready_ratio_strict", engine["stats"]["gate_ready_ratio_strict"], "")
+    print_stat_block("gate_ready_ratio_effective", engine["stats"]["gate_ready_ratio_effective"], "")
     print_stat_block("window_outcomes", engine["stats"]["window_outcomes"], "")
 
     print("\n=== WS FEED LATENCY (RECV - SOURCE TS) ===")
-    ws = asyncio.run(run_ws_latency(args.seconds, args.symbol))
     print_stat_block("rtds_crypto_prices", ws["pm_lag_ms"], "ms")
     print_stat_block("rtds_chainlink", ws["chainlink_lag_ms"], "ms")
     print_stat_block("binance_ws", ws["bin_lag_ms"], "ms")
diff --git a/scripts/full_latency_sweep.py b/scripts/full_latency_sweep.py
index 49d00a0..3efd0f8 100644
--- a/scripts/full_latency_sweep.py
+++ b/scripts/full_latency_sweep.py
@@ -7,6 +7,7 @@ under datasets/reports/<day>/, suitable for comparing runs over time.
 
 from __future__ import annotations
 
+import atexit
 import argparse
 import asyncio
 import json
@@ -22,30 +23,103 @@ from latency_probe.stats import summarize
 from latency_probe.ws_probe import run_ws_latency
 
 PROFILE_DEFAULTS: Dict[str, Dict[str, float]] = {
+    "quick_60s": {"seconds": 60, "poll_interval": 2.0},
     "quick": {"seconds": 60, "poll_interval": 2.0},
     "standard": {"seconds": 120, "poll_interval": 2.0},
     "deep": {"seconds": 300, "poll_interval": 2.0},
 }
 
 
+def post_json(base_url: str, path: str, payload: Dict[str, Any]) -> Dict[str, Any]:
+    resp = requests.post(f"{base_url.rstrip('/')}{path}", json=payload, timeout=8)
+    resp.raise_for_status()
+    return resp.json()
+
+
+def get_json(base_url: str, path: str) -> Dict[str, Any]:
+    resp = requests.get(f"{base_url.rstrip('/')}{path}", timeout=8)
+    resp.raise_for_status()
+    return resp.json()
+
+
+def fusion_payload(
+    mode: str,
+    dedupe_window_ms: int,
+    udp_share_cap: float | None = None,
+    jitter_threshold_ms: float | None = None,
+    fallback_arm_duration_ms: int | None = None,
+    fallback_cooldown_sec: int | None = None,
+    udp_local_only: bool | None = None,
+) -> Dict[str, Any]:
+    if mode == "direct_only":
+        payload = {
+            "enable_udp": False,
+            "mode": "direct_only",
+            "dedupe_window_ms": int(dedupe_window_ms),
+        }
+    elif mode == "udp_only":
+        payload = {
+            "enable_udp": True,
+            "mode": "udp_only",
+            "dedupe_window_ms": int(dedupe_window_ms),
+        }
+    elif mode == "active_active":
+        payload = {
+            "enable_udp": True,
+            "mode": "active_active",
+            "dedupe_window_ms": int(dedupe_window_ms),
+        }
+    elif mode == "websocket_primary":
+        payload = {
+            "enable_udp": True,
+            "mode": "websocket_primary",
+            "dedupe_window_ms": int(dedupe_window_ms),
+        }
+    else:
+        raise ValueError(f"unsupported fusion mode: {mode}")
+
+    if udp_share_cap is not None:
+        payload["udp_share_cap"] = float(udp_share_cap)
+    if jitter_threshold_ms is not None:
+        payload["jitter_threshold_ms"] = float(jitter_threshold_ms)
+    if fallback_arm_duration_ms is not None:
+        payload["fallback_arm_duration_ms"] = int(fallback_arm_duration_ms)
+    if fallback_cooldown_sec is not None:
+        payload["fallback_cooldown_sec"] = int(fallback_cooldown_sec)
+    if udp_local_only is not None:
+        payload["udp_local_only"] = bool(udp_local_only)
+    return payload
+
+
 def utc_day(ts: float | None = None) -> str:
     dt = datetime.fromtimestamp(ts or time.time(), tz=timezone.utc)
     return dt.strftime("%Y-%m-%d")
 
 
-def collect_engine_series(base_url: str, seconds: int, poll_interval: float) -> Dict[str, Any]:
+def collect_engine_series(
+    base_url: str,
+    seconds: int,
+    poll_interval: float,
+    progress_sec: int,
+) -> Dict[str, Any]:
     session = requests.Session()
+    atexit.register(session.close)
+    started = time.time()
     deadline = time.time() + max(1, seconds)
+    next_progress = started + max(1, progress_sec)
     samples = 0
     failures = 0
     last_live: Dict[str, Any] | None = None
 
     series: Dict[str, List[float]] = {
         "tick_to_ack_p99_ms": [],
+        "tick_to_decision_p99_ms": [],
         "decision_queue_wait_p99_ms": [],
         "decision_compute_p99_ms": [],
         "feed_in_p99_ms": [],
         "source_latency_p99_ms": [],
+        "exchange_lag_p99_ms": [],
+        "path_lag_p99_ms": [],
         "local_backlog_p99_ms": [],
         "book_top_lag_p50_ms": [],
         "book_top_lag_p90_ms": [],
@@ -66,6 +140,9 @@ def collect_engine_series(base_url: str, seconds: int, poll_interval: float) ->
         "survival_probe_25ms_n": [],
         "fillability_10ms": [],
         "window_outcomes": [],
+        "udp_share_effective": [],
+        "udp_local_drop_count": [],
+        "share_cap_drop_count": [],
     }
 
     while time.time() < deadline:
@@ -81,6 +158,7 @@ def collect_engine_series(base_url: str, seconds: int, poll_interval: float) ->
                     series[key].append(float(value))
 
             push("tick_to_ack_p99_ms", live.get("tick_to_ack_p99_ms"))
+            push("tick_to_decision_p99_ms", live.get("tick_to_decision_p99_ms"))
             push("decision_queue_wait_p99_ms", live.get("decision_queue_wait_p99_ms"))
             push("decision_compute_p99_ms", live.get("decision_compute_p99_ms"))
             push("quote_block_ratio", live.get("quote_block_ratio"))
@@ -89,6 +167,9 @@ def collect_engine_series(base_url: str, seconds: int, poll_interval: float) ->
             push("ev_net_usdc_p50", live.get("ev_net_usdc_p50"))
             push("ev_positive_ratio", live.get("ev_positive_ratio"))
             push("window_outcomes", live.get("window_outcomes"))
+            push("udp_share_effective", live.get("udp_share_effective"))
+            push("udp_local_drop_count", live.get("udp_local_drop_count"))
+            push("share_cap_drop_count", live.get("share_cap_drop_count"))
             push("survival_5ms", live.get("survival_5ms"))
             push("survival_10ms", live.get("survival_10ms"))
             push("survival_25ms", live.get("survival_25ms"))
@@ -105,11 +186,21 @@ def collect_engine_series(base_url: str, seconds: int, poll_interval: float) ->
 
             push("feed_in_p99_ms", latency.get("feed_in_p99_ms"))
             push("source_latency_p99_ms", live.get("source_latency_p99_ms"))
+            push("exchange_lag_p99_ms", live.get("exchange_lag_p99_ms"))
+            push("path_lag_p99_ms", live.get("path_lag_p99_ms"))
             push("local_backlog_p99_ms", live.get("local_backlog_p99_ms"))
 
             samples += 1
         except Exception:
             failures += 1
+        now = time.time()
+        if progress_sec > 0 and now >= next_progress:
+            elapsed = int(now - started)
+            print(
+                f"[sweep] elapsed={elapsed}s/{seconds}s samples={samples} failures={failures}",
+                flush=True,
+            )
+            next_progress = now + max(1, progress_sec)
         time.sleep(max(0.2, poll_interval))
 
     return {
@@ -123,6 +214,19 @@ def collect_engine_series(base_url: str, seconds: int, poll_interval: float) ->
             "book_top_lag_by_symbol_p50_ms": (last_live or {}).get("book_top_lag_by_symbol_p50_ms"),
             "survival_10ms_by_symbol": (last_live or {}).get("survival_10ms_by_symbol"),
             "survival_probe_10ms_by_symbol": (last_live or {}).get("survival_probe_10ms_by_symbol"),
+            "blocked_reason_counts": (last_live or {}).get("blocked_reason_counts"),
+            "policy_block_reason_distribution": (last_live or {}).get("policy_block_reason_distribution"),
+            "gate_block_reason_distribution": (last_live or {}).get("gate_block_reason_distribution"),
+            "source_mix_ratio": (last_live or {}).get("source_mix_ratio"),
+            "source_health": (last_live or {}).get("source_health"),
+            "last_30s_taker_fallback_count": (last_live or {}).get("last_30s_taker_fallback_count"),
+            "udp_share_effective": (last_live or {}).get("udp_share_effective"),
+            "udp_local_drop_count": (last_live or {}).get("udp_local_drop_count"),
+            "share_cap_drop_count": (last_live or {}).get("share_cap_drop_count"),
+            "fallback_state": (last_live or {}).get("fallback_state"),
+            "fallback_trigger_reason_distribution": (last_live or {}).get(
+                "fallback_trigger_reason_distribution"
+            ),
         },
     }
 
@@ -134,12 +238,84 @@ async def collect_ws_all(seconds: int, symbols: List[str]) -> Dict[str, Any]:
 
 def parse_args() -> argparse.Namespace:
     p = argparse.ArgumentParser(description="PolyEdge full latency sweep (bounded)")
-    p.add_argument("--profile", default="quick", choices=["quick", "standard", "deep"])
+    p.add_argument(
+        "--profile",
+        default="quick_60s",
+        choices=["quick_60s", "quick", "standard", "deep"],
+    )
     p.add_argument("--base-url", default="http://127.0.0.1:8080")
     p.add_argument("--seconds", type=int, default=None)
     p.add_argument("--poll-interval", type=float, default=None)
     p.add_argument("--symbols", default=",".join(SYMBOL_TO_NAME.keys()))
     p.add_argument("--out-root", default="datasets/reports")
+    # Optional: write artifacts under datasets/reports/<day>/runs/<run_id>/ for easier A/B comparison.
+    # When omitted, preserves the legacy location under datasets/reports/<day>/.
+    p.add_argument("--run-id", default=None)
+    p.add_argument("--skip-ws", action="store_true", help="skip CEX websocket latency probe (engine metrics only)")
+    p.add_argument(
+        "--fusion-mode",
+        choices=["direct_only", "udp_only", "active_active", "websocket_primary"],
+        default=None,
+        help="optionally force fusion mode before sampling",
+    )
+    p.add_argument(
+        "--dedupe-window-ms",
+        type=int,
+        default=120,
+        help="dedupe window when applying fusion mode",
+    )
+    p.add_argument(
+        "--reset-shadow",
+        action="store_true",
+        help="reset shadow metrics before sampling",
+    )
+    p.add_argument(
+        "--warmup-sec",
+        type=int,
+        default=0,
+        help="sleep after control actions before sampling",
+    )
+    p.add_argument(
+        "--udp-share-cap",
+        type=float,
+        default=None,
+        help="optional udp share cap when applying fusion mode",
+    )
+    p.add_argument(
+        "--jitter-threshold-ms",
+        type=float,
+        default=None,
+        help="optional jitter threshold when applying fusion mode",
+    )
+    p.add_argument(
+        "--fallback-cooldown-sec",
+        type=int,
+        default=None,
+        help="optional websocket-primary fallback cooldown",
+    )
+    p.add_argument(
+        "--fallback-arm-duration-ms",
+        type=int,
+        default=None,
+        help="optional websocket-primary fallback arm duration",
+    )
+    p.add_argument(
+        "--udp-local-only",
+        choices=["true", "false"],
+        default=None,
+        help="override udp_local_only during fusion reload",
+    )
+    p.add_argument(
+        "--progress-sec",
+        type=int,
+        default=5,
+        help="print progress heartbeat every N seconds (0 disables)",
+    )
+    p.add_argument(
+        "--allow-observe-only",
+        action="store_true",
+        help="allow sampling even when runtime reports observe_only=true/paused=true",
+    )
     return p.parse_args()
 
 
@@ -151,8 +327,65 @@ def main() -> int:
     symbols = [s.strip().upper() for s in str(args.symbols).split(",") if s.strip()]
 
     started_ms = int(time.time() * 1000)
+    control: Dict[str, Any] = {}
+    if args.fusion_mode:
+        control["fusion_applied"] = post_json(
+            args.base_url,
+            "/control/reload_fusion",
+            fusion_payload(
+                args.fusion_mode,
+                args.dedupe_window_ms,
+                args.udp_share_cap,
+                args.jitter_threshold_ms,
+                args.fallback_arm_duration_ms,
+                args.fallback_cooldown_sec,
+                (
+                    None
+                    if args.udp_local_only is None
+                    else args.udp_local_only.lower() == "true"
+                ),
+            ),
+        )
+    if args.reset_shadow:
+        control["shadow_reset"] = post_json(args.base_url, "/control/reset_shadow", {})
+    control["resume"] = post_json(args.base_url, "/control/resume", {})
+    if args.warmup_sec > 0:
+        time.sleep(max(0, int(args.warmup_sec)))
+    try:
+        control["pre_live"] = get_json(args.base_url, "/report/shadow/live")
+    except Exception:
+        control["pre_live"] = None
+    pre_live = control.get("pre_live") or {}
+    pre_live_paused = bool(pre_live.get("paused", False))
+    pre_live_observe_only = bool(pre_live.get("observe_only", False))
+    if (pre_live_paused or pre_live_observe_only) and not args.allow_observe_only:
+        state_flags = []
+        if pre_live_paused:
+            state_flags.append("paused=true")
+        if pre_live_observe_only:
+            state_flags.append("observe_only=true")
+        flags = ",".join(state_flags) if state_flags else "invalid_state"
+        raise RuntimeError(
+            f"runtime is not in active trading state ({flags}); "
+            "fix control mode first or pass --allow-observe-only"
+        )
+    print(
+        f"[sweep] start profile={args.profile} mode={args.fusion_mode or 'unchanged'} "
+        f"seconds={seconds} poll={poll_interval}s",
+        flush=True,
+    )
+
     async def run_all() -> tuple[Dict[str, Any], Dict[str, Any]]:
-        engine_task = asyncio.to_thread(collect_engine_series, args.base_url, seconds, poll_interval)
+        engine_task = asyncio.to_thread(
+            collect_engine_series,
+            args.base_url,
+            seconds,
+            poll_interval,
+            int(args.progress_sec),
+        )
+        if args.skip_ws:
+            engine_res = await engine_task
+            return engine_res, {}
         ws_task = collect_ws_all(seconds, symbols)
         engine_res, ws_res = await asyncio.gather(engine_task, ws_task)
         return engine_res, ws_res
@@ -167,12 +400,27 @@ def main() -> int:
             "poll_interval": poll_interval,
             "symbols": symbols,
             "ts_ms": started_ms,
+            "run_id": args.run_id,
+            "skip_ws": bool(args.skip_ws),
+            "fusion_mode": args.fusion_mode,
+            "reset_shadow": bool(args.reset_shadow),
+            "warmup_sec": int(args.warmup_sec),
+            "dedupe_window_ms": int(args.dedupe_window_ms),
+            "udp_share_cap": args.udp_share_cap,
+            "jitter_threshold_ms": args.jitter_threshold_ms,
+            "fallback_cooldown_sec": args.fallback_cooldown_sec,
+            "fallback_arm_duration_ms": args.fallback_arm_duration_ms,
+            "udp_local_only": args.udp_local_only,
+            "control": control,
         },
         "engine": engine,
         "ws": ws,
     }
 
-    out_dir = Path(args.out_root) / utc_day()
+    if args.run_id:
+        out_dir = Path(args.out_root) / utc_day() / "runs" / str(args.run_id)
+    else:
+        out_dir = Path(args.out_root) / utc_day()
     out_dir.mkdir(parents=True, exist_ok=True)
     out_path = out_dir / f"full_latency_sweep_{started_ms}.json"
     out_path.write_text(json.dumps(payload, ensure_ascii=True, indent=2), encoding="utf-8")
diff --git a/scripts/hft_kernel_tune.sh b/scripts/hft_kernel_tune.sh
new file mode 100644
index 0000000..de4bfcc
--- /dev/null
+++ b/scripts/hft_kernel_tune.sh
@@ -0,0 +1,50 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+# PolyEdge HFT kernel tuning for UDP relay path.
+# Usage:
+#   sudo bash scripts/hft_kernel_tune.sh
+
+if [[ "${EUID}" -ne 0 ]]; then
+  echo "run as root: sudo bash scripts/hft_kernel_tune.sh" >&2
+  exit 1
+fi
+
+SYSCTL_FILE="/etc/sysctl.d/99-polyedge-hft.conf"
+CHRONY_FILE="/etc/chrony/sources.d/aws-time.sources"
+
+cat > "${SYSCTL_FILE}" <<'EOF'
+# PolyEdge HFT UDP relay tuning
+net.core.rmem_max=26214400
+net.core.rmem_default=26214400
+net.core.wmem_max=26214400
+net.core.wmem_default=26214400
+net.core.netdev_max_backlog=250000
+net.core.busy_read=50
+net.core.busy_poll=50
+net.core.default_qdisc=fq
+net.ipv4.tcp_congestion_control=bbr
+net.ipv4.udp_mem=262144 524288 1048576
+net.ipv4.udp_rmem_min=16384
+net.ipv4.udp_wmem_min=16384
+EOF
+
+sysctl --system >/dev/null
+echo "applied sysctl profile: ${SYSCTL_FILE}"
+
+mkdir -p "$(dirname "${CHRONY_FILE}")"
+cat > "${CHRONY_FILE}" <<'EOF'
+# AWS Time Sync Service
+server 169.254.169.123 prefer iburst minpoll 4 maxpoll 4
+EOF
+
+if systemctl is-active --quiet chronyd; then
+  systemctl restart chronyd
+elif systemctl is-active --quiet chrony; then
+  systemctl restart chrony
+fi
+
+echo "updated chrony source: ${CHRONY_FILE}"
+chronyc sources -v || true
+
+echo "done"
diff --git a/scripts/latency_probe/pipeline.py b/scripts/latency_probe/pipeline.py
index f548b17..2cd2aa0 100644
--- a/scripts/latency_probe/pipeline.py
+++ b/scripts/latency_probe/pipeline.py
@@ -3,6 +3,7 @@ from __future__ import annotations
 # NOTE: This module is kept for legacy REST comparison only.
 # The primary benchmark path is scripts/e2e_latency_test.py in ws-first mode.
 
+import atexit
 import json
 import time
 import uuid
@@ -281,6 +282,7 @@ def simulate_execution(intents: List[Dict[str, Any]]) -> List[str]:
 
 def run_rest_pipeline(iterations: int, symbol: str) -> Dict[str, Any]:
     session = requests.Session()
+    atexit.register(session.close)
     market = discover_market(session, symbol)
     samples: List[StageSample] = []
     failures = 0
diff --git a/scripts/latency_probe/ws_probe.py b/scripts/latency_probe/ws_probe.py
index 1ea414b..a50a05f 100644
--- a/scripts/latency_probe/ws_probe.py
+++ b/scripts/latency_probe/ws_probe.py
@@ -3,12 +3,17 @@ from __future__ import annotations
 import asyncio
 import json
 import math
+import random
 import time
 from typing import Dict, List
 
 import websockets
 
-from .stats import percentile, summarize
+try:
+    from .stats import percentile, summarize
+except ImportError:
+    # Allow running as a direct script from repository root.
+    from stats import percentile, summarize
 
 
 async def run_ws_latency(seconds: int, symbol: str) -> Dict[str, float]:
@@ -19,77 +24,121 @@ async def run_ws_latency(seconds: int, symbol: str) -> Dict[str, float]:
     chainlink_lags: List[float] = []
     bin_lags: List[float] = []
 
+    def status_code_from_exc(exc: BaseException) -> int | None:
+        for attr in ("status_code", "status"):
+            val = getattr(exc, attr, None)
+            if isinstance(val, int):
+                return val
+        return None
+
+    async def sleep_with_backoff(
+        end_ts: float,
+        attempt: int,
+        *,
+        throttled: bool,
+    ) -> int:
+        # 429 needs slower reconnect cadence; other errors should retry faster.
+        base = 0.75 if throttled else 0.20
+        cap = 10.0 if throttled else 3.0
+        delay = min(cap, base * (2 ** min(attempt, 6)))
+        delay += random.uniform(0.0, min(0.35, delay * 0.25))
+        remaining = end_ts - time.time()
+        if remaining <= 0:
+            return attempt
+        await asyncio.sleep(min(delay, remaining))
+        return min(attempt + 1, 8)
+
     async def pm_task() -> None:
         url = "wss://ws-live-data.polymarket.com"
-        async with websockets.connect(url, ping_interval=20, ping_timeout=20, max_size=2**22) as ws:
-            sub = {
-                "action": "subscribe",
-                "subscriptions": [
-                    {
-                        "topic": "crypto_prices",
-                        "type": "update",
-                        "filters": f'{{"symbol":"{symbol}"}}',
-                    },
-                    {
-                        # Chainlink RTDS does not currently support server-side symbol filters.
-                        # Subscribe to the topic and filter client-side to keep this probe simple.
-                        "topic": "crypto_prices_chainlink",
-                        "type": "*",
-                        "filters": "",
+        end = time.time() + seconds
+        attempt = 0
+        while time.time() < end:
+            try:
+                async with websockets.connect(
+                    url, ping_interval=20, ping_timeout=20, max_size=2**22
+                ) as ws:
+                    attempt = 0
+                    sub = {
+                        "action": "subscribe",
+                        "subscriptions": [
+                            {
+                                "topic": "crypto_prices",
+                                "type": "update",
+                                "filters": f'{{"symbol":"{symbol}"}}',
+                            },
+                            {
+                                # Chainlink RTDS does not currently support server-side symbol filters.
+                                # Subscribe to the topic and filter client-side to keep this probe simple.
+                                "topic": "crypto_prices_chainlink",
+                                "type": "*",
+                                "filters": "",
+                            },
+                        ],
                     }
-                ],
-            }
-            await ws.send(json.dumps(sub))
-            end = time.time() + seconds
-            while time.time() < end:
-                try:
-                    raw = await asyncio.wait_for(ws.recv(), timeout=3)
-                except asyncio.TimeoutError:
-                    continue
-                recv_ms = time.time() * 1000.0
-                if not raw:
-                    continue
-                try:
-                    msg = json.loads(raw)
-                except Exception:
-                    continue
-                topic = msg.get("topic")
-                if topic == "crypto_prices":
-                    if msg.get("type") != "update":
-                        continue
-                    payload = msg.get("payload") or {}
-                    sym = str(payload.get("symbol", "")).lower()
-                    ts = payload.get("timestamp")
-                    if sym != pm_symbol or ts is None:
-                        continue
-                    pm_lags.append(recv_ms - float(ts))
-                elif topic == "crypto_prices_chainlink":
-                    payload = msg.get("payload") or {}
-                    sym = str(payload.get("symbol", "")).lower()
-                    ts = payload.get("timestamp")
-                    if sym != chainlink_symbol or ts is None:
-                        continue
-                    chainlink_lags.append(recv_ms - float(ts))
+                    await ws.send(json.dumps(sub))
+                    while time.time() < end:
+                        try:
+                            raw = await asyncio.wait_for(ws.recv(), timeout=3)
+                        except asyncio.TimeoutError:
+                            continue
+                        recv_ms = time.time() * 1000.0
+                        if not raw:
+                            continue
+                        try:
+                            msg = json.loads(raw)
+                        except Exception:
+                            continue
+                        topic = msg.get("topic")
+                        if topic == "crypto_prices":
+                            if msg.get("type") != "update":
+                                continue
+                            payload = msg.get("payload") or {}
+                            sym = str(payload.get("symbol", "")).lower()
+                            ts = payload.get("timestamp")
+                            if sym != pm_symbol or ts is None:
+                                continue
+                            pm_lags.append(recv_ms - float(ts))
+                        elif topic == "crypto_prices_chainlink":
+                            payload = msg.get("payload") or {}
+                            sym = str(payload.get("symbol", "")).lower()
+                            ts = payload.get("timestamp")
+                            if sym != chainlink_symbol or ts is None:
+                                continue
+                            chainlink_lags.append(recv_ms - float(ts))
+            except Exception as exc:
+                attempt = await sleep_with_backoff(
+                    end, attempt, throttled=status_code_from_exc(exc) == 429
+                )
 
     async def bin_task() -> None:
         # Keep this consistent with the Rust ref feed which uses `@trade`.
         url = f"wss://stream.binance.com:9443/ws/{bin_symbol}@trade"
-        async with websockets.connect(url, ping_interval=20, ping_timeout=20, max_size=2**22) as ws:
-            end = time.time() + seconds
-            while time.time() < end:
-                try:
-                    raw = await asyncio.wait_for(ws.recv(), timeout=3)
-                except asyncio.TimeoutError:
-                    continue
-                recv_ms = time.time() * 1000.0
-                try:
-                    msg = json.loads(raw)
-                except Exception:
-                    continue
-                event_ts = msg.get("E")
-                if event_ts is None:
-                    continue
-                bin_lags.append(recv_ms - float(event_ts))
+        end = time.time() + seconds
+        attempt = 0
+        while time.time() < end:
+            try:
+                async with websockets.connect(
+                    url, ping_interval=20, ping_timeout=20, max_size=2**22
+                ) as ws:
+                    attempt = 0
+                    while time.time() < end:
+                        try:
+                            raw = await asyncio.wait_for(ws.recv(), timeout=3)
+                        except asyncio.TimeoutError:
+                            continue
+                        recv_ms = time.time() * 1000.0
+                        try:
+                            msg = json.loads(raw)
+                        except Exception:
+                            continue
+                        event_ts = msg.get("E")
+                        if event_ts is None:
+                            continue
+                        bin_lags.append(recv_ms - float(event_ts))
+            except Exception as exc:
+                attempt = await sleep_with_backoff(
+                    end, attempt, throttled=status_code_from_exc(exc) == 429
+                )
 
     await asyncio.gather(pm_task(), bin_task())
     pm_stats = summarize(pm_lags)
diff --git a/scripts/latency_test.py b/scripts/latency_test.py
new file mode 100644
index 0000000..8b9ce9a
--- /dev/null
+++ b/scripts/latency_test.py
@@ -0,0 +1,294 @@
+#!/usr/bin/env python3
+"""
+å»¶è¿Ÿå¯¹æ¯”æµ‹è¯•å·¥å…·
+æ¯”è¾ƒ VPC å†…ç½‘è½¬å‘ vs å…¬ç½‘ç›´è¿žçš„å»¶è¿Ÿ
+
+ä½¿ç”¨:
+    # æµ‹è¯• VPC å†…ç½‘ (éœ€è¦å…ˆåœ¨ä¸œäº¬è¿è¡Œ relay)
+    python3 scripts/latency_test.py --mode vpc
+
+    # æµ‹è¯•å…¬ç½‘ç›´è¿ž (ä»Žçˆ±å°”å…°ç›´æŽ¥è¿žæŽ¥ Binance)
+    python3 scripts/latency_test.py --mode direct
+
+    # å¯¹æ¯”æµ‹è¯•
+    python3 scripts/latency_test.py --mode compare
+"""
+
+import asyncio
+import json
+import time
+import argparse
+import statistics
+from datetime import datetime
+from dataclasses import dataclass
+from typing import List
+
+BINANCE_WS = "wss://stream.binance.com:9443/ws/btcusdt@trade"
+
+
+@dataclass
+class LatencySample:
+    """å•æ¬¡å»¶è¿Ÿé‡‡æ ·"""
+    recv_time: float      # æœ¬åœ°æŽ¥æ”¶æ—¶é—´ (çº³ç§’)
+    exchange_time: float  # äº¤æ˜“æ‰€æ—¶é—´ (çº³ç§’)
+    latency_ms: float     # å»¶è¿Ÿ (æ¯«ç§’)
+
+
+class LatencyTester:
+    def __init__(self, mode: str):
+        self.mode = mode
+        self.samples: List[LatencySample] = []
+        self.running = True
+
+    async def connect_binance(self):
+        """è¿žæŽ¥ Binance WebSocket"""
+        import websockets
+        self.ws = await websockets.connect(BINANCE_WS)
+        print(f"[{datetime.now()}] âœ… è¿žæŽ¥åˆ° Binance")
+
+    async def measure_direct(self):
+        """æµ‹é‡ç›´è¿žå»¶è¿Ÿ: çˆ±å°”å…° -> Binance"""
+        await self.connect_binance()
+
+        print(f"[{datetime.now()}] å¼€å§‹æµ‹é‡ç›´è¿žå»¶è¿Ÿ...")
+        count = 0
+
+        async for msg in self.ws:
+            data = json.loads(msg)
+
+            # Binance æ—¶é—´æˆ³ (æ¯«ç§’)
+            exchange_ts = int(data['E'])
+            recv_ts = int(time.time() * 1000)
+
+            latency = recv_ts - exchange_ts
+            self.samples.append(LatencySample(
+                recv_time=recv_ts * 1_000_000,
+                exchange_time=exchange_ts * 1_000_000,
+                latency_ms=latency
+            ))
+
+            count += 1
+            if count >= 100:  # é‡‡é›† 100 ä¸ªæ ·æœ¬
+                break
+
+        await self.ws.close()
+        self.print_stats("ç›´è¿ž (çˆ±å°”å…° -> Binance)")
+
+    async def measure_vpc(self, tokyo_host: str = "172.31.44.26"):
+        """æµ‹é‡ VPC å†…ç½‘å»¶è¿Ÿ: çˆ±å°”å…° -> ä¸œäº¬ -> Binance"""
+        # è¿™é‡Œéœ€è¦ä¸œäº¬è¿è¡Œ relay è½¬å‘
+        # æš‚æ—¶é€šè¿‡æ¨¡æ‹Ÿæ–¹å¼æµ‹è¯• VPC è¿žé€šæ€§
+
+        import socket
+
+        print(f"[{datetime.now()}] æµ‹è¯• VPC è¿žé€šæ€§: {tokyo_host}:6666")
+
+        try:
+            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
+            sock.settimeout(5)
+            sock.connect((tokyo_host, 6666))
+
+            # å‘é€æŽ¢æµ‹åŒ…
+            start = time.perf_counter_ns()
+            sock.send(b"ping")
+            resp = sock.recv(1024)
+            end = time.perf_counter_ns()
+
+            rtt_ns = end - start
+            one_way = rtt_ns / 2  # å‡è®¾å¯¹ç§°
+
+            print(f"[{datetime.now()}] âœ… VPC è¿žé€šæ­£å¸¸, RTT: {rtt_ns/1e6:.2f}ms (å•ç¨‹: {one_way/1e6:.2f}ms)")
+            print(f"[{datetime.now()}] â„¹ï¸  å®Œæ•´è·¯å¾„: Binance -> ä¸œäº¬({tokyo_host}) -> VPC -> çˆ±å°”å…°")
+            print(f"[{datetime.now()}] â„¹ï¸  é¢„ä¼°å»¶è¿Ÿ: ~7ms (5ms + 1ms + 1ms)")
+
+        except Exception as e:
+            print(f"[{datetime.now()}] âŒ VPC è¿žæŽ¥å¤±è´¥: {e}")
+            print(f"[{datetime.now()}] è¯·ç¡®ä¿ä¸œäº¬æœåŠ¡å™¨å·²å¯åŠ¨ relay")
+
+    async def run_relay(self, ireland_ip: str = "10.0.3.123"):
+        """åœ¨ä¸œäº¬è¿è¡Œ relay (éœ€è¦éƒ¨ç½²åˆ°ä¸œäº¬æœåŠ¡å™¨)"""
+        print(f"[{datetime.now()}] â„¹ï¸  æ­¤æ¨¡å¼éœ€è¦åœ¨ä¸œäº¬æœåŠ¡å™¨è¿è¡Œ relay")
+        print(
+            f"[{datetime.now()}] â„¹ï¸  å»ºè®®éƒ¨ç½²: cargo run -p feeder_tokyo --bin sender --release"
+        )
+        print(f"[{datetime.now()}] â„¹ï¸  TARGET={ireland_ip}:6666")
+
+    def print_stats(self, label: str):
+        """æ‰“å°å»¶è¿Ÿç»Ÿè®¡"""
+        if not self.samples:
+            print("æ— æ•°æ®")
+            return
+
+        latencies = [s.latency_ms for s in self.samples]
+
+        print(f"\n{'='*50}")
+        print(f"ðŸ“Š {label} å»¶è¿Ÿç»Ÿè®¡ (n={len(latencies)})")
+        print(f"{'='*50}")
+        print(f"  æœ€å°:  {min(latencies):.2f} ms")
+        print(f"  æœ€å¤§:  {max(latencies):.2f} ms")
+        print(f"  å¹³å‡:  {statistics.mean(latencies):.2f} ms")
+        print(f"  ä¸­ä½æ•°: {statistics.median(latencies):.2f} ms")
+        print(f"  P95:   {sorted(latencies)[int(len(latencies)*0.95)]:.2f} ms")
+        print(f"  P99:   {sorted(latencies)[int(len(latencies)*0.99)]:.2f} ms")
+        print(f"  æ ‡å‡†å·®: {statistics.stdev(latencies):.2f} ms")
+        print(f"{'='*50}\n")
+
+
+async def run_tcp_latency_test(target: str, port: int, duration_sec: int = 30):
+    """
+    TCP å»¶è¿Ÿæµ‹è¯• - å‘é€æŽ¢æµ‹åŒ…æµ‹é‡ RTT
+
+    ä½¿ç”¨åœºæ™¯:
+    - æµ‹è¯•ä¸œäº¬ -> çˆ±å°”å…° VPC å»¶è¿Ÿ
+    - å¯¹æ¯”ä¸åŒç½‘ç»œè·¯å¾„
+    """
+    import socket
+    import struct
+
+    print(f"\n{'='*50}")
+    print(f"ðŸ”¬ TCP å»¶è¿Ÿæµ‹è¯•: {target}:{port}")
+    print(f"{'='*50}")
+
+    # æž„é€ æŽ¢æµ‹åŒ… (åŒ…å«æ—¶é—´æˆ³)
+    probe_data = struct.pack('!d', time.time())
+
+    latencies = []
+
+    for i in range(duration_sec * 10):  # æ¯ç§’ 10 æ¬¡
+        try:
+            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
+            sock.settimeout(2)
+
+            # æµ‹é‡è¿žæŽ¥æ—¶é—´
+            start = time.perf_counter_ns()
+            sock.connect((target, port))
+            conn_time = time.perf_counter_ns()
+
+            # å‘é€æŽ¢æµ‹
+            sock.send(probe_data)
+            sock.recv(1024)  # ç®€å•å“åº”
+
+            end = time.perf_counter_ns()
+
+            rtt_ns = end - start
+            latencies.append(rtt_ns / 1e6)  # è½¬æ¢ä¸º ms
+
+            sock.close()
+
+        except Exception as e:
+            print(f"é”™è¯¯: {e}")
+
+        await asyncio.sleep(0.1)
+
+    if latencies:
+        print(f"\nðŸ“Š TCP å»¶è¿Ÿç»Ÿè®¡:")
+        print(f"  å¹³å‡: {statistics.mean(latencies):.2f} ms")
+        print(f"  P50:  {statistics.median(latencies):.2f} ms")
+        print(f"  P95:  {sorted(latencies)[int(len(latencies)*0.95)]:.2f} ms")
+        print(f"  P99:  {sorted(latencies)[int(len(latencies)*0.99)]:.2f} ms")
+        print(f"  æŠ–åŠ¨: {statistics.stdev(latencies):.2f} ms")
+
+
+async def run_udp_latency_test(target: str, port: int, duration_sec: int = 30):
+    """
+    UDP å»¶è¿Ÿæµ‹è¯• - å‘é€æŽ¢æµ‹åŒ…æµ‹é‡å»¶è¿Ÿ
+
+    è¿™æ˜¯æ ¸å¿ƒæµ‹è¯•ï¼Œç”¨äºŽéªŒè¯ VPC ç½‘ç»œè´¨é‡
+    """
+    import socket
+
+    print(f"\n{'='*50}")
+    print(f"ðŸ”¬ UDP å»¶è¿Ÿæµ‹è¯•: {target}:{port}")
+    print(f"{'='*50}")
+
+    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
+    sock.settimeout(1)
+
+    latencies = []
+    seq = 0
+
+    try:
+        for i in range(duration_sec * 100):  # æ¯ç§’ 100 æ¬¡
+            # æž„é€ æŽ¢æµ‹åŒ…: åºåˆ—å· + æ—¶é—´æˆ³
+            seq += 1
+            send_ts = time.perf_counter_ns()
+            probe_data = struct.pack('!IQ', seq, send_ts)
+
+            sock.sendto(probe_data, (target, port))
+
+            try:
+                resp, _ = sock.recvfrom(1024)
+                recv_ts = time.perf_counter_ns()
+
+                if len(resp) >= 16:
+                    seq_resp, send_ts_resp = struct.unpack('!IQ', resp[:16])
+                    if seq_resp == seq:
+                        latency_ns = recv_ts - send_ts
+                        latencies.append(latency_ns / 1e6)
+
+            except socket.timeout:
+                pass  # è¶…æ—¶å¿½ç•¥
+
+            await asyncio.sleep(0.01)  # 10ms é—´éš”
+
+    finally:
+        sock.close()
+
+    if latencies:
+        print(f"\nðŸ“Š UDP å»¶è¿Ÿç»Ÿè®¡:")
+        print(f"  æ ·æœ¬æ•°: {len(latencies)}")
+        print(f"  ä¸¢åŒ…çŽ‡: {(duration_sec * 100 - len(latencies)) / (duration_sec * 100) * 100:.1f}%")
+        print(f"  å¹³å‡: {statistics.mean(latencies):.2f} ms")
+        print(f"  P50:  {statistics.median(latencies):.2f} ms")
+        print(f"  P95:  {sorted(latencies)[int(len(latencies)*0.95)]:.2f} ms")
+        print(f"  P99:  {sorted(latencies)[int(len(latencies)*0.99)]:.2f} ms")
+        print(f"  æŠ–åŠ¨: {statistics.stdev(latencies):.2f} ms")
+        print(f"  æœ€å°: {min(latencies):.2f} ms")
+        print(f"  æœ€å¤§: {max(latencies):.2f} ms")
+    else:
+        print("âŒ æ— æœ‰æ•ˆå“åº”ï¼Œè¯·æ£€æŸ¥è¿žæŽ¥")
+
+
+async def main():
+    parser = argparse.ArgumentParser(description="å»¶è¿Ÿæµ‹è¯•å·¥å…·")
+    parser.add_argument("--mode", choices=["direct", "vpc", "compare", "tcp", "udp"],
+                       default="direct", help="æµ‹è¯•æ¨¡å¼")
+    parser.add_argument("--target", default="172.31.44.26", help="ç›®æ ‡åœ°å€")
+    parser.add_argument("--port", type=int, default=6666, help="ç›®æ ‡ç«¯å£")
+    parser.add_argument("--duration", type=int, default=30, help="æµ‹è¯•æ—¶é•¿(ç§’)")
+
+    args = parser.parse_args()
+
+    if args.mode == "direct":
+        tester = LatencyTester("direct")
+        await tester.measure_direct()
+
+    elif args.mode == "vpc":
+        tester = LatencyTester("vpc")
+        await tester.measure_vpc(args.target)
+
+    elif args.mode == "tcp":
+        await run_tcp_latency_test(args.target, args.port, args.duration)
+
+    elif args.mode == "udp":
+        await run_udp_latency_test(args.target, args.port, args.duration)
+
+    elif args.mode == "compare":
+        print("="*60)
+        print("ðŸ”¬ å»¶è¿Ÿå¯¹æ¯”æµ‹è¯•")
+        print("="*60)
+
+        # æµ‹è¯•å…¬ç½‘ç›´è¿ž
+        print("\n[1/2] æµ‹è¯•å…¬ç½‘ç›´è¿žå»¶è¿Ÿ...")
+        tester = LatencyTester("direct")
+        direct_samples = tester.samples.copy()
+
+        # æµ‹è¯• VPC
+        print("[2/2] æµ‹è¯• VPC å†…ç½‘å»¶è¿Ÿ...")
+        tester2 = LatencyTester("vpc")
+        await tester2.measure_vpc(args.target)
+
+
+if __name__ == "__main__":
+    import struct
+    asyncio.run(main())
diff --git a/scripts/legacy_rest_probe.py b/scripts/legacy_rest_probe.py
deleted file mode 100644
index 21e5c30..0000000
--- a/scripts/legacy_rest_probe.py
+++ /dev/null
@@ -1,39 +0,0 @@
-#!/usr/bin/env python3
-"""Legacy REST pipeline benchmark kept only for historical comparison."""
-
-from __future__ import annotations
-
-import argparse
-
-from latency_probe.models import SYMBOL_TO_NAME
-from latency_probe.pipeline import run_rest_pipeline
-from latency_probe.stats import print_stat_block
-
-
-def main() -> None:
-    parser = argparse.ArgumentParser(description="Legacy REST latency probe")
-    parser.add_argument("--symbol", default="BTCUSDT", choices=list(SYMBOL_TO_NAME.keys()))
-    parser.add_argument("--iterations", type=int, default=80)
-    args = parser.parse_args()
-
-    rest = run_rest_pipeline(args.iterations, args.symbol)
-    print(f"symbol={args.symbol}")
-    print(
-        "market=",
-        rest["market"]["question"],
-        f"(market_id={rest['market']['market_id']}, yes_token={rest['market']['yes_token'][:8]}...)",
-    )
-    print(f"samples={rest['n']} failures={rest['failures']} intents_avg={rest['intents_avg']:.3f}")
-    if rest.get("failure_reasons"):
-        print("failure_reasons=", rest["failure_reasons"])
-    print_stat_block("ref_fetch", rest["ref_fetch_ms"], "ms")
-    print_stat_block("book_fetch", rest["book_fetch_ms"], "ms")
-    print_stat_block("signal", rest["signal_us"], "us")
-    print_stat_block("quote", rest["quote_us"], "us")
-    print_stat_block("risk", rest["risk_us"], "us")
-    print_stat_block("exec", rest["exec_us"], "us")
-    print_stat_block("total_e2e", rest["total_ms"], "ms")
-
-
-if __name__ == "__main__":
-    main()
diff --git a/scripts/live_gateway_canary.py b/scripts/live_gateway_canary.py
new file mode 100644
index 0000000..49b08fb
--- /dev/null
+++ b/scripts/live_gateway_canary.py
@@ -0,0 +1,197 @@
+#!/usr/bin/env python3
+"""Canary for the local CLOB gateway.
+
+Goal: prove "I can place a real order via gateway and flatten" with tiny notional.
+
+Writes:
+  datasets/reports/<day>/runs/<run_id>/live_gateway_canary.json
+"""
+
+from __future__ import annotations
+
+import atexit
+import argparse
+import json
+import time
+from datetime import datetime, timezone
+from pathlib import Path
+from typing import Any, Dict, List, Optional, Tuple
+
+import requests
+
+
+def utc_day(ts: Optional[float] = None) -> str:
+    dt = datetime.fromtimestamp(ts or time.time(), tz=timezone.utc)
+    return dt.strftime("%Y-%m-%d")
+
+
+def now_ms() -> int:
+    return int(time.time() * 1000)
+
+
+def write_json(path: Path, payload: Any) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    path.write_text(json.dumps(payload, ensure_ascii=True, indent=2), encoding="utf-8")
+
+
+def fetch_book_top(clob_host: str, token_id: str, timeout_sec: float) -> Tuple[float, float]:
+    """Returns (best_bid, best_ask). 0.0 when missing."""
+    url = f"{clob_host.rstrip('/')}/book?token_id={token_id}"
+    resp = requests.get(url, timeout=timeout_sec)
+    resp.raise_for_status()
+    data = resp.json()
+    bids = data.get("bids") or []
+    asks = data.get("asks") or []
+
+    def px(level: Any) -> Optional[float]:
+        if not isinstance(level, dict):
+            return None
+        v = level.get("price")
+        if v is None:
+            return None
+        try:
+            return float(v)
+        except Exception:
+            return None
+
+    best_bid = 0.0
+    best_ask = 0.0
+    if bids:
+        p0 = px(bids[0])
+        best_bid = float(p0 or 0.0)
+    if asks:
+        p0 = px(asks[0])
+        best_ask = float(p0 or 0.0)
+    return best_bid, best_ask
+
+
+def parse_args() -> argparse.Namespace:
+    p = argparse.ArgumentParser(description="PolyEdge live gateway canary (tiny notional)")
+    p.add_argument("--gateway-url", default="http://127.0.0.1:9001")
+    p.add_argument("--clob-host", default="https://clob.polymarket.com")
+    p.add_argument("--token-id", required=True, help="Polymarket asset_id / token_id (YES or NO token)")
+    p.add_argument(
+        "--price",
+        type=float,
+        default=None,
+        help="Optional fixed price to skip fetching orderbook. Useful when token has no /book or access is restricted.",
+    )
+    p.add_argument("--market-id", default="canary")
+    p.add_argument("--side", default="buy_yes", choices=["buy_yes", "buy_no", "sell_yes", "sell_no"])
+    p.add_argument("--notional-usdc", type=float, default=0.5)
+    p.add_argument("--max-slippage-bps", type=float, default=10.0)
+    p.add_argument("--attempts", type=int, default=5)
+    p.add_argument("--timeout-sec", type=float, default=5.0)
+    p.add_argument("--run-id", default=f"gateway-canary-{int(time.time())}")
+    p.add_argument("--out-root", default="datasets/reports")
+    return p.parse_args()
+
+
+def main() -> int:
+    args = parse_args()
+    day = utc_day()
+    out_dir = Path(args.out_root) / day / "runs" / args.run_id
+    out_dir.mkdir(parents=True, exist_ok=True)
+
+    session = requests.Session()
+    atexit.register(session.close)
+    health = session.get(f"{args.gateway_url.rstrip('/')}/health", timeout=args.timeout_sec).json()
+
+    best_bid = 0.0
+    best_ask = 0.0
+    if args.price is not None:
+        ref_px = float(args.price)
+    else:
+        best_bid, best_ask = fetch_book_top(args.clob_host, args.token_id, args.timeout_sec)
+        if args.side.startswith("buy"):
+            ref_px = best_ask
+            if ref_px <= 0:
+                raise RuntimeError("no asks in book; cannot form crossable buy (pass --price to skip book fetch)")
+        else:
+            ref_px = best_bid
+            if ref_px <= 0:
+                raise RuntimeError("no bids in book; cannot form crossable sell (pass --price to skip book fetch)")
+
+    if not (0.0 < ref_px < 1.0):
+        raise RuntimeError(f"invalid ref_px={ref_px} (must be in (0,1))")
+
+    notional = max(0.0, float(args.notional_usdc))
+    if notional <= 0.0:
+        raise RuntimeError("notional_usdc must be > 0")
+
+    size = notional / ref_px
+
+    records: List[Dict[str, Any]] = []
+    ok = 0
+    for i in range(1, max(1, args.attempts) + 1):
+        client_order_id = f"{args.run_id}-{i:02d}"
+        payload: Dict[str, Any] = {
+            "market_id": args.market_id,
+            "token_id": args.token_id,
+            "side": args.side,
+            "price": ref_px,
+            "size": size,
+            "ttl_ms": 5_000,
+            "style": "taker",
+            "tif": "FAK",
+            "client_order_id": client_order_id,
+            "max_slippage_bps": float(args.max_slippage_bps),
+            "fee_rate_bps": 0.0,
+            "expected_edge_net_bps": 0.0,
+            "hold_to_resolution": False,
+        }
+        started = time.perf_counter()
+        try:
+            resp = session.post(
+                f"{args.gateway_url.rstrip('/')}/orders",
+                json=payload,
+                timeout=args.timeout_sec,
+            )
+            latency_ms = (time.perf_counter() - started) * 1000.0
+            rec: Dict[str, Any] = {
+                "i": i,
+                "latency_ms": latency_ms,
+                "http_status": resp.status_code,
+                "resp": resp.json() if resp.headers.get("content-type", "").startswith("application/json") else resp.text[:240],
+            }
+        except Exception as exc:  # noqa: BLE001
+            rec = {"i": i, "error": str(exc)[:240]}
+
+        records.append(rec)
+        accepted = False
+        try:
+            accepted = bool((rec.get("resp") or {}).get("accepted"))
+        except Exception:
+            accepted = False
+        if accepted:
+            ok += 1
+
+        # Always flatten after each attempt: ultra-safe.
+        try:
+            _ = session.post(f"{args.gateway_url.rstrip('/')}/flatten", timeout=args.timeout_sec)
+        except Exception:
+            pass
+        time.sleep(0.5)
+
+    summary: Dict[str, Any] = {
+        "ts_ms": now_ms(),
+        "gateway_url": args.gateway_url,
+        "clob_host": args.clob_host,
+        "token_id": args.token_id,
+        "side": args.side,
+        "book_top": {"best_bid": best_bid, "best_ask": best_ask, "ref_px": ref_px, "used_fixed_price": (args.price is not None)},
+        "notional_usdc": notional,
+        "size": size,
+        "attempts": int(args.attempts),
+        "accepted": ok,
+        "accept_rate": (ok / max(1, int(args.attempts))),
+        "health": health,
+        "records": records,
+    }
+    write_json(out_dir / "live_gateway_canary.json", summary)
+    print(f"wrote_json={out_dir / 'live_gateway_canary.json'} accept_rate={summary['accept_rate']:.3f}")
+    return 0 if ok > 0 else 3
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/scripts/long_regression_orchestrator.py b/scripts/long_regression_orchestrator.py
index 702e3d0..1fcfc38 100644
--- a/scripts/long_regression_orchestrator.py
+++ b/scripts/long_regression_orchestrator.py
@@ -1,15 +1,17 @@
 #!/usr/bin/env python3
 from __future__ import annotations
 
+import atexit
 import argparse
 import json
+import math
 import os
 import subprocess
 import sys
 import time
 from datetime import datetime, timezone
 from pathlib import Path
-from typing import Any, Dict, List
+from typing import Any, Dict, List, Tuple
 
 import requests
 
@@ -17,10 +19,12 @@ import requests
 def utc_day() -> str:
     return datetime.now(timezone.utc).strftime("%Y-%m-%d")
 
+
 def default_run_id() -> str:
     ts = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
     return f"long-reg-{ts}-{os.getpid()}"
 
+
 PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
     "quick": {
         "cycles": 2,
@@ -35,6 +39,10 @@ PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
         "cooldown_sec": 30,
         "min_outcomes": 10,
         "max_estimated_sec": 1800,
+        "selection_mode": "robust",
+        "walkforward_windows": 2,
+        "walkforward_cooldown_sec": 2.0,
+        "top_k_consensus": 3,
     },
     "standard": {
         "cycles": 4,
@@ -49,6 +57,10 @@ PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
         "cooldown_sec": 120,
         "min_outcomes": 30,
         "max_estimated_sec": 0,
+        "selection_mode": "robust",
+        "walkforward_windows": 2,
+        "walkforward_cooldown_sec": 3.0,
+        "top_k_consensus": 3,
     },
     "deep": {
         "cycles": 8,
@@ -63,6 +75,10 @@ PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
         "cooldown_sec": 120,
         "min_outcomes": 40,
         "max_estimated_sec": 0,
+        "selection_mode": "robust",
+        "walkforward_windows": 3,
+        "walkforward_cooldown_sec": 5.0,
+        "top_k_consensus": 5,
     },
 }
 
@@ -75,15 +91,25 @@ def apply_profile_defaults(args: argparse.Namespace) -> argparse.Namespace:
     return args
 
 
-def post_json(session: requests.Session, url: str, payload: Dict[str, Any]) -> Dict[str, Any]:
-    resp = session.post(url, json=payload, timeout=8)
+def post_json(
+    session: requests.Session,
+    url: str,
+    payload: Dict[str, Any],
+    timeout_sec: float = 8.0,
+) -> Dict[str, Any]:
+    resp = session.post(url, json=payload, timeout=timeout_sec)
     resp.raise_for_status()
     return resp.json()
 
 
-def post_json_optional(session: requests.Session, url: str, payload: Dict[str, Any]) -> Dict[str, Any]:
+def post_json_optional(
+    session: requests.Session,
+    url: str,
+    payload: Dict[str, Any],
+    timeout_sec: float = 8.0,
+) -> Dict[str, Any]:
     try:
-        return post_json(session, url, payload)
+        return post_json(session, url, payload, timeout_sec)
     except requests.HTTPError as exc:
         status = exc.response.status_code if exc.response is not None else None
         if status in (404, 405):
@@ -91,8 +117,8 @@ def post_json_optional(session: requests.Session, url: str, payload: Dict[str, A
         raise
 
 
-def get_json(session: requests.Session, url: str) -> Dict[str, Any]:
-    resp = session.get(url, timeout=8)
+def get_json(session: requests.Session, url: str, timeout_sec: float = 8.0) -> Dict[str, Any]:
+    resp = session.get(url, timeout=timeout_sec)
     resp.raise_for_status()
     return resp.json()
 
@@ -116,9 +142,8 @@ def gate_pass(live: Dict[str, Any], min_outcomes: int) -> bool:
     )
 
 
-def run_param_regression(args: argparse.Namespace, cycle: int, budget_sec: int) -> None:
+def run_param_regression(args: argparse.Namespace, trial_run_id: str, budget_sec: int) -> None:
     script_path = Path(__file__).resolve().parent / "param_regression.py"
-    trial_run_id = f"{args.run_id}-c{cycle:02d}"
     cmd = [
         sys.executable,
         str(script_path),
@@ -142,63 +167,121 @@ def run_param_regression(args: argparse.Namespace, cycle: int, budget_sec: int)
         str(args.heartbeat_sec),
         "--fail-fast-threshold",
         str(args.fail_fast_threshold),
+        "--selection-mode",
+        str(args.selection_mode),
+        "--walkforward-windows",
+        str(args.walkforward_windows),
+        "--walkforward-cooldown-sec",
+        str(args.walkforward_cooldown_sec),
+        "--top-k-consensus",
+        str(args.top_k_consensus),
     ]
+    timeout_sec: float | None = None
     if budget_sec > 0:
         cmd.extend(["--max-runtime-sec", str(budget_sec)])
-    subprocess.run(cmd, check=True)
+        timeout_sec = float(max(60, budget_sec + 90))
+    subprocess.run(cmd, check=True, timeout=timeout_sec)
 
 
-def read_best_trial(day_dir: Path) -> Dict[str, Any] | None:
-    summary_json = day_dir / "regression_summary.json"
-    if not summary_json.exists():
+def read_best_trial(out_root: Path, trial_run_id: str) -> Dict[str, Any] | None:
+    candidates = sorted(
+        out_root.glob(f"*/runs/{trial_run_id}/regression_summary.json"),
+        key=lambda p: p.stat().st_mtime,
+        reverse=True,
+    )
+    if not candidates:
         return None
-    data = json.loads(summary_json.read_text(encoding="utf-8"))
+    data = json.loads(candidates[0].read_text(encoding="utf-8"))
+    auto_tuned = ((data.get("auto_tuned_thresholds") or {}).get("consensus") or {})
+    if isinstance(auto_tuned, dict) and auto_tuned.get("reload_strategy"):
+        return auto_tuned
     trials = data.get("trials") or []
     return trials[0] if trials else None
 
 
-def apply_trial(session: requests.Session, base_url: str, trial: Dict[str, Any]) -> None:
-    base = base_url.rstrip("/")
-    post_json(
-        session,
-        f"{base}/control/reload_strategy",
-        {
+def load_champion_state(state_file: Path) -> Tuple[Dict[str, Any] | None, Dict[str, Any] | None]:
+    if not state_file.exists():
+        return None, None
+    data = json.loads(state_file.read_text(encoding="utf-8"))
+    bundle = data.get("bundle")
+    snapshot = data.get("snapshot")
+    if not isinstance(bundle, dict):
+        return None, None
+    return bundle, snapshot if isinstance(snapshot, dict) else None
+
+
+def save_champion_state(
+    state_file: Path,
+    run_id: str,
+    cycle: int,
+    decision: str,
+    bundle: Dict[str, Any],
+    snapshot: Dict[str, Any],
+) -> None:
+    state_file.parent.mkdir(parents=True, exist_ok=True)
+    state_file.write_text(
+        json.dumps(
+            {
+                "updated_at_utc": datetime.now(timezone.utc).isoformat(),
+                "run_id": run_id,
+                "cycle": cycle,
+                "decision": decision,
+                "bundle": bundle,
+                "snapshot": snapshot,
+            },
+            ensure_ascii=True,
+            indent=2,
+        ),
+        encoding="utf-8",
+    )
+
+
+def to_bundle(trial: Dict[str, Any]) -> Dict[str, Any]:
+    if "reload_strategy" in trial:
+        return {
+            "reload_strategy": dict(trial.get("reload_strategy") or {}),
+            "reload_taker": dict(trial.get("reload_taker") or {}),
+            "reload_allocator": dict(trial.get("reload_allocator") or {}),
+            "reload_toxicity": dict(trial.get("reload_toxicity") or {}),
+        }
+    return {
+        "reload_strategy": {
             "min_edge_bps": trial["min_edge_bps"],
             "ttl_ms": trial["ttl_ms"],
+            "max_spread": trial["max_spread"],
+            "base_quote_size": trial["base_quote_size"],
+            "min_eval_notional_usdc": trial["min_eval_notional_usdc"],
+            "min_expected_edge_usdc": trial["min_expected_edge_usdc"],
             "basis_k_revert": trial["basis_k_revert"],
             "basis_z_cap": trial["basis_z_cap"],
         },
-    )
-    post_json_optional(
-        session,
-        f"{base}/control/reload_taker",
-        {
-            "trigger_bps": max(1.0, float(trial["min_edge_bps"])),
-            "max_slippage_bps": 25.0,
-            "stale_tick_filter_ms": 450.0,
-            "market_tier_profile": "balanced",
+        "reload_taker": {
+            "trigger_bps": trial["taker_trigger_bps"],
+            "max_slippage_bps": trial["taker_max_slippage_bps"],
+            "stale_tick_filter_ms": trial["stale_tick_filter_ms"],
+            "market_tier_profile": trial["market_tier_profile"],
         },
-    )
-    post_json_optional(
-        session,
-        f"{base}/control/reload_allocator",
-        {
+        "reload_allocator": {
             "capital_fraction_kelly": 0.35,
             "variance_penalty_lambda": 0.25,
-            "active_top_n_markets": 8,
+            "active_top_n_markets": trial["active_top_n_markets"],
             "taker_weight": 0.7,
             "maker_weight": 0.2,
             "arb_weight": 0.1,
         },
-    )
-    post_json(
-        session,
-        f"{base}/control/reload_toxicity",
-        {
+        "reload_toxicity": {
             "safe_threshold": trial["safe_threshold"],
             "caution_threshold": trial["caution_threshold"],
         },
-    )
+    }
+
+
+def apply_bundle(session: requests.Session, base_url: str, bundle: Dict[str, Any]) -> None:
+    base = base_url.rstrip("/")
+    post_json(session, f"{base}/control/reload_strategy", bundle.get("reload_strategy") or {})
+    post_json_optional(session, f"{base}/control/reload_taker", bundle.get("reload_taker") or {})
+    post_json_optional(session, f"{base}/control/reload_allocator", bundle.get("reload_allocator") or {})
+    post_json(session, f"{base}/control/reload_toxicity", bundle.get("reload_toxicity") or {})
 
 
 def reset_shadow(session: requests.Session, base_url: str) -> None:
@@ -211,31 +294,254 @@ def collect_live_window(
     base_url: str,
     eval_window_sec: int,
     poll_interval_sec: float,
+    timeout_sec: float,
+    max_read_failures: int,
 ) -> List[Dict[str, Any]]:
     base = base_url.rstrip("/")
     samples: List[Dict[str, Any]] = []
+    consecutive_failures = 0
     deadline = time.monotonic() + max(1, eval_window_sec)
     while time.monotonic() < deadline:
-        samples.append(get_json(session, f"{base}/report/shadow/live"))
+        try:
+            samples.append(get_json(session, f"{base}/report/shadow/live", timeout_sec))
+            consecutive_failures = 0
+        except requests.RequestException as exc:
+            consecutive_failures += 1
+            if consecutive_failures >= max(1, max_read_failures) and samples:
+                print(
+                    f"[warn] shadow/live read failure x{consecutive_failures}; "
+                    "keeping collected samples and ending evaluation window early"
+                )
+                break
+            print(f"[warn] shadow/live read failed ({type(exc).__name__}); retrying")
         time.sleep(max(0.2, poll_interval_sec))
     if not samples:
-        samples.append(get_json(session, f"{base}/report/shadow/live"))
+        try:
+            samples.append(get_json(session, f"{base}/report/shadow/live", timeout_sec))
+        except requests.RequestException:
+            samples.append(
+                {
+                    "gate_ready": False,
+                    "gate_fail_reasons": ["shadow_live_unreachable"],
+                    "window_outcomes": 0,
+                    "total_outcomes": 0,
+                    "net_markout_10s_usdc_p50": 0.0,
+                    "ev_net_usdc_p50": 0.0,
+                    "roi_notional_10s_bps_p50": 0.0,
+                    "fillability_10ms": 0.0,
+                    "quote_block_ratio": 1.0,
+                    "policy_block_ratio": 1.0,
+                    "tick_to_ack_p99_ms": 9999.0,
+                    "decision_compute_p99_ms": 9999.0,
+                    "data_valid_ratio": 0.0,
+                    "latency": {"feed_in_p99_ms": 9999.0},
+                }
+            )
     return samples
 
 
 def pick_gate_snapshot(samples: List[Dict[str, Any]]) -> Dict[str, Any]:
-    # Prefer the richest sample in-window to reduce small-sample artifacts.
     return max(
         samples,
         key=lambda item: int(item.get("window_outcomes", item.get("total_outcomes", 0)) or 0),
     )
 
 
+def stddev(values: List[float]) -> float:
+    if len(values) <= 1:
+        return 0.0
+    mean = sum(values) / len(values)
+    var = sum((v - mean) ** 2 for v in values) / len(values)
+    return math.sqrt(max(0.0, var))
+
+
+def ev_penalty_objective(
+    live: Dict[str, Any],
+    samples: List[Dict[str, Any]],
+    min_outcomes: int,
+    args: argparse.Namespace,
+) -> Tuple[float, float, Dict[str, float]]:
+    ev_net = float(live.get("ev_net_usdc_p50", live.get("net_markout_10s_usdc_p50", 0.0)))
+    tick_to_ack = float(live.get("tick_to_ack_p99_ms", 0.0))
+    decision_compute = float(live.get("decision_compute_p99_ms", 0.0))
+    feed_in = float((live.get("latency") or {}).get("feed_in_p99_ms", 0.0))
+    quote_block = float(live.get("quote_block_ratio", 0.0))
+    policy_block = float(live.get("policy_block_ratio", 0.0))
+    executed_over_eligible = float(live.get("executed_over_eligible", 0.0))
+    data_valid = float(live.get("data_valid_ratio", 1.0))
+
+    ev_series = [
+        float(s.get("ev_net_usdc_p50", s.get("net_markout_10s_usdc_p50", 0.0)))
+        for s in samples
+    ]
+    latency_series = [float(s.get("tick_to_ack_p99_ms", 0.0)) for s in samples]
+
+    penalties = {
+        "latency": max(0.0, tick_to_ack - 450.0) * args.penalty_latency_ms,
+        "decision": max(0.0, decision_compute - 2.0) * args.penalty_decision_ms,
+        "feed": max(0.0, feed_in - 800.0) * args.penalty_feed_ms,
+        "quote_block": max(0.0, quote_block - 0.10) * args.penalty_block_ratio,
+        "policy_block": max(0.0, policy_block - 0.10) * args.penalty_policy_block_ratio,
+        "execution": max(0.0, 0.60 - executed_over_eligible) * args.penalty_exec_shortfall,
+        "data_valid": max(0.0, 0.999 - data_valid) * args.penalty_data_valid,
+        "ev_instability": stddev(ev_series) * args.penalty_instability_ev,
+        "latency_instability": stddev(latency_series) * args.penalty_instability_latency,
+    }
+    passed = gate_pass(live, min_outcomes)
+    penalties["gate_fail"] = 0.0 if passed else args.penalty_gate_fail
+    penalty_total = sum(penalties.values())
+    objective = ev_net - penalty_total
+    return objective, penalty_total, penalties
+
+
+def _step_towards(current: float, target: float, max_step: float) -> float:
+    max_step = abs(max_step)
+    if max_step <= 0.0:
+        return target
+    delta = target - current
+    if delta > max_step:
+        delta = max_step
+    if delta < -max_step:
+        delta = -max_step
+    return current + delta
+
+
+def drift_bundle(
+    champion: Dict[str, Any],
+    challenger: Dict[str, Any],
+    args: argparse.Namespace,
+) -> Dict[str, Any]:
+    out = json.loads(json.dumps(challenger))
+    cst = champion.get("reload_strategy") or {}
+    dst = out.get("reload_strategy") or {}
+    if cst and dst:
+        if "min_edge_bps" in cst and "min_edge_bps" in dst:
+            dst["min_edge_bps"] = _step_towards(
+                float(cst["min_edge_bps"]), float(dst["min_edge_bps"]), args.drift_edge_step_bps
+            )
+        if "ttl_ms" in cst and "ttl_ms" in dst:
+            dst["ttl_ms"] = int(
+                round(
+                    _step_towards(
+                        float(cst["ttl_ms"]),
+                        float(dst["ttl_ms"]),
+                        float(args.drift_ttl_step_ms),
+                    )
+                )
+            )
+        if "max_spread" in cst and "max_spread" in dst:
+            dst["max_spread"] = _step_towards(
+                float(cst["max_spread"]),
+                float(dst["max_spread"]),
+                args.drift_max_spread_step,
+            )
+        if "base_quote_size" in cst and "base_quote_size" in dst:
+            dst["base_quote_size"] = _step_towards(
+                float(cst["base_quote_size"]),
+                float(dst["base_quote_size"]),
+                args.drift_base_quote_step,
+            )
+        out["reload_strategy"] = dst
+
+    ctk = champion.get("reload_taker") or {}
+    dtk = out.get("reload_taker") or {}
+    if ctk and dtk and "trigger_bps" in ctk and "trigger_bps" in dtk:
+        dtk["trigger_bps"] = _step_towards(
+            float(ctk["trigger_bps"]), float(dtk["trigger_bps"]), args.drift_trigger_step_bps
+        )
+    if ctk and dtk and "max_slippage_bps" in ctk and "max_slippage_bps" in dtk:
+        dtk["max_slippage_bps"] = _step_towards(
+            float(ctk["max_slippage_bps"]),
+            float(dtk["max_slippage_bps"]),
+            args.drift_slippage_step_bps,
+        )
+    out["reload_taker"] = dtk
+
+    ctox = champion.get("reload_toxicity") or {}
+    dtox = out.get("reload_toxicity") or {}
+    if ctox and dtox and "safe_threshold" in ctox and "safe_threshold" in dtox:
+        dtox["safe_threshold"] = _step_towards(
+            float(ctox["safe_threshold"]),
+            float(dtox["safe_threshold"]),
+            args.drift_safe_step,
+        )
+    if ctox and dtox and "caution_threshold" in ctox and "caution_threshold" in dtox:
+        dtox["caution_threshold"] = _step_towards(
+            float(ctox["caution_threshold"]),
+            float(dtox["caution_threshold"]),
+            args.drift_caution_step,
+        )
+    out["reload_toxicity"] = dtox
+
+    return out
+
+
+def evaluate_bundle(
+    session: requests.Session,
+    base_url: str,
+    bundle: Dict[str, Any],
+    args: argparse.Namespace,
+    role: str,
+) -> Dict[str, Any]:
+    apply_bundle(session, base_url, bundle)
+    reset_shadow(session, base_url)
+    time.sleep(max(5, args.cooldown_sec))
+    samples = collect_live_window(
+        session,
+        base_url,
+        args.eval_window_sec,
+        args.poll_interval_sec,
+        args.http_timeout_sec,
+        args.max_sample_read_failures,
+    )
+    live = pick_gate_snapshot(samples)
+    objective, penalty, breakdown = ev_penalty_objective(live, samples, args.min_outcomes, args)
+    return {
+        "role": role,
+        "bundle": bundle,
+        "gate_pass": gate_pass(live, args.min_outcomes),
+        "objective": objective,
+        "ev_net_usdc_p50": float(
+            live.get("ev_net_usdc_p50", live.get("net_markout_10s_usdc_p50", 0.0))
+        ),
+        "penalty_total": penalty,
+        "penalty_breakdown": breakdown,
+        "samples": len(samples),
+        "live": {
+            "window_id": int(live.get("window_id", 0) or 0),
+            "window_outcomes": int(live.get("window_outcomes", live.get("total_outcomes", 0)) or 0),
+            "fillability_10ms": float(live.get("fillability_10ms", 0.0)),
+            "quote_block_ratio": float(live.get("quote_block_ratio", 0.0)),
+            "policy_block_ratio": float(live.get("policy_block_ratio", 0.0)),
+            "tick_to_ack_p99_ms": float(live.get("tick_to_ack_p99_ms", 0.0)),
+            "decision_compute_p99_ms": float(live.get("decision_compute_p99_ms", 0.0)),
+            "feed_in_p99_ms": float((live.get("latency") or {}).get("feed_in_p99_ms", 0.0)),
+            "data_valid_ratio": float(live.get("data_valid_ratio", 1.0)),
+            "net_markout_10s_usdc_p50": float(live.get("net_markout_10s_usdc_p50", 0.0)),
+            "ev_net_usdc_p50": float(
+                live.get("ev_net_usdc_p50", live.get("net_markout_10s_usdc_p50", 0.0))
+            ),
+            "ev_net_usdc_p10": float(live.get("ev_net_usdc_p10", 0.0)),
+            "ev_positive_ratio": float(live.get("ev_positive_ratio", 0.0)),
+            "eligible_count": int(live.get("eligible_count", 0)),
+            "executed_count": int(live.get("executed_count", 0)),
+            "executed_over_eligible": float(live.get("executed_over_eligible", 0.0)),
+            "roi_notional_10s_bps_p50": float(live.get("roi_notional_10s_bps_p50", 0.0)),
+            "gate_fail_reasons": live.get("gate_fail_reasons") or [],
+        },
+    }
+
+
 def parse_args() -> argparse.Namespace:
     p = argparse.ArgumentParser(description="Long-run shadow regression orchestrator")
     p.add_argument("--profile", choices=["quick", "standard", "deep"], default="quick")
     p.add_argument("--run-id", default=default_run_id())
     p.add_argument("--base-url", default="http://127.0.0.1:8080")
+    p.add_argument(
+        "--continuous",
+        action="store_true",
+        help="Run continuous optimization cycles until max-runtime or stop-file is reached",
+    )
     p.add_argument("--cycles", type=int, default=None)
     p.add_argument("--max-cycles", type=int, default=None)
     p.add_argument("--max-runtime-sec", type=int, default=None)
@@ -248,12 +554,73 @@ def parse_args() -> argparse.Namespace:
     p.add_argument("--out-root", default="datasets/reports")
     p.add_argument("--cooldown-sec", type=int, default=None)
     p.add_argument("--min-outcomes", type=int, default=None)
+    p.add_argument("--selection-mode", choices=["score", "robust"], default=None)
+    p.add_argument("--walkforward-windows", type=int, default=None)
+    p.add_argument("--walkforward-cooldown-sec", type=float, default=None)
+    p.add_argument("--top-k-consensus", type=int, default=None)
+    p.add_argument(
+        "--cycle-sleep-sec",
+        type=float,
+        default=2.0,
+        help="Sleep between cycles to avoid tight loop on remote APIs",
+    )
+    p.add_argument(
+        "--http-timeout-sec",
+        type=float,
+        default=8.0,
+        help="Per-request HTTP timeout for control/report endpoints",
+    )
+    p.add_argument(
+        "--max-sample-read-failures",
+        type=int,
+        default=4,
+        help="Consecutive /report/shadow/live failures allowed before ending window",
+    )
+    p.add_argument(
+        "--state-file",
+        default="",
+        help="Champion state path; default: <out-root>/champion_state.json",
+    )
+    p.add_argument(
+        "--stop-file",
+        default="",
+        help="If this file exists, orchestrator exits cleanly at cycle boundary",
+    )
     p.add_argument(
         "--max-estimated-sec",
         type=int,
         default=None,
         help="Hard cap for estimated total runtime; trims cycle count automatically when exceeded",
     )
+    p.add_argument(
+        "--min-objective-delta",
+        type=float,
+        default=0.0005,
+        help="Required objective improvement for challenger promotion",
+    )
+    p.add_argument(
+        "--disable-drift",
+        action="store_true",
+        help="Disable champion->challenger small-step drift; apply raw challenger directly",
+    )
+    p.add_argument("--drift-edge-step-bps", type=float, default=0.25)
+    p.add_argument("--drift-ttl-step-ms", type=int, default=50)
+    p.add_argument("--drift-max-spread-step", type=float, default=0.005)
+    p.add_argument("--drift-base-quote-step", type=float, default=0.50)
+    p.add_argument("--drift-trigger-step-bps", type=float, default=0.50)
+    p.add_argument("--drift-slippage-step-bps", type=float, default=2.0)
+    p.add_argument("--drift-safe-step", type=float, default=0.02)
+    p.add_argument("--drift-caution-step", type=float, default=0.02)
+    p.add_argument("--penalty-latency-ms", type=float, default=0.00002)
+    p.add_argument("--penalty-decision-ms", type=float, default=0.05)
+    p.add_argument("--penalty-feed-ms", type=float, default=0.000005)
+    p.add_argument("--penalty-block-ratio", type=float, default=0.20)
+    p.add_argument("--penalty-policy-block-ratio", type=float, default=0.20)
+    p.add_argument("--penalty-exec-shortfall", type=float, default=0.50)
+    p.add_argument("--penalty-data-valid", type=float, default=80.0)
+    p.add_argument("--penalty-instability-ev", type=float, default=1.0)
+    p.add_argument("--penalty-instability-latency", type=float, default=0.0005)
+    p.add_argument("--penalty-gate-fail", type=float, default=0.20)
     return p.parse_args()
 
 
@@ -262,100 +629,178 @@ def main() -> int:
     started = time.monotonic()
     next_heartbeat = started + max(1.0, args.heartbeat_sec)
     session = requests.Session()
-    day_dir = Path(args.out_root) / utc_day()
-    day_dir.mkdir(parents=True, exist_ok=True)
-    audit_file = day_dir / "long_regression_audit.jsonl"
+    atexit.register(session.close)
+    out_root = Path(args.out_root)
+    out_root.mkdir(parents=True, exist_ok=True)
+
+    state_file = Path(args.state_file) if args.state_file else (out_root / "champion_state.json")
+    stop_file = Path(args.stop_file) if args.stop_file else None
+
+    champion_bundle, champion_snapshot = load_champion_state(state_file)
+    if champion_bundle is not None:
+        print(f"[resume] loaded champion state from {state_file}")
 
-    best_trial: Dict[str, Any] | None = None
     cycle_cap = args.max_cycles if args.max_cycles > 0 else args.cycles
-    per_cycle_trial_sec = max(1, int(min(args.window_sec, args.eval_window_sec)))
-    per_cycle_sec = max(1, int(args.cooldown_sec + args.max_trials * per_cycle_trial_sec + args.eval_window_sec))
-    estimated_total_sec = per_cycle_sec * cycle_cap
-    if args.max_estimated_sec and args.max_estimated_sec > 0 and estimated_total_sec > args.max_estimated_sec:
-        allowed_cycles = max(1, int(args.max_estimated_sec // per_cycle_sec))
-        if allowed_cycles < cycle_cap:
-            print(
-                f"[budget] estimated={estimated_total_sec}s exceeds cap={args.max_estimated_sec}s; "
-                f"trimming cycles {cycle_cap} -> {allowed_cycles}"
-            )
-            cycle_cap = allowed_cycles
-            estimated_total_sec = per_cycle_sec * cycle_cap
-    print(
-        f"[profile] {args.profile} cycles={cycle_cap} per_cycle~{per_cycle_sec}s "
-        f"estimated~{estimated_total_sec}s max_runtime={args.max_runtime_sec}s"
+    per_cycle_trial_sec = max(
+        1,
+        int(
+            min(args.window_sec, args.eval_window_sec) * max(1, int(args.walkforward_windows))
+            + max(0.0, float(args.walkforward_cooldown_sec))
+            * max(0, int(args.walkforward_windows) - 1)
+        ),
+    )
+    # Per cycle includes both champion and challenger online windows.
+    per_cycle_sec = max(
+        1,
+        int(
+            args.cooldown_sec
+            + args.max_trials * per_cycle_trial_sec
+            + (2 * (args.cooldown_sec + args.eval_window_sec))
+        ),
     )
+    if args.continuous:
+        print(
+            f"[profile] {args.profile} cycles=continuous per_cycle~{per_cycle_sec}s "
+            f"max_runtime={args.max_runtime_sec}s mode={args.selection_mode} "
+            f"wf_windows={args.walkforward_windows}"
+        )
+    else:
+        estimated_total_sec = per_cycle_sec * cycle_cap
+        if (
+            args.max_estimated_sec
+            and args.max_estimated_sec > 0
+            and estimated_total_sec > args.max_estimated_sec
+        ):
+            allowed_cycles = max(1, int(args.max_estimated_sec // per_cycle_sec))
+            if allowed_cycles < cycle_cap:
+                print(
+                    f"[budget] estimated={estimated_total_sec}s exceeds cap={args.max_estimated_sec}s; "
+                    f"trimming cycles {cycle_cap} -> {allowed_cycles}"
+                )
+                cycle_cap = allowed_cycles
+                estimated_total_sec = per_cycle_sec * cycle_cap
+        print(
+            f"[profile] {args.profile} cycles={cycle_cap} per_cycle~{per_cycle_sec}s "
+            f"estimated~{estimated_total_sec}s max_runtime={args.max_runtime_sec}s "
+            f"mode={args.selection_mode} wf_windows={args.walkforward_windows}"
+        )
+
     consecutive_failures = 0
-    for cycle in range(1, cycle_cap + 1):
+    cycle = 0
+    last_audit_file: Path | None = None
+    last_daily_state_file: Path | None = None
+    while True:
+        cycle += 1
+        if not args.continuous and cycle > cycle_cap:
+            break
+        if stop_file is not None and stop_file.exists():
+            print(f"[stop] stop-file detected: {stop_file}")
+            break
         if args.max_runtime_sec > 0 and (time.monotonic() - started) >= args.max_runtime_sec:
             print("[stop] max-runtime-sec reached; ending orchestrator")
             break
+
         budget_remaining = 0
         if args.max_runtime_sec > 0:
             budget_remaining = max(1, int(args.max_runtime_sec - (time.monotonic() - started)))
-        run_param_regression(args, cycle, budget_remaining)
-        trial = read_best_trial(day_dir)
+        trial_run_id = f"{args.run_id}-c{cycle:04d}"
+        run_param_regression(args, trial_run_id, budget_remaining)
+        trial = read_best_trial(out_root, trial_run_id)
         if trial is None:
             raise RuntimeError("No best trial found after param_regression")
 
-        apply_trial(session, args.base_url, trial)
-        # Use cycle-local statistics for gate decision; avoid cumulative contamination.
-        reset_shadow(session, args.base_url)
-        time.sleep(max(10, args.cooldown_sec))
-        samples = collect_live_window(
-            session,
-            args.base_url,
-            args.eval_window_sec,
-            args.poll_interval_sec,
-        )
-        live = pick_gate_snapshot(samples)
-        passed = gate_pass(live, args.min_outcomes)
-
-        if passed:
-            best_trial = trial
+        challenger_bundle = to_bundle(trial)
+        if champion_bundle is not None and not args.disable_drift:
+            challenger_bundle = drift_bundle(champion_bundle, challenger_bundle, args)
+
+        champion_eval: Dict[str, Any] | None = None
+        if champion_bundle is not None:
+            champion_eval = evaluate_bundle(session, args.base_url, champion_bundle, args, "champion")
+
+        challenger_eval = evaluate_bundle(session, args.base_url, challenger_bundle, args, "challenger")
+
+        decision = "bootstrap_reject"
+        rollback_applied = False
+        promoted = False
+        if champion_bundle is None:
+            if challenger_eval["gate_pass"]:
+                champion_bundle = challenger_bundle
+                champion_snapshot = challenger_eval
+                promoted = True
+                decision = "bootstrap_promote"
+            else:
+                decision = "bootstrap_reject"
+        else:
+            champ_obj = float(champion_eval["objective"] if champion_eval else -1e9)
+            chall_obj = float(challenger_eval["objective"])
+            improve = chall_obj - champ_obj
+            if challenger_eval["gate_pass"] and improve >= args.min_objective_delta:
+                champion_bundle = challenger_bundle
+                champion_snapshot = challenger_eval
+                promoted = True
+                decision = "promote_challenger"
+            else:
+                apply_bundle(session, args.base_url, champion_bundle)
+                rollback_applied = True
+                if champion_eval is not None:
+                    champion_snapshot = champion_eval
+                decision = "rollback_to_champion"
+
+        final_eval = champion_snapshot if champion_snapshot is not None else challenger_eval
+        final_pass = bool(final_eval["gate_pass"])
+        if final_pass:
             consecutive_failures = 0
-        elif best_trial is not None:
-            apply_trial(session, args.base_url, best_trial)
-            consecutive_failures += 1
         else:
             consecutive_failures += 1
 
+        day_dir = out_root / utc_day()
+        day_dir.mkdir(parents=True, exist_ok=True)
+        audit_file = day_dir / "long_regression_audit.jsonl"
+        daily_state_file = day_dir / "champion_state.json"
+
         row = {
             "run_id": args.run_id,
             "ts_utc": datetime.now(timezone.utc).isoformat(),
             "cycle": cycle,
-            "applied_trial": trial,
-            "gate_ready": bool(live.get("gate_ready", False)),
-            "gate_pass": passed,
-            "live": {
-                "window_id": int(live.get("window_id", 0) or 0),
-                "window_outcomes": int(live.get("window_outcomes", live.get("total_outcomes", 0)) or 0),
-                "fillability_10ms": float(live.get("fillability_10ms", 0.0)),
-                "quote_block_ratio": float(live.get("quote_block_ratio", 0.0)),
-                "policy_block_ratio": float(live.get("policy_block_ratio", 0.0)),
-                "tick_to_ack_p99_ms": float(live.get("tick_to_ack_p99_ms", 0.0)),
-                "decision_compute_p99_ms": float(live.get("decision_compute_p99_ms", 0.0)),
-                "feed_in_p99_ms": float((live.get("latency") or {}).get("feed_in_p99_ms", 0.0)),
-                "data_valid_ratio": float(live.get("data_valid_ratio", 1.0)),
-                "net_markout_10s_usdc_p50": float(live.get("net_markout_10s_usdc_p50", 0.0)),
-                "ev_net_usdc_p50": float(live.get("ev_net_usdc_p50", live.get("net_markout_10s_usdc_p50", 0.0))),
-                "ev_net_usdc_p10": float(live.get("ev_net_usdc_p10", 0.0)),
-                "ev_positive_ratio": float(live.get("ev_positive_ratio", 0.0)),
-                "eligible_count": int(live.get("eligible_count", 0)),
-                "executed_count": int(live.get("executed_count", 0)),
-                "executed_over_eligible": float(live.get("executed_over_eligible", 0.0)),
-                "roi_notional_10s_bps_p50": float(live.get("roi_notional_10s_bps_p50", 0.0)),
-                "gate_fail_reasons": live.get("gate_fail_reasons") or [],
-            },
-            "min_outcomes": args.min_outcomes,
+            "trial_run_id": trial_run_id,
+            "decision": decision,
+            "promoted": promoted,
+            "rollback_applied": rollback_applied,
+            "min_objective_delta": args.min_objective_delta,
+            "champion_eval": champion_eval,
+            "challenger_eval": challenger_eval,
+            "final_eval": final_eval,
+            "final_gate_pass": final_pass,
             "eval_window_sec": args.eval_window_sec,
-            "rollback_applied": (not passed and best_trial is not None),
-            "eval_samples": len(samples),
         }
         with audit_file.open("a", encoding="utf-8") as f:
             f.write(json.dumps(row, ensure_ascii=True) + "\n")
+        last_audit_file = audit_file
+
+        if champion_bundle is not None:
+            save_champion_state(
+                daily_state_file,
+                args.run_id,
+                cycle,
+                decision,
+                champion_bundle,
+                final_eval,
+            )
+            if state_file.resolve() != daily_state_file.resolve():
+                save_champion_state(
+                    state_file,
+                    args.run_id,
+                    cycle,
+                    decision,
+                    champion_bundle,
+                    final_eval,
+                )
+            last_daily_state_file = daily_state_file
+
+        cycle_text = f"{cycle}/{cycle_cap}" if not args.continuous else f"{cycle}/inf"
         print(
-            f"[cycle {cycle}/{cycle_cap}] gate_pass={passed} "
-            f"net_usdc={row['live']['net_markout_10s_usdc_p50']:.6f}"
+            f"[cycle {cycle_text}] decision={decision} final_pass={final_pass} "
+            f"final_obj={float(final_eval['objective']):.6f} ev={float(final_eval['ev_net_usdc_p50']):.6f}"
         )
         now = time.monotonic()
         if now >= next_heartbeat:
@@ -370,8 +815,17 @@ def main() -> int:
                 f"[stop] fail-fast-threshold reached with {consecutive_failures} consecutive failures"
             )
             break
-
-    print(f"wrote={audit_file}")
+        if args.cycle_sleep_sec > 0:
+            time.sleep(args.cycle_sleep_sec)
+
+    if last_audit_file is not None:
+        print(f"wrote={last_audit_file}")
+    if last_daily_state_file is not None:
+        print(f"wrote={last_daily_state_file}")
+    if state_file.exists():
+        print(f"wrote={state_file}")
+    else:
+        print(f"state_not_written={state_file}")
     return 0
 
 
diff --git a/scripts/network_monitor.py b/scripts/network_monitor.py
new file mode 100644
index 0000000..660931c
--- /dev/null
+++ b/scripts/network_monitor.py
@@ -0,0 +1,299 @@
+#!/usr/bin/env python3
+"""
+PolyEdge å®žæ—¶ç½‘ç»œç›‘æŽ§å·¥å…·
+æ˜¾ç¤ºå®žæ—¶ç½‘ç»œçŠ¶æ€å’Œå»¶è¿Ÿç»Ÿè®¡
+
+ä½¿ç”¨:
+    # åŸºæœ¬ç›‘æŽ§
+    python3 scripts/network_monitor.py
+
+    # è¯¦ç»†ç›‘æŽ§ (æ˜¾ç¤ºæ‰€æœ‰ç»Ÿè®¡)
+    python3 scripts/network_monitor.py --detail
+
+    # æŒç»­è¿è¡Œ
+    python3 scripts/network_monitor.py --interval 5 --duration 300
+"""
+
+import asyncio
+import socket
+import struct
+import time
+import argparse
+import statistics
+import os
+from datetime import datetime
+from typing import List, Dict, Optional
+import json
+
+
+class NetworkMonitor:
+    """ç½‘ç»œç›‘æŽ§å™¨"""
+
+    def __init__(self, target: str = "172.31.44.26", port: int = 6666):
+        self.target = target
+        self.port = port
+        self.latencies: List[float] = []
+        self.max_samples = 1000
+        self.last_seq = 0
+        self.gaps = 0
+        self.total_received = 0
+        self.errors = 0
+        self.start_time = time.time()
+
+    def update_latency(self, seq: int, send_ts: int):
+        """æ›´æ–°å»¶è¿Ÿç»Ÿè®¡"""
+        recv_ts = time.perf_counter_ns()
+        rtt_ns = recv_ts - send_ts
+        one_way_ns = rtt_ns // 2
+        latency_ms = one_way_ns / 1e6
+
+        self.latencies.append(latency_ms)
+        if len(self.latencies) > self.max_samples:
+            self.latencies = self.latencies[-self.max_samples:]
+
+        # Gap æ£€æµ‹
+        if self.last_seq > 0 and seq > self.last_seq + 1:
+            self.gaps += (seq - self.last_seq - 1)
+        self.last_seq = seq
+        self.total_received += 1
+
+    def get_stats(self) -> Dict:
+        """èŽ·å–å½“å‰ç»Ÿè®¡"""
+        if not self.latencies:
+            return {
+                "samples": 0,
+                "avg_ms": 0,
+                "p50_ms": 0,
+                "p95_ms": 0,
+                "p99_ms": 0,
+                "min_ms": 0,
+                "max_ms": 0,
+                "jitter_ms": 0,
+                "gaps": self.gaps,
+                "received": self.total_received,
+                "errors": self.errors,
+                "uptime_sec": time.time() - self.start_time
+            }
+
+        sorted_latencies = sorted(self.latencies)
+        n = len(sorted_latencies)
+
+        jitter = 0
+        if n > 1:
+            diffs = [abs(sorted_latencies[i] - sorted_latencies[i-1])
+                    for i in range(1, n)]
+            jitter = statistics.median(diffs)
+
+        return {
+            "samples": n,
+            "avg_ms": statistics.mean(self.latencies),
+            "p50_ms": sorted_latencies[int(n * 0.5)],
+            "p95_ms": sorted_latencies[int(n * 0.95)] if n >= 20 else sorted_latencies[-1],
+            "p99_ms": sorted_latencies[int(n * 0.99)] if n >= 100 else sorted_latencies[-1],
+            "min_ms": sorted_latencies[0],
+            "max_ms": sorted_latencies[-1],
+            "jitter_ms": jitter,
+            "gaps": self.gaps,
+            "received": self.total_received,
+            "errors": self.errors,
+            "uptime_sec": time.time() - self.start_time
+        }
+
+    def print_stats(self, detail: bool = False):
+        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
+        stats = self.get_stats()
+
+        # æ¸…é™¤å±å¹•
+        os.system('cls' if os.name == 'nt' else 'clear')
+
+        print(f"\n{'='*70}")
+        print(f"ðŸ“¡ PolyEdge ç½‘ç»œç›‘æŽ§")
+        print(f"{'='*70}")
+        print(f"ç›®æ ‡: {self.target}:{self.port}")
+        print(f"è¿è¡Œæ—¶é—´: {stats['uptime_sec']:.0f}s")
+        print(f"{'='*70}")
+
+        # å»¶è¿Ÿç»Ÿè®¡
+        print(f"\nâ±ï¸  å»¶è¿Ÿç»Ÿè®¡ (æœ€è¿‘ {stats['samples']} æ ·æœ¬)")
+        print(f"   æœ€å°:     {stats['min_ms']:>8.3f} ms")
+        print(f"   æœ€å¤§:     {stats['max_ms']:>8.3f} ms")
+        print(f"   å¹³å‡:     {stats['avg_ms']:>8.3f} ms")
+        print(f"   P50:      {stats['p50_ms']:>8.3f} ms")
+        print(f"   P95:      {stats['p95_ms']:>8.3f} ms")
+        print(f"   P99:      {stats['p99_ms']:>8.3f} ms")
+        print(f"   æŠ–åŠ¨:     {stats['jitter_ms']:>8.3f} ms")
+
+        # ç½‘ç»œè´¨é‡
+        print(f"\nðŸ“¶ ç½‘ç»œè´¨é‡")
+        loss_rate = (stats['gaps'] / stats['received'] * 100) if stats['received'] > 0 else 0
+        print(f"   æŽ¥æ”¶æ¶ˆæ¯: {stats['received']:,}")
+        print(f"   Gap æ•°:   {stats['gaps']:,} ({loss_rate:.4f}%)")
+        print(f"   é”™è¯¯æ•°:   {stats['errors']:,}")
+
+        # åžåé‡ä¼°ç®—
+        if stats['uptime_sec'] > 0:
+            msg_rate = stats['received'] / stats['uptime_sec']
+            print(f"   æ¶ˆæ¯çŽ‡:   {msg_rate:,.0f} msg/s")
+
+        if detail:
+            # è¯¦ç»†ç»Ÿè®¡
+            print(f"\nðŸ“Š è¯¦ç»†ç»Ÿè®¡")
+            print(f"   æ ·æœ¬ç¼“å†²åŒº: {len(self.latencies)}/{self.max_samples}")
+
+            # æœ€è¿‘ 10 ä¸ªå»¶è¿Ÿ
+            recent = self.latencies[-10:] if self.latencies else []
+            if recent:
+                print(f"   æœ€è¿‘å»¶è¿Ÿ: {[f'{x:.2f}' for x in recent]}")
+
+            # å»¶è¿Ÿåˆ†å¸ƒ
+            if stats['samples'] > 0:
+                ranges = [
+                    (0, 1, "0-1ms"),
+                    (1, 2, "1-2ms"),
+                    (2, 5, "2-5ms"),
+                    (5, 10, "5-10ms"),
+                    (10, 100, "10ms+")
+                ]
+                print(f"   å»¶è¿Ÿåˆ†å¸ƒ:")
+                for low, high, label in ranges:
+                    count = sum(1 for x in self.latencies if low <= x < high)
+                    pct = count / len(self.latencies) * 100
+                    bar = "â–ˆ" * int(pct / 2)
+                    print(f"      {label:>8}: {count:>5} ({pct:>5.1f}%) {bar}")
+
+        print(f"\n{'='*70}")
+
+        return stats
+
+
+async def ping_target(target: str, port: int) -> Optional[float]:
+    """Ping ç›®æ ‡èŽ·å– RTT"""
+    try:
+        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
+        sock.settimeout(1)
+
+        send_ts = time.perf_counter_ns()
+        sock.sendto(b"ping", (target, port))
+        sock.recvfrom(1024)
+        recv_ts = time.perf_counter_ns()
+
+        sock.close()
+        return (recv_ts - send_ts) / 1e6  # ms
+
+    except Exception:
+        return None
+
+
+async def monitor_loop(target: str, port: int, interval: int, detail: bool):
+    """ç›‘æŽ§å¾ªçŽ¯"""
+    monitor = NetworkMonitor(target, port)
+
+    # åˆ›å»º UDP ç›‘å¬ (ç®€å• echo å“åº”æµ‹è¯•)
+    print("å¯åŠ¨ç›‘æŽ§...")
+    print(f"ç›®æ ‡: {target}:{port}")
+
+    # å¯åŠ¨ ping ä»»åŠ¡
+    ping_latency = 0
+
+    async def ping_task():
+        nonlocal ping_latency
+        while True:
+            rtt = await ping_target(target, port)
+            if rtt:
+                ping_latency = rtt
+            await asyncio.sleep(interval)
+
+    # å¯åŠ¨ ping
+    ping_task_handle = asyncio.create_task(ping_task())
+
+    try:
+        while True:
+            # æ‰“å°ç»Ÿè®¡
+            stats = monitor.print_stats(detail)
+
+            # æ‰“å° ping ç»“æžœ
+            if ping_latency > 0:
+                print(f"   TCP RTT:   {ping_latency:>8.3f} ms")
+
+            # çŠ¶æ€è¯„ä¼°
+            print(f"\nðŸ” çŠ¶æ€è¯„ä¼°:")
+            if stats['samples'] > 0:
+                if stats['p99_ms'] < 5:
+                    print("   âœ… ä¼˜ç§€ - P99 < 5ms")
+                elif stats['p99_ms'] < 10:
+                    print("   âœ… è‰¯å¥½ - P99 < 10ms")
+                elif stats['p99_ms'] < 20:
+                    print("   âš ï¸ ä¸€èˆ¬ - P99 < 20ms")
+                else:
+                    print("   âŒ è¾ƒå·® - P99 > 20ms")
+
+                if stats['jitter_ms'] < 1:
+                    print("   âœ… ä½ŽæŠ–åŠ¨")
+                elif stats['jitter_ms'] < 3:
+                    print("   âš ï¸ ä¸­ç­‰æŠ–åŠ¨")
+                else:
+                    print("   âŒ é«˜æŠ–åŠ¨")
+
+                loss_rate = (stats['gaps'] / stats['received'] * 100) if stats['received'] > 0 else 0
+                if loss_rate < 0.01:
+                    print("   âœ… æ— ä¸¢åŒ…")
+                elif loss_rate < 0.1:
+                    print("   âš ï¸ è½»å¾®ä¸¢åŒ…")
+                else:
+                    print("   âŒ ä¸¥é‡ä¸¢åŒ…")
+
+            await asyncio.sleep(interval)
+
+    except KeyboardInterrupt:
+        print("\n\nåœæ­¢ç›‘æŽ§...")
+        ping_task_handle.cancel()
+
+
+async def quick_test(target: str, port: int, count: int = 100):
+    """å¿«é€Ÿå»¶è¿Ÿæµ‹è¯•"""
+    print(f"\n{'='*60}")
+    print(f"âš¡ å¿«é€Ÿå»¶è¿Ÿæµ‹è¯•: {target}:{port} ({count} æ¬¡)")
+    print(f"{'='*60}")
+
+    latencies = []
+
+    for i in range(count):
+        rtt = await ping_target(target, port)
+        if rtt:
+            latencies.append(rtt)
+            print(f"\rè¿›åº¦: {i+1}/{count}", end="", flush=True)
+        await asyncio.sleep(0.1)
+
+    print(f"\n\nå®Œæˆ! æœ‰æ•ˆæ ·æœ¬: {len(latencies)}/{count}")
+
+    if latencies:
+        latencies.sort()
+        n = len(latencies)
+        print(f"\nðŸ“Š å»¶è¿Ÿç»Ÿè®¡:")
+        print(f"   æœ€å°:  {min(latencies):.3f} ms")
+        print(f"   æœ€å¤§:  {max(latencies):.3f} ms")
+        print(f"   å¹³å‡:  {statistics.mean(latencies):.3f} ms")
+        print(f"   P50:   {latencies[int(n*0.5)]:.3f} ms")
+        print(f"   P95:   {latencies[int(n*0.95)]:.3f} ms")
+        print(f"   P99:   {latencies[int(n*0.99)]:.3f} ms")
+
+
+async def main():
+    parser = argparse.ArgumentParser(description="PolyEdge ç½‘ç»œç›‘æŽ§")
+    parser.add_argument("--target", default="172.31.44.26", help="ç›®æ ‡åœ°å€ (ä¸œäº¬)")
+    parser.add_argument("--port", type=int, default=6666, help="ç›®æ ‡ç«¯å£")
+    parser.add_argument("--interval", type=int, default=3, help="åˆ·æ–°é—´éš”(ç§’)")
+    parser.add_argument("--duration", type=int, help="è¿è¡ŒæŒç»­æ—¶é—´(ç§’)")
+    parser.add_argument("--detail", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")
+    parser.add_argument("--quick", action="store_true", help="å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
+
+    args = parser.parse_args()
+
+    if args.quick:
+        await quick_test(args.target, args.port)
+    else:
+        await monitor_loop(args.target, args.port, args.interval, args.detail)
+
+
+if __name__ == "__main__":
+    asyncio.run(main())
diff --git a/scripts/network_stress_test.py b/scripts/network_stress_test.py
new file mode 100644
index 0000000..1e2c62c
--- /dev/null
+++ b/scripts/network_stress_test.py
@@ -0,0 +1,592 @@
+#!/usr/bin/env python3
+"""
+PolyEdge ç½‘ç»œåŽ‹æµ‹å·¥å…·
+ç”¨äºŽæµ‹è¯•ä¸œäº¬ -> çˆ±å°”å…° VPC ç½‘ç»œæ€§èƒ½
+
+åŠŸèƒ½:
+1. UDP å»¶è¿Ÿæµ‹è¯• (RTT, å•ç¨‹)
+2. åžåé‡æµ‹è¯• (æ¶ˆæ¯/ç§’)
+3. ä¸¢åŒ…çŽ‡æµ‹è¯•
+4. æŠ–åŠ¨æµ‹è¯•
+5. å¯¹æ¯”å…¬ç½‘ç›´è¿ž
+
+ä½¿ç”¨:
+    # åŸºæœ¬å»¶è¿Ÿæµ‹è¯•
+    python3 scripts/network_stress_test.py --mode latency
+
+    # åžåé‡æµ‹è¯•
+    python3 scripts/network_stress_test.py --mode throughput --target 10.0.3.123 --port 6666
+
+    # ä¸¢åŒ…çŽ‡æµ‹è¯•
+    python3 scripts/network_stress_test.py --mode packet-loss --target 10.0.3.123 --port 6666
+
+    # ç»¼åˆåŽ‹æµ‹
+    python3 scripts/network_stress_test.py --mode stress --target 10.0.3.123 --port 6666 --duration 60
+"""
+
+import asyncio
+import socket
+import struct
+import time
+import argparse
+import statistics
+import json
+import random
+from datetime import datetime
+from dataclasses import dataclass, asdict
+from typing import List, Optional
+import numpy as np
+
+PROBE_FMT = "!QQ"
+PROBE_SIZE = struct.calcsize(PROBE_FMT)
+
+
+# ============================================================
+# æ•°æ®ç»“æž„
+# ============================================================
+
+@dataclass
+class LatencyResult:
+    """å»¶è¿Ÿæµ‹è¯•ç»“æžœ"""
+    min_ms: float
+    max_ms: float
+    avg_ms: float
+    p50_ms: float
+    p95_ms: float
+    p99_ms: float
+    std_ms: float
+    jitter_ms: float
+    samples: int
+
+
+@dataclass
+class ThroughputResult:
+    """åžåé‡æµ‹è¯•ç»“æžœ"""
+    total_msgs: int
+    total_bytes: int
+    duration_sec: float
+    msgs_per_sec: float
+    mbps: float
+
+
+@dataclass
+class PacketLossResult:
+    """ä¸¢åŒ…æµ‹è¯•ç»“æžœ"""
+    sent: int
+    received: int
+    lost: int
+    loss_rate_percent: float
+    avg_rtt_ms: float
+
+
+@dataclass
+class StressResult:
+    """åŽ‹åŠ›æµ‹è¯•ç»“æžœ"""
+    duration_sec: float
+    total_packets: int
+    total_bytes: int
+    latency: LatencyResult
+    packet_loss: PacketLossResult
+    errors: int
+
+
+# ============================================================
+# UDP å»¶è¿Ÿæµ‹è¯•
+# ============================================================
+
+async def test_latency_udp(target: str, port: int, duration_sec: int = 30,
+                          rate_hz: int = 100) -> LatencyResult:
+    """
+    UDP å»¶è¿Ÿæµ‹è¯•
+    å‘é€å¸¦æ—¶é—´æˆ³çš„æŽ¢æµ‹åŒ…ï¼Œæµ‹é‡ RTT
+    """
+    print(f"\n{'='*60}")
+    print(f"ðŸ”¬ UDP å»¶è¿Ÿæµ‹è¯•: {target}:{port}")
+    print(f"   æŒç»­: {duration_sec}s, é¢‘çŽ‡: {rate_hz}Hz")
+    print(f"{'='*60}")
+
+    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
+    sock.settimeout(2)
+
+    latencies = []
+    errors = 0
+    start_time = time.time()
+
+    # æŽ¢æµ‹åŒ…æ ¼å¼: seq(8) + send_ts_nanos(8)
+    seq = 0
+    packet_interval = 1.0 / rate_hz
+
+    try:
+        while time.time() - start_time < duration_sec:
+            loop_start = time.perf_counter()
+
+            try:
+                seq += 1
+                send_ts = time.perf_counter_ns()
+
+                # æ‰“åŒ…: åºåˆ—å· + å‘é€æ—¶é—´
+                payload = struct.pack(PROBE_FMT, seq, send_ts)
+                sock.sendto(payload, (target, port))
+
+                # ç­‰å¾…å“åº” (ç®€å• echo)
+                try:
+                    resp, _ = sock.recvfrom(1024)
+                    recv_ts = time.perf_counter_ns()
+
+                    if len(resp) >= PROBE_SIZE:
+                        resp_seq, resp_ts = struct.unpack(PROBE_FMT, resp[:PROBE_SIZE])
+                        if resp_seq == seq:
+                            # RTT = recv - send (çº³ç§’)
+                            rtt_ns = recv_ts - send_ts
+                            # å•ç¨‹å»¶è¿Ÿ = RTT / 2 (å‡è®¾å¯¹ç§°)
+                            one_way_ns = rtt_ns // 2
+                            latencies.append(one_way_ns / 1e6)  # è½¬æ¢ä¸ºæ¯«ç§’
+                except socket.timeout:
+                    errors += 1
+
+            except Exception as e:
+                errors += 1
+
+            # é€ŸçŽ‡æŽ§åˆ¶
+            elapsed = time.perf_counter() - loop_start
+            sleep_time = packet_interval - elapsed
+            if sleep_time > 0:
+                time.sleep(sleep_time)
+
+    finally:
+        sock.close()
+
+    if not latencies:
+        return LatencyResult(0, 0, 0, 0, 0, 0, 0, 0, 0)
+
+    latencies.sort()
+    n = len(latencies)
+
+    return LatencyResult(
+        min_ms=latencies[0],
+        max_ms=latencies[-1],
+        avg_ms=statistics.mean(latencies),
+        p50_ms=latencies[int(n * 0.5)],
+        p95_ms=latencies[int(n * 0.95)],
+        p99_ms=latencies[int(n * 0.99)],
+        std_ms=statistics.stdev(latencies) if n > 1 else 0,
+        jitter_ms=statistics.median([abs(latencies[i] - latencies[i-1])
+                                     for i in range(1, n)]) if n > 1 else 0,
+        samples=n
+    )
+
+
+# ============================================================
+# åžåé‡æµ‹è¯•
+# ============================================================
+
+async def test_throughput_udp(target: str, port: int, duration_sec: int = 10,
+                              msg_size: int = 64, rate_hz: int = 10000) -> ThroughputResult:
+    """
+    UDP åžåé‡æµ‹è¯•
+    å‘é€å¤§é‡æ•°æ®åŒ…ï¼Œæµ‹é‡åžåé‡
+    """
+    print(f"\n{'='*60}")
+    print(f"ðŸ“ˆ UDP åžåé‡æµ‹è¯•: {target}:{port}")
+    print(f"   æŒç»­: {duration_sec}s, åŒ…å¤§å°: {msg_size}B, é¢‘çŽ‡: {rate_hz}Hz")
+    print(f"{'='*60}")
+
+    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
+    sock.settimeout(1)
+
+    # æž„é€ å›ºå®šå¤§å°æ•°æ®åŒ…
+    payload = struct.pack(PROBE_FMT, 0, 0) + b'X' * (msg_size - PROBE_SIZE)
+
+    total_bytes = 0
+    total_msgs = 0
+    start_time = time.time()
+    packet_interval = 1.0 / rate_hz
+
+    try:
+        while time.time() - start_time < duration_sec:
+            loop_start = time.perf_counter()
+
+            try:
+                seq = total_msgs + 1
+                send_ts = time.perf_counter_ns()
+                packet = struct.pack(PROBE_FMT, seq, send_ts) + payload[:msg_size-PROBE_SIZE]
+
+                sock.sendto(packet, (target, port))
+                total_bytes += len(packet)
+                total_msgs += 1
+
+            except Exception as e:
+                pass
+
+            # é€ŸçŽ‡æŽ§åˆ¶
+            elapsed = time.perf_counter() - loop_start
+            sleep_time = packet_interval - elapsed
+            if sleep_time > 0:
+                time.sleep(sleep_time)
+
+    finally:
+        sock.close()
+
+    actual_duration = time.time() - start_time
+
+    return ThroughputResult(
+        total_msgs=total_msgs,
+        total_bytes=total_bytes,
+        duration_sec=actual_duration,
+        msgs_per_sec=total_msgs / actual_duration,
+        mbps=total_bytes * 8 / actual_duration / 1e6
+    )
+
+
+# ============================================================
+# ä¸¢åŒ…çŽ‡æµ‹è¯•
+# ============================================================
+
+async def test_packet_loss_udp(target: str, port: int, duration_sec: int = 30,
+                               rate_hz: int = 100) -> PacketLossResult:
+    """
+    UDP ä¸¢åŒ…çŽ‡æµ‹è¯•
+    å‘é€åºåˆ—å·æ•°æ®åŒ…ï¼Œæ£€æµ‹ä¸¢åŒ…
+    """
+    print(f"\n{'='*60}")
+    print(f"ðŸ“¦ UDP ä¸¢åŒ…çŽ‡æµ‹è¯•: {target}:{port}")
+    print(f"   æŒç»­: {duration_sec}s, é¢‘çŽ‡: {rate_hz}Hz")
+    print(f"{'='*60}")
+
+    # éœ€è¦åœ¨ç›®æ ‡ç«¯è¿è¡Œ echo æœåŠ¡å™¨
+    # è¿™é‡Œä½¿ç”¨ç®€å•æ¨¡å¼: å‘é€ä½†ä¸ç­‰å¾…å“åº”
+
+    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
+    sock.settimeout(0.5)
+
+    sent = 0
+    received = 0
+    rtts = []
+    start_time = time.time()
+    packet_interval = 1.0 / rate_hz
+
+    try:
+        while time.time() - start_time < duration_sec:
+            loop_start = time.perf_counter()
+
+            try:
+                sent += 1
+                send_ts = time.perf_counter_ns()
+
+                payload = struct.pack(PROBE_FMT, sent, send_ts)
+                sock.sendto(payload, (target, port))
+
+                # å°è¯•æŽ¥æ”¶å“åº”
+                try:
+                    resp, _ = sock.recvfrom(1024)
+                    recv_ts = time.perf_counter_ns()
+
+                    if len(resp) >= PROBE_SIZE:
+                        seq, _ = struct.unpack(PROBE_FMT, resp[:PROBE_SIZE])
+                        received += 1
+                        rtt = (recv_ts - send_ts) / 1e6
+                        rtts.append(rtt)
+                except socket.timeout:
+                    pass
+
+            except Exception as e:
+                pass
+
+            elapsed = time.perf_counter() - loop_start
+            sleep_time = packet_interval - elapsed
+            if sleep_time > 0:
+                time.sleep(sleep_time)
+
+    finally:
+        sock.close()
+
+    lost = sent - received
+    loss_rate = (lost / sent * 100) if sent > 0 else 0
+
+    return PacketLossResult(
+        sent=sent,
+        received=received,
+        lost=lost,
+        loss_rate_percent=loss_rate,
+        avg_rtt_ms=statistics.mean(rtts) if rtts else 0
+    )
+
+
+# ============================================================
+# ç»¼åˆåŽ‹åŠ›æµ‹è¯•
+# ============================================================
+
+async def test_stress(target: str, port: int, duration_sec: int = 60) -> StressResult:
+    """
+    ç»¼åˆåŽ‹åŠ›æµ‹è¯•
+    åŒæ—¶æµ‹è¯•å»¶è¿Ÿã€åžåã€ä¸¢åŒ…
+    """
+    print(f"\n{'='*60}")
+    print(f"ðŸ’ª ç»¼åˆåŽ‹åŠ›æµ‹è¯•: {target}:{port}")
+    print(f"   æŒç»­: {duration_sec}s")
+    print(f"{'='*60}")
+
+    # å¹¶è¡Œè¿è¡Œå¤šä¸ªæµ‹è¯•
+    latency_task = asyncio.create_task(
+        test_latency_udp(target, port, duration_sec, rate_hz=50)
+    )
+    throughput_task = asyncio.create_task(
+        test_throughput_udp(target, port, min(duration_sec, 10), msg_size=64, rate_hz=5000)
+    )
+    packet_loss_task = asyncio.create_task(
+        test_packet_loss_udp(target, port, duration_sec, rate_hz=50)
+    )
+
+    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
+    latency, throughput, packet_loss = await asyncio.gather(
+        latency_task, throughput_task, packet_loss_task,
+        return_exceptions=True
+    )
+
+    # å¤„ç†å¼‚å¸¸
+    errors = 0
+    if isinstance(latency, Exception):
+        errors += 1
+        latency = LatencyResult(0, 0, 0, 0, 0, 0, 0, 0, 0)
+    if isinstance(throughput, Exception):
+        errors += 1
+        throughput = ThroughputResult(0, 0, 0, 0, 0)
+    if isinstance(packet_loss, Exception):
+        errors += 1
+        packet_loss = PacketLossResult(0, 0, 0, 0, 0)
+
+    return StressResult(
+        duration_sec=duration_sec,
+        total_packets=throughput.total_msgs,
+        total_bytes=throughput.total_bytes,
+        latency=latency,
+        packet_loss=packet_loss,
+        errors=errors
+    )
+
+
+# ============================================================
+# å…¬ç½‘ç›´è¿žæµ‹è¯•
+# ============================================================
+
+async def test_direct_binance():
+    """
+    æµ‹è¯•å…¬ç½‘ç›´è¿žå»¶è¿Ÿ (çˆ±å°”å…° -> Binance)
+    """
+    print(f"\n{'='*60}")
+    print(f"ðŸŒ å…¬ç½‘ç›´è¿žæµ‹è¯•: çˆ±å°”å…° -> Binance")
+    print(f"{'='*60}")
+
+    import websockets
+
+    latencies = []
+    ws = None
+
+    try:
+        ws = await websockets.connect("wss://stream.binance.com:9443/ws/btcusdt@trade")
+
+        for i in range(100):
+            msg = await ws.recv()
+            data = json.loads(msg)
+
+            # Binance äº‹ä»¶æ—¶é—´æˆ³ (æ¯«ç§’)
+            exchange_ts = int(data['E'])
+            recv_ts = int(time.time() * 1000)
+
+            latency = recv_ts - exchange_ts
+            latencies.append(latency)
+
+            if i >= 99:
+                break
+
+    finally:
+        if ws:
+            await ws.close()
+
+    if not latencies:
+        return None
+
+    latencies.sort()
+    n = len(latencies)
+
+    return LatencyResult(
+        min_ms=latencies[0],
+        max_ms=latencies[-1],
+        avg_ms=statistics.mean(latencies),
+        p50_ms=latencies[int(n * 0.5)],
+        p95_ms=latencies[int(n * 0.95)],
+        p99_ms=latencies[int(n * 0.99)],
+        std_ms=statistics.stdev(latencies) if n > 1 else 0,
+        jitter_ms=statistics.median([abs(latencies[i] - latencies[i-1])
+                                     for i in range(1, n)]) if n > 1 else 0,
+        samples=n
+    )
+
+
+# ============================================================
+# è¾“å‡ºæ ¼å¼
+# ============================================================
+
+def print_latency_result(name: str, result: LatencyResult):
+    """æ‰“å°å»¶è¿Ÿæµ‹è¯•ç»“æžœ"""
+    print(f"\nðŸ“Š {name}")
+    print(f"   æ ·æœ¬æ•°:   {result.samples}")
+    print(f"   æœ€å°:     {result.min_ms:.3f} ms")
+    print(f"   æœ€å¤§:     {result.max_ms:.3f} ms")
+    print(f"   å¹³å‡:     {result.avg_ms:.3f} ms")
+    print(f"   P50:      {result.p50_ms:.3f} ms")
+    print(f"   P95:      {result.p95_ms:.3f} ms")
+    print(f"   P99:      {result.p99_ms:.3f} ms")
+    print(f"   æŠ–åŠ¨:     {result.jitter_ms:.3f} ms")
+    print(f"   æ ‡å‡†å·®:   {result.std_ms:.3f} ms")
+
+
+def print_throughput_result(result: ThroughputResult):
+    """æ‰“å°åžåé‡æµ‹è¯•ç»“æžœ"""
+    print(f"\nðŸ“ˆ åžåé‡")
+    print(f"   æ€»æ¶ˆæ¯æ•°: {result.total_msgs:,}")
+    print(f"   æ€»å­—èŠ‚:   {result.total_bytes:,} ({result.total_bytes/1024/1024:.2f} MB)")
+    print(f"   æŒç»­æ—¶é—´: {result.duration_sec:.2f} s")
+    print(f"   æ¶ˆæ¯/ç§’:  {result.msgs_per_sec:,.0f}")
+    print(f"   åžåé‡:   {result.mbps:.2f} Mbps")
+
+
+def print_packet_loss_result(result: PacketLossResult):
+    """æ‰“å°ä¸¢åŒ…æµ‹è¯•ç»“æžœ"""
+    print(f"\nðŸ“¦ ä¸¢åŒ…çŽ‡")
+    print(f"   å‘é€:     {result.sent:,}")
+    print(f"   æŽ¥æ”¶:     {result.received:,}")
+    print(f"   ä¸¢åŒ…:     {result.lost:,}")
+    print(f"   ä¸¢åŒ…çŽ‡:   {result.loss_rate_percent:.2f}%")
+    print(f"   å¹³å‡RTT:  {result.avg_rtt_ms:.2f} ms")
+
+
+def save_results_to_json(result, filename: str):
+    """ä¿å­˜ç»“æžœåˆ° JSON æ–‡ä»¶"""
+    with open(filename, 'w') as f:
+        json.dump(result, f, indent=2, default=lambda x: asdict(x) if hasattr(x, '__dict__') else str(x))
+    print(f"\nðŸ’¾ ç»“æžœå·²ä¿å­˜åˆ°: {filename}")
+
+
+# ============================================================
+# ä¸»å‡½æ•°
+# ============================================================
+
+async def main():
+    parser = argparse.ArgumentParser(description="PolyEdge ç½‘ç»œåŽ‹æµ‹å·¥å…·")
+    parser.add_argument("--mode", choices=["latency", "throughput", "packet-loss",
+                                           "stress", "compare", "direct"],
+                       default="latency", help="æµ‹è¯•æ¨¡å¼")
+    parser.add_argument("--target", default="10.0.3.123", help="ç›®æ ‡åœ°å€ (VPC)")
+    parser.add_argument("--port", type=int, default=6666, help="ç›®æ ‡ç«¯å£")
+    parser.add_argument("--duration", type=int, default=30, help="æµ‹è¯•æŒç»­æ—¶é—´(ç§’)")
+    parser.add_argument("--rate", type=int, default=100, help="å‘åŒ…é¢‘çŽ‡(Hz)")
+    parser.add_argument("--output", help="è¾“å‡º JSON æ–‡ä»¶")
+    parser.add_argument("--direct", action="store_true", help="åŒæ—¶æµ‹è¯•å…¬ç½‘ç›´è¿ž")
+
+    args = parser.parse_args()
+
+    results = {}
+
+    if args.mode == "latency":
+        result = await test_latency_udp(args.target, args.port, args.duration, args.rate)
+        print_latency_result("UDP å»¶è¿Ÿæµ‹è¯•", result)
+        results["latency"] = asdict(result)
+
+    elif args.mode == "throughput":
+        result = await test_throughput_udp(args.target, args.port,
+                                          min(args.duration, 10), rate_hz=args.rate)
+        print_throughput_result(result)
+        results["throughput"] = asdict(result)
+
+    elif args.mode == "packet-loss":
+        result = await test_packet_loss_udp(args.target, args.port, args.duration, args.rate)
+        print_packet_loss_result(result)
+        results["packet_loss"] = asdict(result)
+
+    elif args.mode == "stress":
+        result = await test_stress(args.target, args.port, args.duration)
+        print_latency_result("å»¶è¿Ÿ", result.latency)
+        print_throughput_result(ThroughputResult(
+            result.total_packets, result.total_bytes, result.duration_sec,
+            result.total_packets / result.duration_sec,
+            result.total_bytes * 8 / result.duration_sec / 1e6
+        ))
+        print_packet_loss_result(result.packet_loss)
+        print(f"\n   é”™è¯¯æ•°: {result.errors}")
+        results["stress"] = {
+            "duration_sec": result.duration_sec,
+            "latency": asdict(result.latency),
+            "throughput": {
+                "total_msgs": result.total_packets,
+                "total_bytes": result.total_bytes,
+                "msgs_per_sec": result.total_packets / result.duration_sec,
+                "mbps": result.total_bytes * 8 / result.duration_sec / 1e6
+            },
+            "packet_loss": asdict(result.packet_loss),
+            "errors": result.errors
+        }
+
+    elif args.mode == "direct":
+        result = await test_direct_binance()
+        if result:
+            print_latency_result("å…¬ç½‘ç›´è¿ž (çˆ±å°”å…° -> Binance)", result)
+            results["direct"] = asdict(result)
+
+    elif args.mode == "compare":
+        print("\n" + "="*60)
+        print("ðŸ”¬ VPC vs å…¬ç½‘ç›´è¿ž å¯¹æ¯”æµ‹è¯•")
+        print("="*60)
+
+        # 1. VPC å»¶è¿Ÿæµ‹è¯•
+        vpc_result = await test_latency_udp(args.target, args.port, 30, 50)
+        print_latency_result("VPC å†…ç½‘ (ä¸œäº¬ -> çˆ±å°”å…°)", vpc_result)
+        results["vpc"] = asdict(vpc_result)
+
+        # 2. å…¬ç½‘ç›´è¿žæµ‹è¯•
+        if args.direct:
+            direct_result = await test_direct_binance()
+            if direct_result:
+                print_latency_result("å…¬ç½‘ç›´è¿ž (çˆ±å°”å…° -> Binance)", direct_result)
+                results["direct"] = asdict(direct_result)
+
+                # å¯¹æ¯”
+                print("\n" + "="*60)
+                print("ðŸ“Š å¯¹æ¯”ç»“æžœ")
+                print("="*60)
+                print(f"   VPC å¹³å‡å»¶è¿Ÿ:   {vpc_result.avg_ms:.2f} ms")
+                print(f"   å…¬ç½‘å¹³å‡å»¶è¿Ÿ:   {direct_result.avg_ms:.2f} ms")
+                comparison = {
+                    "vpc_avg_ms": vpc_result.avg_ms,
+                    "vpc_samples": vpc_result.samples,
+                    "direct_avg_ms": direct_result.avg_ms,
+                    "direct_samples": direct_result.samples,
+                    "speedup_x": None,
+                    "comparable": False,
+                    "reason": None,
+                }
+                if vpc_result.samples <= 0 or vpc_result.avg_ms <= 0:
+                    comparison["reason"] = "vpc_latency_invalid_or_empty"
+                    print("   é€Ÿåº¦æå‡:       N/A (VPC æ ·æœ¬æ— æ•ˆæˆ–ä¸ºç©º)")
+                elif direct_result.samples <= 0 or direct_result.avg_ms <= 0:
+                    comparison["reason"] = "direct_latency_invalid_or_empty"
+                    print("   é€Ÿåº¦æå‡:       N/A (å…¬ç½‘æ ·æœ¬æ— æ•ˆæˆ–ä¸ºç©º)")
+                else:
+                    speedup_x = direct_result.avg_ms / vpc_result.avg_ms
+                    comparison["speedup_x"] = speedup_x
+                    comparison["comparable"] = True
+                    print(f"   é€Ÿåº¦æå‡:       {speedup_x:.1f}x")
+                results["compare"] = comparison
+
+    # ä¿å­˜ç»“æžœ
+    if args.output:
+        save_results_to_json(results, args.output)
+    else:
+        # è‡ªåŠ¨ä¿å­˜
+        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
+        filename = f"stress_test_{args.mode}_{timestamp}.json"
+        save_results_to_json(results, filename)
+
+
+if __name__ == "__main__":
+    asyncio.run(main())
diff --git a/scripts/paper_runner.py b/scripts/paper_runner.py
new file mode 100644
index 0000000..86200bb
--- /dev/null
+++ b/scripts/paper_runner.py
@@ -0,0 +1,328 @@
+#!/usr/bin/env python3
+import argparse
+import csv
+import json
+import os
+import socket
+import subprocess
+import sys
+import time
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Any, Dict, List, Optional, TextIO
+
+import requests
+
+
+def now_run_id() -> str:
+    return time.strftime("paper-%Y%m%d-%H%M%S", time.gmtime())
+
+
+def repo_root() -> Path:
+    return Path(__file__).resolve().parents[1]
+
+
+def default_binary() -> Path:
+    name = "app_runner.exe" if os.name == "nt" else "app_runner"
+    return repo_root() / "target" / "release" / name
+
+
+def fallback_debug_binary() -> Path:
+    name = "app_runner.exe" if os.name == "nt" else "app_runner"
+    return repo_root() / "target" / "debug" / name
+
+
+def bool_env(v: bool) -> str:
+    return "true" if v else "false"
+
+
+def get_json(base_url: str, path: str, timeout: float = 5.0) -> Optional[Dict[str, Any]]:
+    try:
+        resp = requests.get(f"{base_url.rstrip('/')}{path}", timeout=timeout)
+        resp.raise_for_status()
+        return resp.json()
+    except Exception:
+        return None
+
+
+@dataclass
+class InstanceRun:
+    idx: int
+    run_id: str
+    base_url: str
+    dataset_root: Path
+    proc: subprocess.Popen
+    strategy_config: Optional[str]
+    log_path: Path
+    log_file: TextIO
+
+
+def spawn_instance(
+    idx: int,
+    run_id: str,
+    binary_path: Path,
+    control_port: int,
+    initial_capital: float,
+    dataset_root: Path,
+    strategy_config: Optional[str],
+) -> InstanceRun:
+    udp_port = 20_000 + idx * 1_000
+    inst_run_id = f"{run_id}-i{idx + 1}"
+    inst_dataset = dataset_root / run_id / f"inst{idx + 1}"
+    inst_dataset.mkdir(parents=True, exist_ok=True)
+    log_path = inst_dataset / "app_runner.log"
+    log_file = log_path.open("w", encoding="utf-8")
+    env = os.environ.copy()
+    env["POLYEDGE_FORCE_PAPER"] = bool_env(True)
+    env["POLYEDGE_PAPER_ENABLED"] = bool_env(True)
+    env["POLYEDGE_PAPER_SQLITE_ENABLED"] = bool_env(True)
+    env["POLYEDGE_PAPER_RUN_ID"] = inst_run_id
+    env["POLYEDGE_PAPER_INITIAL_CAPITAL"] = str(initial_capital)
+    env["POLYEDGE_SEAT_ENABLED"] = bool_env(False)
+    env["POLYEDGE_CONTROL_PORT"] = str(control_port)
+    env["POLYEDGE_UDP_PORT"] = str(udp_port)
+    env["POLYEDGE_DATASET_ROOT"] = str(inst_dataset)
+    # Force per-instance UDP listener isolation even if parent shell exported
+    # symbol->port maps for production wire setups.
+    env.pop("POLYEDGE_UDP_SYMBOL_PORTS", None)
+    env.pop("POLYEDGE_UDP_PIN_CORES", None)
+    if strategy_config:
+        env["POLYEDGE_STRATEGY_CONFIG_PATH"] = strategy_config
+
+    proc = subprocess.Popen(
+        [str(binary_path)],
+        cwd=str(repo_root()),
+        env=env,
+        stdout=log_file,
+        stderr=subprocess.STDOUT,
+        text=True,
+    )
+    return InstanceRun(
+        idx=idx,
+        run_id=inst_run_id,
+        base_url=f"http://127.0.0.1:{control_port}",
+        dataset_root=inst_dataset,
+        proc=proc,
+        strategy_config=strategy_config,
+        log_path=log_path,
+        log_file=log_file,
+    )
+
+
+def pick_available_port(start: int, used: set[int]) -> int:
+    for port in range(max(1025, start), 65535):
+        if port in used:
+            continue
+        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
+            try:
+                sock.bind(("127.0.0.1", port))
+            except OSError:
+                continue
+        used.add(port)
+        return port
+    raise RuntimeError("unable to find available control port")
+
+
+def wait_ready(inst: InstanceRun, timeout_sec: int = 30) -> bool:
+    deadline = time.time() + timeout_sec
+    while time.time() < deadline:
+        if inst.proc.poll() is not None:
+            return False
+        payload = get_json(inst.base_url, "/health", timeout=1.5)
+        if payload and payload.get("status") == "ok":
+            return True
+        time.sleep(0.5)
+    return False
+
+
+def stop_instance(inst: InstanceRun) -> None:
+    try:
+        if inst.proc.poll() is None:
+            try:
+                inst.proc.terminate()
+                inst.proc.wait(timeout=8)
+            except Exception:
+                inst.proc.kill()
+                inst.proc.wait(timeout=3)
+    finally:
+        inst.log_file.close()
+
+
+def read_summary_from_files(dataset_root: Path) -> Optional[Dict[str, Any]]:
+    day = time.strftime("%Y-%m-%d", time.gmtime())
+    summary = dataset_root / "reports" / day / "paper_summary_latest.json"
+    if not summary.exists():
+        return None
+    try:
+        return json.loads(summary.read_text(encoding="utf-8"))
+    except Exception:
+        return None
+
+
+def collect_final_summary(inst: InstanceRun) -> Dict[str, Any]:
+    api = get_json(inst.base_url, "/report/paper/summary", timeout=3.0)
+    if api:
+        return api
+    file_payload = read_summary_from_files(inst.dataset_root)
+    if file_payload:
+        return file_payload
+    return {
+        "run_id": inst.run_id,
+        "roi_pct": 0.0,
+        "win_rate": 0.0,
+        "fee_ratio": 0.0,
+        "trades": 0,
+        "pnl_total_usdc": 0.0,
+        "avg_trade_duration_ms": 0.0,
+        "median_trade_duration_ms": 0.0,
+        "bankroll": 0.0,
+    }
+
+
+def write_parallel_compare(run_dir: Path, rows: List[Dict[str, Any]]) -> Path:
+    out = run_dir / "paper_parallel_compare.csv"
+    out.parent.mkdir(parents=True, exist_ok=True)
+    with out.open("w", newline="", encoding="utf-8") as f:
+        writer = csv.DictWriter(
+            f,
+            fieldnames=[
+                "instance",
+                "run_id",
+                "strategy_config",
+                "roi_pct",
+                "win_rate",
+                "fee_ratio",
+                "trades",
+                "pnl_total_usdc",
+                "bankroll",
+                "avg_trade_duration_ms",
+                "median_trade_duration_ms",
+            ],
+        )
+        writer.writeheader()
+        for row in rows:
+            writer.writerow(row)
+    return out
+
+
+def run(args: argparse.Namespace) -> int:
+    root = repo_root()
+    if args.binary:
+        binary = Path(args.binary)
+        if not binary.exists():
+            print(f"[error] app_runner binary not found: {binary}", file=sys.stderr)
+            return 2
+    else:
+        release_bin = default_binary()
+        debug_bin = fallback_debug_binary()
+        if release_bin.exists():
+            binary = release_bin
+        elif debug_bin.exists():
+            binary = debug_bin
+        else:
+            print(
+                f"[error] app_runner binary not found: {release_bin} or {debug_bin}",
+                file=sys.stderr,
+            )
+            print(
+                "[hint] build first: cargo build -p app_runner --release (or --debug)",
+                file=sys.stderr,
+            )
+            return 2
+
+    instances = max(1, int(args.instances))
+    run_id = args.run_id or now_run_id()
+    dataset_root = Path(args.dataset_root)
+    run_dir = dataset_root / run_id
+    run_dir.mkdir(parents=True, exist_ok=True)
+
+    strategy_configs: List[Optional[str]] = []
+    for i in range(instances):
+        key = f"config{i + 1}"
+        strategy_configs.append(getattr(args, key))
+
+    runners: List[InstanceRun] = []
+    used_ports: set[int] = set()
+    try:
+        for i in range(instances):
+            preferred_port = int(args.base_port) + i * max(2, int(args.port_stride))
+            control_port = pick_available_port(preferred_port, used_ports)
+            inst = spawn_instance(
+                idx=i,
+                run_id=run_id,
+                binary_path=binary,
+                control_port=control_port,
+                initial_capital=float(args.initial_capital),
+                dataset_root=dataset_root,
+                strategy_config=strategy_configs[i],
+            )
+            runners.append(inst)
+            ok = wait_ready(inst, timeout_sec=45)
+            if not ok:
+                print(f"[error] instance {i+1} failed health check: {inst.base_url}")
+                print(f"[hint] inspect log: {inst.log_path}")
+                return 3
+            print(
+                f"[ready] instance={i+1} run_id={inst.run_id} url={inst.base_url} log={inst.log_path}"
+            )
+
+        t_end = time.time() + int(args.duration)
+        while time.time() < t_end:
+            for inst in runners:
+                live = get_json(inst.base_url, "/report/paper/live", timeout=2.5) or {}
+                roi = float(live.get("roi_pct", 0.0))
+                trades = int(live.get("trades", 0))
+                win_rate = float(live.get("win_rate", 0.0))
+                print(
+                    f"[live] inst={inst.idx+1} roi={roi:.4f}% trades={trades} win_rate={win_rate:.4f}"
+                )
+            time.sleep(float(args.poll_sec))
+
+        rows: List[Dict[str, Any]] = []
+        for inst in runners:
+            summary = collect_final_summary(inst)
+            row = {
+                "instance": inst.idx + 1,
+                "run_id": summary.get("run_id", inst.run_id),
+                "strategy_config": inst.strategy_config or "",
+                "roi_pct": float(summary.get("roi_pct", 0.0)),
+                "win_rate": float(summary.get("win_rate", 0.0)),
+                "fee_ratio": float(summary.get("fee_ratio", 0.0)),
+                "trades": int(summary.get("trades", 0)),
+                "pnl_total_usdc": float(summary.get("pnl_total_usdc", 0.0)),
+                "bankroll": float(summary.get("bankroll", 0.0)),
+                "avg_trade_duration_ms": float(summary.get("avg_trade_duration_ms", 0.0)),
+                "median_trade_duration_ms": float(summary.get("median_trade_duration_ms", 0.0)),
+            }
+            rows.append(row)
+            (run_dir / f"summary_inst{inst.idx+1}.json").write_text(
+                json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8"
+            )
+
+        compare_path = write_parallel_compare(run_dir, rows)
+        print(f"[done] compare_csv={compare_path}")
+        return 0
+    finally:
+        for inst in runners:
+            stop_instance(inst)
+
+
+def build_parser() -> argparse.ArgumentParser:
+    p = argparse.ArgumentParser(description="PolyEdge Paper runner with optional parallel mode")
+    p.add_argument("--run-id", default=None)
+    p.add_argument("--duration", type=int, default=3600)
+    p.add_argument("--initial-capital", type=float, default=100.0)
+    p.add_argument("--instances", type=int, default=1)
+    p.add_argument("--base-port", type=int, default=38080)
+    p.add_argument("--port-stride", type=int, default=10)
+    p.add_argument("--binary", default=None)
+    p.add_argument("--poll-sec", type=float, default=5.0)
+    p.add_argument("--dataset-root", default="datasets/paper_runs")
+    for idx in range(1, 9):
+        p.add_argument(f"--config{idx}", default=None)
+    return p
+
+
+if __name__ == "__main__":
+    parser = build_parser()
+    raise SystemExit(run(parser.parse_args()))
diff --git a/scripts/param_regression.py b/scripts/param_regression.py
index 6a77dbd..3cc1ea1 100644
--- a/scripts/param_regression.py
+++ b/scripts/param_regression.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 from __future__ import annotations
 
+import atexit
 import argparse
 import csv
 import itertools
@@ -44,22 +45,37 @@ def parse_int_grid(raw: str) -> List[int]:
 
 PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
     "quick": {
-        "window_sec": 120,
+        # 5-hour sprint default: fewer trials, longer per-trial window, bounded runtime.
+        "window_sec": 300,
         "poll_interval_sec": 3.0,
-        "eval_window_sec": 120,
-        "max_trials": 2,
-        "max_runtime_sec": 480,
+        "eval_window_sec": 300,
+        "max_trials": 6,
+        "max_runtime_sec": 3600,
         "heartbeat_sec": 15.0,
-        "fail_fast_threshold": 1,
-        "min_outcomes": 10,
-        "min_edge_grid": "4.5,5.0",
-        "ttl_grid": "350,400",
+        # Don't stop after the first failure; we want at least a few parameter probes in quick mode.
+        "fail_fast_threshold": 3,
+        "min_outcomes": 30,
+        "min_edge_grid": "0.5,1.0,2.0",
+        "ttl_grid": "250,400,700",
+        "max_spread_grid": "0.03,0.05,0.08",
+        "base_quote_size_grid": "2,5",
+        "min_eval_notional_usdc_grid": "0.01,0.05",
+        "min_expected_edge_usdc_grid": "0.0002",
+        "taker_trigger_grid": "3,4,6",
+        "taker_max_slippage_grid": "20,30",
+        "stale_tick_filter_ms": 2000,
+        "market_tier_profile": "balanced_sol_guard",
+        "active_top_n_markets": 12,
         "basis_k_grid": "0.8",
         "basis_z_grid": "3.0",
         "safe_threshold_grid": "0.35",
         "caution_threshold_grid": "0.65",
         "warmup_sec": 5,
         "max_estimated_sec": 900,
+        "walkforward_windows": 2,
+        "walkforward_cooldown_sec": 2.0,
+        "selection_mode": "robust",
+        "top_k_consensus": 3,
     },
     "standard": {
         "window_sec": 300,
@@ -70,14 +86,27 @@ PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
         "heartbeat_sec": 30.0,
         "fail_fast_threshold": 0,
         "min_outcomes": 30,
-        "min_edge_grid": "5,7,9",
+        "min_edge_grid": "0.5,1.0,2.0,3.0",
         "ttl_grid": "250,400,700",
+        "max_spread_grid": "0.03,0.05,0.08",
+        "base_quote_size_grid": "2,5",
+        "min_eval_notional_usdc_grid": "0.01,0.05",
+        "min_expected_edge_usdc_grid": "0.0002",
+        "taker_trigger_grid": "3,4,6",
+        "taker_max_slippage_grid": "20,30",
+        "stale_tick_filter_ms": 2000,
+        "market_tier_profile": "balanced_sol_guard",
+        "active_top_n_markets": 12,
         "basis_k_grid": "0.70,0.85,1.00",
         "basis_z_grid": "2.0,3.0",
         "safe_threshold_grid": "0.35",
         "caution_threshold_grid": "0.65",
         "warmup_sec": 15,
         "max_estimated_sec": 0,
+        "walkforward_windows": 2,
+        "walkforward_cooldown_sec": 3.0,
+        "selection_mode": "robust",
+        "top_k_consensus": 3,
     },
     "deep": {
         "window_sec": 600,
@@ -88,14 +117,27 @@ PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
         "heartbeat_sec": 30.0,
         "fail_fast_threshold": 0,
         "min_outcomes": 50,
-        "min_edge_grid": "4.5,5,6,7,9",
+        "min_edge_grid": "0.5,1.0,2.0,3.0,4.0",
         "ttl_grid": "250,350,500,700",
+        "max_spread_grid": "0.03,0.05,0.08",
+        "base_quote_size_grid": "2,5,8",
+        "min_eval_notional_usdc_grid": "0.01,0.05,0.10",
+        "min_expected_edge_usdc_grid": "0.0002,0.001",
+        "taker_trigger_grid": "3,4,6,8",
+        "taker_max_slippage_grid": "15,20,30",
+        "stale_tick_filter_ms": 2000,
+        "market_tier_profile": "balanced_sol_guard",
+        "active_top_n_markets": 12,
         "basis_k_grid": "0.70,0.80,0.90,1.00",
         "basis_z_grid": "2.0,2.5,3.0",
         "safe_threshold_grid": "0.30,0.35",
         "caution_threshold_grid": "0.60,0.65",
         "warmup_sec": 20,
         "max_estimated_sec": 0,
+        "walkforward_windows": 3,
+        "walkforward_cooldown_sec": 5.0,
+        "selection_mode": "robust",
+        "top_k_consensus": 5,
     },
 }
 
@@ -123,6 +165,15 @@ class TrialResult:
     trial_index: int
     min_edge_bps: float
     ttl_ms: int
+    max_spread: float
+    base_quote_size: float
+    min_eval_notional_usdc: float
+    min_expected_edge_usdc: float
+    taker_trigger_bps: float
+    taker_max_slippage_bps: float
+    stale_tick_filter_ms: float
+    market_tier_profile: str
+    active_top_n_markets: int
     basis_k_revert: float
     basis_z_cap: float
     safe_threshold: float
@@ -150,6 +201,10 @@ class TrialResult:
     data_valid_ratio: float
     net_edge_p50_bps: float
     gate_fail_reasons: List[str]
+    blocked_reason_top: str
+    walkforward_windows: int = 1
+    stability_penalty: float = 0.0
+    consistency_score: float = 1.0
 
     def gate_pass(self) -> bool:
         return (
@@ -172,6 +227,7 @@ class TrialResult:
 
 def score_trial(row: TrialResult) -> float:
     """Single-score ranking used for best trial selection in reports."""
+    objective = objective_ev_net_penalty(row)
     score = 0.0
     if row.gate_ready:
         score += 200.0
@@ -184,26 +240,259 @@ def score_trial(row: TrialResult) -> float:
     score += row.pnl_10s_p50_bps_robust * 0.2
     score += row.fillability_10ms * 100.0
     score += row.net_edge_p50_bps * 0.1
+    score += row.consistency_score * 80.0
     score -= row.quote_block_ratio * 300.0
     score -= row.policy_block_ratio * 120.0
     score -= row.tick_to_ack_p99_ms * 0.2
     score -= row.feed_in_p99_ms * 0.05
     score -= row.decision_compute_p99_ms * 20.0
+    score -= row.stability_penalty
     score -= max(0.0, 0.999 - row.data_valid_ratio) * 10_000.0
     score -= max(0.0, 0.60 - row.executed_over_eligible) * 500.0
+    score += objective * 120.0
     return score
 
 
-def fetch_json(session: requests.Session, url: str, timeout: float = 5.0) -> Dict[str, Any]:
-    resp = session.get(url, timeout=timeout)
-    resp.raise_for_status()
-    return resp.json()
+def objective_penalty(row: TrialResult) -> float:
+    penalty = 0.0
+    penalty += max(0.0, row.tick_to_ack_p99_ms - 450.0) * 0.00002
+    penalty += max(0.0, row.decision_compute_p99_ms - 2.0) * 0.05
+    penalty += max(0.0, row.feed_in_p99_ms - 800.0) * 0.000005
+    penalty += max(0.0, row.quote_block_ratio - 0.10) * 0.20
+    penalty += max(0.0, row.policy_block_ratio - 0.10) * 0.20
+    penalty += max(0.0, 0.60 - row.executed_over_eligible) * 0.50
+    penalty += max(0.0, 0.999 - row.data_valid_ratio) * 80.0
+    penalty += row.stability_penalty * 0.01
+    if not row.gate_pass():
+        penalty += 0.20
+    return penalty
+
+
+def objective_ev_net_penalty(row: TrialResult) -> float:
+    return row.ev_net_usdc_p50 - objective_penalty(row)
+
+
+def aggregate_walkforward_results(
+    run_id: str,
+    trial_index: int,
+    windows: List[TrialResult],
+    selection_mode: str,
+) -> TrialResult:
+    if not windows:
+        raise ValueError("walkforward windows must not be empty")
+
+    mode = selection_mode.strip().lower()
+    if mode not in {"score", "robust"}:
+        mode = "robust"
+
+    def as_list(field: str) -> List[float]:
+        return [float(getattr(w, field)) for w in windows]
+
+    def aggregate_good(field: str) -> float:
+        values = as_list(field)
+        q = 0.50 if mode == "score" else 0.25
+        return percentile(values, q)
+
+    def aggregate_bad(field: str) -> float:
+        values = as_list(field)
+        q = 0.50 if mode == "score" else 0.75
+        return percentile(values, q)
+
+    def span(values: List[float]) -> float:
+        return max(values) - min(values) if values else 0.0
+
+    basis = windows[0]
+    gate_ready_vals = [1.0 if w.gate_ready else 0.0 for w in windows]
+    ev_vals = as_list("ev_net_usdc_p50")
+    markout_vals = as_list("net_markout_10s_usdc_p50")
+    ack_vals = as_list("tick_to_ack_p99_ms")
+    block_vals = as_list("quote_block_ratio")
+    exec_vals = as_list("executed_over_eligible")
+    data_valid_vals = as_list("data_valid_ratio")
+    unique_reasons = sorted({r for w in windows for r in w.gate_fail_reasons})
+    blocked_by_row = sorted(
+        windows,
+        key=lambda w: (
+            w.quote_block_ratio + w.policy_block_ratio,
+            w.tick_to_ack_p99_ms,
+            -w.ev_net_usdc_p50,
+        ),
+        reverse=True,
+    )
+
+    stability_penalty = (
+        span(ev_vals) * 60.0
+        + span(markout_vals) * 80.0
+        + span(ack_vals) * 0.15
+        + span(block_vals) * 320.0
+        + max(0.0, 0.999 - min(data_valid_vals)) * 30_000.0
+        + max(0.0, 0.60 - min(exec_vals)) * 800.0
+    )
+    consistency_score = 1.0 / (1.0 + (stability_penalty / 200.0))
+
+    if mode == "robust":
+        gate_ready = all(w.gate_ready for w in windows)
+    else:
+        gate_ready = bool(percentile(gate_ready_vals, 0.50) >= 1.0)
+
+    return TrialResult(
+        run_id=run_id,
+        trial_index=trial_index,
+        min_edge_bps=basis.min_edge_bps,
+        ttl_ms=basis.ttl_ms,
+        max_spread=basis.max_spread,
+        base_quote_size=basis.base_quote_size,
+        min_eval_notional_usdc=basis.min_eval_notional_usdc,
+        min_expected_edge_usdc=basis.min_expected_edge_usdc,
+        taker_trigger_bps=basis.taker_trigger_bps,
+        taker_max_slippage_bps=basis.taker_max_slippage_bps,
+        stale_tick_filter_ms=basis.stale_tick_filter_ms,
+        market_tier_profile=basis.market_tier_profile,
+        active_top_n_markets=basis.active_top_n_markets,
+        basis_k_revert=basis.basis_k_revert,
+        basis_z_cap=basis.basis_z_cap,
+        safe_threshold=basis.safe_threshold,
+        caution_threshold=basis.caution_threshold,
+        window_id=windows[-1].window_id,
+        gate_ready=gate_ready,
+        samples=sum(w.samples for w in windows),
+        fillability_10ms=aggregate_good("fillability_10ms"),
+        pnl_10s_p50_bps_raw=aggregate_good("pnl_10s_p50_bps_raw"),
+        pnl_10s_p50_bps_robust=aggregate_good("pnl_10s_p50_bps_robust"),
+        pnl_10s_p25_bps_robust=min(as_list("pnl_10s_p25_bps_robust")),
+        ev_net_usdc_p50=aggregate_good("ev_net_usdc_p50"),
+        ev_net_usdc_p10=min(as_list("ev_net_usdc_p10")),
+        ev_positive_ratio=aggregate_good("ev_positive_ratio"),
+        net_markout_10s_usdc_p50=aggregate_good("net_markout_10s_usdc_p50"),
+        roi_notional_10s_bps_p50=aggregate_good("roi_notional_10s_bps_p50"),
+        eligible_count=int(aggregate_good("eligible_count")),
+        executed_count=int(aggregate_good("executed_count")),
+        executed_over_eligible=aggregate_good("executed_over_eligible"),
+        quote_block_ratio=aggregate_bad("quote_block_ratio"),
+        policy_block_ratio=aggregate_bad("policy_block_ratio"),
+        tick_to_ack_p99_ms=aggregate_bad("tick_to_ack_p99_ms"),
+        decision_compute_p99_ms=aggregate_bad("decision_compute_p99_ms"),
+        feed_in_p99_ms=aggregate_bad("feed_in_p99_ms"),
+        data_valid_ratio=aggregate_good("data_valid_ratio"),
+        net_edge_p50_bps=aggregate_good("net_edge_p50_bps"),
+        gate_fail_reasons=unique_reasons,
+        blocked_reason_top=blocked_by_row[0].blocked_reason_top if blocked_by_row else "",
+        walkforward_windows=len(windows),
+        stability_penalty=stability_penalty,
+        consistency_score=consistency_score,
+    )
+
+
+def build_consensus_params(rows: List[TrialResult], top_k: int) -> Dict[str, Any]:
+    if not rows:
+        return {}
+
+    preferred = [row for row in rows if row.gate_pass()]
+    if not preferred:
+        preferred = [row for row in rows if row.gate_ready]
+    if not preferred:
+        preferred = rows
+    chosen = preferred[: max(1, top_k)]
 
+    def median(values: List[float]) -> float:
+        return percentile(values, 0.50)
 
-def post_json(session: requests.Session, url: str, payload: Dict[str, Any], timeout: float = 5.0) -> Dict[str, Any]:
-    resp = session.post(url, json=payload, timeout=timeout)
-    resp.raise_for_status()
-    return resp.json()
+    def medf(field: str) -> float:
+        return median([float(getattr(row, field)) for row in chosen])
+
+    def medi(field: str) -> int:
+        return int(round(medf(field)))
+
+    first = chosen[0]
+    return {
+        "source_trial_indices": [row.trial_index for row in chosen],
+        "selection_count": len(chosen),
+        "reload_strategy": {
+            "min_edge_bps": medf("min_edge_bps"),
+            "ttl_ms": medi("ttl_ms"),
+            "max_spread": medf("max_spread"),
+            "base_quote_size": medf("base_quote_size"),
+            "min_eval_notional_usdc": medf("min_eval_notional_usdc"),
+            "min_expected_edge_usdc": medf("min_expected_edge_usdc"),
+            "basis_k_revert": medf("basis_k_revert"),
+            "basis_z_cap": medf("basis_z_cap"),
+        },
+        "reload_taker": {
+            "trigger_bps": medf("taker_trigger_bps"),
+            "max_slippage_bps": medf("taker_max_slippage_bps"),
+            "stale_tick_filter_ms": medf("stale_tick_filter_ms"),
+            "market_tier_profile": first.market_tier_profile,
+        },
+        "reload_allocator": {
+            "capital_fraction_kelly": 0.35,
+            "variance_penalty_lambda": 0.25,
+            "active_top_n_markets": medi("active_top_n_markets"),
+            "taker_weight": 0.7,
+            "maker_weight": 0.2,
+            "arb_weight": 0.1,
+        },
+        "reload_toxicity": {
+            "safe_threshold": medf("safe_threshold"),
+            "caution_threshold": medf("caution_threshold"),
+        },
+    }
+
+
+def write_auto_tuned_thresholds(
+    path: Path,
+    rows: List[TrialResult],
+    top_k: int,
+) -> Dict[str, Any]:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    payload = {
+        "generated_at_utc": datetime.now(timezone.utc).isoformat(),
+        "optimizer": "top-k-consensus",
+        "top_k": max(1, top_k),
+        "consensus": build_consensus_params(rows, top_k),
+    }
+    path.write_text(json.dumps(payload, ensure_ascii=True, indent=2), encoding="utf-8")
+    return payload
+
+
+def fetch_json(
+    session: requests.Session,
+    url: str,
+    timeout: float = 15.0,
+    retries: int = 3,
+    backoff_sec: float = 0.5,
+) -> Dict[str, Any]:
+    last_exc: Exception | None = None
+    for attempt in range(max(1, retries)):
+        try:
+            resp = session.get(url, timeout=timeout)
+            resp.raise_for_status()
+            return resp.json()
+        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as exc:
+            last_exc = exc
+            time.sleep(backoff_sec * float(attempt + 1))
+    assert last_exc is not None
+    raise last_exc
+
+
+def post_json(
+    session: requests.Session,
+    url: str,
+    payload: Dict[str, Any],
+    timeout: float = 10.0,
+    retries: int = 3,
+    backoff_sec: float = 0.5,
+) -> Dict[str, Any]:
+    last_exc: Exception | None = None
+    for attempt in range(max(1, retries)):
+        try:
+            resp = session.post(url, json=payload, timeout=timeout)
+            resp.raise_for_status()
+            return resp.json()
+        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as exc:
+            last_exc = exc
+            time.sleep(backoff_sec * float(attempt + 1))
+    assert last_exc is not None
+    raise last_exc
 
 
 def post_json_optional(
@@ -230,6 +519,15 @@ def run_trial(
     poll_interval_sec: float,
     min_edge_bps: float,
     ttl_ms: int,
+    max_spread: float,
+    base_quote_size: float,
+    min_eval_notional_usdc: float,
+    min_expected_edge_usdc: float,
+    taker_trigger_bps: float,
+    taker_max_slippage_bps: float,
+    stale_tick_filter_ms: float,
+    market_tier_profile: str,
+    active_top_n_markets: int,
     basis_k_revert: float,
     basis_z_cap: float,
     safe_threshold: float,
@@ -237,6 +535,8 @@ def run_trial(
     warmup_sec: int,
 ) -> TrialResult:
     base = base_url.rstrip("/")
+    # Ensure the runtime isn't stuck paused from a previous test cycle.
+    post_json_optional(session, f"{base}/control/resume", {})
     reset_resp = post_json(session, f"{base}/control/reset_shadow", {})
     reset_window_id = int(reset_resp.get("window_id", 0) or 0)
     post_json(
@@ -245,6 +545,10 @@ def run_trial(
         {
             "min_edge_bps": min_edge_bps,
             "ttl_ms": ttl_ms,
+            "max_spread": max_spread,
+            "base_quote_size": base_quote_size,
+            "min_eval_notional_usdc": min_eval_notional_usdc,
+            "min_expected_edge_usdc": min_expected_edge_usdc,
             "basis_k_revert": basis_k_revert,
             "basis_z_cap": basis_z_cap,
         },
@@ -253,10 +557,10 @@ def run_trial(
         session,
         f"{base}/control/reload_taker",
         {
-            "trigger_bps": max(1.0, min_edge_bps),
-            "max_slippage_bps": 25.0,
-            "stale_tick_filter_ms": 450.0,
-            "market_tier_profile": "balanced",
+            "trigger_bps": taker_trigger_bps,
+            "max_slippage_bps": taker_max_slippage_bps,
+            "stale_tick_filter_ms": stale_tick_filter_ms,
+            "market_tier_profile": market_tier_profile,
         },
     )
     post_json_optional(
@@ -265,7 +569,7 @@ def run_trial(
         {
             "capital_fraction_kelly": 0.35,
             "variance_penalty_lambda": 0.25,
-            "active_top_n_markets": 8,
+            "active_top_n_markets": active_top_n_markets,
             "taker_weight": 0.7,
             "maker_weight": 0.2,
             "arb_weight": 0.1,
@@ -304,10 +608,12 @@ def run_trial(
     gate_fail_reasons: List[str] = []
     observed_window_id = reset_window_id
     next_heartbeat = time.time() + max(1.0, heartbeat_sec)
+    last_live: Dict[str, Any] | None = None
 
     deadline = time.time() + min(window_sec, eval_window_sec)
     while time.time() < deadline:
         live = fetch_json(session, f"{base}/report/shadow/live")
+        last_live = live
         observed_window_id = int(live.get("window_id", observed_window_id) or observed_window_id)
         fillability.append(float(live.get("fillability_10ms", 0.0)))
         pnl10_raw.append(float(live.get("pnl_10s_p50_bps_raw", live.get("pnl_10s_p50_bps", 0.0))))
@@ -341,11 +647,27 @@ def run_trial(
             next_heartbeat = time.time() + max(1.0, heartbeat_sec)
         time.sleep(max(1.0, poll_interval_sec))
 
+    blocked_top = ""
+    if isinstance(last_live, dict):
+        br = last_live.get("blocked_reason_counts")
+        if isinstance(br, dict) and br:
+            top_items = sorted(br.items(), key=lambda kv: float(kv[1]), reverse=True)[:8]
+            blocked_top = ";".join(f"{k}:{int(v)}" for k, v in top_items)
+
     return TrialResult(
         run_id=run_id,
         trial_index=trial_index,
         min_edge_bps=min_edge_bps,
         ttl_ms=ttl_ms,
+        max_spread=max_spread,
+        base_quote_size=base_quote_size,
+        min_eval_notional_usdc=min_eval_notional_usdc,
+        min_expected_edge_usdc=min_expected_edge_usdc,
+        taker_trigger_bps=taker_trigger_bps,
+        taker_max_slippage_bps=taker_max_slippage_bps,
+        stale_tick_filter_ms=stale_tick_filter_ms,
+        market_tier_profile=market_tier_profile,
+        active_top_n_markets=active_top_n_markets,
         basis_k_revert=basis_k_revert,
         basis_z_cap=basis_z_cap,
         safe_threshold=safe_threshold,
@@ -376,6 +698,7 @@ def run_trial(
         data_valid_ratio=percentile(data_valid_ratio, 0.50),
         net_edge_p50_bps=percentile(net_edge, 0.50),
         gate_fail_reasons=gate_fail_reasons,
+        blocked_reason_top=blocked_top,
     )
 
 
@@ -387,6 +710,15 @@ def write_ablation_csv(path: Path, rows: Iterable[TrialResult]) -> None:
             [
                 "min_edge_bps",
                 "ttl_ms",
+                "max_spread",
+                "base_quote_size",
+                "min_eval_notional_usdc",
+                "min_expected_edge_usdc",
+                "taker_trigger_bps",
+                "taker_max_slippage_bps",
+                "stale_tick_filter_ms",
+                "market_tier_profile",
+                "active_top_n_markets",
                 "basis_k_revert",
                 "basis_z_cap",
                 "safe_threshold",
@@ -415,7 +747,14 @@ def write_ablation_csv(path: Path, rows: Iterable[TrialResult]) -> None:
                 "feed_in_p99_ms",
                 "data_valid_ratio",
                 "net_edge_p50_bps",
+                "walkforward_windows",
+                "consistency_score",
+                "stability_penalty",
+                "objective_penalty",
+                "objective_ev_net_penalty",
+                "score",
                 "gate_pass",
+                "blocked_reason_top",
             ]
         )
         for row in rows:
@@ -423,6 +762,15 @@ def write_ablation_csv(path: Path, rows: Iterable[TrialResult]) -> None:
                 [
                     row.min_edge_bps,
                     row.ttl_ms,
+                    row.max_spread,
+                    row.base_quote_size,
+                    row.min_eval_notional_usdc,
+                    row.min_expected_edge_usdc,
+                    row.taker_trigger_bps,
+                    row.taker_max_slippage_bps,
+                    row.stale_tick_filter_ms,
+                    row.market_tier_profile,
+                    row.active_top_n_markets,
                     row.basis_k_revert,
                     row.basis_z_cap,
                     row.safe_threshold,
@@ -451,7 +799,14 @@ def write_ablation_csv(path: Path, rows: Iterable[TrialResult]) -> None:
                     f"{row.feed_in_p99_ms:.6f}",
                     f"{row.data_valid_ratio:.6f}",
                     f"{row.net_edge_p50_bps:.6f}",
+                    row.walkforward_windows,
+                    f"{row.consistency_score:.6f}",
+                    f"{row.stability_penalty:.6f}",
+                    f"{objective_penalty(row):.6f}",
+                    f"{objective_ev_net_penalty(row):.6f}",
+                    f"{score_trial(row):.6f}",
                     row.gate_pass(),
+                    row.blocked_reason_top,
                 ]
             )
 
@@ -466,10 +821,17 @@ def write_summary_md(path: Path, rows: List[TrialResult]) -> None:
     if rows:
         best = rows[0]
         lines.append(f"- best_score: {score_trial(best):.3f}")
+        lines.append(f"- best_objective_ev_net_penalty: {objective_ev_net_penalty(best):.6f}")
         lines.append(f"- best_gate_pass: {best.gate_pass()}")
         lines.append(f"- best_gate_ready: {best.gate_ready}")
+        lines.append(f"- best_walkforward_windows: {best.walkforward_windows}")
+        lines.append(f"- best_consistency_score: {best.consistency_score:.3f}")
+        lines.append(f"- best_stability_penalty: {best.stability_penalty:.3f}")
         lines.append(
-            f"- best_params: edge={best.min_edge_bps}, ttl={best.ttl_ms}, "
+            f"- best_params: edge={best.min_edge_bps}, ttl={best.ttl_ms}, base_quote={best.base_quote_size}, "
+            f"min_eval_notional={best.min_eval_notional_usdc}, "
+            f"taker_trigger={best.taker_trigger_bps}, taker_slip={best.taker_max_slippage_bps}, "
+            f"stale_ms={best.stale_tick_filter_ms}, tier={best.market_tier_profile}, topn={best.active_top_n_markets}, "
             f"k={best.basis_k_revert}, z={best.basis_z_cap}, "
             f"safe={best.safe_threshold}, caution={best.caution_threshold}"
         )
@@ -478,7 +840,10 @@ def write_summary_md(path: Path, rows: List[TrialResult]) -> None:
     lines.append("## Top Trials")
     for i, row in enumerate(top, start=1):
         lines.append(
-                f"- #{i} edge={row.min_edge_bps}, ttl={row.ttl_ms}, "
+                f"- #{i} edge={row.min_edge_bps}, ttl={row.ttl_ms}, base_quote={row.base_quote_size}, "
+                f"min_eval_notional={row.min_eval_notional_usdc}, "
+                f"taker_trigger={row.taker_trigger_bps}, taker_slip={row.taker_max_slippage_bps}, "
+                f"stale_ms={row.stale_tick_filter_ms}, tier={row.market_tier_profile}, topn={row.active_top_n_markets}, "
                 f"k={row.basis_k_revert}, z={row.basis_z_cap}, "
                 f"pnl10_raw_p50={row.pnl_10s_p50_bps_raw:.3f}, "
                 f"pnl10_robust_p50={row.pnl_10s_p50_bps_robust:.3f}, "
@@ -488,8 +853,14 @@ def write_summary_md(path: Path, rows: List[TrialResult]) -> None:
                 f"fill10={row.fillability_10ms:.3f}, block={row.quote_block_ratio:.3f}, "
                 f"exec_over_eligible={row.executed_over_eligible:.3f}, "
                 f"ready={row.gate_ready}, "
-                f"tick_to_ack_p99={row.tick_to_ack_p99_ms:.3f}, gate={row.gate_pass()}"
+                f"tick_to_ack_p99={row.tick_to_ack_p99_ms:.3f}, "
+                f"wf={row.walkforward_windows}, "
+                f"consistency={row.consistency_score:.3f}, "
+                f"objective={objective_ev_net_penalty(row):.6f}, "
+                f"score={score_trial(row):.2f}, gate={row.gate_pass()}"
             )
+        if row.blocked_reason_top:
+            lines.append(f"  blocked_top: {row.blocked_reason_top}")
     path.write_text("\n".join(lines) + "\n", encoding="utf-8")
 
 
@@ -556,11 +927,34 @@ def parse_args() -> argparse.Namespace:
     p.add_argument("--min-outcomes", type=int, default=None)
     p.add_argument("--min-edge-grid", default=None)
     p.add_argument("--ttl-grid", default=None)
+    p.add_argument("--max-spread-grid", default=None)
+    p.add_argument("--base-quote-size-grid", default=None)
+    p.add_argument("--min-eval-notional-usdc-grid", default=None)
+    p.add_argument("--min-expected-edge-usdc-grid", default=None)
+    p.add_argument("--taker-trigger-grid", default=None)
+    p.add_argument("--taker-max-slippage-grid", default=None)
+    p.add_argument("--stale-tick-filter-ms", type=float, default=None)
+    p.add_argument("--market-tier-profile", default=None)
+    p.add_argument("--active-top-n-markets", type=int, default=None)
     p.add_argument("--basis-k-grid", default=None)
     p.add_argument("--basis-z-grid", default=None)
     p.add_argument("--safe-threshold-grid", default=None)
     p.add_argument("--caution-threshold-grid", default=None)
     p.add_argument("--warmup-sec", type=int, default=None)
+    p.add_argument(
+        "--selection-mode",
+        choices=["score", "robust"],
+        default=None,
+        help="score=median ranking, robust=conservative walk-forward aggregation",
+    )
+    p.add_argument("--walkforward-windows", type=int, default=None)
+    p.add_argument("--walkforward-cooldown-sec", type=float, default=None)
+    p.add_argument(
+        "--top-k-consensus",
+        type=int,
+        default=None,
+        help="Use top-K ranked trials to build consensus auto-tuned thresholds",
+    )
     p.add_argument(
         "--max-estimated-sec",
         type=int,
@@ -573,20 +967,131 @@ def parse_args() -> argparse.Namespace:
 def main() -> int:
     args = apply_profile_defaults(parse_args())
     day_dir = Path(args.out_root) / utc_day()
+    run_dir = day_dir / "runs" / str(args.run_id)
+    run_dir.mkdir(parents=True, exist_ok=True)
     session = requests.Session()
+    atexit.register(session.close)
     started = time.monotonic()
 
     edge_grid = parse_float_grid(args.min_edge_grid)
     ttl_grid = parse_int_grid(args.ttl_grid)
+    max_spread_grid = parse_float_grid(args.max_spread_grid)
+    base_quote_grid = parse_float_grid(args.base_quote_size_grid)
+    min_eval_grid = parse_float_grid(args.min_eval_notional_usdc_grid)
+    min_edge_usdc_grid = parse_float_grid(args.min_expected_edge_usdc_grid)
+    taker_trigger_grid = parse_float_grid(args.taker_trigger_grid)
+    taker_slip_grid = parse_float_grid(args.taker_max_slippage_grid)
     k_grid = parse_float_grid(args.basis_k_grid)
     z_grid = parse_float_grid(args.basis_z_grid)
     safe_grid = parse_float_grid(args.safe_threshold_grid)
     caution_grid = parse_float_grid(args.caution_threshold_grid)
 
-    combos = list(itertools.product(edge_grid, ttl_grid, k_grid, z_grid, safe_grid, caution_grid))
-    combos = combos[: max(1, args.max_trials)]
+    # For small max_trials, prefer a deterministic OFAT-style set instead of a huge cartesian product.
+    def pick_default(seq: List[Any], prefer_last: bool = False) -> Any:
+        if not seq:
+            raise ValueError("empty grid")
+        return seq[-1] if prefer_last else seq[0]
 
-    per_trial_sec = max(1, int(args.warmup_sec + min(args.window_sec, args.eval_window_sec)))
+    base = {
+        "edge": edge_grid[min(1, len(edge_grid) - 1)] if edge_grid else 1.0,
+        "ttl": ttl_grid[min(1, len(ttl_grid) - 1)] if ttl_grid else 400,
+        "max_spread": pick_default(max_spread_grid, prefer_last=True) if max_spread_grid else 0.03,
+        "base_quote": pick_default(base_quote_grid, prefer_last=True),
+        "min_eval": pick_default(min_eval_grid, prefer_last=False),
+        "min_edge_usdc": pick_default(min_edge_usdc_grid, prefer_last=False),
+        "taker_trigger": taker_trigger_grid[min(1, len(taker_trigger_grid) - 1)]
+        if taker_trigger_grid
+        else 4.0,
+        "taker_slip": pick_default(taker_slip_grid, prefer_last=True),
+        "k": pick_default(k_grid, prefer_last=False),
+        "z": pick_default(z_grid, prefer_last=False),
+        "safe": pick_default(safe_grid, prefer_last=False),
+        "caution": pick_default(caution_grid, prefer_last=False),
+    }
+
+    combos: List[tuple[Any, ...]] = []
+    combos.append(
+        (
+            base["edge"],
+            base["ttl"],
+            base["max_spread"],
+            base["base_quote"],
+            base["min_eval"],
+            base["min_edge_usdc"],
+            base["taker_trigger"],
+            base["taker_slip"],
+            base["k"],
+            base["z"],
+            base["safe"],
+            base["caution"],
+        )
+    )
+
+    def add_variants(key: str, grid: List[Any]) -> None:
+        for v in grid:
+            if len(combos) >= max(1, args.max_trials):
+                return
+            if v == base[key]:
+                continue
+            spec = dict(base)
+            spec[key] = v
+            combos.append(
+                (
+                    spec["edge"],
+                    spec["ttl"],
+                    spec["max_spread"],
+                    spec["base_quote"],
+                    spec["min_eval"],
+                    spec["min_edge_usdc"],
+                    spec["taker_trigger"],
+                    spec["taker_slip"],
+                    spec["k"],
+                    spec["z"],
+                    spec["safe"],
+                    spec["caution"],
+                )
+            )
+
+    add_variants("edge", edge_grid)
+    add_variants("ttl", ttl_grid)
+    add_variants("max_spread", max_spread_grid)
+    add_variants("base_quote", base_quote_grid)
+    add_variants("min_eval", min_eval_grid)
+    add_variants("taker_trigger", taker_trigger_grid)
+    add_variants("taker_slip", taker_slip_grid)
+
+    # If still short, fall back to cartesian product, deterministic order.
+    if len(combos) < max(1, args.max_trials):
+        prod = itertools.product(
+            edge_grid,
+            ttl_grid,
+            max_spread_grid,
+            base_quote_grid,
+            min_eval_grid,
+            min_edge_usdc_grid,
+            taker_trigger_grid,
+            taker_slip_grid,
+            k_grid,
+            z_grid,
+            safe_grid,
+            caution_grid,
+        )
+        for row in prod:
+            if len(combos) >= max(1, args.max_trials):
+                break
+            if row in combos:
+                continue
+            combos.append(row)
+
+    single_window_sec = max(1, int(args.warmup_sec + min(args.window_sec, args.eval_window_sec)))
+    per_trial_sec = max(
+        1,
+        int(
+            single_window_sec * max(1, int(args.walkforward_windows))
+            + max(0.0, float(args.walkforward_cooldown_sec))
+            * max(0, int(args.walkforward_windows) - 1)
+        ),
+    )
     estimated_full_sec = per_trial_sec * len(combos)
     if args.max_estimated_sec and args.max_estimated_sec > 0 and estimated_full_sec > args.max_estimated_sec:
         allowed_trials = max(1, int(args.max_estimated_sec // per_trial_sec))
@@ -599,36 +1104,84 @@ def main() -> int:
             estimated_full_sec = per_trial_sec * len(combos)
     print(
         f"[profile] {args.profile} trials={len(combos)} per_trial~{per_trial_sec}s "
-        f"estimated~{estimated_full_sec}s max_runtime={args.max_runtime_sec}s"
+        f"estimated~{estimated_full_sec}s max_runtime={args.max_runtime_sec}s "
+        f"mode={args.selection_mode} wf_windows={args.walkforward_windows}"
     )
 
     rows: List[TrialResult] = []
     consecutive_failures = 0
-    for idx, (edge, ttl, k, z, safe, caution) in enumerate(combos, start=1):
+    for idx, combo in enumerate(combos, start=1):
         if args.max_runtime_sec > 0 and (time.monotonic() - started) >= args.max_runtime_sec:
             print("[stop] max-runtime-sec reached; ending regression loop")
             break
+        (
+            edge,
+            ttl,
+            max_spread,
+            base_quote_size,
+            min_eval_notional_usdc,
+            min_expected_edge_usdc,
+            taker_trigger_bps,
+            taker_max_slippage_bps,
+            k,
+            z,
+            safe,
+            caution,
+        ) = combo  # type: ignore[misc]
         print(
             f"[trial {idx}/{len(combos)}] edge={edge} ttl={ttl} "
+            f"max_spread={max_spread} "
+            f"base_quote={base_quote_size} min_eval={min_eval_notional_usdc} min_edge_usdc={min_expected_edge_usdc} "
+            f"taker_trigger={taker_trigger_bps} taker_slip={taker_max_slippage_bps} "
             f"k={k} z={z} safe={safe} caution={caution}"
         )
-        row = run_trial(
-            session=session,
-            base_url=args.base_url,
+        window_rows: List[TrialResult] = []
+        for wf_idx in range(max(1, int(args.walkforward_windows))):
+            if args.max_runtime_sec > 0 and (time.monotonic() - started) >= args.max_runtime_sec:
+                print("[stop] max-runtime-sec reached while running walk-forward windows")
+                break
+            print(
+                f"[trial {idx}/{len(combos)} window {wf_idx + 1}/{max(1, int(args.walkforward_windows))}] "
+                f"running..."
+            )
+            row_window = run_trial(
+                session=session,
+                base_url=args.base_url,
+                run_id=args.run_id,
+                trial_index=idx,
+                min_outcomes=args.min_outcomes,
+                eval_window_sec=args.eval_window_sec,
+                heartbeat_sec=args.heartbeat_sec,
+                window_sec=args.window_sec,
+                poll_interval_sec=args.poll_interval_sec,
+                min_edge_bps=edge,
+                ttl_ms=ttl,
+                max_spread=max_spread,
+                base_quote_size=base_quote_size,
+                min_eval_notional_usdc=min_eval_notional_usdc,
+                min_expected_edge_usdc=min_expected_edge_usdc,
+                taker_trigger_bps=taker_trigger_bps,
+                taker_max_slippage_bps=taker_max_slippage_bps,
+                stale_tick_filter_ms=float(args.stale_tick_filter_ms),
+                market_tier_profile=str(args.market_tier_profile),
+                active_top_n_markets=int(args.active_top_n_markets),
+                basis_k_revert=k,
+                basis_z_cap=z,
+                safe_threshold=safe,
+                caution_threshold=caution,
+                warmup_sec=args.warmup_sec,
+            )
+            window_rows.append(row_window)
+            if wf_idx + 1 < max(1, int(args.walkforward_windows)):
+                time.sleep(max(0.0, float(args.walkforward_cooldown_sec)))
+
+        if not window_rows:
+            break
+        row = aggregate_walkforward_results(
             run_id=args.run_id,
             trial_index=idx,
-            min_outcomes=args.min_outcomes,
-            eval_window_sec=args.eval_window_sec,
-            heartbeat_sec=args.heartbeat_sec,
-            window_sec=args.window_sec,
-            poll_interval_sec=args.poll_interval_sec,
-            min_edge_bps=edge,
-            ttl_ms=ttl,
-            basis_k_revert=k,
-            basis_z_cap=z,
-            safe_threshold=safe,
-            caution_threshold=caution,
-            warmup_sec=args.warmup_sec,
+            windows=window_rows,
+            selection_mode=str(args.selection_mode),
         )
         rows.append(row)
         consecutive_failures = 0 if row.gate_pass() else consecutive_failures + 1
@@ -638,30 +1191,18 @@ def main() -> int:
             )
             break
 
-    rows.sort(
-        key=lambda r: (
-            r.gate_pass(),
-            r.gate_ready,
-            r.ev_net_usdc_p50,
-            r.ev_positive_ratio,
-            r.executed_over_eligible,
-            r.net_markout_10s_usdc_p50,
-            r.roi_notional_10s_bps_p50,
-            r.fillability_10ms,
-            -r.quote_block_ratio,
-            -r.tick_to_ack_p99_ms,
-        ),
-        reverse=True,
-    )
+    rows.sort(key=score_trial, reverse=True)
 
-    ablation_path = day_dir / "ablation_toxicity.csv"
-    summary_path = day_dir / "regression_summary.md"
-    fixlist_path = day_dir / "next_fixlist.md"
+    ablation_path = run_dir / "ablation_toxicity.csv"
+    summary_path = run_dir / "regression_summary.md"
+    fixlist_path = run_dir / "next_fixlist.md"
     write_ablation_csv(ablation_path, rows)
     write_summary_md(summary_path, rows)
     write_fixlist(fixlist_path, rows[0] if rows else None)
+    auto_tuned_path = run_dir / "auto_tuned_thresholds.json"
+    auto_tuned = write_auto_tuned_thresholds(auto_tuned_path, rows, int(args.top_k_consensus))
 
-    out_json = day_dir / "regression_summary.json"
+    out_json = run_dir / "regression_summary.json"
     best = rows[0] if rows else None
     out_json.write_text(
         json.dumps(
@@ -670,23 +1211,48 @@ def main() -> int:
                 "run_id": args.run_id,
                 "min_outcomes": args.min_outcomes,
                 "eval_window_sec": args.eval_window_sec,
+                "selection_mode": args.selection_mode,
+                "walkforward_windows": args.walkforward_windows,
                 "best_score": score_trial(best) if best else None,
+                "best_objective_ev_net_penalty": objective_ev_net_penalty(best) if best else None,
                 "best_pass": best.gate_pass() if best else None,
                 "best_gate_ready": best.gate_ready if best else None,
                 "best_params": (
                     {
                         "min_edge_bps": best.min_edge_bps,
                         "ttl_ms": best.ttl_ms,
+                        "base_quote_size": best.base_quote_size,
+                        "min_eval_notional_usdc": best.min_eval_notional_usdc,
+                        "min_expected_edge_usdc": best.min_expected_edge_usdc,
+                        "taker_trigger_bps": best.taker_trigger_bps,
+                        "taker_max_slippage_bps": best.taker_max_slippage_bps,
+                        "stale_tick_filter_ms": best.stale_tick_filter_ms,
+                        "market_tier_profile": best.market_tier_profile,
+                        "active_top_n_markets": best.active_top_n_markets,
                         "basis_k_revert": best.basis_k_revert,
                         "basis_z_cap": best.basis_z_cap,
                         "safe_threshold": best.safe_threshold,
                         "caution_threshold": best.caution_threshold,
                         "policy_block_ratio": best.policy_block_ratio,
+                        "walkforward_windows": best.walkforward_windows,
+                        "consistency_score": best.consistency_score,
+                        "stability_penalty": best.stability_penalty,
+                        "objective_penalty": objective_penalty(best),
+                        "objective_ev_net_penalty": objective_ev_net_penalty(best),
                     }
                     if best
                     else None
                 ),
-                "trials": [row.__dict__ | {"gate_pass": row.gate_pass()} for row in rows],
+                "auto_tuned_thresholds": auto_tuned,
+                "trials": [
+                    row.__dict__
+                    | {
+                        "gate_pass": row.gate_pass(),
+                        "objective_penalty": objective_penalty(row),
+                        "objective_ev_net_penalty": objective_ev_net_penalty(row),
+                    }
+                    for row in rows
+                ],
             },
             ensure_ascii=True,
             indent=2,
@@ -696,6 +1262,7 @@ def main() -> int:
     print(f"wrote={ablation_path}")
     print(f"wrote={summary_path}")
     print(f"wrote={fixlist_path}")
+    print(f"wrote={auto_tuned_path}")
     print(f"wrote={out_json}")
     return 0
 
diff --git a/scripts/pipeline_latency_audit.py b/scripts/pipeline_latency_audit.py
new file mode 100644
index 0000000..8db5c49
--- /dev/null
+++ b/scripts/pipeline_latency_audit.py
@@ -0,0 +1,436 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import atexit
+import argparse
+import json
+import os
+import statistics
+import subprocess
+import sys
+import time
+from datetime import datetime, timezone
+from pathlib import Path
+from typing import Any, Dict, List
+
+import requests
+
+
+def utc_day() -> str:
+    return datetime.now(timezone.utc).strftime("%Y-%m-%d")
+
+
+def default_run_id() -> str:
+    ts = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
+    return f"pipeline-latency-{ts}-{os.getpid()}"
+
+
+def percentile(values: List[float], p: float) -> float:
+    if not values:
+        return 0.0
+    arr = sorted(values)
+    idx = int(round((len(arr) - 1) * p))
+    idx = max(0, min(len(arr) - 1, idx))
+    return arr[idx]
+
+
+def parse_args() -> argparse.Namespace:
+    p = argparse.ArgumentParser(description="Full pipeline latency audit for direct/udp/active-active modes")
+    p.add_argument("--base-url", default="http://127.0.0.1:18080")
+    p.add_argument("--run-id", default=default_run_id())
+    p.add_argument("--out-root", default="datasets/reports")
+    p.add_argument("--profile", choices=["quick", "standard", "deep"], default="quick")
+    p.add_argument("--sample-seconds", type=int, default=90)
+    p.add_argument("--poll-interval-sec", type=float, default=2.0)
+    p.add_argument("--warmup-sec", type=int, default=8)
+    p.add_argument("--skip-sweep", action="store_true")
+    p.add_argument("--skip-e2e", action="store_true")
+    return p.parse_args()
+
+
+def post_json(session: requests.Session, base_url: str, path: str, payload: Dict[str, Any]) -> Dict[str, Any]:
+    resp = session.post(f"{base_url.rstrip('/')}{path}", json=payload, timeout=8)
+    resp.raise_for_status()
+    return resp.json()
+
+
+def get_json(session: requests.Session, base_url: str, path: str) -> Dict[str, Any]:
+    resp = session.get(f"{base_url.rstrip('/')}{path}", timeout=8)
+    resp.raise_for_status()
+    return resp.json()
+
+
+def run_cmd(cmd: List[str]) -> None:
+    subprocess.run(cmd, check=True)
+
+
+def read_json(path: Path) -> Dict[str, Any]:
+    return json.loads(path.read_text(encoding="utf-8"))
+
+
+def e2e_summary(e2e_payload: Dict[str, Any]) -> Dict[str, Any]:
+    stats = (e2e_payload.get("engine") or {}).get("stats") or {}
+
+    def pick(name: str) -> Dict[str, float]:
+        obj = stats.get(name) or {}
+        if isinstance(obj, dict):
+            return {
+                "p50": float(obj.get("p50", 0.0) or 0.0),
+                "p90": float(obj.get("p90", 0.0) or 0.0),
+                "p99": float(obj.get("p99", 0.0) or 0.0),
+            }
+        return {"p50": 0.0, "p90": 0.0, "p99": 0.0}
+
+    return {
+        "tick_to_ack_p99_ms": pick("tick_to_ack_p99_ms"),
+        "tick_to_decision_p99_ms": pick("tick_to_decision_p99_ms"),
+        "decision_compute_p99_ms": pick("decision_compute_p99_ms"),
+        "source_latency_p99_ms": pick("source_latency_p99_ms"),
+        "local_backlog_p99_ms": pick("local_backlog_p99_ms"),
+        "samples": int((e2e_payload.get("engine") or {}).get("samples") or 0),
+        "failures": int((e2e_payload.get("engine") or {}).get("failures") or 0),
+    }
+
+
+def collect_live_samples(
+    session: requests.Session,
+    base_url: str,
+    seconds: int,
+    poll_interval: float,
+) -> List[Dict[str, Any]]:
+    samples: List[Dict[str, Any]] = []
+    deadline = time.time() + max(1, seconds)
+    while time.time() < deadline:
+        try:
+            samples.append(get_json(session, base_url, "/report/shadow/live"))
+        except requests.RequestException:
+            pass
+        time.sleep(max(0.5, poll_interval))
+    if not samples:
+        samples.append(get_json(session, base_url, "/report/shadow/live"))
+    return samples
+
+
+def summary_from_samples(samples: List[Dict[str, Any]]) -> Dict[str, Any]:
+    def col(name: str) -> List[float]:
+        out: List[float] = []
+        for row in samples:
+            if name in row:
+                try:
+                    out.append(float(row[name]))
+                except Exception:
+                    continue
+        return out
+
+    def col_lat(name: str) -> List[float]:
+        out: List[float] = []
+        for row in samples:
+            lat = row.get("latency") or {}
+            if name in lat:
+                try:
+                    out.append(float(lat[name]))
+                except Exception:
+                    continue
+        return out
+
+    def p(vals: List[float], q: float) -> float:
+        return percentile(vals, q)
+
+    tick_to_ack = col("tick_to_ack_p99_ms")
+    tick_to_decision = col("tick_to_decision_p99_ms")
+    decision_compute = col("decision_compute_p99_ms")
+    quote_block = col("quote_block_ratio")
+    policy_block = col("policy_block_ratio")
+    executed_over_eligible = col("executed_over_eligible")
+    eligible_count = col("eligible_count")
+    executed_count = col("executed_count")
+    fillability = col("fillability_10ms")
+    ev_net = col("ev_net_usdc_p50")
+    ev_positive_ratio = col("ev_positive_ratio")
+    data_valid = col("data_valid_ratio")
+    lag_half_life = col("lag_half_life_ms")
+    outcomes = col("window_outcomes")
+    source_latency = col("source_latency_p99_ms")
+    local_backlog = col("local_backlog_p99_ms")
+    feed_in_p99 = col_lat("feed_in_p99_ms")
+    queue_wait_p99 = col_lat("decision_queue_wait_p99_ms")
+    compute_p99 = col_lat("decision_compute_p99_ms")
+
+    source_mix: Dict[str, float] = {}
+    exit_reason_top: Dict[str, int] = {}
+    gate_ready_series_strict: List[float] = []
+    gate_ready_series_reported: List[float] = []
+    gate_ready_series_effective: List[float] = []
+    gate_ready_mismatch_count = 0
+    for row in samples:
+        strict = bool(row.get("gate_ready_strict", row.get("gate_ready", False)))
+        reported = bool(row.get("gate_ready_effective", strict))
+        eligible = float(row.get("eligible_count", 0.0) or 0.0)
+        executed = float(row.get("executed_count", 0.0) or 0.0)
+        effective = reported or eligible > 0.0 or executed > 0.0
+        gate_ready_series_strict.append(1.0 if strict else 0.0)
+        gate_ready_series_reported.append(1.0 if reported else 0.0)
+        gate_ready_series_effective.append(1.0 if effective else 0.0)
+        if executed > 0.0 and not reported:
+            gate_ready_mismatch_count += 1
+
+        source_mix_row = row.get("source_mix_ratio") or row.get("source_mix_ratio_peak") or {}
+        for k, v in source_mix_row.items():
+            source_mix[k] = max(source_mix.get(k, 0.0), float(v))
+        exit_reason_row = row.get("exit_reason_top") or {}
+        if isinstance(exit_reason_row, dict):
+            for k, v in exit_reason_row.items():
+                try:
+                    exit_reason_top[str(k)] = int(v)
+                except Exception:
+                    continue
+        elif isinstance(exit_reason_row, list):
+            for item in exit_reason_row:
+                if isinstance(item, list) and len(item) == 2:
+                    exit_reason_top[str(item[0])] = int(item[1])
+
+    return {
+        "samples": len(samples),
+        "tick_to_ack_p99_ms": {"p50": p(tick_to_ack, 0.50), "p90": p(tick_to_ack, 0.90), "p99": p(tick_to_ack, 0.99)},
+        "tick_to_decision_p99_ms": {"p50": p(tick_to_decision, 0.50), "p90": p(tick_to_decision, 0.90), "p99": p(tick_to_decision, 0.99)},
+        "decision_compute_p99_ms": {"p50": p(decision_compute, 0.50), "p90": p(decision_compute, 0.90), "p99": p(decision_compute, 0.99)},
+        "quote_block_ratio": {"p50": p(quote_block, 0.50), "p90": p(quote_block, 0.90)},
+        "policy_block_ratio": {"p50": p(policy_block, 0.50), "p90": p(policy_block, 0.90)},
+        "eligible_count": {"p50": p(eligible_count, 0.50), "p90": p(eligible_count, 0.90)},
+        "executed_count": {"p50": p(executed_count, 0.50), "p90": p(executed_count, 0.90)},
+        "executed_over_eligible": {"p50": p(executed_over_eligible, 0.50)},
+        "fillability_10ms": {"p50": p(fillability, 0.50)},
+        "ev_net_usdc_p50": {"p50": p(ev_net, 0.50), "p90": p(ev_net, 0.90)},
+        "ev_positive_ratio": {"p50": p(ev_positive_ratio, 0.50)},
+        "data_valid_ratio": {"p50": p(data_valid, 0.50), "p10": p(data_valid, 0.10)},
+        "lag_half_life_ms": {"p50": p(lag_half_life, 0.50), "p90": p(lag_half_life, 0.90)},
+        "window_outcomes": {"p50": p(outcomes, 0.50), "max": max(outcomes) if outcomes else 0.0},
+        "source_latency_p99_ms": {"p50": p(source_latency, 0.50), "p90": p(source_latency, 0.90)},
+        "local_backlog_p99_ms": {"p50": p(local_backlog, 0.50), "p90": p(local_backlog, 0.90)},
+        "feed_in_p99_ms": {"p50": p(feed_in_p99, 0.50), "p90": p(feed_in_p99, 0.90)},
+        "decision_queue_wait_p99_ms": {"p50": p(queue_wait_p99, 0.50), "p90": p(queue_wait_p99, 0.90)},
+        "latency_decision_compute_p99_ms": {"p50": p(compute_p99, 0.50), "p90": p(compute_p99, 0.90)},
+        "gate_ready_ratio": p(gate_ready_series_effective, 0.50),
+        "gate_ready_ratio_strict": p(gate_ready_series_strict, 0.50),
+        "gate_ready_ratio_reported": p(gate_ready_series_reported, 0.50),
+        "gate_ready_ratio_effective": p(gate_ready_series_effective, 0.50),
+        "gate_ready_mismatch_count": gate_ready_mismatch_count,
+        "source_mix_ratio_peak": source_mix,
+        "exit_reason_top_last": dict(sorted(exit_reason_top.items(), key=lambda kv: kv[1], reverse=True)[:8]),
+        "tick_to_ack_stddev": statistics.pstdev(tick_to_ack) if len(tick_to_ack) > 1 else 0.0,
+    }
+
+
+def mode_payload(mode: str) -> Dict[str, Any]:
+    if mode == "direct_only":
+        return {"enable_udp": False, "mode": "direct_only", "dedupe_window_ms": 30}
+    if mode == "udp_only":
+        return {"enable_udp": True, "mode": "udp_only", "dedupe_window_ms": 30}
+    if mode == "active_active":
+        return {"enable_udp": True, "mode": "active_active", "dedupe_window_ms": 30}
+    if mode == "websocket_primary":
+        return {
+            "enable_udp": True,
+            "mode": "websocket_primary",
+            "dedupe_window_ms": 30,
+        }
+    raise ValueError(f"unsupported mode: {mode}")
+
+
+def write_markdown(out_md: Path, payload: Dict[str, Any]) -> None:
+    lines: List[str] = []
+    lines.append("# Full Pipeline Latency Audit")
+    lines.append("")
+    lines.append(f"- run_id: {payload['run_id']}")
+    lines.append(f"- generated_at_utc: {payload['generated_at_utc']}")
+    lines.append(f"- base_url: {payload['base_url']}")
+    lines.append(f"- profile: {payload['profile']}")
+    lines.append("")
+    lines.append("## Mode Summary")
+    lines.append("")
+    lines.append("| mode | tick_to_ack_p99 p50 (ms) | tick_to_decision_p99 p50 (ms) | feed_in_p99 p50 (ms) | decision_compute_p99 p50 (ms) | data_valid p50 | gate_ready_effective |")
+    lines.append("|---|---:|---:|---:|---:|---:|---:|")
+    for mode in payload["modes"]:
+        s = payload["modes"][mode]["summary"]
+        lines.append(
+            "| "
+            + f"{mode} | {s['tick_to_ack_p99_ms']['p50']:.3f} | {s['tick_to_decision_p99_ms']['p50']:.3f} | "
+            + f"{s['feed_in_p99_ms']['p50']:.3f} | {s['decision_compute_p99_ms']['p50']:.3f} | "
+            + f"{s['data_valid_ratio']['p50']:.5f} | {s['gate_ready_ratio_effective']:.3f} |"
+        )
+    lines.append("")
+    lines.append("## End-to-End Flow")
+    lines.append("")
+    lines.append("```mermaid")
+    lines.append("flowchart LR")
+    lines.append("    A[Binance/Chainlink ticks] --> B[Tokyo Sender parse + 24-byte pack]")
+    lines.append("    B --> C[AWS Backbone UDP]")
+    lines.append("    C --> D[Ireland app_runner UDP ingest]")
+    lines.append("    A --> E[Ireland direct WS ingest]")
+    lines.append("    D --> F[Fusion dedupe + source selection]")
+    lines.append("    E --> F")
+    lines.append("    F --> G[Time alignment + fair value]")
+    lines.append("    G --> H[Edge engine EV_net - penalty]")
+    lines.append("    H --> I[Execution router maker/taker]")
+    lines.append("    I --> J[Order ACK / fill updates]")
+    lines.append("    J --> K[Shadow stats + gate metrics]")
+    lines.append("    K --> L[Optimizer champion/challenger]")
+    lines.append("```")
+    lines.append("")
+    lines.append("## Per-Mode Details")
+    lines.append("")
+    for mode in payload["modes"]:
+        m = payload["modes"][mode]
+        s = m["summary"]
+        lines.append(f"### {mode}")
+        lines.append("")
+        lines.append(f"- samples: {s['samples']}")
+        lines.append(f"- tick_to_ack_p99_ms p50/p90/p99: {s['tick_to_ack_p99_ms']['p50']:.3f}/{s['tick_to_ack_p99_ms']['p90']:.3f}/{s['tick_to_ack_p99_ms']['p99']:.3f}")
+        lines.append(f"- tick_to_decision_p99_ms p50/p90/p99: {s['tick_to_decision_p99_ms']['p50']:.3f}/{s['tick_to_decision_p99_ms']['p90']:.3f}/{s['tick_to_decision_p99_ms']['p99']:.3f}")
+        lines.append(f"- source_latency_p99_ms p50/p90: {s['source_latency_p99_ms']['p50']:.3f}/{s['source_latency_p99_ms']['p90']:.3f}")
+        lines.append(f"- local_backlog_p99_ms p50/p90: {s['local_backlog_p99_ms']['p50']:.3f}/{s['local_backlog_p99_ms']['p90']:.3f}")
+        lines.append(f"- feed_in_p99_ms p50/p90: {s['feed_in_p99_ms']['p50']:.3f}/{s['feed_in_p99_ms']['p90']:.3f}")
+        lines.append(f"- decision_queue_wait_p99_ms p50/p90: {s['decision_queue_wait_p99_ms']['p50']:.3f}/{s['decision_queue_wait_p99_ms']['p90']:.3f}")
+        lines.append(f"- decision_compute_p99_ms p50/p90/p99: {s['decision_compute_p99_ms']['p50']:.3f}/{s['decision_compute_p99_ms']['p90']:.3f}/{s['decision_compute_p99_ms']['p99']:.3f}")
+        lines.append(f"- lag_half_life_ms p50/p90: {s['lag_half_life_ms']['p50']:.3f}/{s['lag_half_life_ms']['p90']:.3f}")
+        lines.append(f"- quote_block_ratio p50/p90: {s['quote_block_ratio']['p50']:.4f}/{s['quote_block_ratio']['p90']:.4f}")
+        lines.append(f"- policy_block_ratio p50/p90: {s['policy_block_ratio']['p50']:.4f}/{s['policy_block_ratio']['p90']:.4f}")
+        lines.append(f"- eligible_count p50/p90: {s['eligible_count']['p50']:.3f}/{s['eligible_count']['p90']:.3f}")
+        lines.append(f"- executed_count p50/p90: {s['executed_count']['p50']:.3f}/{s['executed_count']['p90']:.3f}")
+        lines.append(f"- data_valid_ratio p10/p50: {s['data_valid_ratio']['p10']:.5f}/{s['data_valid_ratio']['p50']:.5f}")
+        lines.append(f"- executed_over_eligible p50: {s['executed_over_eligible']['p50']:.4f}")
+        lines.append(
+            f"- gate_ready_ratio strict/reported/effective: {s['gate_ready_ratio_strict']:.3f}/{s['gate_ready_ratio_reported']:.3f}/{s['gate_ready_ratio_effective']:.3f}"
+        )
+        lines.append(f"- gate_ready_mismatch_count: {s['gate_ready_mismatch_count']}")
+        lines.append(f"- ev_net_usdc_p50 p50/p90: {s['ev_net_usdc_p50']['p50']:.6f}/{s['ev_net_usdc_p50']['p90']:.6f}")
+        lines.append(f"- source_mix_ratio_peak: {json.dumps(s['source_mix_ratio_peak'], ensure_ascii=True)}")
+        lines.append(f"- exit_reason_top_last: {json.dumps(s['exit_reason_top_last'], ensure_ascii=True)}")
+        if m.get("e2e_json"):
+            lines.append(f"- e2e_json: `{m['e2e_json']}`")
+        if m.get("sweep_jsons"):
+            lines.append(f"- sweep_jsons: {', '.join(m['sweep_jsons'])}")
+        lines.append("")
+    out_md.write_text("\n".join(lines), encoding="utf-8")
+
+
+def main() -> int:
+    args = parse_args()
+    out_dir = Path(args.out_root) / utc_day() / "runs" / args.run_id
+    out_dir.mkdir(parents=True, exist_ok=True)
+    modes = ["direct_only", "udp_only", "active_active", "websocket_primary"]
+
+    session = requests.Session()
+    atexit.register(session.close)
+    payload: Dict[str, Any] = {
+        "generated_at_utc": datetime.now(timezone.utc).isoformat(),
+        "run_id": args.run_id,
+        "base_url": args.base_url,
+        "profile": args.profile,
+        "sample_seconds": args.sample_seconds,
+        "modes": {},
+    }
+
+    for mode in modes:
+        mode_dir = out_dir / mode
+        mode_dir.mkdir(parents=True, exist_ok=True)
+        print(f"[mode] {mode} start")
+        fusion_resp = post_json(session, args.base_url, "/control/reload_fusion", mode_payload(mode))
+        post_json(session, args.base_url, "/control/reset_shadow", {})
+        post_json(session, args.base_url, "/control/resume", {})
+        time.sleep(max(1, args.warmup_sec))
+
+        mode_result: Dict[str, Any] = {
+            "fusion_applied": fusion_resp,
+            "live_samples_file": str(mode_dir / "live_samples.json"),
+        }
+
+        if not args.skip_e2e:
+            e2e_json = mode_dir / "e2e_latency.json"
+            cmd = [
+                sys.executable,
+                "scripts/e2e_latency_test.py",
+                "--profile",
+                args.profile,
+                "--mode",
+                "ws-first",
+                "--base-url",
+                args.base_url,
+                "--seconds",
+                str(max(30, args.sample_seconds)),
+                "--json-out",
+                str(e2e_json),
+            ]
+            try:
+                run_cmd(cmd)
+                mode_result["e2e_json"] = str(e2e_json)
+                mode_result["summary_e2e"] = e2e_summary(read_json(e2e_json))
+            except subprocess.CalledProcessError as err:
+                mode_result["e2e_error"] = {
+                    "returncode": int(err.returncode),
+                    "command": cmd,
+                }
+
+        if not args.skip_sweep:
+            sweep_cmd = [
+                sys.executable,
+                "scripts/full_latency_sweep.py",
+                "--profile",
+                args.profile,
+                "--base-url",
+                args.base_url,
+                "--out-root",
+                args.out_root,
+                "--run-id",
+                f"{args.run_id}-{mode}",
+                "--fusion-mode",
+                mode,
+                "--reset-shadow",
+                "--warmup-sec",
+                str(max(1, args.warmup_sec)),
+                "--dedupe-window-ms",
+                "30",
+            ]
+            try:
+                run_cmd(sweep_cmd)
+                sweep_files = sorted(
+                    str(p)
+                    for p in (Path(args.out_root) / utc_day() / "runs" / f"{args.run_id}-{mode}").glob("full_latency_sweep_*.json")
+                )
+                mode_result["sweep_jsons"] = sweep_files
+            except subprocess.CalledProcessError as err:
+                mode_result["sweep_error"] = {
+                    "returncode": int(err.returncode),
+                    "command": sweep_cmd,
+                }
+
+        # Re-baseline live summary after sweep to prevent cross-window contamination.
+        post_json(session, args.base_url, "/control/reload_fusion", mode_payload(mode))
+        post_json(session, args.base_url, "/control/reset_shadow", {})
+        post_json(session, args.base_url, "/control/resume", {})
+        time.sleep(max(1, args.warmup_sec))
+        samples = collect_live_samples(session, args.base_url, args.sample_seconds, args.poll_interval_sec)
+        (mode_dir / "live_samples.json").write_text(json.dumps(samples, ensure_ascii=True, indent=2), encoding="utf-8")
+        mode_result["summary"] = summary_from_samples(samples)
+        if mode_result.get("summary_e2e"):
+            live_ack = mode_result["summary"]["tick_to_ack_p99_ms"]["p50"]
+            e2e_ack = mode_result["summary_e2e"]["tick_to_ack_p99_ms"]["p50"]
+            ratio = 0.0 if e2e_ack <= 0 else live_ack / e2e_ack
+            mode_result["consistency"] = {
+                "tick_to_ack_p50_ratio_live_over_e2e": ratio,
+                "consistent": bool(0.5 <= ratio <= 2.0) if e2e_ack > 0 else (live_ack == 0.0),
+            }
+        payload["modes"][mode] = mode_result
+        print(f"[mode] {mode} done samples={len(samples)}")
+
+    out_json = out_dir / "pipeline_latency_audit.json"
+    out_md = out_dir / "pipeline_latency_audit.md"
+    out_json.write_text(json.dumps(payload, ensure_ascii=True, indent=2), encoding="utf-8")
+    write_markdown(out_md, payload)
+    print(f"wrote={out_json}")
+    print(f"wrote={out_md}")
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/scripts/probe_binance_endpoints_tokyo.sh b/scripts/probe_binance_endpoints_tokyo.sh
new file mode 100644
index 0000000..1a7652b
--- /dev/null
+++ b/scripts/probe_binance_endpoints_tokyo.sh
@@ -0,0 +1,61 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+# Quick host RTT probe for Tokyo feeder. Run directly on Tokyo EC2.
+# Example:
+#   bash scripts/probe_binance_endpoints_tokyo.sh
+#   PING_COUNT=60 bash scripts/probe_binance_endpoints_tokyo.sh stream.binance.com stream1.binance.com ws-api.binance.com
+
+COUNT="${PING_COUNT:-100}"
+if [[ $# -gt 0 ]]; then
+  HOSTS=("$@")
+else
+  HOSTS=("stream.binance.com" "stream1.binance.com" "ws-api.binance.com")
+fi
+
+echo "probe_count=$COUNT"
+echo "ts_utc=$(date -u '+%Y-%m-%dT%H:%M:%SZ')"
+
+for host in "${HOSTS[@]}"; do
+  echo "=== $host ==="
+  # Keep script alive even if one host has intermittent packet loss.
+  if ! out="$(ping -c "$COUNT" "$host" 2>/dev/null || true)"; then
+    echo "status=error"
+    continue
+  fi
+  if [[ -z "$out" ]]; then
+    echo "status=no_output"
+    continue
+  fi
+
+  # Parse icmp_seq lines to extract all RTT samples.
+  samples="$(echo "$out" | awk -F'time=' '/time=/{print $2}' | awk '{print $1}')"
+  if [[ -z "$samples" ]]; then
+    echo "status=no_samples"
+    echo "$out" | tail -n 3
+    continue
+  fi
+
+  python - "$host" <<'PY'
+import sys
+from statistics import median
+
+host = sys.argv[1]
+vals = [float(x.strip()) for x in sys.stdin if x.strip()]
+vals.sort()
+n = len(vals)
+def pct(p: float) -> float:
+    if not vals:
+        return 0.0
+    idx = round((n - 1) * p)
+    idx = max(0, min(idx, n - 1))
+    return vals[idx]
+
+print(f"host={host} samples={n} p50_ms={pct(0.50):.3f} p90_ms={pct(0.90):.3f} p99_ms={pct(0.99):.3f} min_ms={vals[0]:.3f} max_ms={vals[-1]:.3f}")
+PY
+  <<<"$samples"
+
+  # Also print packet loss summary from ping output.
+  echo "$out" | awk '/packet loss|rtt min\/avg\/max/{print}'
+done
+
diff --git a/scripts/remote_deploy_validate.ps1 b/scripts/remote_deploy_validate.ps1
index 0ed2f30..b54b140 100644
--- a/scripts/remote_deploy_validate.ps1
+++ b/scripts/remote_deploy_validate.ps1
@@ -36,7 +36,7 @@ Invoke-Remote "echo connected && uname -a && date -u +%Y-%m-%dT%H:%M:%SZ"
 
 Write-Host "[2/7] Ensure repository is up to date"
 $repoSyncTemplate = @'
-set -e; if [ -d __REPO_DIR__/.git ]; then cd __REPO_DIR__ && git fetch origin && git checkout __BRANCH__ && git pull --ff-only origin __BRANCH__; else git clone --branch __BRANCH__ __REPO_URL__ __REPO_DIR__; fi
+set -e; if [ -d __REPO_DIR__ ] && git -C __REPO_DIR__ rev-parse --is-inside-work-tree >/dev/null 2>&1; then cd __REPO_DIR__ && git fetch origin && git checkout __BRANCH__ && git pull --ff-only origin __BRANCH__; elif [ -e __REPO_DIR__ ]; then rm -rf __REPO_DIR__ && git clone --branch __BRANCH__ __REPO_URL__ __REPO_DIR__; else git clone --branch __BRANCH__ __REPO_URL__ __REPO_DIR__; fi
 '@
 $repoSync = $repoSyncTemplate.Replace("__REPO_DIR__", $RepoDir).Replace("__BRANCH__", $Branch).Replace("__REPO_URL__", $RepoUrl)
 Invoke-Remote $repoSync
@@ -56,7 +56,15 @@ Invoke-Remote $buildCmd
 
 Write-Host "[5/7] Restart runtime"
 $restartTemplate = @'
-cd __REPO_DIR__ || exit 1; pkill -x app_runner >/dev/null 2>&1 || true; nohup env RUST_LOG=info ./target/release/app_runner >/tmp/polyedge_app.log 2>&1 & true
+set -e
+cd __REPO_DIR__ || exit 1
+if command -v systemctl >/dev/null 2>&1 && systemctl --quiet is-enabled polyedge.service 2>/dev/null; then
+  sudo systemctl daemon-reload || true
+  sudo systemctl restart polyedge.service
+else
+  pkill -x app_runner >/dev/null 2>&1 || true
+  nohup env RUST_LOG=info POLYEDGE_ENABLE_BINANCE_WS=true POLYEDGE_ENABLE_BYBIT_WS=false POLYEDGE_ENABLE_COINBASE_WS=false POLYEDGE_ENABLE_CHAINLINK_ANCHOR=true ./target/release/app_runner >/tmp/polyedge_app.log 2>&1 & true
+fi
 '@
 $restartCmd = $restartTemplate.Replace("__REPO_DIR__", $RepoDir)
 Invoke-Remote $restartCmd
diff --git a/scripts/remote_fullchain_benchmark.ps1 b/scripts/remote_fullchain_benchmark.ps1
new file mode 100644
index 0000000..2e7f7bd
--- /dev/null
+++ b/scripts/remote_fullchain_benchmark.ps1
@@ -0,0 +1,253 @@
+Param(
+  [Parameter(Mandatory = $true)]
+  [string]$SshHost,
+
+  [Parameter(Mandatory = $true)]
+  [string]$KeyPath,
+
+  [string]$User = "ubuntu",
+
+  # Local port for SSH -L tunnel -> remote 127.0.0.1:8080
+  [int]$LocalPort = 18080,
+
+  # Remote engine/control API port bound to loopback on the server
+  [int]$RemotePort = 8080,
+
+  [string]$RunId = "",
+
+  [int]$SweepRepeats = 3,
+  [ValidateSet("quick", "standard", "deep")]
+  [string]$SweepProfile = "quick",
+
+  [int]$StormDurationSec = 60,
+  [int]$StormConcurrency = 8,
+  [int]$StormBurstRps = 20,
+
+  [ValidateSet("maker_first", "taker_first", "taker_only")]
+  [string]$PredatorPriority = "taker_first",
+
+  # Optional baseline run dir for automatic regression attribution + gate.
+  [string]$BaselineRunDir = "",
+  [switch]$RegressionGate = $false,
+
+  # Optional: three-window A/B is more about gate/EV than raw latency; keep opt-in for latency work.
+  [switch]$DoThreeWindow = $false
+)
+
+Set-StrictMode -Version Latest
+$ErrorActionPreference = "Stop"
+
+function UtcDay {
+  return (Get-Date).ToUniversalTime().ToString("yyyy-MM-dd")
+}
+
+function NowUtcIso {
+  return (Get-Date).ToUniversalTime().ToString("o")
+}
+
+function Ensure-RunId {
+  if ($RunId -and $RunId.Trim().Length -gt 0) { return }
+  $script:RunId = "fullchain-" + [DateTimeOffset]::UtcNow.ToUnixTimeSeconds()
+}
+
+function Write-TextFile([string]$Path, [string]$Content) {
+  $dir = Split-Path -Parent $Path
+  if ($dir) { New-Item -ItemType Directory -Force -Path $dir | Out-Null }
+  Set-Content -Path $Path -Value $Content -Encoding utf8
+}
+
+function Write-JsonFile([string]$Path, $Obj) {
+  $dir = Split-Path -Parent $Path
+  if ($dir) { New-Item -ItemType Directory -Force -Path $dir | Out-Null }
+  ($Obj | ConvertTo-Json -Depth 40) | Set-Content -Path $Path -Encoding utf8
+}
+
+function Invoke-RestJson([string]$Method, [string]$Url, $Body = $null, [int]$TimeoutSec = 5) {
+  if ($Method -eq "GET") {
+    return Invoke-RestMethod -Method Get -Uri $Url -TimeoutSec $TimeoutSec
+  }
+  if ($Body -eq $null) { $Body = @{} }
+  return Invoke-RestMethod -Method Post -Uri $Url -TimeoutSec $TimeoutSec -ContentType "application/json" -Body ($Body | ConvertTo-Json -Compress)
+}
+
+function Wait-HttpOk([string]$Url, [int]$Attempts = 40, [int]$SleepMs = 250) {
+  for ($i = 0; $i -lt $Attempts; $i++) {
+    try {
+      $resp = Invoke-WebRequest -Method Get -Uri $Url -TimeoutSec 2
+      if ($resp.StatusCode -ge 200 -and $resp.StatusCode -lt 300) { return }
+    } catch {}
+    Start-Sleep -Milliseconds $SleepMs
+  }
+  throw "endpoint not reachable: $Url"
+}
+
+function Try-JsonSnapshot([string]$Path, [string]$Url) {
+  try {
+    Write-JsonFile $Path (Invoke-RestJson "GET" $Url $null 5)
+    return $true
+  } catch {
+    Write-TextFile ($Path + ".err.txt") ($_.Exception.Message)
+    return $false
+  }
+}
+
+function Try-TextSnapshot([string]$Path, [string]$Url) {
+  try {
+    $resp = Invoke-WebRequest -Method Get -Uri $Url -TimeoutSec 10
+    Write-TextFile $Path $resp.Content
+    return $true
+  } catch {
+    Write-TextFile ($Path + ".err.txt") ($_.Exception.Message)
+    return $false
+  }
+}
+
+Ensure-RunId
+
+$Day = UtcDay
+$BaseUrl = "http://127.0.0.1:$LocalPort"
+$RunDir = "datasets/reports/$Day/runs/$RunId"
+$SnapDir = "$RunDir/snapshots"
+
+  Write-Host ("run_id=" + $RunId)
+  Write-Host ("base_url=" + $BaseUrl)
+  Write-Host ("run_dir=" + $RunDir)
+  if ($BaselineRunDir) { Write-Host ("baseline_run_dir=" + $BaselineRunDir) }
+
+# Start SSH tunnel in background.
+$sshArgs = @(
+  "-F", "NUL",
+  "-i", $KeyPath,
+  "-o", "ExitOnForwardFailure=yes",
+  "-o", "ServerAliveInterval=10",
+  "-o", "ServerAliveCountMax=3",
+  "-N",
+  "-L", "$LocalPort`:`127.0.0.1`:$RemotePort",
+  "$User@$SshHost"
+)
+
+$tunnel = $null
+try {
+  $tunnel = Start-Process -FilePath "ssh" -ArgumentList $sshArgs -NoNewWindow -PassThru
+
+  # Wait for the tunnelled HTTP endpoint.
+  Wait-HttpOk "$BaseUrl/health" 60 250
+
+  # Remote system snapshot (for later attribution).
+  $remoteInfo = & ssh -F NUL -i $KeyPath "$User@$SshHost" "bash -lc 'set -e; date -u -Ins; uname -a; (lscpu || true) | head -n 40; (free -m || true); (ss -lntp || true) | head -n 60'"
+  Write-TextFile "$SnapDir/remote_env.txt" ($remoteInfo -join "`n")
+
+  # Pre snapshots
+  Write-JsonFile "$SnapDir/health_pre.json" (Invoke-RestJson "GET" "$BaseUrl/health" $null 5)
+  Write-JsonFile "$SnapDir/shadow_live_pre.json" (Invoke-RestJson "GET" "$BaseUrl/report/shadow/live" $null 5)
+  Try-JsonSnapshot "$SnapDir/toxicity_live_pre.json" "$BaseUrl/report/toxicity/live" | Out-Null
+  Try-JsonSnapshot "$SnapDir/direction_pre.json" "$BaseUrl/report/direction" | Out-Null
+  Try-JsonSnapshot "$SnapDir/router_pre.json" "$BaseUrl/report/router" | Out-Null
+  Try-JsonSnapshot "$SnapDir/capital_pre.json" "$BaseUrl/report/capital" | Out-Null
+  Try-TextSnapshot "$SnapDir/metrics_pre.prom" "$BaseUrl/metrics" | Out-Null
+
+  # Safety: resume (no-op if already).
+  Write-JsonFile "$SnapDir/resume_pre.json" (Invoke-RestJson "POST" "$BaseUrl/control/resume" @{} 5)
+  Write-JsonFile "$SnapDir/reset_shadow_pre_sweeps.json" (Invoke-RestJson "POST" "$BaseUrl/control/reset_shadow" @{} 5)
+  Start-Sleep -Seconds 5
+
+  # Sweeps (engine series + ws probe; base_url points to remote via tunnel).
+  for ($i = 1; $i -le [Math]::Max(1, $SweepRepeats); $i++) {
+    if ($i -gt 1) {
+      Write-Host ("reset_shadow before sweep " + $i)
+      Write-JsonFile "$SnapDir/reset_shadow_before_sweep_$i.json" (Invoke-RestJson "POST" "$BaseUrl/control/reset_shadow" @{} 5)
+      Start-Sleep -Seconds 5
+    }
+    Write-Host ("sweep=" + $i + "/" + $SweepRepeats)
+    & python scripts/full_latency_sweep.py --profile $SweepProfile --base-url $BaseUrl --out-root "datasets/reports" --run-id $RunId --skip-ws --reset-shadow --warmup-sec 5
+    if ($LASTEXITCODE -ne 0) { throw "full_latency_sweep failed (exit=$LASTEXITCODE)" }
+    if ($i -lt $SweepRepeats) {
+      Start-Sleep -Seconds 5
+    }
+  }
+  Write-JsonFile "$SnapDir/shadow_live_after_sweeps.json" (Invoke-RestJson "GET" "$BaseUrl/report/shadow/live" $null 5)
+
+  # Storm test (control churn + poll). Writes under runs/<run_id>/ due to --use-run-dir.
+  Write-Host "storm_test"
+  & python scripts/storm_test.py --base-url $BaseUrl --duration-sec $StormDurationSec --concurrency $StormConcurrency --burst-rps $StormBurstRps --out-root "datasets/reports" --run-id $RunId --use-run-dir
+  if ($LASTEXITCODE -ne 0) { throw "storm_test failed (exit=$LASTEXITCODE)" }
+
+  Write-JsonFile "$SnapDir/health_after_storm.json" (Invoke-RestJson "GET" "$BaseUrl/health" $null 5)
+  Write-JsonFile "$SnapDir/shadow_live_after_storm.json" (Invoke-RestJson "GET" "$BaseUrl/report/shadow/live" $null 5)
+
+  if ($DoThreeWindow) {
+    Write-Host "three_window_verify (ab)"
+    & python scripts/three_window_verify.py --base-url $BaseUrl --mode "ab" --predator-priority $PredatorPriority --out-root "datasets/reports" --run-id $RunId
+    if ($LASTEXITCODE -ne 0) { throw "three_window_verify failed (exit=$LASTEXITCODE)" }
+    Write-JsonFile "$SnapDir/shadow_live_after_threew.json" (Invoke-RestJson "GET" "$BaseUrl/report/shadow/live" $null 5)
+    Try-JsonSnapshot "$SnapDir/pnl_by_engine_after_threew.json" "$BaseUrl/report/pnl/by_engine" | Out-Null
+  }
+
+  if ($BaselineRunDir -and (Test-Path $BaselineRunDir)) {
+    Write-Host "analyze_fullchain_run (with baseline)"
+    $analysisJson = "$RunDir/regression_analysis.json"
+    $analysisArgs = @(
+      "scripts/analyze_fullchain_run.py",
+      "--run-dir", $RunDir,
+      "--baseline-run-dir", $BaselineRunDir,
+      "--json-out", $analysisJson
+    )
+    if ($RegressionGate) {
+      $analysisArgs += "--fail-on-regression"
+    }
+    & python @analysisArgs
+    if ($LASTEXITCODE -ne 0) { throw "analyze_fullchain_run failed (exit=$LASTEXITCODE)" }
+  }
+
+  # Post snapshots + safety resume
+  Write-JsonFile "$SnapDir/resume_post.json" (Invoke-RestJson "POST" "$BaseUrl/control/resume" @{} 5)
+  Write-JsonFile "$SnapDir/health_post.json" (Invoke-RestJson "GET" "$BaseUrl/health" $null 5)
+  Try-TextSnapshot "$SnapDir/metrics_post.prom" "$BaseUrl/metrics" | Out-Null
+
+  Write-JsonFile "$RunDir/run_meta.json" @{
+    ts_utc = NowUtcIso
+    run_id = $RunId
+    ssh_user = $User
+    ssh_host = $SshHost
+    local_port = $LocalPort
+    remote_port = $RemotePort
+    base_url = $BaseUrl
+    sweep_profile = $SweepProfile
+    sweep_repeats = $SweepRepeats
+    storm = @{
+      duration_sec = $StormDurationSec
+      concurrency = $StormConcurrency
+      burst_rps = $StormBurstRps
+    }
+    do_three_window = [bool]$DoThreeWindow
+    predator_priority = $PredatorPriority
+  }
+
+  Write-TextFile "$RunDir/README.md" @"
+# Fullchain Benchmark Run
+
+- RunId: $RunId
+- Date(UTC): $Day
+- BaseUrl (tunnel -> remote 127.0.0.1:$RemotePort): $BaseUrl
+
+## Artifacts
+- $RunDir/snapshots/*.json: point-in-time snapshots of /health, /report/*, etc.
+- $RunDir/snapshots/*.prom: /metrics before/after.
+- datasets/reports/$Day/runs/$RunId/full_latency_sweep_*.json: engine series + ws probe results.
+- datasets/reports/$Day/runs/$RunId/storm_test_summary.json + storm_test_trace.jsonl: stress polling + control churn.
+- datasets/reports/$Day/runs/$RunId/regression_analysis.json: optional baseline diff + likely cause attribution.
+
+## What To Look At First
+- snapshots/shadow_live_pre.json vs snapshots/shadow_live_after_storm.json
+  - decision_queue_wait_p99_ms
+  - decision_compute_p99_ms
+  - local_backlog_p99_ms
+- full_latency_sweep_*.json: engine.stats.* time series stability across repeats.
+"@
+
+  Write-Host "done"
+} finally {
+  if ($tunnel -and -not $tunnel.HasExited) {
+    try { Stop-Process -Id $tunnel.Id -Force } catch {}
+  }
+}
diff --git a/scripts/run_continuous_optimizer.ps1 b/scripts/run_continuous_optimizer.ps1
new file mode 100644
index 0000000..f238c42
--- /dev/null
+++ b/scripts/run_continuous_optimizer.ps1
@@ -0,0 +1,137 @@
+param(
+    [Parameter(Mandatory = $true)]
+    [string]$SshHost,
+
+    [Parameter(Mandatory = $true)]
+    [string]$KeyPath,
+
+    [string]$User = "ubuntu",
+    [int]$LocalPort = 18080,
+    [int]$RemotePort = 8080,
+
+    [ValidateSet("quick", "standard", "deep")]
+    [string]$Profile = "standard",
+
+    [string]$RunIdPrefix = "optimizer",
+    [string]$StateFile = "datasets/reports/champion_state.json",
+    [string]$StopFile = "datasets/reports/STOP_OPTIMIZER",
+    [string]$OutRoot = "datasets/reports",
+
+    [int]$MaxRuntimeSec = 0,
+    [int]$CycleSleepSec = 2,
+    [int]$MinOutcomes = 30,
+    [double]$MinObjectiveDelta = 0.0005,
+    [double]$HttpTimeoutSec = 8.0,
+    [int]$MaxSampleReadFailures = 4,
+    [bool]$RestartOnFailure = $true,
+    [int]$RestartDelaySec = 5,
+    [int]$MaxRestarts = 0
+)
+
+Set-StrictMode -Version Latest
+$ErrorActionPreference = "Stop"
+
+function Wait-HttpOk([string]$Url, [int]$Attempts = 60, [int]$SleepMs = 250) {
+    for ($i = 0; $i -lt $Attempts; $i++) {
+        try {
+            $resp = Invoke-WebRequest -Method Get -Uri $Url -TimeoutSec 2
+            if ($resp.StatusCode -ge 200 -and $resp.StatusCode -lt 300) {
+                return
+            }
+        } catch {
+        }
+        Start-Sleep -Milliseconds $SleepMs
+    }
+    throw "endpoint not reachable: $Url"
+}
+
+$baseUrl = "http://127.0.0.1:$LocalPort"
+
+$sshArgs = @(
+    "-F", "NUL",
+    "-i", $KeyPath,
+    "-o", "ExitOnForwardFailure=yes",
+    "-o", "ServerAliveInterval=10",
+    "-o", "ServerAliveCountMax=3",
+    "-N",
+    "-L", "$LocalPort`:`127.0.0.1`:$RemotePort",
+    "$User@$SshHost"
+)
+
+$tunnel = $null
+try {
+    Write-Host "starting ssh tunnel -> $SshHost ($LocalPort -> 127.0.0.1:$RemotePort)"
+    $tunnel = Start-Process -FilePath "ssh" -ArgumentList $sshArgs -NoNewWindow -PassThru
+    Wait-HttpOk "$baseUrl/health" 80 250
+
+    Write-Host "base_url=$baseUrl"
+    Write-Host "state_file=$StateFile"
+    Write-Host "stop_file=$StopFile"
+    Write-Host "restart_on_failure=$RestartOnFailure restart_delay_sec=$RestartDelaySec max_restarts=$MaxRestarts"
+
+    $deadlineUtc = $null
+    if ($MaxRuntimeSec -gt 0) {
+        $deadlineUtc = (Get-Date).ToUniversalTime().AddSeconds($MaxRuntimeSec)
+    }
+
+    $restarts = 0
+    while ($true) {
+        if (Test-Path $StopFile) {
+            Write-Host "stop file detected before launch: $StopFile"
+            break
+        }
+
+        $runId = "$RunIdPrefix-" + (Get-Date).ToUniversalTime().ToString("yyyyMMddTHHmmssZ") + "-r$restarts"
+        $args = @(
+            "scripts/long_regression_orchestrator.py",
+            "--profile", $Profile,
+            "--continuous",
+            "--base-url", $baseUrl,
+            "--run-id", $runId,
+            "--out-root", $OutRoot,
+            "--state-file", $StateFile,
+            "--stop-file", $StopFile,
+            "--cycle-sleep-sec", "$CycleSleepSec",
+            "--min-outcomes", "$MinOutcomes",
+            "--min-objective-delta", "$MinObjectiveDelta",
+            "--http-timeout-sec", "$HttpTimeoutSec",
+            "--max-sample-read-failures", "$MaxSampleReadFailures"
+        )
+
+        if ($deadlineUtc -ne $null) {
+            $remaining = [int][Math]::Floor(($deadlineUtc - (Get-Date).ToUniversalTime()).TotalSeconds)
+            if ($remaining -le 0) {
+                Write-Host "global max runtime reached"
+                break
+            }
+            $args += @("--max-runtime-sec", "$remaining")
+        }
+
+        Write-Host "run_id=$runId"
+        & python @args
+        $exitCode = $LASTEXITCODE
+        if ($exitCode -eq 0) {
+            break
+        }
+        if (-not $RestartOnFailure) {
+            throw "long_regression_orchestrator failed (exit=$exitCode)"
+        }
+        if (Test-Path $StopFile) {
+            Write-Host "stop file detected after failure: $StopFile"
+            break
+        }
+        $restarts += 1
+        if ($MaxRestarts -gt 0 -and $restarts -gt $MaxRestarts) {
+            throw "long_regression_orchestrator failed too many times; restarts=$restarts"
+        }
+        Write-Host "orchestrator failed (exit=$exitCode), restarting in $RestartDelaySec sec..."
+        Start-Sleep -Seconds ([Math]::Max(1, $RestartDelaySec))
+    }
+} finally {
+    if ($tunnel -and -not $tunnel.HasExited) {
+        try {
+            Stop-Process -Id $tunnel.Id -Force
+        } catch {
+        }
+    }
+}
diff --git a/scripts/run_guard_background.py b/scripts/run_guard_background.py
new file mode 100644
index 0000000..9e3cdad
--- /dev/null
+++ b/scripts/run_guard_background.py
@@ -0,0 +1,118 @@
+#!/usr/bin/env python3
+"""Run seat_transport_guard.py as a background child with heartbeat logging."""
+
+from __future__ import annotations
+
+import argparse
+import subprocess
+import sys
+import time
+from datetime import datetime, timezone
+from pathlib import Path
+
+
+def utc_day(ts: float | None = None) -> str:
+    dt = datetime.fromtimestamp(ts or time.time(), tz=timezone.utc)
+    return dt.strftime("%Y-%m-%d")
+
+
+def parse_args() -> argparse.Namespace:
+    p = argparse.ArgumentParser(description="Background wrapper for seat_transport_guard.py")
+    p.add_argument("--run-id", required=True)
+    p.add_argument("--base-url", default="http://127.0.0.1:8080")
+    p.add_argument("--out-root", default="datasets/reports")
+    p.add_argument("--profile", default="quick_60s", choices=["quick_60s", "quick", "standard", "deep"])
+    p.add_argument("--dedupe-window-ms", type=int, default=8)
+    p.add_argument("--udp-share-cap", type=float, default=0.35)
+    p.add_argument("--jitter-threshold-ms", type=float, default=25.0)
+    p.add_argument("--fallback-arm-duration-ms", type=int, default=8000)
+    p.add_argument("--fallback-cooldown-sec", type=int, default=300)
+    p.add_argument("--udp-local-only", choices=["true", "false"], default="true")
+    p.add_argument("--warmup-sec", type=int, default=5)
+    p.add_argument("--storm-duration-sec", type=int, default=60)
+    p.add_argument("--storm-concurrency", type=int, default=8)
+    p.add_argument("--storm-burst-rps", type=int, default=20)
+    p.add_argument("--skip-storm", action="store_true")
+    p.add_argument("--heartbeat-sec", type=int, default=5)
+    p.add_argument("--timeout-sec", type=int, default=3600)
+    return p.parse_args()
+
+
+def tail_last_line(path: Path) -> str:
+    if not path.exists():
+        return ""
+    data = path.read_text(encoding="utf-8", errors="ignore").splitlines()
+    for line in reversed(data):
+        if line.strip():
+            return line.strip()
+    return ""
+
+
+def main() -> int:
+    args = parse_args()
+    run_dir = Path(args.out_root) / utc_day() / "runs" / args.run_id
+    run_dir.mkdir(parents=True, exist_ok=True)
+    log_path = run_dir / "seat_transport_guard_live.log"
+
+    cmd = [
+        sys.executable,
+        "scripts/seat_transport_guard.py",
+        "--run-id",
+        args.run_id,
+        "--base-url",
+        args.base_url,
+        "--out-root",
+        args.out_root,
+        "--profile",
+        args.profile,
+        "--dedupe-window-ms",
+        str(args.dedupe_window_ms),
+        "--udp-share-cap",
+        str(args.udp_share_cap),
+        "--jitter-threshold-ms",
+        str(args.jitter_threshold_ms),
+        "--fallback-arm-duration-ms",
+        str(args.fallback_arm_duration_ms),
+        "--fallback-cooldown-sec",
+        str(args.fallback_cooldown_sec),
+        "--udp-local-only",
+        args.udp_local_only,
+        "--warmup-sec",
+        str(args.warmup_sec),
+        "--storm-duration-sec",
+        str(args.storm_duration_sec),
+        "--storm-concurrency",
+        str(args.storm_concurrency),
+        "--storm-burst-rps",
+        str(args.storm_burst_rps),
+    ]
+    if args.skip_storm:
+        cmd.append("--skip-storm")
+
+    started = time.time()
+    with log_path.open("w", encoding="utf-8") as log_file:
+        proc = subprocess.Popen(cmd, stdout=log_file, stderr=subprocess.STDOUT)
+        print(f"guard_pid={proc.pid}")
+        print(f"log={log_path}")
+        while True:
+            rc = proc.poll()
+            elapsed = int(time.time() - started)
+            if rc is not None:
+                print(f"exit={rc} elapsed={elapsed}s")
+                summary = run_dir / "seat_transport_guard_summary.json"
+                print(f"summary={summary}")
+                return rc
+            if elapsed >= args.timeout_sec:
+                proc.kill()
+                print(f"timeout after {elapsed}s")
+                return 124
+            line = tail_last_line(log_path)
+            if line:
+                print(f"[hb] elapsed={elapsed}s last={line}")
+            else:
+                print(f"[hb] elapsed={elapsed}s waiting-for-first-log-line")
+            time.sleep(max(1, args.heartbeat_sec))
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/scripts/runtime_watchdog.py b/scripts/runtime_watchdog.py
index a5f780a..8de36bf 100644
--- a/scripts/runtime_watchdog.py
+++ b/scripts/runtime_watchdog.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 from __future__ import annotations
 
+import atexit
 import argparse
 import json
 import sys
@@ -294,6 +295,7 @@ def run_once(session: requests.Session, args: argparse.Namespace) -> int:
 def main() -> int:
     args = parse_args()
     session = requests.Session()
+    atexit.register(session.close)
 
     if args.once:
         return run_once(session, args)
diff --git a/scripts/seat_optimizer_service.py b/scripts/seat_optimizer_service.py
new file mode 100644
index 0000000..94bf131
--- /dev/null
+++ b/scripts/seat_optimizer_service.py
@@ -0,0 +1,719 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import json
+import math
+import os
+import random
+import statistics
+import time
+from dataclasses import dataclass
+from http.server import BaseHTTPRequestHandler, ThreadingHTTPServer
+from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple
+
+
+L1_FIELDS: Tuple[str, ...] = (
+    "position_fraction",
+    "min_edge_net_bps",
+    "convergence_exit_ratio",
+    "min_velocity_bps_per_sec",
+)
+
+L2_EXTRA_FIELDS: Tuple[str, ...] = (
+    "capital_fraction_kelly",
+    "t100ms_reversal_bps",
+    "t300ms_reversal_bps",
+    "max_single_trade_loss_usdc",
+    "risk_max_drawdown_pct",
+    "risk_max_market_notional",
+)
+
+L3_EXTRA_FIELDS: Tuple[str, ...] = (
+    "maker_min_edge_bps",
+    "basis_k_revert",
+    "basis_z_cap",
+)
+
+# Coarse absolute bounds to avoid optimizer drift.
+FIELD_BOUNDS: Dict[str, Tuple[float, float]] = {
+    "position_fraction": (0.01, 1.0),
+    "min_edge_net_bps": (1.0, 5_000.0),
+    "convergence_exit_ratio": (0.05, 0.99),
+    "min_velocity_bps_per_sec": (0.1, 1_000.0),
+    "capital_fraction_kelly": (0.01, 1.0),
+    "t100ms_reversal_bps": (0.1, 2_000.0),
+    "t300ms_reversal_bps": (0.1, 2_000.0),
+    "max_single_trade_loss_usdc": (0.0, 5_000.0),
+    "risk_max_drawdown_pct": (0.001, 1.0),
+    "risk_max_market_notional": (0.0, 5_000_000.0),
+    "maker_min_edge_bps": (0.1, 1_000.0),
+    "basis_k_revert": (0.0, 5.0),
+    "basis_z_cap": (0.5, 8.0),
+}
+
+STYLE_STORE: Dict[str, Dict[str, Any]] = {}
+RL_TABLE: Dict[str, Dict[str, float]] = {}
+
+
+@dataclass
+class CandidateEval:
+    params: Dict[str, float]
+    objective: float
+    ev_pred: float
+    dd_pred: float
+
+
+def now_ms() -> int:
+    return int(time.time() * 1000)
+
+
+def clamp(v: float, lo: float, hi: float) -> float:
+    return min(max(v, lo), hi)
+
+
+def percentile(values: Sequence[float], p: float) -> float:
+    if not values:
+        return 0.0
+    data = sorted(values)
+    idx = int(round((len(data) - 1) * p))
+    idx = max(0, min(idx, len(data) - 1))
+    return float(data[idx])
+
+
+def get_float(data: Dict[str, Any], key: str, default: float) -> float:
+    value = data.get(key, default)
+    try:
+        out = float(value)
+        if math.isfinite(out):
+            return out
+    except Exception:
+        pass
+    return float(default)
+
+
+def parse_param_set(raw: Dict[str, Any]) -> Dict[str, float]:
+    out: Dict[str, float] = {}
+    for k, v in raw.items():
+        if v is None:
+            continue
+        try:
+            fv = float(v)
+            if math.isfinite(fv):
+                out[k] = fv
+        except Exception:
+            continue
+    return out
+
+
+def get_layer_fields(layer: str) -> Tuple[str, ...]:
+    if layer == "layer1":
+        return L1_FIELDS
+    if layer == "layer2":
+        return L1_FIELDS + L2_EXTRA_FIELDS
+    if layer == "layer3":
+        return L1_FIELDS + L2_EXTRA_FIELDS + L3_EXTRA_FIELDS
+    return L1_FIELDS
+
+
+def relative_clip(current: float, candidate: float, pct: float) -> float:
+    if not math.isfinite(current) or not math.isfinite(candidate):
+        return current
+    step = abs(current) * max(0.0, pct)
+    if step <= 0.0:
+        return candidate
+    return clamp(candidate, current - step, current + step)
+
+
+def apply_bounds(field: str, value: float) -> float:
+    lo, hi = FIELD_BOUNDS.get(field, (-1.0e18, 1.0e18))
+    return clamp(value, lo, hi)
+
+
+def style_distance(a: Dict[str, float], b: Dict[str, float]) -> float:
+    # Weighted normalized distance for 4-d style vector.
+    weights = {
+        "volatility_proxy": 0.35,
+        "source_health_min": 0.30,
+        "roi_notional_10s_bps_p50": 0.20,
+        "win_rate": 0.15,
+    }
+    total = 0.0
+    for key, w in weights.items():
+        av = float(a.get(key, 0.0))
+        bv = float(b.get(key, 0.0))
+        scale = max(1.0, abs(av), abs(bv))
+        z = (av - bv) / scale
+        total += w * (z * z)
+    return math.sqrt(max(0.0, total))
+
+
+def weighted_median(values: List[Tuple[float, float]]) -> float:
+    if not values:
+        return 0.0
+    data = sorted(values, key=lambda item: item[0])
+    total = sum(max(0.0, w) for _, w in data)
+    if total <= 0.0:
+        return data[len(data) // 2][0]
+    acc = 0.0
+    for v, w in data:
+        acc += max(0.0, w)
+        if acc >= total * 0.5:
+            return v
+    return data[-1][0]
+
+
+def knn_warm_start(
+    current: Dict[str, float],
+    current_style: Dict[str, float],
+    style_memory: List[Dict[str, Any]],
+    fields: Tuple[str, ...],
+) -> Tuple[Dict[str, float], float, int, str]:
+    if len(style_memory) < 8:
+        return dict(current), 0.0, 0, "fallback_layer2_bo"
+
+    scored: List[Tuple[float, Dict[str, Any]]] = []
+    for entry in style_memory:
+        vector = entry.get("vector") or {}
+        params = entry.get("params") or {}
+        if not isinstance(vector, dict) or not isinstance(params, dict):
+            continue
+        d = style_distance(current_style, parse_param_set(vector))
+        scored.append((d, entry))
+    if not scored:
+        return dict(current), 0.0, 0, "fallback_layer2_bo"
+
+    scored.sort(key=lambda item: item[0])
+    neighbors = scored[: min(5, len(scored))]
+    warm = dict(current)
+    for field in fields:
+        weighted_values: List[Tuple[float, float]] = []
+        for dist, entry in neighbors:
+            params = parse_param_set(entry.get("params") or {})
+            if field not in params:
+                continue
+            weight = 1.0 / (1.0e-6 + dist)
+            weighted_values.append((params[field], weight))
+        if weighted_values:
+            warm[field] = weighted_median(weighted_values)
+
+    mean_dist = statistics.mean(d for d, _ in neighbors)
+    match_score = 1.0 / (1.0 + mean_dist)
+    return warm, match_score, len(neighbors), "knn_memory"
+
+
+def infer_style_id(style: Dict[str, float]) -> str:
+    vol = "hv" if float(style.get("volatility_proxy", 0.0)) > 8.0 else "lv"
+    health = "hh" if float(style.get("source_health_min", 0.0)) > 0.6 else "lh"
+    drift = "pr" if float(style.get("roi_notional_10s_bps_p50", 0.0)) > 0.0 else "ng"
+    return f"{vol}_{health}_{drift}"
+
+
+def choose_action(layer: str, baseline: Dict[str, float]) -> str:
+    ev = float(baseline.get("ev_usdc_p50", 0.0))
+    dd = float(baseline.get("max_drawdown_pct", 0.0))
+    win = float(baseline.get("win_rate", 0.5))
+    if ev < 0.0 or dd > 0.06 or win < 0.5:
+        return "tighten"
+    if layer == "layer3" and ev > 0.0 and dd < 0.03 and win > 0.55:
+        return "loosen"
+    return "neutral"
+
+
+def rl_signal(style_id: str, action: str) -> float:
+    table = RL_TABLE.get(style_id, {})
+    return float(table.get(action, 0.0))
+
+
+def surrogate_eval(
+    current: Dict[str, float],
+    candidate: Dict[str, float],
+    baseline: Dict[str, float],
+    layer: str,
+    action: str,
+    rl: float,
+) -> CandidateEval:
+    base_obj = float(baseline.get("objective", 0.0))
+    base_ev = float(baseline.get("ev_usdc_p50", 0.0))
+    base_dd = max(0.0, float(baseline.get("max_drawdown_pct", 0.0)))
+    base_win = float(baseline.get("win_rate", 0.5))
+
+    def rel_delta(field: str) -> float:
+        cur = float(current.get(field, candidate.get(field, 0.0)))
+        nxt = float(candidate.get(field, cur))
+        scale = max(1.0e-6, abs(cur))
+        return (nxt - cur) / scale
+
+    d_pos = rel_delta("position_fraction")
+    d_edge = rel_delta("min_edge_net_bps")
+    d_exit = rel_delta("convergence_exit_ratio")
+    d_vel = rel_delta("min_velocity_bps_per_sec")
+    d_kelly = rel_delta("capital_fraction_kelly")
+    d_risk_dd = rel_delta("risk_max_drawdown_pct")
+    d_risk_notional = rel_delta("risk_max_market_notional")
+    d_maker = rel_delta("maker_min_edge_bps")
+    d_basis_k = rel_delta("basis_k_revert")
+
+    ev_gain = (
+        0.22 * d_pos
+        - 0.14 * d_edge
+        + 0.07 * d_exit
+        - 0.08 * d_vel
+        + 0.19 * d_kelly
+        - 0.10 * d_maker
+        + 0.05 * d_basis_k
+    )
+    dd_risk = (
+        0.20 * max(0.0, d_pos)
+        + 0.20 * max(0.0, d_kelly)
+        + 0.15 * max(0.0, d_risk_notional)
+        + 0.10 * max(0.0, d_risk_dd)
+        + 0.08 * max(0.0, -d_edge)
+    )
+
+    if action == "tighten":
+        ev_gain -= 0.03
+        dd_risk *= 0.75
+    elif action == "loosen":
+        ev_gain += 0.03
+        dd_risk *= 1.15
+
+    uplift = ev_gain * max(0.5, abs(base_ev) * 0.15 + 1.0)
+    ev_pred = base_ev + uplift + rl * 0.02
+    dd_pred = clamp(base_dd + dd_risk * 0.04 - max(0.0, base_win - 0.5) * 0.01, 0.0, 1.0)
+
+    obj = base_obj + uplift - dd_risk * 0.35 + rl * 0.04
+    return CandidateEval(params=candidate, objective=obj, ev_pred=ev_pred, dd_pred=dd_pred)
+
+
+def sample_candidate(
+    rng: random.Random,
+    current: Dict[str, float],
+    warm: Dict[str, float],
+    fields: Tuple[str, ...],
+    step_limit: float,
+    layer: str,
+    baseline: Dict[str, float],
+    action: str,
+    rl: float,
+) -> CandidateEval:
+    out = dict(current)
+    for field in fields:
+        if field not in current and field not in warm:
+            continue
+        cur = float(current.get(field, warm.get(field, 0.0)))
+        prior = float(warm.get(field, cur))
+        scale = max(1.0e-6, abs(cur), abs(prior))
+        sigma = scale * step_limit * (0.22 if layer == "layer1" else 0.45)
+        proposal = rng.gauss(prior, sigma)
+        proposal = relative_clip(cur, proposal, step_limit)
+        out[field] = apply_bounds(field, proposal)
+
+    return surrogate_eval(current, out, baseline, layer, action, rl)
+
+
+def bayesian_consensus(
+    current: Dict[str, float],
+    warm: Dict[str, float],
+    fields: Tuple[str, ...],
+    ranked: List[CandidateEval],
+) -> Dict[str, float]:
+    if not ranked:
+        return dict(current)
+    top_k = ranked
+    out = dict(current)
+    for field in fields:
+        prior = float(warm.get(field, current.get(field, 0.0)))
+        values = [row.params[field] for row in top_k if field in row.params]
+        if not values:
+            continue
+        consensus = percentile(values, 0.50)
+        spread = max(1.0e-6, percentile(values, 0.75) - percentile(values, 0.25))
+        prior_var = max(1.0e-6, abs(prior) * 0.12)
+        obs_var = spread if spread > 0.0 else prior_var
+        posterior = (prior / prior_var + consensus / obs_var) / (1.0 / prior_var + 1.0 / obs_var)
+        out[field] = apply_bounds(field, posterior)
+    return out
+
+
+def apply_rl_post_adjust(
+    candidate: Dict[str, float],
+    current: Dict[str, float],
+    action: str,
+    rl: float,
+    step_limit: float,
+) -> Dict[str, float]:
+    out = dict(candidate)
+    mag = clamp(abs(rl), 0.0, 0.35) * 0.02
+    if action == "tighten":
+        if "position_fraction" in out:
+            out["position_fraction"] = relative_clip(
+                current.get("position_fraction", out["position_fraction"]),
+                out["position_fraction"] * (1.0 - mag),
+                step_limit,
+            )
+        if "capital_fraction_kelly" in out:
+            out["capital_fraction_kelly"] = relative_clip(
+                current.get("capital_fraction_kelly", out["capital_fraction_kelly"]),
+                out["capital_fraction_kelly"] * (1.0 - mag),
+                step_limit,
+            )
+    elif action == "loosen":
+        if "position_fraction" in out:
+            out["position_fraction"] = relative_clip(
+                current.get("position_fraction", out["position_fraction"]),
+                out["position_fraction"] * (1.0 + mag),
+                step_limit,
+            )
+    for k, v in list(out.items()):
+        out[k] = apply_bounds(k, v)
+    return out
+
+
+def compute_walk_forward(
+    layer: str,
+    baseline: Dict[str, float],
+    candidate_eval: CandidateEval,
+    objective_history: List[Dict[str, Any]],
+) -> Tuple[bool, int, float]:
+    required = 6 if layer == "layer1" else 12 if layer == "layer2" else 20
+    values = [
+        get_float(point, "objective", float(baseline.get("objective", 0.0)))
+        for point in objective_history[-required * 12 :]
+    ]
+    if not values:
+        values = [float(baseline.get("objective", 0.0))] * required
+
+    windows: List[float] = []
+    window_size = max(1, len(values) // required)
+    for i in range(0, len(values), window_size):
+        seg = values[i : i + window_size]
+        if not seg:
+            continue
+        windows.append(sum(seg) / len(seg))
+    if len(windows) < required:
+        windows.extend([windows[-1] if windows else float(baseline.get("objective", 0.0))] * (required - len(windows)))
+
+    baseline_obj = float(baseline.get("objective", 0.0))
+    # Candidate should show robust uplift under a conservative discount.
+    uplift = candidate_eval.objective - baseline_obj
+    adjusted = [w + uplift * 0.65 for w in windows[:required]]
+    wins = sum(1 for v in adjusted if v >= baseline_obj)
+    score = wins / max(1, required)
+
+    threshold = 0.52 if layer == "layer1" else 0.58 if layer == "layer2" else 0.60
+    return score >= threshold, required, score
+
+
+def simulate_max_drawdown(path: Iterable[float]) -> float:
+    peak = 0.0
+    pnl = 0.0
+    max_dd = 0.0
+    for x in path:
+        pnl += x
+        peak = max(peak, pnl)
+        dd = peak - pnl
+        max_dd = max(max_dd, dd)
+    return max_dd
+
+
+def run_monte_carlo(
+    layer: str,
+    baseline: Dict[str, float],
+    candidate_eval: CandidateEval,
+    runs: int,
+    seed: int,
+) -> Tuple[bool, float, float]:
+    rng = random.Random(seed)
+    base_ev = float(baseline.get("ev_usdc_p50", 0.0))
+    base_dd = max(0.0, float(baseline.get("max_drawdown_pct", 0.0)))
+    uplift = candidate_eval.ev_pred - base_ev
+
+    horizon = 40 if layer == "layer1" else 70 if layer == "layer2" else 100
+    sigma = max(0.02, abs(float(baseline.get("volatility_proxy", 0.0))) * 0.002)
+
+    ev_delta_series: List[float] = []
+    dd_series: List[float] = []
+    for _ in range(max(1, runs)):
+        path: List[float] = []
+        mean_step = (base_ev + uplift) / max(1, horizon)
+        for _ in range(horizon):
+            # Mixture noise approximates heavy tails without extra deps.
+            noise = rng.gauss(0.0, sigma)
+            if rng.random() < 0.06:
+                noise += rng.gauss(0.0, sigma * 2.6)
+            path.append(mean_step + noise)
+        ev_new = sum(path)
+        ev_delta_series.append(ev_new - base_ev)
+
+        dd_path = [x - statistics.mean(path) for x in path]
+        dd_series.append(simulate_max_drawdown(dd_path) * 0.001)
+
+    ev_delta_p50 = percentile(ev_delta_series, 0.50)
+    ev_delta_p25 = percentile(ev_delta_series, 0.25)
+    ev_delta_p10 = percentile(ev_delta_series, 0.10)
+    dd_p95 = percentile(dd_series, 0.95)
+
+    if layer == "layer1":
+        passed = ev_delta_p25 >= -abs(base_ev) * 0.08 and dd_p95 <= max(base_dd * 1.35, 0.06)
+    elif layer == "layer2":
+        passed = ev_delta_p50 >= -abs(base_ev) * 0.03 and dd_p95 <= max(base_dd * 1.25, 0.06)
+    else:
+        passed = ev_delta_p50 >= -abs(base_ev) * 0.02 and dd_p95 <= max(base_dd * 1.20, 0.06)
+
+    return passed, ev_delta_p50, dd_p95
+
+
+def optimize_payload(layer: str, data: Dict[str, Any]) -> Dict[str, Any]:
+    baseline = data.get("baseline") or {}
+    current = parse_param_set(data.get("current_params") or {})
+    if not current:
+        return {
+            "layer": layer,
+            "candidate": {},
+            "validation": {
+                "mc_runs": 0,
+                "mc_pass": False,
+                "walk_forward_pass": False,
+                "shadow_pass": False,
+                "walk_forward_windows": 0,
+                "walk_forward_score": 0.0,
+                "mc_ev_delta_p50": 0.0,
+                "mc_drawdown_p95": 0.0,
+            },
+            "meta": {
+                "style_match_score": 0.0,
+                "style_match_count": 0,
+                "top_k_size": 0,
+                "objective_uplift_estimate": 0.0,
+                "rl_signal": 0.0,
+            },
+            "notes": ["current_params_empty"],
+        }
+
+    fields = get_layer_fields(layer)
+    step_limit = 0.05 if layer == "layer1" else 0.12
+    mc_runs = 100 if layer == "layer1" else 500 if layer == "layer2" else 1000
+    sample_count = 64 if layer == "layer1" else 120 if layer == "layer2" else 160
+    top_k_size = 5 if layer == "layer1" else 7 if layer == "layer2" else 9
+
+    style_memory = data.get("style_memory") or []
+    current_style = parse_param_set(data.get("current_style") or {})
+    warm, match_score, match_count, warm_source = knn_warm_start(
+        current=current,
+        current_style=current_style,
+        style_memory=style_memory if isinstance(style_memory, list) else [],
+        fields=fields,
+    )
+
+    style_id = infer_style_id(current_style)
+    action = choose_action(layer, baseline)
+    rl = rl_signal(style_id, action)
+
+    seed = (
+        now_ms()
+        ^ int(abs(get_float(baseline, "objective", 0.0)) * 10_000)
+        ^ (hash(style_id) & 0xFFFF)
+        ^ hash(layer)
+    )
+    rng = random.Random(seed)
+
+    ranked: List[CandidateEval] = []
+    for _ in range(sample_count):
+        eval_row = sample_candidate(
+            rng=rng,
+            current=current,
+            warm=warm,
+            fields=fields,
+            step_limit=step_limit,
+            layer=layer,
+            baseline=baseline,
+            action=action,
+            rl=rl,
+        )
+        ranked.append(eval_row)
+    ranked.sort(key=lambda row: row.objective, reverse=True)
+
+    top = ranked[: max(1, top_k_size)]
+    posterior = bayesian_consensus(current, warm, fields, top)
+    candidate = apply_rl_post_adjust(posterior, current, action, rl, step_limit)
+
+    final_eval = surrogate_eval(current, candidate, baseline, layer, action, rl)
+    objective_uplift = final_eval.objective - get_float(baseline, "objective", 0.0)
+
+    objective_history = data.get("objective_history") if isinstance(data.get("objective_history"), list) else []
+    wf_pass, wf_windows, wf_score = compute_walk_forward(layer, baseline, final_eval, objective_history)
+
+    mc_pass, mc_ev_delta_p50, mc_dd_p95 = run_monte_carlo(
+        layer=layer,
+        baseline=baseline,
+        candidate_eval=final_eval,
+        runs=mc_runs,
+        seed=seed ^ 0x5A5A,
+    )
+
+    # Shadow gate: same hard rule as runtime. Keep here so runtime can audit service opinion.
+    ev_old = get_float(baseline, "ev_usdc_p50", 0.0)
+    dd_old = max(0.0, get_float(baseline, "max_drawdown_pct", 0.0))
+    shadow_pass = final_eval.ev_pred >= ev_old * 1.05 and final_eval.dd_pred <= dd_old * 1.12
+
+    notes = [
+        f"warm_source={warm_source}",
+        f"action={action}",
+        f"sample_count={sample_count}",
+        f"style_id={style_id}",
+        f"ev_pred={final_eval.ev_pred:.6f}",
+        f"dd_pred={final_eval.dd_pred:.6f}",
+    ]
+
+    return {
+        "layer": layer,
+        "candidate": candidate,
+        "validation": {
+            "mc_runs": mc_runs,
+            "mc_pass": bool(mc_pass),
+            "walk_forward_pass": bool(wf_pass),
+            "shadow_pass": bool(shadow_pass),
+            "walk_forward_windows": int(wf_windows),
+            "walk_forward_score": float(wf_score),
+            "mc_ev_delta_p50": float(mc_ev_delta_p50),
+            "mc_drawdown_p95": float(mc_dd_p95),
+        },
+        "meta": {
+            "style_match_score": float(match_score),
+            "style_match_count": int(match_count),
+            "top_k_size": int(len(top)),
+            "objective_uplift_estimate": float(objective_uplift),
+            "rl_signal": float(rl),
+        },
+        "notes": notes,
+    }
+
+
+def run_shadow_compare(data: Dict[str, Any]) -> Dict[str, Any]:
+    ev_new = get_float(data, "ev_new", 0.0)
+    ev_old = get_float(data, "ev_old", 0.0)
+    dd_new = max(0.0, get_float(data, "dd_new", 0.0))
+    dd_old = max(0.0, get_float(data, "dd_old", 0.0))
+    cycles_observed = int(get_float(data, "cycles_observed", 0.0))
+    cycles_required = int(get_float(data, "cycles_required", 0.0))
+
+    pass_ev = ev_new >= ev_old * 1.05
+    pass_dd = dd_new <= dd_old * 1.12
+    pass_cycles = cycles_observed >= cycles_required
+    passed = pass_ev and pass_dd and pass_cycles
+    return {
+        "ok": True,
+        "pass": passed,
+        "checks": {
+            "pass_ev": pass_ev,
+            "pass_dd": pass_dd,
+            "pass_cycles": pass_cycles,
+        },
+    }
+
+
+def run_monitor_60m(data: Dict[str, Any]) -> Dict[str, Any]:
+    ev_new = get_float(data, "ev_new", 0.0)
+    ev_old = get_float(data, "ev_old", 0.0)
+    dd_new = max(0.0, get_float(data, "dd_new", 0.0))
+    dd_old = max(0.0, get_float(data, "dd_old", 0.0))
+
+    rollback = ev_new < ev_old or dd_new > dd_old
+    return {"ok": True, "rollback": rollback}
+
+
+def update_style_memory(data: Dict[str, Any]) -> Dict[str, Any]:
+    entry = data.get("entry") or {}
+    style_id = str(entry.get("style_id") or infer_style_id(parse_param_set(entry.get("vector") or {})))
+    reward = get_float(data, "reward", get_float(data, "objective", 0.0))
+    action = str(data.get("action") or "neutral")
+
+    STYLE_STORE[style_id] = {
+        "entry": entry,
+        "reward": reward,
+        "ts_ms": now_ms(),
+    }
+    table = RL_TABLE.setdefault(style_id, {"tighten": 0.0, "neutral": 0.0, "loosen": 0.0})
+    old = float(table.get(action, 0.0))
+    table[action] = old * 0.8 + reward * 0.2
+
+    return {
+        "ok": True,
+        "accepted": True,
+        "style_id": style_id,
+        "rl_value": table[action],
+        "style_memory_size": len(STYLE_STORE),
+        "ts_ms": now_ms(),
+    }
+
+
+class Handler(BaseHTTPRequestHandler):
+    server_version = "seat-opt/2.3"
+
+    def _send(self, code: int, payload: Dict[str, Any]) -> None:
+        body = json.dumps(payload, ensure_ascii=True).encode("utf-8")
+        self.send_response(code)
+        self.send_header("content-type", "application/json")
+        self.send_header("content-length", str(len(body)))
+        self.end_headers()
+        self.wfile.write(body)
+
+    def _read_json(self) -> Dict[str, Any]:
+        try:
+            size = int(self.headers.get("content-length", "0"))
+        except Exception:
+            size = 0
+        if size <= 0:
+            return {}
+        raw = self.rfile.read(size)
+        try:
+            data = json.loads(raw.decode("utf-8"))
+            return data if isinstance(data, dict) else {}
+        except Exception:
+            return {}
+
+    def do_GET(self) -> None:
+        if self.path == "/health":
+            self._send(200, {"ok": True, "ts_ms": now_ms(), "style_memory_size": len(STYLE_STORE)})
+            return
+        self._send(404, {"ok": False, "error": "not_found"})
+
+    def do_POST(self) -> None:
+        data = self._read_json()
+        path = self.path
+
+        if path == "/v1/seat/l1/optimize":
+            self._send(200, optimize_payload("layer1", data))
+            return
+        if path == "/v1/seat/l2/optimize":
+            self._send(200, optimize_payload("layer2", data))
+            return
+        if path == "/v1/seat/l3/optimize":
+            self._send(200, optimize_payload("layer3", data))
+            return
+        if path == "/v1/seat/shadow_compare":
+            self._send(200, run_shadow_compare(data))
+            return
+        if path == "/v1/seat/monitor_60m":
+            self._send(200, run_monitor_60m(data))
+            return
+        if path == "/v1/seat/style_memory/update":
+            self._send(200, update_style_memory(data))
+            return
+
+        self._send(404, {"ok": False, "error": "not_found"})
+
+    def log_message(self, fmt: str, *args: Any) -> None:
+        return
+
+
+def main() -> None:
+    host = os.environ.get("POLYEDGE_SEAT_OPTIMIZER_HOST", "127.0.0.1")
+    port = int(os.environ.get("POLYEDGE_SEAT_OPTIMIZER_PORT", "8091"))
+    server = ThreadingHTTPServer((host, port), Handler)
+    print(f"[seat-optimizer] listening on {host}:{port}", flush=True)
+    server.serve_forever()
+
+
+if __name__ == "__main__":
+    main()
diff --git a/scripts/seat_remote_acceptance.py b/scripts/seat_remote_acceptance.py
new file mode 100644
index 0000000..2beb3d2
--- /dev/null
+++ b/scripts/seat_remote_acceptance.py
@@ -0,0 +1,228 @@
+#!/usr/bin/env python3
+"""Remote SEAT acceptance checker for Ireland runtime.
+
+This script validates the production acceptance goals without modifying remote state:
+1) Runtime reached Layer2+ after >=72h and >=800 trades.
+2) At least one challenger cycle decision is present.
+3) Reports and decision trail are retrievable remotely.
+"""
+
+from __future__ import annotations
+
+import argparse
+import json
+import subprocess
+import time
+from dataclasses import dataclass
+from datetime import datetime, timezone
+from pathlib import Path
+from typing import Any, Dict, List
+
+
+def utc_day(ts: float | None = None) -> str:
+    dt = datetime.fromtimestamp(ts or time.time(), tz=timezone.utc)
+    return dt.strftime("%Y-%m-%d")
+
+
+def run_ssh_json(host: str, user: str, key: str, remote_cmd: str, timeout: int = 12) -> Dict[str, Any]:
+    cmd = [
+        "ssh",
+        "-i",
+        key,
+        "-o",
+        "StrictHostKeyChecking=no",
+        "-o",
+        "BatchMode=yes",
+        f"{user}@{host}",
+        remote_cmd,
+    ]
+    try:
+        proc = subprocess.run(cmd, check=False, capture_output=True, text=True, timeout=timeout)
+    except subprocess.TimeoutExpired as err:
+        raise RuntimeError(f"ssh timeout after {timeout}s: {err}") from err
+    if proc.returncode != 0:
+        raise RuntimeError(f"ssh failed ({proc.returncode}): {proc.stderr.strip()}")
+    raw = proc.stdout.strip()
+    if not raw:
+        raise RuntimeError("ssh returned empty output")
+    return json.loads(raw)
+
+
+def fetch_status(host: str, user: str, key: str, base_url: str) -> Dict[str, Any]:
+    return run_ssh_json(
+        host,
+        user,
+        key,
+        f"curl -fsSL '{base_url.rstrip('/')}/report/seat/status'",
+    )
+
+
+def fetch_history(host: str, user: str, key: str, base_url: str, limit: int) -> List[Dict[str, Any]]:
+    payload = run_ssh_json(
+        host,
+        user,
+        key,
+        f"curl -fsSL '{base_url.rstrip('/')}/report/seat/history?limit={int(limit)}'",
+    )
+    if isinstance(payload, list):
+        return payload
+    return []
+
+
+@dataclass
+class AcceptanceState:
+    ready_layer2: bool
+    challenger_seen: bool
+    last_layer: str
+    trade_count: int
+    uptime_hours: float
+    reasons: List[str]
+
+
+def evaluate(status: Dict[str, Any], history: List[Dict[str, Any]]) -> AcceptanceState:
+    now_ms = int(time.time() * 1000)
+    started_ms = int(status.get("started_ms", 0) or 0)
+    uptime_hours = max(0.0, (now_ms - started_ms) / 1000.0 / 3600.0)
+
+    layer = str(status.get("current_layer", "unknown"))
+    trade_count = int(status.get("trade_count", 0) or 0)
+
+    ready_layer2 = layer in {"layer2", "layer3"} and trade_count >= 800 and uptime_hours >= 72.0
+
+    decisions = [str(row.get("decision", "")) for row in history if isinstance(row, dict)]
+    challenger_seen = any(dec.startswith("shadow_started") for dec in decisions) and any(
+        dec.startswith("monitor_pass") or dec.startswith("shadow_reject") for dec in decisions
+    )
+
+    reasons: List[str] = []
+    if not ready_layer2:
+        reasons.append(
+            f"layer/trade/uptime not ready: layer={layer}, trades={trade_count}, uptime_h={uptime_hours:.2f}"
+        )
+    if not challenger_seen:
+        reasons.append("challenger cycle not seen in decision history")
+
+    return AcceptanceState(
+        ready_layer2=ready_layer2,
+        challenger_seen=challenger_seen,
+        last_layer=layer,
+        trade_count=trade_count,
+        uptime_hours=uptime_hours,
+        reasons=reasons,
+    )
+
+
+def parse_args() -> argparse.Namespace:
+    p = argparse.ArgumentParser(description="Validate remote SEAT Layer2 acceptance on Ireland node")
+    p.add_argument("--host", default="54.77.232.166")
+    p.add_argument("--user", default="ubuntu")
+    p.add_argument("--key", default=r"C:\Users\Shini\Documents\PolyEdge.pem")
+    p.add_argument("--base-url", default="http://127.0.0.1:8080")
+    p.add_argument("--history-limit", type=int, default=400)
+    p.add_argument("--watch-sec", type=int, default=0, help="poll until timeout; 0 = single shot")
+    p.add_argument("--poll-sec", type=int, default=30)
+    p.add_argument("--run-id", default=f"seat-remote-accept-{int(time.time())}")
+    p.add_argument("--out-root", default="datasets/reports")
+    return p.parse_args()
+
+
+def main() -> int:
+    args = parse_args()
+    deadline = time.time() + max(0, args.watch_sec)
+
+    snapshots: List[Dict[str, Any]] = []
+    final_state: AcceptanceState | None = None
+
+    while True:
+        try:
+            status = fetch_status(args.host, args.user, args.key, args.base_url)
+            history = fetch_history(args.host, args.user, args.key, args.base_url, args.history_limit)
+            state = evaluate(status, history)
+            final_state = state
+
+            snapshots.append(
+                {
+                    "ts_ms": int(time.time() * 1000),
+                    "status": status,
+                    "history_size": len(history),
+                    "evaluation": {
+                        "ready_layer2": state.ready_layer2,
+                        "challenger_seen": state.challenger_seen,
+                        "layer": state.last_layer,
+                        "trade_count": state.trade_count,
+                        "uptime_hours": state.uptime_hours,
+                        "reasons": state.reasons,
+                    },
+                }
+            )
+        except Exception as err:  # noqa: BLE001
+            state = AcceptanceState(
+                ready_layer2=False,
+                challenger_seen=False,
+                last_layer="unreachable",
+                trade_count=0,
+                uptime_hours=0.0,
+                reasons=[f"remote_probe_failed: {err}"],
+            )
+            final_state = state
+            snapshots.append(
+                {
+                    "ts_ms": int(time.time() * 1000),
+                    "error": str(err),
+                    "evaluation": {
+                        "ready_layer2": False,
+                        "challenger_seen": False,
+                        "layer": "unreachable",
+                        "trade_count": 0,
+                        "uptime_hours": 0.0,
+                        "reasons": state.reasons,
+                    },
+                }
+            )
+
+        if state.ready_layer2 and state.challenger_seen:
+            break
+        if args.watch_sec <= 0 or time.time() >= deadline:
+            break
+        time.sleep(max(5, args.poll_sec))
+
+    assert final_state is not None
+    accepted = final_state.ready_layer2 and final_state.challenger_seen
+
+    out_dir = Path(args.out_root) / utc_day() / "runs" / args.run_id
+    out_dir.mkdir(parents=True, exist_ok=True)
+    out_path = out_dir / "seat_remote_acceptance.json"
+    out = {
+        "meta": {
+            "ts_ms": int(time.time() * 1000),
+            "host": args.host,
+            "base_url": args.base_url,
+            "history_limit": args.history_limit,
+            "watch_sec": args.watch_sec,
+            "poll_sec": args.poll_sec,
+            "run_id": args.run_id,
+        },
+        "accepted": accepted,
+        "final": {
+            "ready_layer2": final_state.ready_layer2,
+            "challenger_seen": final_state.challenger_seen,
+            "layer": final_state.last_layer,
+            "trade_count": final_state.trade_count,
+            "uptime_hours": final_state.uptime_hours,
+            "reasons": final_state.reasons,
+        },
+        "snapshots": snapshots,
+    }
+    out_path.write_text(json.dumps(out, ensure_ascii=True, indent=2), encoding="utf-8")
+
+    print(f"accepted={accepted}")
+    print(f"layer={final_state.last_layer}")
+    print(f"trade_count={final_state.trade_count}")
+    print(f"uptime_hours={final_state.uptime_hours:.2f}")
+    print(f"report={out_path}")
+
+    return 0 if accepted else 3
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/scripts/seat_transport_guard.py b/scripts/seat_transport_guard.py
new file mode 100644
index 0000000..a26cb15
--- /dev/null
+++ b/scripts/seat_transport_guard.py
@@ -0,0 +1,386 @@
+#!/usr/bin/env python3
+"""SEAT transport guard: A/B validate candidate transport mode and auto-rollback on regression."""
+
+from __future__ import annotations
+
+import argparse
+import json
+import subprocess
+import sys
+import time
+from dataclasses import dataclass
+from datetime import datetime, timezone
+from pathlib import Path
+from typing import Any, Dict, List, Optional
+
+import requests
+
+
+def utc_day(ts: float | None = None) -> str:
+    dt = datetime.fromtimestamp(ts or datetime.now(timezone.utc).timestamp(), tz=timezone.utc)
+    return dt.strftime("%Y-%m-%d")
+
+
+def log(msg: str) -> None:
+    ts = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
+    print(f"[guard][{ts}] {msg}", flush=True)
+
+
+def run(cmd: List[str]) -> None:
+    started = time.time()
+    log(f"run: {' '.join(cmd)}")
+    proc = subprocess.run(cmd, check=False)
+    elapsed = time.time() - started
+    log(f"exit={proc.returncode} elapsed={elapsed:.1f}s")
+    if proc.returncode != 0:
+        raise RuntimeError(f"command failed (exit={proc.returncode}): {' '.join(cmd)}")
+
+
+def latest_sweep(run_dir: Path) -> Dict[str, Any]:
+    files = sorted(run_dir.glob("full_latency_sweep_*.json"))
+    if not files:
+        raise FileNotFoundError(f"no full_latency_sweep_*.json under {run_dir}")
+    return json.loads(files[-1].read_text(encoding="utf-8"))
+
+
+def storm_summary(run_dir: Path) -> Dict[str, Any]:
+    path = run_dir / "storm_test_summary.json"
+    if not path.exists():
+        return {}
+    return json.loads(path.read_text(encoding="utf-8"))
+
+
+def metric(sweep: Dict[str, Any], key: str, stat: str) -> Optional[float]:
+    try:
+        v = sweep["engine"]["stats"][key][stat]
+        return float(v)
+    except Exception:
+        return None
+
+
+def udp_share(sweep: Dict[str, Any]) -> float:
+    try:
+        mix = sweep["engine"]["last"]["source_mix_ratio"]
+        return float(mix.get("binance_udp", 0.0))
+    except Exception:
+        return 0.0
+
+
+def storm_p99(summary: Dict[str, Any]) -> Optional[float]:
+    try:
+        return float(summary["latency_ms"]["p99"])
+    except Exception:
+        return None
+
+
+@dataclass
+class Check:
+    key: str
+    stat: str
+    direction: str  # lower|higher
+    abs_tol: float
+    rel_tol: float
+
+
+def check_regression(
+    baseline: Dict[str, Any],
+    candidate: Dict[str, Any],
+    checks: List[Check],
+) -> Dict[str, Any]:
+    rows: List[Dict[str, Any]] = []
+    regressed = False
+    for spec in checks:
+        b = metric(baseline, spec.key, spec.stat)
+        c = metric(candidate, spec.key, spec.stat)
+        if b is None or c is None:
+            rows.append(
+                {
+                    "key": spec.key,
+                    "stat": spec.stat,
+                    "status": "missing",
+                    "baseline": b,
+                    "candidate": c,
+                }
+            )
+            continue
+
+        delta = c - b
+        threshold = max(spec.abs_tol, abs(b) * spec.rel_tol)
+        if spec.direction == "lower":
+            is_regressed = delta > threshold
+            is_improved = delta < -threshold
+        else:
+            is_regressed = -delta > threshold
+            is_improved = delta > threshold
+
+        status = "flat"
+        if is_regressed:
+            status = "regressed"
+            regressed = True
+        elif is_improved:
+            status = "improved"
+
+        rows.append(
+            {
+                "key": spec.key,
+                "stat": spec.stat,
+                "status": status,
+                "baseline": b,
+                "candidate": c,
+                "delta": delta,
+                "threshold": threshold,
+                "direction": spec.direction,
+            }
+        )
+    return {"rows": rows, "regressed": regressed}
+
+
+def build_fusion_payload(
+    mode: str,
+    dedupe_window_ms: int,
+    udp_share_cap: Optional[float],
+    jitter_threshold_ms: Optional[float],
+    fallback_arm_duration_ms: Optional[int],
+    fallback_cooldown_sec: Optional[int],
+    udp_local_only: Optional[bool],
+) -> Dict[str, Any]:
+    if mode == "direct_only":
+        payload: Dict[str, Any] = {
+            "enable_udp": False,
+            "mode": "direct_only",
+            "dedupe_window_ms": int(dedupe_window_ms),
+        }
+    else:
+        payload = {
+            "enable_udp": True,
+            "mode": mode,
+            "dedupe_window_ms": int(dedupe_window_ms),
+        }
+    if udp_share_cap is not None:
+        payload["udp_share_cap"] = float(udp_share_cap)
+    if jitter_threshold_ms is not None:
+        payload["jitter_threshold_ms"] = float(jitter_threshold_ms)
+    if fallback_arm_duration_ms is not None:
+        payload["fallback_arm_duration_ms"] = int(fallback_arm_duration_ms)
+    if fallback_cooldown_sec is not None:
+        payload["fallback_cooldown_sec"] = int(fallback_cooldown_sec)
+    if udp_local_only is not None:
+        payload["udp_local_only"] = bool(udp_local_only)
+    return payload
+
+
+def post_json(base_url: str, path: str, payload: Dict[str, Any]) -> Dict[str, Any]:
+    resp = requests.post(f"{base_url.rstrip('/')}{path}", json=payload, timeout=8)
+    resp.raise_for_status()
+    return resp.json()
+
+
+def parse_args() -> argparse.Namespace:
+    p = argparse.ArgumentParser(description="SEAT transport A/B guard with automatic rollback")
+    p.add_argument("--base-url", default="http://127.0.0.1:8080")
+    p.add_argument("--out-root", default="datasets/reports")
+    p.add_argument("--run-id", required=True)
+    p.add_argument(
+        "--profile",
+        default="quick_60s",
+        choices=["quick_60s", "quick", "standard", "deep"],
+    )
+    p.add_argument("--baseline-mode", default="direct_only", choices=["direct_only"])
+    p.add_argument(
+        "--candidate-mode",
+        default="websocket_primary",
+        choices=["websocket_primary", "active_active", "udp_only"],
+    )
+    p.add_argument("--dedupe-window-ms", type=int, default=8)
+    p.add_argument("--storm-duration-sec", type=int, default=60)
+    p.add_argument("--storm-concurrency", type=int, default=8)
+    p.add_argument("--storm-burst-rps", type=int, default=20)
+    p.add_argument("--warmup-sec", type=int, default=5)
+    p.add_argument("--udp-share-cap", type=float, default=0.35)
+    p.add_argument("--jitter-threshold-ms", type=float, default=25.0)
+    p.add_argument("--fallback-arm-duration-ms", type=int, default=8000)
+    p.add_argument("--fallback-cooldown-sec", type=int, default=300)
+    p.add_argument("--udp-local-only", choices=["true", "false"], default="true")
+    p.add_argument(
+        "--skip-storm",
+        action="store_true",
+        help="skip storm_test.py phase for quick transport-only validation",
+    )
+    p.add_argument(
+        "--no-rollback",
+        action="store_true",
+        help="do not apply rollback when regression is detected",
+    )
+    return p.parse_args()
+
+
+def run_phase(
+    mode: str,
+    run_id: str,
+    args: argparse.Namespace,
+    include_candidate_params: bool,
+) -> Path:
+    sweep_cmd = [
+        sys.executable,
+        "scripts/full_latency_sweep.py",
+        "--profile",
+        args.profile,
+        "--base-url",
+        args.base_url,
+        "--fusion-mode",
+        mode,
+        "--dedupe-window-ms",
+        str(args.dedupe_window_ms),
+        "--skip-ws",
+        "--out-root",
+        args.out_root,
+        "--run-id",
+        run_id,
+        "--reset-shadow",
+        "--warmup-sec",
+        str(args.warmup_sec),
+        "--progress-sec",
+        "5",
+    ]
+    if include_candidate_params:
+        sweep_cmd.extend(
+            [
+                "--udp-share-cap",
+                str(args.udp_share_cap),
+                "--jitter-threshold-ms",
+                str(args.jitter_threshold_ms),
+                "--fallback-arm-duration-ms",
+                str(args.fallback_arm_duration_ms),
+                "--fallback-cooldown-sec",
+                str(args.fallback_cooldown_sec),
+                "--udp-local-only",
+                str(args.udp_local_only),
+            ]
+        )
+    run(sweep_cmd)
+
+    if not args.skip_storm:
+        storm_cmd = [
+            sys.executable,
+            "scripts/storm_test.py",
+            "--base-url",
+            args.base_url,
+            "--duration-sec",
+            str(args.storm_duration_sec),
+            "--concurrency",
+            str(args.storm_concurrency),
+            "--burst-rps",
+            str(args.storm_burst_rps),
+            "--out-root",
+            args.out_root,
+            "--run-id",
+            run_id,
+            "--use-run-dir",
+        ]
+        run(storm_cmd)
+    return Path(args.out_root) / utc_day() / "runs" / run_id
+
+
+def main() -> int:
+    args = parse_args()
+    baseline_run_id = f"{args.run_id}-baseline"
+    candidate_run_id = f"{args.run_id}-candidate"
+
+    log(
+        f"start run_id={args.run_id} baseline={args.baseline_mode} "
+        f"candidate={args.candidate_mode} profile={args.profile} skip_storm={args.skip_storm}"
+    )
+    log("phase=baseline")
+    baseline_dir = run_phase(args.baseline_mode, baseline_run_id, args, False)
+    log("phase=candidate")
+    candidate_dir = run_phase(args.candidate_mode, candidate_run_id, args, True)
+
+    base_sweep = latest_sweep(baseline_dir)
+    cand_sweep = latest_sweep(candidate_dir)
+    base_storm = storm_summary(baseline_dir)
+    cand_storm = storm_summary(candidate_dir)
+
+    checks = [
+        Check("tick_to_decision_p99_ms", "p99", "lower", 0.08, 0.20),
+        Check("tick_to_ack_p99_ms", "p99", "lower", 0.08, 0.20),
+        Check("decision_queue_wait_p99_ms", "p99", "lower", 0.08, 0.20),
+        Check("source_latency_p99_ms", "p99", "lower", 5.0, 0.12),
+        Check("policy_block_ratio", "p50", "lower", 0.03, 0.20),
+        Check("survival_probe_10ms", "p50", "higher", 0.02, 0.05),
+        Check("fillability_10ms", "p50", "higher", 0.02, 0.05),
+        Check("ev_net_usdc_p50", "p50", "higher", 0.00015, 0.12),
+    ]
+
+    regression = check_regression(base_sweep, cand_sweep, checks)
+    base_udp_share = udp_share(base_sweep)
+    cand_udp_share = udp_share(cand_sweep)
+    cap_regressed = cand_udp_share > (args.udp_share_cap + 0.05)
+
+    base_storm_p99 = storm_p99(base_storm)
+    cand_storm_p99 = storm_p99(cand_storm)
+    storm_regressed = False
+    if base_storm_p99 is not None and cand_storm_p99 is not None:
+        storm_threshold = max(5.0, abs(base_storm_p99) * 0.25)
+        storm_regressed = (cand_storm_p99 - base_storm_p99) > storm_threshold
+
+    regressed = regression["regressed"] or cap_regressed or storm_regressed
+    rollback_applied = False
+    rollback_resp: Dict[str, Any] | None = None
+
+    if regressed and not args.no_rollback:
+        log("regression detected; applying rollback to direct_only")
+        rollback_payload = build_fusion_payload(
+            mode="direct_only",
+            dedupe_window_ms=args.dedupe_window_ms,
+            udp_share_cap=None,
+            jitter_threshold_ms=None,
+            fallback_arm_duration_ms=None,
+            fallback_cooldown_sec=None,
+            udp_local_only=None,
+        )
+        rollback_resp = post_json(args.base_url, "/control/reload_fusion", rollback_payload)
+        post_json(args.base_url, "/control/reset_shadow", {})
+        post_json(args.base_url, "/control/resume", {})
+        rollback_applied = True
+    elif regressed:
+        log("regression detected; rollback skipped by --no-rollback")
+    else:
+        log("no regression detected")
+
+    summary = {
+        "ts_utc": datetime.now(timezone.utc).isoformat(),
+        "run_id": args.run_id,
+        "baseline_run_id": baseline_run_id,
+        "candidate_run_id": candidate_run_id,
+        "baseline_dir": str(baseline_dir),
+        "candidate_dir": str(candidate_dir),
+        "baseline_mode": args.baseline_mode,
+        "candidate_mode": args.candidate_mode,
+        "regressed": regressed,
+        "rollback_applied": rollback_applied,
+        "rollback_response": rollback_resp,
+        "udp_share_cap_target": args.udp_share_cap,
+        "baseline_udp_share": base_udp_share,
+        "candidate_udp_share": cand_udp_share,
+        "udp_share_cap_regressed": cap_regressed,
+        "baseline_storm_p99_ms": base_storm_p99,
+        "candidate_storm_p99_ms": cand_storm_p99,
+        "storm_regressed": storm_regressed,
+        "metric_checks": regression["rows"],
+    }
+
+    out_dir = Path(args.out_root) / utc_day() / "runs" / args.run_id
+    out_dir.mkdir(parents=True, exist_ok=True)
+    out_path = out_dir / "seat_transport_guard_summary.json"
+    out_path.write_text(json.dumps(summary, ensure_ascii=True, indent=2), encoding="utf-8")
+
+    print(f"baseline_dir={baseline_dir}")
+    print(f"candidate_dir={candidate_dir}")
+    print(f"regressed={regressed}")
+    print(f"rollback_applied={rollback_applied}")
+    print(f"summary={out_path}")
+    return 10 if regressed else 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/scripts/setup_app_runner_systemd.sh b/scripts/setup_app_runner_systemd.sh
new file mode 100644
index 0000000..31a7292
--- /dev/null
+++ b/scripts/setup_app_runner_systemd.sh
@@ -0,0 +1,98 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+# Install and enable a stable app_runner service so reboot does not leave 8080 down.
+# Usage:
+#   bash scripts/setup_app_runner_systemd.sh
+# Optional env:
+#   POLYEDGE_REPO_DIR=/home/ubuntu/PolyEdge
+#   POLYEDGE_BIN_PATH=/home/ubuntu/PolyEdge/target/release/app_runner
+#   POLYEDGE_USER=ubuntu
+
+REPO_DIR="${POLYEDGE_REPO_DIR:-$HOME/PolyEdge}"
+BIN_PATH="${POLYEDGE_BIN_PATH:-$REPO_DIR/target/release/app_runner}"
+RUN_USER="${POLYEDGE_USER:-$(id -un)}"
+ENV_FILE="/etc/polyedge/app_runner.env"
+SERVICE_FILE="/etc/systemd/system/polyedge.service"
+
+echo "[setup] repo=$REPO_DIR"
+echo "[setup] bin=$BIN_PATH"
+echo "[setup] user=$RUN_USER"
+
+if [[ ! -x "$BIN_PATH" ]]; then
+  echo "[setup] build release binary first: cargo build -p app_runner --release" >&2
+  exit 1
+fi
+
+sudo mkdir -p /etc/polyedge
+if [[ ! -f "$ENV_FILE" ]]; then
+  sudo tee "$ENV_FILE" >/dev/null <<'EOF'
+# PolyEdge app_runner runtime env
+RUST_LOG=info
+POLYEDGE_ENABLE_BINANCE_WS=true
+POLYEDGE_ENABLE_BYBIT_WS=false
+POLYEDGE_ENABLE_COINBASE_WS=false
+POLYEDGE_ENABLE_CHAINLINK_ANCHOR=true
+POLYEDGE_ACK_ONLY_PROBE_ENABLED=false
+POLYEDGE_ACK_ONLY_PROBE_EVERY=20
+POLYEDGE_UDP_USER_SPIN=true
+POLYEDGE_UDP_BUSY_POLL_US=50
+POLYEDGE_UDP_RCVBUF_BYTES=33554432
+POLYEDGE_UDP_PIN_CORES=6666:0,6667:0,6668:0,6669:0
+TOKIO_WORKER_THREADS=3
+EOF
+  echo "[setup] wrote default env: $ENV_FILE"
+else
+  echo "[setup] keep existing env: $ENV_FILE"
+fi
+
+ensure_env_line() {
+  local key="$1"
+  local value="$2"
+  if ! sudo grep -qE "^${key}=" "$ENV_FILE"; then
+    echo "[setup] append default: ${key}=${value}"
+    echo "${key}=${value}" | sudo tee -a "$ENV_FILE" >/dev/null
+  fi
+}
+
+ensure_env_line "POLYEDGE_ACK_ONLY_PROBE_ENABLED" "false"
+ensure_env_line "POLYEDGE_ACK_ONLY_PROBE_EVERY" "20"
+ensure_env_line "POLYEDGE_UDP_USER_SPIN" "true"
+ensure_env_line "POLYEDGE_UDP_BUSY_POLL_US" "50"
+ensure_env_line "POLYEDGE_UDP_RCVBUF_BYTES" "33554432"
+ensure_env_line "POLYEDGE_UDP_PIN_CORES" "6666:0,6667:0,6668:0,6669:0"
+ensure_env_line "TOKIO_WORKER_THREADS" "3"
+
+sudo tee "$SERVICE_FILE" >/dev/null <<EOF
+[Unit]
+Description=PolyEdge app_runner
+After=network-online.target
+Wants=network-online.target
+
+[Service]
+Type=simple
+User=$RUN_USER
+WorkingDirectory=$REPO_DIR
+EnvironmentFile=$ENV_FILE
+ExecStart=$BIN_PATH
+Restart=always
+RestartSec=2
+LimitNOFILE=1048576
+
+[Install]
+WantedBy=multi-user.target
+EOF
+
+sudo systemctl daemon-reload
+sudo systemctl stop polyedge.service || true
+pkill -x app_runner || true
+sleep 1
+sudo systemctl enable --now polyedge.service
+sleep 2
+sudo systemctl --no-pager --full status polyedge.service || true
+curl -fsS http://127.0.0.1:8080/health || {
+  echo "[setup] health check failed after service start" >&2
+  exit 2
+}
+echo
+echo "[setup] polyedge.service installed and healthy"
diff --git a/scripts/setup_seat_optimizer_systemd.sh b/scripts/setup_seat_optimizer_systemd.sh
new file mode 100644
index 0000000..6612738
--- /dev/null
+++ b/scripts/setup_seat_optimizer_systemd.sh
@@ -0,0 +1,39 @@
+#!/usr/bin/env bash
+set -euo pipefail
+
+SERVICE_NAME="polyedge-seat-optimizer.service"
+REPO_DIR="${REPO_DIR:-$HOME/PolyEdge}"
+PYTHON_BIN="${PYTHON_BIN:-/usr/bin/python3}"
+HOST="${POLYEDGE_SEAT_OPTIMIZER_HOST:-127.0.0.1}"
+PORT="${POLYEDGE_SEAT_OPTIMIZER_PORT:-8091}"
+
+SERVICE_PATH="/etc/systemd/system/${SERVICE_NAME}"
+
+cat <<EOF | sudo tee "${SERVICE_PATH}" >/dev/null
+[Unit]
+Description=PolyEdge SEAT Optimizer Service
+After=network-online.target
+Wants=network-online.target
+
+[Service]
+Type=simple
+User=${USER}
+WorkingDirectory=${REPO_DIR}
+Environment=POLYEDGE_SEAT_OPTIMIZER_HOST=${HOST}
+Environment=POLYEDGE_SEAT_OPTIMIZER_PORT=${PORT}
+ExecStart=${PYTHON_BIN} ${REPO_DIR}/scripts/seat_optimizer_service.py
+Restart=always
+RestartSec=2
+NoNewPrivileges=true
+PrivateTmp=true
+ProtectSystem=full
+ProtectHome=false
+
+[Install]
+WantedBy=multi-user.target
+EOF
+
+sudo systemctl daemon-reload
+sudo systemctl enable "${SERVICE_NAME}"
+sudo systemctl restart "${SERVICE_NAME}"
+sudo systemctl --no-pager --full status "${SERVICE_NAME}" || true
diff --git a/scripts/storm_test.py b/scripts/storm_test.py
index c2b7e5d..c22a0f1 100644
--- a/scripts/storm_test.py
+++ b/scripts/storm_test.py
@@ -1,6 +1,7 @@
 #!/usr/bin/env python3
 from __future__ import annotations
 
+import atexit
 import argparse
 import concurrent.futures
 import json
@@ -82,12 +83,22 @@ def parse_args() -> argparse.Namespace:
     p.add_argument("--heartbeat-sec", type=float, default=30.0)
     p.add_argument("--run-id", default=f"storm-{int(time.time())}")
     p.add_argument("--out-root", default="datasets/reports")
+    # When enabled, write artifacts under datasets/reports/<day>/runs/<run_id>/ to avoid overwriting
+    # day-level legacy files (storm_test_summary.json / storm_test_trace.jsonl).
+    p.add_argument("--use-run-dir", action="store_true")
     p.add_argument("--fail-fast-threshold", type=int, default=20)
+    # Default is safe: do NOT leave the engine paused after a test. Enable only when
+    # explicitly testing pause/resume semantics.
+    p.add_argument("--churn-pause-resume", action="store_true")
     p.add_argument("--once", action="store_true")
+    # P4: è½»é‡çº§æŽ¢æµ‹ç«¯ç‚¹ï¼Œä½¿ç”¨ /health/latency ä»£æ›¿ /report/shadow/live
+    p.add_argument("--lightweight", action="store_true", help="ä½¿ç”¨è½»é‡çº§ /health/latency ç«¯ç‚¹è€Œéž /report/shadow/live")
     return p.parse_args()
 
 
-def maybe_control_churn(session: requests.Session, base_url: str, timeout_sec: float) -> List[ProbeResult]:
+def maybe_control_churn(
+    session: requests.Session, base_url: str, timeout_sec: float, churn_pause_resume: bool
+) -> List[ProbeResult]:
     jitter = random.uniform(-2.5, 2.5)
     maker_payload = {
         "min_edge_bps": max(1.0, 6.0 + jitter),
@@ -115,9 +126,14 @@ def maybe_control_churn(session: requests.Session, base_url: str, timeout_sec: f
         ("POST", f"{base_url}/control/reload_taker", maker_payload),
         ("POST", f"{base_url}/control/reload_allocator", alloc_payload),
         ("POST", f"{base_url}/control/reload_risk", risk_payload),
-        ("POST", f"{base_url}/control/pause", {}),
-        ("POST", f"{base_url}/control/resume", {}),
     ]
+    if churn_pause_resume:
+        ops.extend(
+            [
+                ("POST", f"{base_url}/control/pause", {}),
+                ("POST", f"{base_url}/control/resume", {}),
+            ]
+        )
     out: List[ProbeResult] = []
     for method, url, payload in ops:
         out.append(request_json(session, method, url, timeout_sec, payload))
@@ -138,91 +154,106 @@ def main() -> int:
     next_control = started + max(1.0, args.control_interval_sec)
 
     day = utc_day()
-    out_dir = Path(args.out_root) / day
+    if args.use_run_dir:
+        out_dir = Path(args.out_root) / day / "runs" / str(args.run_id)
+    else:
+        out_dir = Path(args.out_root) / day
     summary_path = out_dir / "storm_test_summary.json"
     trace_path = out_dir / "storm_test_trace.jsonl"
     out_dir.mkdir(parents=True, exist_ok=True)
 
     session = requests.Session()
+    atexit.register(session.close)
     errors = 0
     consecutive_failures = 0
     samples: List[ProbeResult] = []
 
-    with concurrent.futures.ThreadPoolExecutor(max_workers=max(1, args.concurrency)) as pool:
-        if args.once:
-            probe = request_json(session, "GET", f"{args.base_url}/report/shadow/live", args.timeout_sec)
-            samples.append(probe)
-        else:
-            while True:
-                now = time.monotonic()
-                if now >= deadline:
-                    break
-                if now >= hard_deadline:
-                    break
-
-                burst = max(1, args.burst_rps)
-                futures = [
-                    pool.submit(
-                        request_json,
-                        session,
-                        "GET",
-                        f"{args.base_url}/report/shadow/live",
-                        args.timeout_sec,
-                        None,
-                    )
-                    for _ in range(burst)
-                ]
-                for f in futures:
-                    r = f.result()
-                    samples.append(r)
-                    if not r.ok:
-                        errors += 1
-                        consecutive_failures += 1
-                    else:
-                        consecutive_failures = 0
-                    with trace_path.open("a", encoding="utf-8") as fp:
-                        fp.write(
-                            json.dumps(
-                                {
-                                    "ts_ms": now_ms(),
-                                    "ok": r.ok,
-                                    "latency_ms": round(r.latency_ms, 3),
-                                    "status": r.status,
-                                    "endpoint": r.endpoint,
-                                    "error": r.error,
-                                },
-                                ensure_ascii=True,
-                                separators=(",", ":"),
-                            )
-                            + "\n"
-                        )
+    # P4: é€‰æ‹©ç«¯ç‚¹ - è½»é‡çº§æˆ–å®Œæ•´æŠ¥å‘Š
+    endpoint = "/health/latency" if args.lightweight else "/report/shadow/live"
+
+    try:
+        with concurrent.futures.ThreadPoolExecutor(max_workers=max(1, args.concurrency)) as pool:
+            if args.once:
+                probe = request_json(session, "GET", f"{args.base_url}{endpoint}", args.timeout_sec)
+                samples.append(probe)
+            else:
+                while True:
+                    now = time.monotonic()
+                    if now >= deadline:
+                        break
+                    if now >= hard_deadline:
+                        break
 
-                if now >= next_control:
-                    for ctrl in maybe_control_churn(session, args.base_url, args.timeout_sec):
-                        samples.append(ctrl)
-                        if not ctrl.ok:
+                    burst = max(1, args.burst_rps)
+                    futures = [
+                        pool.submit(
+                            request_json,
+                            session,
+                            "GET",
+                            f"{args.base_url}{endpoint}",
+                            args.timeout_sec,
+                            None,
+                        )
+                        for _ in range(burst)
+                    ]
+                    for f in futures:
+                        r = f.result()
+                        samples.append(r)
+                        if not r.ok:
                             errors += 1
                             consecutive_failures += 1
-                    next_control = now + max(1.0, args.control_interval_sec)
-
-                if consecutive_failures >= max(1, args.fail_fast_threshold):
-                    break
-                if errors >= max(1, args.max_errors):
-                    break
-                if now >= heartbeat_at:
-                    elapsed = int(now - started)
-                    print(
-                        f"[heartbeat] elapsed={elapsed}s samples={len(samples)} errors={errors} "
-                        f"consecutive_failures={consecutive_failures}"
-                    )
-                    heartbeat_at = now + max(1.0, args.heartbeat_sec)
-                time.sleep(1.0)
+                        else:
+                            consecutive_failures = 0
+                        with trace_path.open("a", encoding="utf-8") as fp:
+                            fp.write(
+                                json.dumps(
+                                    {
+                                        "ts_ms": now_ms(),
+                                        "ok": r.ok,
+                                        "latency_ms": round(r.latency_ms, 3),
+                                        "status": r.status,
+                                        "endpoint": r.endpoint,
+                                        "error": r.error,
+                                    },
+                                    ensure_ascii=True,
+                                    separators=(",", ":"),
+                                )
+                                + "\n"
+                            )
+
+                    if now >= next_control:
+                        for ctrl in maybe_control_churn(
+                            session, args.base_url, args.timeout_sec, args.churn_pause_resume
+                        ):
+                            samples.append(ctrl)
+                            if not ctrl.ok:
+                                errors += 1
+                                consecutive_failures += 1
+                        next_control = now + max(1.0, args.control_interval_sec)
+
+                    if consecutive_failures >= max(1, args.fail_fast_threshold):
+                        break
+                    if errors >= max(1, args.max_errors):
+                        break
+                    if now >= heartbeat_at:
+                        elapsed = int(now - started)
+                        print(
+                            f"[heartbeat] elapsed={elapsed}s samples={len(samples)} errors={errors} "
+                            f"consecutive_failures={consecutive_failures}"
+                        )
+                        heartbeat_at = now + max(1.0, args.heartbeat_sec)
+                    time.sleep(1.0)
+    finally:
+        # Safety: never leave the engine paused after a stress run.
+        _ = request_json(session, "POST", f"{args.base_url}/control/resume", 2.0, {})
 
     lat_ok = [s.latency_ms for s in samples if s.ok]
     lat_fail = [s.latency_ms for s in samples if not s.ok]
     summary: Dict[str, Any] = {
         "ts_ms": now_ms(),
         "run_id": args.run_id,
+        "use_run_dir": bool(args.use_run_dir),
+        "out_dir": str(out_dir),
         "base_url": args.base_url,
         "duration_sec": int(time.monotonic() - started),
         "sample_count": len(samples),
diff --git a/scripts/three_window_verify.py b/scripts/three_window_verify.py
new file mode 100644
index 0000000..41808da
--- /dev/null
+++ b/scripts/three_window_verify.py
@@ -0,0 +1,484 @@
+#!/usr/bin/env python3
+"""Three-window verification harness (bounded, fail-fast).
+
+Supports baseline vs Predator C+ modes and can optionally run A/B in one invocation.
+
+Artifacts are written under:
+  datasets/reports/<YYYY-MM-DD>/runs/<run_id>/<mode>/
+"""
+
+from __future__ import annotations
+
+import atexit
+import argparse
+import json
+import time
+from dataclasses import dataclass
+from datetime import datetime, timezone
+from pathlib import Path
+from typing import Any, Dict, List, Optional, Tuple
+
+import requests
+
+
+def utc_day(ts: Optional[float] = None) -> str:
+    dt = datetime.fromtimestamp(ts or time.time(), tz=timezone.utc)
+    return dt.strftime("%Y-%m-%d")
+
+
+def now_ms() -> int:
+    return int(time.time() * 1000)
+
+
+def write_json(path: Path, payload: Any) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    path.write_text(json.dumps(payload, ensure_ascii=True, indent=2), encoding="utf-8")
+
+
+def write_text(path: Path, text: str) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    path.write_text(text, encoding="utf-8")
+
+
+def top_items(d: Any, n: int = 5) -> List[Tuple[str, int]]:
+    if not isinstance(d, dict):
+        return []
+    items: List[Tuple[str, int]] = []
+    for k, v in d.items():
+        try:
+            items.append((str(k), int(v)))
+        except Exception:
+            continue
+    items.sort(key=lambda kv: kv[1], reverse=True)
+    return items[:n]
+
+
+def request_json(
+    session: requests.Session,
+    method: str,
+    url: str,
+    timeout_sec: float,
+    payload: Optional[Dict[str, Any]] = None,
+) -> Dict[str, Any]:
+    if method.upper() == "GET":
+        resp = session.get(url, timeout=timeout_sec)
+    else:
+        resp = session.post(url, timeout=timeout_sec, json=payload or {})
+    resp.raise_for_status()
+    data = resp.json()
+    if not isinstance(data, dict):
+        return {"_raw": data}
+    return data
+
+
+def set_predator_mode(
+    session: requests.Session,
+    base_url: str,
+    timeout_sec: float,
+    enabled: bool,
+    priority: str,
+) -> Dict[str, Any]:
+    payload: Dict[str, Any] = {"enabled": enabled}
+    if enabled:
+        payload["priority"] = priority
+    return request_json(session, "POST", f"{base_url.rstrip('/')}/control/reload_predator_c", timeout_sec, payload)
+
+
+def resume_and_reset(session: requests.Session, base_url: str, timeout_sec: float) -> int:
+    _ = request_json(session, "POST", f"{base_url.rstrip('/')}/control/resume", timeout_sec, {})
+    res = request_json(session, "POST", f"{base_url.rstrip('/')}/control/reset_shadow", timeout_sec, {})
+    try:
+        return int(res.get("window_id") or 0)
+    except Exception:
+        return 0
+
+
+def poll_until_outcomes(
+    session: requests.Session,
+    base_url: str,
+    timeout_sec: float,
+    min_outcomes: int,
+    window_timeout_sec: int,
+    poll_interval: float,
+) -> Dict[str, Any]:
+    deadline = time.monotonic() + max(1, window_timeout_sec)
+    last: Dict[str, Any] = {}
+    while time.monotonic() < deadline:
+        try:
+            last = request_json(
+                session,
+                "GET",
+                f"{base_url.rstrip('/')}/report/shadow/live",
+                timeout_sec,
+            )
+            outcomes = int(last.get("window_outcomes") or 0)
+            if outcomes >= min_outcomes:
+                return last
+        except Exception:
+            # keep polling; the runtime might be restarting
+            pass
+        time.sleep(max(0.2, poll_interval))
+    return last
+
+
+def compute_fixlist(live: Dict[str, Any]) -> List[str]:
+    reasons = live.get("blocked_reason_counts") or {}
+    top = [k for k, _ in top_items(reasons, n=10)]
+    out: List[str] = []
+
+    observe_only = bool(live.get("observe_only"))
+    if observe_only:
+        out.append("observe_only=true: check market tier profile / SOL guard / universe scope; reduce scope to BTC/ETH first.")
+
+    if "paused" in top:
+        out.append("blocked_reason=paused: POST /control/resume and ensure storm_test doesn't leave engine paused.")
+
+    if any("tiny_notional" in k for k in top):
+        out.append("blocked_reason=tiny_notional: lower min_eval_notional_usdc or increase base_quote_size to generate outcomes faster.")
+
+    if any("market_untracked" in k for k in top):
+        out.append("blocked_reason=market_untracked: check market_discovery mappings and active_top_n_markets scope.")
+
+    if any("edge_below" in k for k in top) or any("no_quote_spread" in k for k in top):
+        out.append("edge/no_quote blocks: thresholds too strict; relax min_edge (maker) or min_edge_net_bps (predator) and/or max_spread.")
+
+    if any("rate_budget" in k for k in top):
+        out.append("rate_budget blocks: raise rate_limit_rps and/or per-market budgets; confirm gateway + endpoint latency is stable.")
+
+    # Strongly bounded: top 3 only.
+    return out[:3] if out else ["No obvious fixlist from blocked reasons; inspect /report/shadow/live blocked_reason_counts and latency tails."]
+
+
+@dataclass
+class WindowResult:
+    idx: int
+    window_id: int
+    live: Dict[str, Any]
+    pnl_by_engine: Dict[str, Any]
+
+
+def summarize_windows(results: List[WindowResult], min_outcomes: int) -> Dict[str, Any]:
+    rows: List[Dict[str, Any]] = []
+    for r in results:
+        live = r.live
+        rows.append(
+            {
+                "idx": r.idx,
+                "window_id": r.window_id,
+                "window_outcomes": int(live.get("window_outcomes") or 0),
+                "timed_out": bool(live.get("_timed_out", False)),
+                "gate_ready": bool(live.get("gate_ready")),
+                "gate_fail_reasons": live.get("gate_fail_reasons") or [],
+                "ev_net_usdc_p50": float(live.get("ev_net_usdc_p50") or 0.0),
+                "roi_notional_10s_bps_p50": float(live.get("roi_notional_10s_bps_p50") or 0.0),
+                "executed_over_eligible": float(live.get("executed_over_eligible") or 0.0),
+                "fillability_10ms": float(live.get("fillability_10ms") or 0.0),
+                "quote_block_ratio": float(live.get("quote_block_ratio") or 0.0),
+                "policy_block_ratio": float(live.get("policy_block_ratio") or 0.0),
+                "data_valid_ratio": float(live.get("data_valid_ratio") or 0.0),
+                "tick_to_ack_p99_ms": float(live.get("tick_to_ack_p99_ms") or 0.0),
+                "decision_compute_p99_ms": float(live.get("decision_compute_p99_ms") or 0.0),
+                "feed_in_p99_ms": float((live.get("latency") or {}).get("feed_in_p99_ms") or 0.0),
+                "blocked_reason_top5": top_items(live.get("blocked_reason_counts") or {}, n=5),
+                "predator": {
+                    "enabled": bool(live.get("predator_c_enabled")),
+                    "dir_up": int(live.get("direction_signals_up") or 0),
+                    "dir_down": int(live.get("direction_signals_down") or 0),
+                    "dir_neutral": int(live.get("direction_signals_neutral") or 0),
+                    "sniper_fired": int(live.get("taker_sniper_fired") or 0),
+                    "sniper_skipped": int(live.get("taker_sniper_skipped") or 0),
+                },
+            }
+        )
+
+    def avg(key: str) -> float:
+        vals = [float(row.get(key) or 0.0) for row in rows]
+        return sum(vals) / len(vals) if vals else 0.0
+
+    all_have_samples = all(int(row["window_outcomes"]) >= min_outcomes for row in rows)
+    all_gate_ok = all_have_samples and all((row.get("gate_fail_reasons") or []) == [] for row in rows)
+    timed_out_count = sum(1 for row in rows if bool(row.get("timed_out")))
+
+    return {
+        "ts_ms": now_ms(),
+        "windows": rows,
+        "avg": {
+            "ev_net_usdc_p50": avg("ev_net_usdc_p50"),
+            "roi_notional_10s_bps_p50": avg("roi_notional_10s_bps_p50"),
+            "executed_over_eligible": avg("executed_over_eligible"),
+            "fillability_10ms": avg("fillability_10ms"),
+            "quote_block_ratio": avg("quote_block_ratio"),
+            "policy_block_ratio": avg("policy_block_ratio"),
+            "data_valid_ratio": avg("data_valid_ratio"),
+            "tick_to_ack_p99_ms": avg("tick_to_ack_p99_ms"),
+            "decision_compute_p99_ms": avg("decision_compute_p99_ms"),
+            "feed_in_p99_ms": avg("feed_in_p99_ms"),
+        },
+        "pass": bool(all_gate_ok),
+        "timed_out_windows": timed_out_count,
+        "notes": [],
+    }
+
+
+def render_md(mode_name: str, summary: Dict[str, Any]) -> str:
+    avg = summary.get("avg") or {}
+    lines: List[str] = []
+    lines.append(f"# Three-Window Summary ({mode_name})")
+    lines.append("")
+    lines.append(f"- pass: `{summary.get('pass')}`")
+    lines.append(f"- timed_out_windows: `{int(summary.get('timed_out_windows') or 0)}`")
+    lines.append("")
+    lines.append("## Averages")
+    lines.append("")
+    lines.append("| metric | value |")
+    lines.append("|---|---:|")
+    for k in [
+        "ev_net_usdc_p50",
+        "roi_notional_10s_bps_p50",
+        "executed_over_eligible",
+        "fillability_10ms",
+        "quote_block_ratio",
+        "policy_block_ratio",
+        "data_valid_ratio",
+        "tick_to_ack_p99_ms",
+        "decision_compute_p99_ms",
+        "feed_in_p99_ms",
+    ]:
+        try:
+            v = float(avg.get(k) or 0.0)
+        except Exception:
+            v = 0.0
+        lines.append(f"| `{k}` | `{v:.6g}` |")
+
+    lines.append("")
+    lines.append("## Windows")
+    lines.append("")
+    lines.append("| idx | window_id | outcomes | timed_out | gate_ready | ev_p50 | roi_p50_bps | exec/eligible | quote_block | policy_block |")
+    lines.append("|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|")
+    for row in summary.get("windows") or []:
+        lines.append(
+            "| {idx} | {window_id} | {out} | {timed_out} | {gate_ready} | {ev:.6g} | {roi:.6g} | {eoe:.4f} | {qbr:.4f} | {pbr:.4f} |".format(
+                idx=int(row.get("idx") or 0),
+                window_id=int(row.get("window_id") or 0),
+                out=int(row.get("window_outcomes") or 0),
+                timed_out=bool(row.get("timed_out")),
+                gate_ready=bool(row.get("gate_ready")),
+                ev=float(row.get("ev_net_usdc_p50") or 0.0),
+                roi=float(row.get("roi_notional_10s_bps_p50") or 0.0),
+                eoe=float(row.get("executed_over_eligible") or 0.0),
+                qbr=float(row.get("quote_block_ratio") or 0.0),
+                pbr=float(row.get("policy_block_ratio") or 0.0),
+            )
+        )
+
+    lines.append("")
+    lines.append("## Top Block Reasons (per window)")
+    lines.append("")
+    for row in summary.get("windows") or []:
+        lines.append(f"- window {int(row.get('idx') or 0)}: `{row.get('blocked_reason_top5')}`")
+    lines.append("")
+    return "\n".join(lines)
+
+
+def run_one_mode(
+    mode_name: str,
+    session: requests.Session,
+    base_url: str,
+    timeout_sec: float,
+    predator_enabled: bool,
+    predator_priority: str,
+    windows: int,
+    min_outcomes: int,
+    window_timeout_sec: int,
+    poll_interval: float,
+    out_dir: Path,
+    continue_on_timeout: bool,
+) -> Dict[str, Any]:
+    out_dir.mkdir(parents=True, exist_ok=True)
+
+    _ = set_predator_mode(session, base_url, timeout_sec, predator_enabled, predator_priority)
+
+    results: List[WindowResult] = []
+    for i in range(1, windows + 1):
+        window_id = resume_and_reset(session, base_url, timeout_sec)
+        live = poll_until_outcomes(
+            session,
+            base_url,
+            timeout_sec,
+            min_outcomes=min_outcomes,
+            window_timeout_sec=window_timeout_sec,
+            poll_interval=poll_interval,
+        )
+
+        outcomes = int(live.get("window_outcomes") or 0)
+        if outcomes < min_outcomes:
+            # Persist whatever we have for debugging.
+            try:
+                pnl_by_engine = request_json(
+                    session, "GET", f"{base_url.rstrip('/')}/report/pnl/by_engine", timeout_sec
+                )
+            except Exception:
+                pnl_by_engine = {}
+            write_json(out_dir / f"window{i:02d}_shadow_live.json", live)
+            write_json(out_dir / f"window{i:02d}_pnl_by_engine.json", pnl_by_engine)
+
+            fixlist = compute_fixlist(live)
+            write_text(out_dir / "next_fixlist.md", "\n".join(f"- {x}" for x in fixlist) + "\n")
+            if not continue_on_timeout:
+                raise RuntimeError(
+                    f"window {i} timed out: outcomes={outcomes} < min_outcomes={min_outcomes}"
+                )
+            live = dict(live)
+            live["_timed_out"] = True
+            live["_min_outcomes"] = min_outcomes
+            results.append(WindowResult(idx=i, window_id=window_id, live=live, pnl_by_engine=pnl_by_engine))
+            continue
+
+        pnl_by_engine = request_json(
+            session, "GET", f"{base_url.rstrip('/')}/report/pnl/by_engine", timeout_sec
+        )
+
+        write_json(out_dir / f"window{i:02d}_shadow_live.json", live)
+        write_json(out_dir / f"window{i:02d}_pnl_by_engine.json", pnl_by_engine)
+        results.append(WindowResult(idx=i, window_id=window_id, live=live, pnl_by_engine=pnl_by_engine))
+
+    summary = summarize_windows(results, min_outcomes=min_outcomes)
+    write_json(out_dir / "three_window_summary.json", summary)
+    write_text(out_dir / "three_window_summary.md", render_md(mode_name, summary))
+    return summary
+
+
+def render_compare_md(base: Dict[str, Any], pred: Dict[str, Any]) -> str:
+    lines: List[str] = []
+    lines.append("# Three-Window A/B Compare")
+    lines.append("")
+    lines.append("| metric | baseline | predator_c | delta |")
+    lines.append("|---|---:|---:|---:|")
+    for k in [
+        "ev_net_usdc_p50",
+        "roi_notional_10s_bps_p50",
+        "executed_over_eligible",
+        "fillability_10ms",
+        "quote_block_ratio",
+        "policy_block_ratio",
+        "data_valid_ratio",
+        "tick_to_ack_p99_ms",
+        "decision_compute_p99_ms",
+        "feed_in_p99_ms",
+    ]:
+        b = float((base.get("avg") or {}).get(k) or 0.0)
+        p = float((pred.get("avg") or {}).get(k) or 0.0)
+        lines.append(f"| `{k}` | `{b:.6g}` | `{p:.6g}` | `{(p - b):.6g}` |")
+    lines.append("")
+    lines.append(f"- baseline pass: `{base.get('pass')}`")
+    lines.append(f"- predator_c pass: `{pred.get('pass')}`")
+    lines.append("")
+    return "\n".join(lines)
+
+
+def parse_args() -> argparse.Namespace:
+    p = argparse.ArgumentParser(description="PolyEdge three-window verify (bounded, fail-fast)")
+    p.add_argument("--base-url", default="http://127.0.0.1:8080")
+    p.add_argument("--mode", default="ab", choices=["baseline", "predator_c", "ab"])
+    p.add_argument("--predator-priority", default="taker_first", choices=["maker_first", "taker_first", "taker_only"])
+    p.add_argument("--windows", type=int, default=3)
+    p.add_argument("--min-outcomes", type=int, default=30)
+    p.add_argument("--window-timeout-sec", type=int, default=20 * 60)
+    p.add_argument("--poll-interval", type=float, default=2.0)
+    p.add_argument("--timeout-sec", type=float, default=5.0)
+    p.add_argument("--continue-on-timeout", action="store_true")
+    p.add_argument("--run-id", default=f"threew-{int(time.time())}")
+    p.add_argument("--out-root", default="datasets/reports")
+    return p.parse_args()
+
+
+def main() -> int:
+    args = parse_args()
+    day = utc_day()
+    root = Path(args.out_root) / day / "runs" / args.run_id
+    session = requests.Session()
+    atexit.register(session.close)
+
+    try:
+        if args.mode == "baseline":
+            out_dir = root / "baseline"
+            _ = run_one_mode(
+                "baseline",
+                session,
+                args.base_url,
+                args.timeout_sec,
+                predator_enabled=False,
+                predator_priority=args.predator_priority,
+                windows=args.windows,
+                min_outcomes=args.min_outcomes,
+                window_timeout_sec=args.window_timeout_sec,
+                poll_interval=args.poll_interval,
+                out_dir=out_dir,
+                continue_on_timeout=args.continue_on_timeout,
+            )
+            print(f"wrote_dir={out_dir}")
+            return 0
+
+        if args.mode == "predator_c":
+            out_dir = root / "predator_c"
+            _ = run_one_mode(
+                "predator_c",
+                session,
+                args.base_url,
+                args.timeout_sec,
+                predator_enabled=True,
+                predator_priority=args.predator_priority,
+                windows=args.windows,
+                min_outcomes=args.min_outcomes,
+                window_timeout_sec=args.window_timeout_sec,
+                poll_interval=args.poll_interval,
+                out_dir=out_dir,
+                continue_on_timeout=args.continue_on_timeout,
+            )
+            print(f"wrote_dir={out_dir}")
+            return 0
+
+        # A/B
+        baseline_dir = root / "baseline"
+        predator_dir = root / "predator_c"
+        base = run_one_mode(
+            "baseline",
+            session,
+            args.base_url,
+            args.timeout_sec,
+            predator_enabled=False,
+            predator_priority=args.predator_priority,
+            windows=args.windows,
+            min_outcomes=args.min_outcomes,
+            window_timeout_sec=args.window_timeout_sec,
+            poll_interval=args.poll_interval,
+            out_dir=baseline_dir,
+            continue_on_timeout=args.continue_on_timeout,
+        )
+        pred = run_one_mode(
+            "predator_c",
+            session,
+            args.base_url,
+            args.timeout_sec,
+            predator_enabled=True,
+            predator_priority=args.predator_priority,
+            windows=args.windows,
+            min_outcomes=args.min_outcomes,
+            window_timeout_sec=args.window_timeout_sec,
+            poll_interval=args.poll_interval,
+            out_dir=predator_dir,
+            continue_on_timeout=args.continue_on_timeout,
+        )
+        compare_md = render_compare_md(base, pred)
+        write_text(root / "three_window_compare.md", compare_md)
+        print(f"wrote_dir={root}")
+        return 0
+    except Exception as exc:  # noqa: BLE001
+        # Fail-fast: persist a short error marker and exit non-zero.
+        write_text(root / "FAILED.txt", f"{exc}\n")
+        print(f"failed: {exc}")
+        return 2
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/scripts/transport_path_probe.py b/scripts/transport_path_probe.py
new file mode 100644
index 0000000..81f8d6a
--- /dev/null
+++ b/scripts/transport_path_probe.py
@@ -0,0 +1,126 @@
+#!/usr/bin/env python3
+"""Probe transport paths (GA/PrivateLink/direct) with lightweight HTTP latency checks."""
+
+from __future__ import annotations
+
+import argparse
+import json
+import time
+from datetime import datetime, timezone
+from pathlib import Path
+from statistics import mean
+from typing import Dict, List
+
+import requests
+
+
+def utc_day(ts: float | None = None) -> str:
+    dt = datetime.fromtimestamp(ts or time.time(), tz=timezone.utc)
+    return dt.strftime("%Y-%m-%d")
+
+
+def percentile(values: List[float], p: float) -> float:
+    if not values:
+        return 0.0
+    data = sorted(values)
+    i = int(round((len(data) - 1) * p))
+    i = max(0, min(i, len(data) - 1))
+    return float(data[i])
+
+
+def probe_url(url: str, samples: int, timeout_sec: float, interval_ms: int) -> Dict[str, float]:
+    latencies: List[float] = []
+    errors = 0
+    session = requests.Session()
+    for _ in range(max(1, samples)):
+        t0 = time.perf_counter()
+        try:
+            r = session.get(url, timeout=timeout_sec)
+            r.raise_for_status()
+            latencies.append((time.perf_counter() - t0) * 1000.0)
+        except Exception:
+            errors += 1
+        if interval_ms > 0:
+            time.sleep(interval_ms / 1000.0)
+    return {
+        "samples": len(latencies),
+        "errors": errors,
+        "p50_ms": percentile(latencies, 0.50),
+        "p90_ms": percentile(latencies, 0.90),
+        "p99_ms": percentile(latencies, 0.99),
+        "mean_ms": mean(latencies) if latencies else 0.0,
+        "max_ms": max(latencies) if latencies else 0.0,
+    }
+
+
+def parse_targets(raw_targets: str, path: str) -> Dict[str, str]:
+    out: Dict[str, str] = {}
+    for token in raw_targets.split(","):
+        token = token.strip()
+        if not token:
+            continue
+        if "=" not in token:
+            continue
+        name, base = token.split("=", 1)
+        name = name.strip()
+        base = base.strip().rstrip("/")
+        if not name or not base:
+            continue
+        if base.startswith("http://") or base.startswith("https://"):
+            out[name] = f"{base}{path}"
+    return out
+
+
+def parse_args() -> argparse.Namespace:
+    p = argparse.ArgumentParser(description="Probe transport paths via HTTP latency")
+    p.add_argument(
+        "--targets",
+        required=True,
+        help=(
+            "comma list: name=url. "
+            "example: direct=http://127.0.0.1:8080,ga=http://10.0.3.10:8080,pl=http://10.0.3.20:8080"
+        ),
+    )
+    p.add_argument("--path", default="/health/latency")
+    p.add_argument("--samples", type=int, default=120)
+    p.add_argument("--timeout-sec", type=float, default=2.0)
+    p.add_argument("--interval-ms", type=int, default=50)
+    p.add_argument("--run-id", default=None)
+    p.add_argument("--out-root", default="datasets/reports")
+    return p.parse_args()
+
+
+def main() -> int:
+    args = parse_args()
+    targets = parse_targets(args.targets, args.path)
+    if not targets:
+        raise SystemExit("no valid targets")
+    started_ms = int(time.time() * 1000)
+    rows = {}
+    for name, url in targets.items():
+        print(f"[probe] target={name} url={url}", flush=True)
+        rows[name] = probe_url(url, args.samples, args.timeout_sec, args.interval_ms)
+        print(f"[probe] {name} p50={rows[name]['p50_ms']:.3f} p99={rows[name]['p99_ms']:.3f} errors={rows[name]['errors']}", flush=True)
+    payload = {
+        "meta": {
+            "ts_ms": started_ms,
+            "run_id": args.run_id,
+            "path": args.path,
+            "samples": args.samples,
+            "timeout_sec": args.timeout_sec,
+            "interval_ms": args.interval_ms,
+        },
+        "targets": targets,
+        "results": rows,
+    }
+    day_dir = Path(args.out_root) / utc_day()
+    out_dir = day_dir / "runs" / str(args.run_id) if args.run_id else day_dir
+    out_dir.mkdir(parents=True, exist_ok=True)
+    out = out_dir / f"transport_path_probe_{started_ms}.json"
+    out.write_text(json.dumps(payload, ensure_ascii=True, indent=2), encoding="utf-8")
+    print(f"wrote_json={out}")
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/scripts/tune_ireland.sh b/scripts/tune_ireland.sh
new file mode 100644
index 0000000..9b9fa22
--- /dev/null
+++ b/scripts/tune_ireland.sh
@@ -0,0 +1,114 @@
+#!/usr/bin/env bash
+# =============================================================================
+# tune_ireland.sh â€” çˆ±å°”å…°æœåŠ¡å™¨ (54.77.232.166) ç½‘ç»œæ ˆ + è¿›ç¨‹è°ƒä¼˜
+# =============================================================================
+# ç”¨æ³•: ssh ubuntu@54.77.232.166 'bash -s' < scripts/tune_ireland.sh
+# æ•ˆæžœ: æŒä¹…åŒ–åˆ° /etc/sysctl.d/99-polyedge.confï¼Œé‡å¯åŽç”Ÿæ•ˆ
+# =============================================================================
+set -euo pipefail
+
+# -----------------------------------------------------------------------
+# F1-1: ç½‘ç»œæ ˆè°ƒä¼˜ â€” å‡å°‘ TCP ç¼“å†²åŒºå»¶è¿Ÿ + å¯ç”¨ busy_poll
+# -----------------------------------------------------------------------
+SYSCTL_CONF=/etc/sysctl.d/99-polyedge.conf
+
+cat > "$SYSCTL_CONF" << 'EOF'
+# PolyEdge ç½‘ç»œæ ˆè°ƒä¼˜ â€” çˆ±å°”å…°èŠ‚ç‚¹
+
+# TCP æŽ¥æ”¶/å‘é€ç¼“å†²åŒº (8MB)
+net.core.rmem_max = 8388608
+net.core.wmem_max = 8388608
+net.core.rmem_default = 1048576
+net.core.wmem_default = 1048576
+net.ipv4.tcp_rmem = 4096 1048576 8388608
+net.ipv4.tcp_wmem = 4096 1048576 8388608
+
+# Busy poll â€” å‡å°‘ epoll å”¤é†’å»¶è¿Ÿï¼ˆ50Î¼sï¼‰
+# é€‚ç”¨äºŽä½Žå»¶è¿Ÿ WebSocket è¿žæŽ¥ï¼ˆPolymarket CLOBï¼‰
+net.core.busy_read = 50
+net.core.busy_poll = 50
+
+# å¢žå¤§ socket é˜Ÿåˆ—æ·±åº¦
+net.core.netdev_max_backlog = 65536
+net.core.somaxconn = 65536
+
+# TCP å¿«é€Ÿé‡ä¼  + ä½Žè¶…æ—¶
+net.ipv4.tcp_syn_retries = 2
+net.ipv4.tcp_synack_retries = 2
+net.ipv4.tcp_fin_timeout = 15
+
+# ç¦ç”¨ TCP æ—¶é—´æˆ³ï¼ˆå‡å°‘ CPU å¼€é”€ï¼‰
+net.ipv4.tcp_timestamps = 0
+
+# å¯ç”¨ TCP BBR æ‹¥å¡žæŽ§åˆ¶ï¼ˆä½Žå»¶è¿Ÿåœºæ™¯æ›´ä¼˜ï¼‰
+net.core.default_qdisc = fq
+net.ipv4.tcp_congestion_control = bbr
+EOF
+
+# ç«‹å³åº”ç”¨
+sysctl -p "$SYSCTL_CONF"
+echo "[F1] sysctl è°ƒä¼˜å®Œæˆ"
+
+# éªŒè¯ busy_poll
+BUSY_READ=$(sysctl -n net.core.busy_read)
+if [ "$BUSY_READ" = "50" ]; then
+    echo "[F1] âœ… net.core.busy_read = 50"
+else
+    echo "[F1] âš ï¸  net.core.busy_read = $BUSY_READ (æœŸæœ› 50)"
+fi
+
+# -----------------------------------------------------------------------
+# F1-2: è¿›ç¨‹å®žæ—¶ä¼˜å…ˆçº§ â€” ç»™ polyedge è¿›ç¨‹è®¾ç½® SCHED_FIFO
+# -----------------------------------------------------------------------
+POLYEDGE_PID=$(pgrep -f "polyedge\|app_runner" | head -1 || true)
+
+if [ -n "$POLYEDGE_PID" ]; then
+    chrt -f -p 90 "$POLYEDGE_PID"
+    echo "[F1] âœ… polyedge PID=$POLYEDGE_PID è®¾ç½®ä¸º SCHED_FIFO priority=90"
+else
+    echo "[F1] â„¹ï¸  polyedge è¿›ç¨‹æœªè¿è¡Œï¼Œè·³è¿‡å®žæ—¶ä¼˜å…ˆçº§è®¾ç½®"
+    echo "[F1]    å¯åŠ¨åŽæ‰§è¡Œ: chrt -f -p 90 \$(pgrep -f polyedge)"
+fi
+
+# -----------------------------------------------------------------------
+# F1-3: CPU äº²å’Œæ€§ â€” å°† polyedge ç»‘å®šåˆ°æ ¸å¿ƒ 0-3ï¼ˆé¿å… NUMA è·¨èŠ‚ç‚¹ï¼‰
+# -----------------------------------------------------------------------
+if [ -n "$POLYEDGE_PID" ]; then
+    taskset -cp 0-3 "$POLYEDGE_PID"
+    echo "[F1] âœ… polyedge ç»‘å®šåˆ° CPU 0-3"
+fi
+
+# -----------------------------------------------------------------------
+# F1-4: ç¦ç”¨ CPU é¢‘çŽ‡è°ƒèŠ‚ï¼ˆä¿æŒæœ€é«˜é¢‘çŽ‡ï¼‰
+# -----------------------------------------------------------------------
+if command -v cpupower &>/dev/null; then
+    cpupower frequency-set -g performance || true
+    echo "[F1] âœ… CPU governor è®¾ç½®ä¸º performance"
+elif [ -d /sys/devices/system/cpu/cpu0/cpufreq ]; then
+    for cpu in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do
+        echo performance > "$cpu" 2>/dev/null || true
+    done
+    echo "[F1] âœ… CPU governor è®¾ç½®ä¸º performance (via sysfs)"
+fi
+
+# -----------------------------------------------------------------------
+# F1-5: IRQ äº²å’Œæ€§ â€” å°†ç½‘å¡ä¸­æ–­ç»‘å®šåˆ°æ ¸å¿ƒ 4-7ï¼ˆä¸Ž polyedge åˆ†ç¦»ï¼‰
+# -----------------------------------------------------------------------
+NIC=$(ip route | grep default | awk '{print $5}' | head -1)
+if [ -n "$NIC" ]; then
+    for IRQ_FILE in /proc/irq/*/smp_affinity_list; do
+        IRQ_DIR=$(dirname "$IRQ_FILE")
+        IRQ_NAME=$(cat "$IRQ_DIR/actions" 2>/dev/null || true)
+        if echo "$IRQ_NAME" | grep -q "$NIC"; then
+            echo "4-7" > "$IRQ_FILE" 2>/dev/null || true
+        fi
+    done
+    echo "[F1] âœ… NIC=$NIC IRQ äº²å’Œæ€§è®¾ç½®ä¸ºæ ¸å¿ƒ 4-7"
+fi
+
+echo ""
+echo "============================================================"
+echo "[F1] çˆ±å°”å…°æœåŠ¡å™¨è°ƒä¼˜å®Œæˆ"
+echo "     é‡å¯åŽ sysctl è®¾ç½®è‡ªåŠ¨ç”Ÿæ•ˆ"
+echo "     polyedge é‡å¯åŽéœ€é‡æ–°æ‰§è¡Œ chrt + taskset"
+echo "============================================================"
diff --git a/scripts/tune_tokyo.sh b/scripts/tune_tokyo.sh
new file mode 100644
index 0000000..07b8601
--- /dev/null
+++ b/scripts/tune_tokyo.sh
@@ -0,0 +1,120 @@
+#!/usr/bin/env bash
+# =============================================================================
+# tune_tokyo.sh â€” ä¸œäº¬æœåŠ¡å™¨ (57.180.89.145) UDP å‘é€å™¨è°ƒä¼˜
+# =============================================================================
+# ç”¨æ³•: ssh ubuntu@57.180.89.145 'bash -s' < scripts/tune_tokyo.sh
+# æ•ˆæžœ: è®¾ç½® UDP å†—ä½™å‘é€ + ç¼“å†²åŒº + CPU äº²å’Œæ€§ + è¿›ç¨‹ä¼˜å…ˆçº§
+# =============================================================================
+set -euo pipefail
+
+# -----------------------------------------------------------------------
+# F2-1: ç½‘ç»œæ ˆè°ƒä¼˜ â€” UDP å¤§ç¼“å†²åŒº + å‡å°‘ä¸¢åŒ…
+# -----------------------------------------------------------------------
+SYSCTL_CONF=/etc/sysctl.d/99-polyedge-tokyo.conf
+
+cat > "$SYSCTL_CONF" << 'EOF'
+# PolyEdge ç½‘ç»œæ ˆè°ƒä¼˜ â€” ä¸œäº¬ UDP å‘é€èŠ‚ç‚¹
+
+# UDP æŽ¥æ”¶/å‘é€ç¼“å†²åŒº (4MB) â€” é˜²æ­¢ UDP ä¸¢åŒ…
+net.core.rmem_max = 4194304
+net.core.wmem_max = 4194304
+net.core.rmem_default = 1048576
+net.core.wmem_default = 1048576
+
+# UDP socket ç¼“å†²åŒº
+net.ipv4.udp_rmem_min = 65536
+net.ipv4.udp_wmem_min = 65536
+
+# å¢žå¤§ socket é˜Ÿåˆ—æ·±åº¦ï¼ˆé˜²æ­¢ UDP ä¸¢åŒ…ï¼‰
+net.core.netdev_max_backlog = 65536
+
+# Busy poll â€” å‡å°‘ UDP å‘é€å»¶è¿Ÿ
+net.core.busy_read = 50
+net.core.busy_poll = 50
+
+# ç¦ç”¨ TCP æ—¶é—´æˆ³ï¼ˆå‡å°‘ CPU å¼€é”€ï¼‰
+net.ipv4.tcp_timestamps = 0
+
+# å¯ç”¨ BBR
+net.core.default_qdisc = fq
+net.ipv4.tcp_congestion_control = bbr
+EOF
+
+sysctl -p "$SYSCTL_CONF"
+echo "[F2] sysctl è°ƒä¼˜å®Œæˆ"
+
+# éªŒè¯ UDP ç¼“å†²åŒº
+WME=$(sysctl -n net.core.wmem_max)
+echo "[F2] net.core.wmem_max = $WME"
+
+# -----------------------------------------------------------------------
+# F2-2: çŽ¯å¢ƒå˜é‡æŒä¹…åŒ– â€” UDP å†—ä½™å‘é€ + ç¼“å†²åŒºé…ç½®
+# -----------------------------------------------------------------------
+ENV_FILE=/etc/polyedge/env.conf
+mkdir -p /etc/polyedge
+
+cat > "$ENV_FILE" << 'EOF'
+# PolyEdge ä¸œäº¬ UDP å‘é€å™¨é…ç½®
+
+# UDP å†—ä½™å‘é€ â€” æ¯ä¸ªæ•°æ®åŒ…å‘é€ 2 æ¬¡ï¼Œå‡å°‘ä¸¢åŒ…æ¦‚çŽ‡
+POLYEDGE_UDP_REDUNDANCY=2
+
+# UDP å‘é€ç¼“å†²åŒº 4MB
+POLYEDGE_UDP_SNDBUF_BYTES=4194304
+
+# UDP å‘é€å™¨ç»‘å®šåˆ°æ ¸å¿ƒ 2ï¼ˆä¸ŽæŽ¥æ”¶å™¨åˆ†ç¦»ï¼‰
+POLYEDGE_SENDER_PIN_CORE=2
+
+# ä¸œäº¬ â†’ çˆ±å°”å…° UDP ç›®æ ‡ï¼ˆè·¨åŒºåŸŸ VPC peering èµ°ç§ç½‘ï¼‰
+POLYEDGE_UDP_TARGET_HOST=10.0.3.123
+EOF
+
+echo "[F2] çŽ¯å¢ƒå˜é‡å†™å…¥ $ENV_FILE"
+
+# -----------------------------------------------------------------------
+# F2-3: è¿›ç¨‹å®žæ—¶ä¼˜å…ˆçº§
+# -----------------------------------------------------------------------
+POLYEDGE_PID=$(pgrep -f "polyedge\|feeder_tokyo\|feed_udp" | head -1 || true)
+
+if [ -n "$POLYEDGE_PID" ]; then
+    chrt -f -p 90 "$POLYEDGE_PID"
+    echo "[F2] âœ… polyedge PID=$POLYEDGE_PID è®¾ç½®ä¸º SCHED_FIFO priority=90"
+else
+    echo "[F2] â„¹ï¸  polyedge è¿›ç¨‹æœªè¿è¡Œï¼Œè·³è¿‡å®žæ—¶ä¼˜å…ˆçº§è®¾ç½®"
+    echo "[F2]    å¯åŠ¨åŽæ‰§è¡Œ: chrt -f -p 90 \$(pgrep -f feeder_tokyo)"
+fi
+
+# -----------------------------------------------------------------------
+# F2-4: UDP å‘é€å™¨ CPU äº²å’Œæ€§ â€” ç»‘å®šåˆ°æ ¸å¿ƒ 2
+# -----------------------------------------------------------------------
+if [ -n "$POLYEDGE_PID" ]; then
+    taskset -cp 2 "$POLYEDGE_PID"
+    echo "[F2] âœ… UDP å‘é€å™¨ç»‘å®šåˆ° CPU 2"
+fi
+
+# -----------------------------------------------------------------------
+# F2-5: CPU governor
+# -----------------------------------------------------------------------
+if command -v cpupower &>/dev/null; then
+    cpupower frequency-set -g performance || true
+    echo "[F2] âœ… CPU governor è®¾ç½®ä¸º performance"
+elif [ -d /sys/devices/system/cpu/cpu0/cpufreq ]; then
+    for cpu in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do
+        echo performance > "$cpu" 2>/dev/null || true
+    done
+    echo "[F2] âœ… CPU governor è®¾ç½®ä¸º performance (via sysfs)"
+fi
+
+# -----------------------------------------------------------------------
+# F2-6: éªŒè¯ UDP å†—ä½™è®¾ç½®
+# -----------------------------------------------------------------------
+echo ""
+echo "============================================================"
+echo "[F2] ä¸œäº¬æœåŠ¡å™¨è°ƒä¼˜å®Œæˆ"
+echo ""
+echo "     é‡å¯ feeder_tokyo æ—¶åŠ è½½çŽ¯å¢ƒå˜é‡:"
+echo "     source /etc/polyedge/env.conf && ./feeder_tokyo"
+echo ""
+echo "     éªŒè¯å†—ä½™å‘é€ (å¯åŠ¨åŽæŸ¥çœ‹æ—¥å¿—):"
+echo "     journalctl -u feeder_tokyo | grep 'redundancy'"
+echo "============================================================"
diff --git a/scripts/verify_seat_fabric.py b/scripts/verify_seat_fabric.py
new file mode 100644
index 0000000..cce944f
--- /dev/null
+++ b/scripts/verify_seat_fabric.py
@@ -0,0 +1,336 @@
+#!/usr/bin/env python3
+"""Verify SEAT Latency Fabric implementation status and runtime readiness.
+
+Checks:
+- Runtime control plane + live report fields
+- Transport path reachability (direct / GA / optional PrivateLink)
+- Static config expectations in configs/strategy.toml and configs/execution.toml
+"""
+
+from __future__ import annotations
+
+import argparse
+import json
+import time
+from dataclasses import asdict, dataclass
+from datetime import datetime, timezone
+from pathlib import Path
+from statistics import mean
+from typing import Any, Dict, List, Optional
+
+import requests
+
+
+def utc_day(ts: float | None = None) -> str:
+    dt = datetime.fromtimestamp(ts or time.time(), tz=timezone.utc)
+    return dt.strftime("%Y-%m-%d")
+
+
+def percentile(values: List[float], p: float) -> float:
+    if not values:
+        return 0.0
+    data = sorted(values)
+    i = int(round((len(data) - 1) * p))
+    i = max(0, min(i, len(data) - 1))
+    return float(data[i])
+
+
+def probe_url(
+    url: str,
+    samples: int,
+    timeout_sec: float,
+    interval_ms: int,
+    accepted_statuses: Optional[set[int]] = None,
+) -> Dict[str, float]:
+    latencies: List[float] = []
+    errors = 0
+    status_counts: Dict[str, int] = {}
+    session = requests.Session()
+    accepted_statuses = accepted_statuses or {200}
+    for _ in range(max(1, samples)):
+        t0 = time.perf_counter()
+        try:
+            r = session.get(url, timeout=timeout_sec)
+            code = int(r.status_code)
+            status_counts[str(code)] = status_counts.get(str(code), 0) + 1
+            if code in accepted_statuses:
+                latencies.append((time.perf_counter() - t0) * 1000.0)
+            else:
+                errors += 1
+        except Exception:
+            errors += 1
+        if interval_ms > 0:
+            time.sleep(interval_ms / 1000.0)
+    return {
+        "samples": len(latencies),
+        "errors": errors,
+        "p50_ms": percentile(latencies, 0.50),
+        "p90_ms": percentile(latencies, 0.90),
+        "p99_ms": percentile(latencies, 0.99),
+        "mean_ms": mean(latencies) if latencies else 0.0,
+        "status_counts": status_counts,
+    }
+
+
+@dataclass
+class CheckResult:
+    name: str
+    ok: bool
+    detail: str
+    extra: Optional[Dict[str, Any]] = None
+
+
+def parse_simple_toml(path: Path) -> Dict[str, Dict[str, str]]:
+    raw = path.read_text(encoding="utf-8")
+    out: Dict[str, Dict[str, str]] = {}
+    section = ""
+    for line in raw.splitlines():
+        line = line.strip()
+        if not line or line.startswith("#"):
+            continue
+        if line.startswith("[") and line.endswith("]"):
+            section = line[1:-1].strip()
+            out.setdefault(section, {})
+            continue
+        if "=" not in line or not section:
+            continue
+        k, v = line.split("=", 1)
+        out[section][k.strip()] = v.strip().strip('"').strip("'")
+    return out
+
+
+def check_runtime(base_url: str) -> List[CheckResult]:
+    checks: List[CheckResult] = []
+    try:
+        health = requests.get(f"{base_url.rstrip('/')}/health", timeout=4)
+        health.raise_for_status()
+        payload = health.json()
+        checks.append(
+            CheckResult(
+                name="runtime_health",
+                ok=payload.get("status") == "ok",
+                detail=f"status={payload.get('status')}",
+                extra=payload,
+            )
+        )
+    except Exception as err:
+        checks.append(
+            CheckResult(
+                name="runtime_health",
+                ok=False,
+                detail=f"request_failed: {err}",
+            )
+        )
+        return checks
+
+    try:
+        live = requests.get(f"{base_url.rstrip('/')}/report/shadow/live", timeout=6)
+        live.raise_for_status()
+        row = live.json()
+        required = [
+            "udp_share_effective",
+            "udp_local_drop_count",
+            "share_cap_drop_count",
+            "fallback_state",
+            "fallback_trigger_reason_distribution",
+            "policy_block_ratio",
+            "source_latency_p99_ms",
+        ]
+        missing = [k for k in required if k not in row]
+        checks.append(
+            CheckResult(
+                name="live_report_fields",
+                ok=not missing,
+                detail="missing=" + ",".join(missing) if missing else "all_present",
+                extra={k: row.get(k) for k in required},
+            )
+        )
+    except Exception as err:
+        checks.append(
+            CheckResult(
+                name="live_report_fields",
+                ok=False,
+                detail=f"request_failed: {err}",
+            )
+        )
+    return checks
+
+
+def check_static_configs(strategy_toml: Path, execution_toml: Path) -> List[CheckResult]:
+    checks: List[CheckResult] = []
+    try:
+        strat = parse_simple_toml(strategy_toml)
+        transport = strat.get("transport", {})
+        mode = transport.get("mode")
+        udp_local_only = transport.get("udp_local_only", "").lower() == "true"
+        cap = float(transport.get("udp_share_cap", "0") or 0)
+        checks.append(
+            CheckResult(
+                name="strategy_transport_section",
+                ok=bool(transport),
+                detail="present" if transport else "missing [transport] section",
+                extra=transport,
+            )
+        )
+        checks.append(
+            CheckResult(
+                name="transport_direct_only_profile",
+                ok=(mode == "direct_only" and udp_local_only and cap <= 0.35 and cap > 0),
+                detail=f"mode={mode},udp_local_only={udp_local_only},udp_share_cap={cap}",
+            )
+        )
+    except Exception as err:
+        checks.append(
+            CheckResult(
+                name="strategy_transport_section",
+                ok=False,
+                detail=f"parse_failed: {err}",
+            )
+        )
+
+    try:
+        exe = parse_simple_toml(execution_toml)
+        ecfg = exe.get("execution", {})
+        order_endpoint = ecfg.get("order_endpoint", "")
+        backup_endpoint = ecfg.get("order_backup_endpoint", "")
+        clob_endpoint = ecfg.get("clob_endpoint", "")
+        dual_ok = bool(order_endpoint) and bool(backup_endpoint) and order_endpoint != backup_endpoint
+        checks.append(
+            CheckResult(
+                name="execution_dual_order_endpoint",
+                ok=dual_ok,
+                detail=f"order_endpoint={order_endpoint},order_backup_endpoint={backup_endpoint}",
+                extra={"clob_endpoint": clob_endpoint},
+            )
+        )
+    except Exception as err:
+        checks.append(
+            CheckResult(
+                name="execution_dual_order_endpoint",
+                ok=False,
+                detail=f"parse_failed: {err}",
+            )
+        )
+    return checks
+
+
+def check_paths(
+    base_url: str,
+    ga_url: Optional[str],
+    pl_url: Optional[str],
+    require_privatelink: bool,
+    samples: int,
+    timeout_sec: float,
+    interval_ms: int,
+) -> List[CheckResult]:
+    checks: List[CheckResult] = []
+    targets = {"direct": base_url.rstrip("/") + "/health/latency"}
+    if ga_url:
+        targets["ga"] = ga_url.rstrip("/") + "/health/latency"
+    if pl_url:
+        targets["privatelink"] = pl_url.rstrip("/") + "/health/latency"
+
+    for name, url in targets.items():
+        accepted = {200}
+        if name == "privatelink":
+            # API Gateway PrivateLink endpoints often return 403 without API-id stage path;
+            # treat 403 as reachable network path.
+            accepted = {200, 403}
+        result = probe_url(
+            url,
+            samples=samples,
+            timeout_sec=timeout_sec,
+            interval_ms=interval_ms,
+            accepted_statuses=accepted,
+        )
+        ok = result["errors"] == 0 and result["samples"] > 0
+        if name == "privatelink" and not require_privatelink:
+            ok = True
+        checks.append(
+            CheckResult(
+                name=f"path_{name}",
+                ok=ok,
+                detail=(
+                    f"url={url}, accepted={sorted(accepted)}, "
+                    f"errors={int(result['errors'])}, p99_ms={result['p99_ms']:.3f}"
+                ),
+                extra=result,
+            )
+        )
+    return checks
+
+
+def parse_args() -> argparse.Namespace:
+    p = argparse.ArgumentParser(description="Verify SEAT latency fabric implementation/readiness")
+    p.add_argument("--base-url", default="http://127.0.0.1:8080")
+    p.add_argument("--ga-url", default=None)
+    p.add_argument("--privatelink-url", default=None)
+    p.add_argument("--strategy-toml", default="configs/strategy.toml")
+    p.add_argument("--execution-toml", default="configs/execution.toml")
+    p.add_argument(
+        "--require-privatelink",
+        action="store_true",
+        help="treat PrivateLink path reachability as hard requirement",
+    )
+    p.add_argument("--samples", type=int, default=30)
+    p.add_argument("--timeout-sec", type=float, default=2.0)
+    p.add_argument("--interval-ms", type=int, default=50)
+    p.add_argument("--run-id", default=None)
+    p.add_argument("--out-root", default="datasets/reports")
+    return p.parse_args()
+
+
+def main() -> int:
+    args = parse_args()
+    checks: List[CheckResult] = []
+    checks.extend(check_runtime(args.base_url))
+    checks.extend(
+        check_static_configs(
+            strategy_toml=Path(args.strategy_toml),
+            execution_toml=Path(args.execution_toml),
+        )
+    )
+    checks.extend(
+        check_paths(
+            base_url=args.base_url,
+            ga_url=args.ga_url,
+            pl_url=args.privatelink_url,
+            require_privatelink=args.require_privatelink,
+            samples=args.samples,
+            timeout_sec=args.timeout_sec,
+            interval_ms=args.interval_ms,
+        )
+    )
+
+    all_ok = all(c.ok for c in checks)
+    payload = {
+        "meta": {
+            "ts_ms": int(time.time() * 1000),
+            "run_id": args.run_id,
+            "base_url": args.base_url,
+            "ga_url": args.ga_url,
+            "privatelink_url": args.privatelink_url,
+            "samples": args.samples,
+            "timeout_sec": args.timeout_sec,
+            "interval_ms": args.interval_ms,
+        },
+        "all_ok": all_ok,
+        "checks": [asdict(c) for c in checks],
+    }
+
+    day_dir = Path(args.out_root) / utc_day()
+    out_dir = day_dir / "runs" / str(args.run_id) if args.run_id else day_dir
+    out_dir.mkdir(parents=True, exist_ok=True)
+    out = out_dir / f"seat_fabric_verify_{payload['meta']['ts_ms']}.json"
+    out.write_text(json.dumps(payload, ensure_ascii=True, indent=2), encoding="utf-8")
+
+    for c in checks:
+        status = "OK" if c.ok else "FAIL"
+        print(f"[{status}] {c.name}: {c.detail}")
+    print(f"all_ok={all_ok}")
+    print(f"wrote_json={out}")
+    return 0 if all_ok else 2
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/scripts/verify_udp_flow.ps1 b/scripts/verify_udp_flow.ps1
new file mode 100644
index 0000000..728fcda
--- /dev/null
+++ b/scripts/verify_udp_flow.ps1
@@ -0,0 +1,64 @@
+# verify_udp_flow.ps1 - Local Validation Script
+
+Write-Host "ðŸš€ Building binaries..."
+cargo build --release -p feeder_tokyo --bin sender
+cargo build --release --bin bench_feed
+
+if ($LASTEXITCODE -ne 0) {
+    Write-Error "Build failed!"
+    exit 1
+}
+
+$env:RUST_LOG = "info"
+$env:TARGET = "127.0.0.1:6666"
+$env:SYMBOL = "BTCUSDT"
+
+Write-Host "Starting Listener (bench_feed)..."
+$listener = Start-Job -ScriptBlock {
+    Set-Location "e:\Projects\test"
+    $env:RUST_LOG = "info"
+    ./target/release/bench_feed.exe
+}
+
+Start-Sleep -Seconds 2
+
+Write-Host "Starting Sender (feeder_tokyo)..."
+$sender = Start-Job -ScriptBlock {
+    Set-Location "e:\Projects\test"
+    $env:RUST_LOG = "info"
+    $env:TARGET = "127.0.0.1:6666"
+    $env:SYMBOL = "BTCUSDT"
+    ./target/release/sender.exe
+}
+
+Write-Host "â³ Running for 15 seconds..."
+Start-Sleep -Seconds 15
+
+Write-Host "ðŸ›‘ Stopping jobs..."
+Stop-Job $sender
+Stop-Job $listener
+
+Write-Host "=== Sender Output ==="
+Receive-Job $sender
+Write-Host "====================="
+
+Write-Host "=== Listener Output ==="
+$output = Receive-Job $listener
+$output
+Write-Host "======================="
+
+$matchCount = ($output | Select-String "MATCH").Count
+$gapCount = ($output | Select-String "UDP Gap").Count
+
+Write-Host "ðŸ“Š Summary:"
+Write-Host "   - Matches Received: $matchCount"
+Write-Host "   - Gaps Detected:    $gapCount"
+
+if ($matchCount -gt 0) {
+    Write-Host "âœ… verification PASSED: UDP flow confirmed." -ForegroundColor Green
+} else {
+    Write-Error "âŒ verification FAILED: No matches found."
+}
+
+Remove-Job $sender
+Remove-Job $listener
diff --git a/setup_relay_test.sh b/setup_relay_test.sh
new file mode 100644
index 0000000..e9d39ea
--- /dev/null
+++ b/setup_relay_test.sh
@@ -0,0 +1,57 @@
+#!/bin/bash
+set -e
+
+# PolyEdge Relay Setup Script
+# Usage: ./setup_relay_test.sh [sender|receiver] [target_ip]
+
+ROLE=$1
+TARGET_IP=${2:-"10.0.3.123"} # Default to Ireland Private IP
+SYMBOL=${3:-"btcusdt"}
+
+echo "ðŸš€ PolyEdge Setup: Role=$ROLE, Target=$TARGET_IP"
+
+# 1. Update Codebase
+if [ -d "PolyEdge" ]; then
+    echo "ðŸ“‚ Updating PolyEdge..."
+    cd PolyEdge
+    git fetch origin
+    git checkout codex/fullchain-20260216
+    git pull origin codex/fullchain-20260216
+else
+    echo "ðŸ“‚ Cloning PolyEdge..."
+    git clone https://github.com/TYCT-tyct/PolyEdge.git
+    cd PolyEdge
+    git checkout codex/fullchain-20260216
+fi
+
+# 2. Build Rust Binaries
+source "$HOME/.cargo/env" || true
+echo "ðŸ› ï¸ Building Release Binaries..."
+
+if [ "$ROLE" == "sender" ]; then
+    cargo build --release --bin feeder_tokyo
+    echo "âœ… Sender Built."
+
+    echo "ðŸƒ Starting Feeder (Tokyo)..."
+    export TARGET="${TARGET_IP}:6666"
+    export SYMBOL="$SYMBOL"
+    pkill -f feeder_tokyo || true
+    nohup ./target/release/feeder_tokyo > feeder.log 2>&1 &
+    echo "ðŸ”¥ Sender running! PID: $!"
+    echo "See logs: tail -f PolyEdge/feeder.log"
+
+elif [ "$ROLE" == "receiver" ]; then
+    cargo build --release --bin bench_feed
+    echo "âœ… Receiver Built."
+
+    echo "ðŸŽ§ Starting Receiver (Ireland)..."
+    pkill -f bench_feed || true
+    nohup ./target/release/bench_feed > latency_report.csv 2>&1 &
+    echo "ðŸ”¥ Receiver running! PID: $!"
+    echo "See logs: tail -f PolyEdge/latency_report.csv"
+
+else
+    echo "âŒ Unknown Role. Use 'sender' or 'receiver'."
+    exit 1
+fi
+
