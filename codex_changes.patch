diff --git a/Cargo.lock b/Cargo.lock
index 564b8d9..8b67e7a 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -46,6 +46,8 @@ dependencies = [
  "axum",
  "chrono",
  "core_types",
+ "dashmap",
+ "direction_detector",
  "execution_clob",
  "fair_value",
  "feed_polymarket",
@@ -63,8 +65,11 @@ dependencies = [
  "rustls",
  "serde",
  "serde_json",
+ "settlement_compounder",
  "sha2",
  "strategy_maker",
+ "taker_sniper",
+ "timeframe_router",
  "tokio",
  "tracing",
 ]
@@ -332,6 +337,20 @@ dependencies = [
  "typenum",
 ]
 
+[[package]]
+name = "dashmap"
+version = "6.1.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5041cc499144891f3790297212f32a74fb938e5136a14943f338ef9e0ae276cf"
+dependencies = [
+ "cfg-if",
+ "crossbeam-utils",
+ "hashbrown 0.14.5",
+ "lock_api",
+ "once_cell",
+ "parking_lot_core",
+]
+
 [[package]]
 name = "data-encoding"
 version = "2.10.0"
@@ -348,6 +367,14 @@ dependencies = [
  "crypto-common",
 ]
 
+[[package]]
+name = "direction_detector"
+version = "0.1.0"
+dependencies = [
+ "core_types",
+ "serde",
+]
+
 [[package]]
 name = "displaydoc"
 version = "0.2.5"
@@ -665,6 +692,12 @@ dependencies = [
  "tracing",
 ]
 
+[[package]]
+name = "hashbrown"
+version = "0.14.5"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "e5274423e17b7c9fc20b6e7e208532f9b19825d82dfd615708b70edd83df41f1"
+
 [[package]]
 name = "hashbrown"
 version = "0.15.5"
@@ -1814,6 +1847,14 @@ dependencies = [
  "serde",
 ]
 
+[[package]]
+name = "settlement_compounder"
+version = "0.1.0"
+dependencies = [
+ "core_types",
+ "serde",
+]
+
 [[package]]
 name = "sha1"
 version = "0.10.6"
@@ -1961,6 +2002,14 @@ dependencies = [
  "libc",
 ]
 
+[[package]]
+name = "taker_sniper"
+version = "0.1.0"
+dependencies = [
+ "core_types",
+ "serde",
+]
+
 [[package]]
 name = "tempfile"
 version = "3.25.0"
@@ -2023,6 +2072,14 @@ dependencies = [
  "cfg-if",
 ]
 
+[[package]]
+name = "timeframe_router"
+version = "0.1.0"
+dependencies = [
+ "core_types",
+ "serde",
+]
+
 [[package]]
 name = "tinystr"
 version = "0.8.2"
diff --git a/Cargo.toml b/Cargo.toml
index 338f9c3..302cb1f 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -9,6 +9,10 @@ members = [
   "crates/market_discovery",
   "crates/fair_value",
   "crates/strategy_maker",
+  "crates/direction_detector",
+  "crates/taker_sniper",
+  "crates/timeframe_router",
+  "crates/settlement_compounder",
   "crates/risk_engine",
   "crates/execution_clob",
   "crates/portfolio",
diff --git a/configs/execution.toml b/configs/execution.toml
index 3d4a2bf..52e312a 100644
--- a/configs/execution.toml
+++ b/configs/execution.toml
@@ -3,3 +3,6 @@ mode = "paper"
 rate_limit_rps = 15
 http_timeout_ms = 3000
 clob_endpoint = "https://clob.polymarket.com"
+# Optional: separate endpoint for authenticated order operations (typically a localhost gateway).
+# If omitted, the engine uses `clob_endpoint` for both reads and order writes.
+# order_endpoint = "http://127.0.0.1:9001"
diff --git a/configs/strategy.toml b/configs/strategy.toml
index 3bb92a6..88dee66 100644
--- a/configs/strategy.toml
+++ b/configs/strategy.toml
@@ -1,12 +1,12 @@
 [maker]
-base_quote_size = 2.0
-min_edge_bps = 4.0
+base_quote_size = 5.0
+min_edge_bps = 1.0
 inventory_skew = 0.15
-max_spread = 0.03
-ttl_ms = 400
+max_spread = 0.08
+ttl_ms = 250
 
 [taker]
-trigger_bps = 7.0
+trigger_bps = 4.0
 max_slippage_bps = 30.0
 stale_tick_filter_ms = 2000
 market_tier_profile = "balanced_sol_guard"
@@ -14,7 +14,7 @@ market_tier_profile = "balanced_sol_guard"
 [online_calibration]
 capital_fraction_kelly = 0.35
 variance_penalty_lambda = 0.25
-min_eval_notional_usdc = 0.05
+min_eval_notional_usdc = 0.01
 min_expected_edge_usdc = 0.0002
 
 [fair_value.basis_mr]
@@ -33,3 +33,48 @@ enabled = true
 outlier_method = "iqr"
 iqr_k = 1.5
 min_samples = 5
+
+# ===== Predator C+ (MVP) =====
+# Edge-confirmed: Direction only decides YES/NO side; EV thresholds are still enforced.
+
+[predator_c]
+enabled = false
+# "maker_first" | "taker_first" | "taker_only"
+priority = "taker_first"
+
+[predator_c.direction_detector]
+window_max_sec = 120
+threshold_5m_pct = 0.05
+threshold_15m_pct = 0.10
+threshold_1h_pct = 0.20
+threshold_1d_pct = 0.50
+lookback_short_sec = 15
+lookback_long_sec = 60
+min_sources_for_high_confidence = 2
+min_ticks_for_signal = 5
+
+[predator_c.taker_sniper]
+min_direction_confidence = 0.70
+min_edge_net_bps = 10.0
+max_spread = 0.08
+cooldown_ms_per_market = 800
+
+[predator_c.router]
+max_locked_pct_5m = 0.30
+max_locked_pct_15m = 0.40
+max_locked_pct_1h = 0.50
+max_locked_pct_1d = 0.30
+max_concurrent_positions = 8
+liquidity_reserve_pct = 0.20
+# Micro-live hard caps (keep permissive in paper/shadow; override when armed)
+max_order_notional_usdc = 1000000.0
+max_total_notional_usdc = 1000000.0
+
+[predator_c.compounder]
+enabled = false
+initial_capital_usdc = 100.0
+compound_ratio = 1.0
+position_fraction = 0.15
+min_quote_size = 1.0
+# For micro-live: loss <= -1U triggers pause+flatten (enforced only when live-armed).
+daily_loss_cap_usdc = 1.0
diff --git a/crates/app_runner/Cargo.toml b/crates/app_runner/Cargo.toml
index 96a6ae7..a7b1ce7 100644
--- a/crates/app_runner/Cargo.toml
+++ b/crates/app_runner/Cargo.toml
@@ -8,7 +8,9 @@ license.workspace = true
 anyhow.workspace = true
 axum.workspace = true
 chrono.workspace = true
+dashmap.workspace = true
 core_types = { path = "../core_types" }
+direction_detector = { path = "../direction_detector" }
 execution_clob = { path = "../execution_clob" }
 fair_value = { path = "../fair_value" }
 feed_polymarket = { path = "../feed_polymarket" }
@@ -26,7 +28,10 @@ risk_engine = { path = "../risk_engine" }
 rustls.workspace = true
 serde.workspace = true
 serde_json.workspace = true
+settlement_compounder = { path = "../settlement_compounder" }
 sha2.workspace = true
 strategy_maker = { path = "../strategy_maker" }
+taker_sniper = { path = "../taker_sniper" }
+timeframe_router = { path = "../timeframe_router" }
 tokio.workspace = true
 tracing.workspace = true
diff --git a/crates/app_runner/src/control_api.rs b/crates/app_runner/src/control_api.rs
index c707414..499f160 100644
--- a/crates/app_runner/src/control_api.rs
+++ b/crates/app_runner/src/control_api.rs
@@ -9,6 +9,9 @@ pub(super) fn build_router(state: AppState) -> Router {
         .route("/report/shadow/live", get(report_shadow_live))
         .route("/report/shadow/final", get(report_shadow_final))
         .route("/report/pnl/by_engine", get(report_pnl_by_engine))
+        .route("/report/direction", get(report_direction))
+        .route("/report/router", get(report_router))
+        .route("/report/capital", get(report_capital))
         .route("/report/toxicity/live", get(report_toxicity_live))
         .route("/report/toxicity/final", get(report_toxicity_final))
         .route("/control/pause", post(pause))
@@ -20,6 +23,7 @@ pub(super) fn build_router(state: AppState) -> Router {
         .route("/control/reload_allocator", post(reload_allocator))
         .route("/control/reload_toxicity", post(reload_toxicity))
         .route("/control/reload_risk", post(reload_risk))
+        .route("/control/reload_predator_c", post(reload_predator_c))
         .route("/control/reload_perf_profile", post(reload_perf_profile))
         .with_state(state)
 }
@@ -85,52 +89,180 @@ async fn flatten(State(state): State<AppState>) -> impl IntoResponse {
 async fn reset_shadow(State(state): State<AppState>) -> impl IntoResponse {
     let window_id = state.shadow_stats.reset().await;
     state.tox_state.write().await.clear();
+    {
+        let mut router = state.shared.predator_router.write().await;
+        *router = TimeframeRouter::new(router.cfg().clone());
+    }
+    {
+        let mut sniper = state.shared.predator_taker_sniper.write().await;
+        *sniper = TakerSniper::new(sniper.cfg().clone());
+    }
+    {
+        let cfg = state.shared.predator_cfg.read().await.clone();
+        let mut compounder = state.shared.predator_compounder.write().await;
+        *compounder = SettlementCompounder::new(cfg.compounder);
+    }
     Json(serde_json::json!({"ok": true, "shadow_reset": true, "window_id": window_id}))
 }
 
+#[derive(Debug, Deserialize)]
+struct PredatorCReloadReq {
+    enabled: Option<bool>,
+    priority: Option<PredatorCPriority>,
+    direction_detector: Option<DirectionConfig>,
+    taker_sniper: Option<TakerSniperConfig>,
+    router: Option<RouterConfig>,
+    compounder: Option<CompounderConfig>,
+}
+
+#[derive(Debug, Serialize)]
+struct PredatorCReloadResp {
+    predator_c: PredatorCConfig,
+}
+
+async fn reload_predator_c(
+    State(state): State<AppState>,
+    Json(req): Json<PredatorCReloadReq>,
+) -> Json<PredatorCReloadResp> {
+    let mut cfg = state.shared.predator_cfg.write().await;
+    if let Some(v) = req.enabled {
+        cfg.enabled = v;
+    }
+    if let Some(v) = req.priority {
+        cfg.priority = v;
+    }
+    if let Some(v) = req.direction_detector {
+        cfg.direction_detector = v;
+    }
+    if let Some(v) = req.taker_sniper {
+        cfg.taker_sniper = v;
+    }
+    if let Some(v) = req.router {
+        cfg.router = v;
+    }
+    if let Some(v) = req.compounder {
+        cfg.compounder = v;
+    }
+    let snapshot = cfg.clone();
+    drop(cfg);
+
+    state.shadow_stats.set_predator_enabled(snapshot.enabled);
+    {
+        let mut det = state.shared.predator_direction_detector.write().await;
+        det.set_cfg(snapshot.direction_detector.clone());
+    }
+    {
+        let mut sniper = state.shared.predator_taker_sniper.write().await;
+        sniper.set_cfg(snapshot.taker_sniper.clone());
+    }
+    {
+        let mut router = state.shared.predator_router.write().await;
+        router.set_cfg(snapshot.router.clone());
+    }
+    {
+        let mut compounder = state.shared.predator_compounder.write().await;
+        compounder.set_cfg(snapshot.compounder.clone());
+    }
+
+    append_jsonl(
+        &dataset_path("reports", "predator_c_reload.jsonl"),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "predator_c": snapshot}),
+    );
+
+    Json(PredatorCReloadResp { predator_c: snapshot })
+}
+
+async fn report_direction(
+    State(state): State<AppState>,
+) -> Json<serde_json::Value> {
+    let now = Utc::now().timestamp_millis();
+    let latest = state
+        .shared
+        .predator_latest_direction
+        .read()
+        .await
+        .clone();
+    Json(serde_json::json!({"ts_ms": now, "latest": latest}))
+}
+
+async fn report_router(State(state): State<AppState>) -> Json<serde_json::Value> {
+    let now = Utc::now().timestamp_millis();
+    let mut router = state.shared.predator_router.write().await;
+    let locks = router.snapshot_locks(now);
+    let locked_by_tf = router.locked_by_tf_usdc(now);
+    let mut locked_by_tf_usdc = HashMap::<String, f64>::new();
+    for (tf, v) in locked_by_tf {
+        locked_by_tf_usdc.insert(tf.to_string(), v);
+    }
+    Json(serde_json::json!({
+        "ts_ms": now,
+        "locks": locks,
+        "locked_by_tf_usdc": locked_by_tf_usdc,
+        "active_positions": router.active_positions(now),
+        "locked_total_usdc": router.locked_total_usdc(now)
+    }))
+}
+
+async fn report_capital(State(state): State<AppState>) -> Json<serde_json::Value> {
+    let now = Utc::now().timestamp_millis();
+    let compounder = state.shared.predator_compounder.read().await;
+    let cfg = compounder.cfg().clone();
+    Json(serde_json::json!({
+        "ts_ms": now,
+        "cfg": cfg,
+        "available_usdc": compounder.available(),
+        "total_pnl_usdc": compounder.total_pnl(),
+        "daily_pnl_usdc": compounder.daily_pnl(),
+        "halted": compounder.halted(),
+        "win_rate": compounder.win_rate(),
+        "recommended_quote_notional_usdc": compounder.recommended_quote_notional_usdc(),
+    }))
+}
+
 async fn reload_strategy(
     State(state): State<AppState>,
     Json(req): Json<StrategyReloadReq>,
 ) -> Json<StrategyReloadResp> {
-    let mut cfg = state.strategy_cfg.write().await;
+    let cur = state.strategy_cfg.read().await.clone();
+    let mut next = (*cur).clone();
     if let Some(v) = req.min_edge_bps {
-        cfg.min_edge_bps = v.max(0.0);
+        next.min_edge_bps = v.max(0.0);
     }
     if let Some(v) = req.ttl_ms {
-        cfg.ttl_ms = v.max(50);
+        next.ttl_ms = v.max(50);
     }
     if let Some(v) = req.inventory_skew {
-        cfg.inventory_skew = v.clamp(0.0, 1.0);
+        next.inventory_skew = v.clamp(0.0, 1.0);
     }
     if let Some(v) = req.base_quote_size {
-        cfg.base_quote_size = v.max(0.01);
+        next.base_quote_size = v.max(0.01);
     }
     if let Some(v) = req.max_spread {
-        cfg.max_spread = v.max(0.0001);
+        next.max_spread = v.max(0.0001);
     }
     if let Some(v) = req.taker_trigger_bps {
-        cfg.taker_trigger_bps = v.max(0.0);
+        next.taker_trigger_bps = v.max(0.0);
     }
     if let Some(v) = req.taker_max_slippage_bps {
-        cfg.taker_max_slippage_bps = v.max(0.0);
+        next.taker_max_slippage_bps = v.max(0.0);
     }
     if let Some(v) = req.stale_tick_filter_ms {
-        cfg.stale_tick_filter_ms = v.clamp(50.0, 5_000.0);
+        next.stale_tick_filter_ms = v.clamp(50.0, 5_000.0);
     }
     if let Some(v) = req.market_tier_profile {
-        cfg.market_tier_profile = v;
+        next.market_tier_profile = v;
     }
     if let Some(v) = req.capital_fraction_kelly {
-        cfg.capital_fraction_kelly = v.clamp(0.01, 1.0);
+        next.capital_fraction_kelly = v.clamp(0.01, 1.0);
     }
     if let Some(v) = req.variance_penalty_lambda {
-        cfg.variance_penalty_lambda = v.clamp(0.0, 5.0);
+        next.variance_penalty_lambda = v.clamp(0.0, 5.0);
     }
     if let Some(v) = req.min_eval_notional_usdc {
-        cfg.min_eval_notional_usdc = v.max(0.0);
+        next.min_eval_notional_usdc = v.max(0.0);
     }
     if let Some(v) = req.min_expected_edge_usdc {
-        cfg.min_expected_edge_usdc = v.max(0.0);
+        next.min_expected_edge_usdc = v.max(0.0);
     }
     let mut fair_cfg = state
         .fair_value_cfg
@@ -149,8 +281,8 @@ async fn reload_strategy(
     if let Ok(mut guard) = state.fair_value_cfg.write() {
         *guard = fair_cfg.clone();
     }
-    let maker_cfg = cfg.clone();
-    drop(cfg);
+    *state.strategy_cfg.write().await = std::sync::Arc::new(next.clone());
+    let maker_cfg = next;
     append_jsonl(
         &dataset_path("reports", "strategy_reload.jsonl"),
         &serde_json::json!({
@@ -169,24 +301,26 @@ async fn reload_taker(
     State(state): State<AppState>,
     Json(req): Json<TakerReloadReq>,
 ) -> Json<TakerReloadResp> {
-    let mut cfg = state.strategy_cfg.write().await;
+    let cur = state.strategy_cfg.read().await.clone();
+    let mut next = (*cur).clone();
     if let Some(v) = req.trigger_bps {
-        cfg.taker_trigger_bps = v.max(0.0);
+        next.taker_trigger_bps = v.max(0.0);
     }
     if let Some(v) = req.max_slippage_bps {
-        cfg.taker_max_slippage_bps = v.max(0.0);
+        next.taker_max_slippage_bps = v.max(0.0);
     }
     if let Some(v) = req.stale_tick_filter_ms {
-        cfg.stale_tick_filter_ms = v.clamp(50.0, 5_000.0);
+        next.stale_tick_filter_ms = v.clamp(50.0, 5_000.0);
     }
     if let Some(v) = req.market_tier_profile {
-        cfg.market_tier_profile = v;
+        next.market_tier_profile = v;
     }
+    *state.strategy_cfg.write().await = std::sync::Arc::new(next.clone());
     let resp = TakerReloadResp {
-        trigger_bps: cfg.taker_trigger_bps,
-        max_slippage_bps: cfg.taker_max_slippage_bps,
-        stale_tick_filter_ms: cfg.stale_tick_filter_ms,
-        market_tier_profile: cfg.market_tier_profile.clone(),
+        trigger_bps: next.taker_trigger_bps,
+        max_slippage_bps: next.taker_max_slippage_bps,
+        stale_tick_filter_ms: next.stale_tick_filter_ms,
+        market_tier_profile: next.market_tier_profile.clone(),
     };
     append_jsonl(
         &dataset_path("reports", "taker_reload.jsonl"),
@@ -228,13 +362,17 @@ async fn reload_allocator(
     }
 
     {
-        let mut strategy = state.strategy_cfg.write().await;
-        strategy.capital_fraction_kelly = allocator.capital_fraction_kelly;
-        strategy.variance_penalty_lambda = allocator.variance_penalty_lambda;
+        let cur = state.strategy_cfg.read().await.clone();
+        let mut next = (*cur).clone();
+        next.capital_fraction_kelly = allocator.capital_fraction_kelly;
+        next.variance_penalty_lambda = allocator.variance_penalty_lambda;
+        *state.strategy_cfg.write().await = std::sync::Arc::new(next);
     }
     {
-        let mut tox = state.toxicity_cfg.write().await;
-        tox.active_top_n_markets = allocator.active_top_n_markets;
+        let cur = state.toxicity_cfg.read().await.clone();
+        let mut next = (*cur).clone();
+        next.active_top_n_markets = allocator.active_top_n_markets;
+        *state.toxicity_cfg.write().await = std::sync::Arc::new(next);
     }
 
     let resp = AllocatorReloadResp {
@@ -285,68 +423,70 @@ async fn reload_toxicity(
     State(state): State<AppState>,
     Json(req): Json<ToxicityReloadReq>,
 ) -> Json<ToxicityConfig> {
-    let mut cfg = state.toxicity_cfg.write().await;
+    let cur = state.toxicity_cfg.read().await.clone();
+    let mut next = (*cur).clone();
     if let Some(v) = req.safe_threshold {
-        cfg.safe_threshold = v.clamp(0.0, 1.0);
+        next.safe_threshold = v.clamp(0.0, 1.0);
     }
     if let Some(v) = req.caution_threshold {
-        cfg.caution_threshold = v.clamp(0.0, 1.0);
+        next.caution_threshold = v.clamp(0.0, 1.0);
     }
     if let Some(v) = req.cooldown_min_sec {
-        cfg.cooldown_min_sec = v.max(1);
+        next.cooldown_min_sec = v.max(1);
     }
     if let Some(v) = req.cooldown_max_sec {
-        cfg.cooldown_max_sec = v.max(cfg.cooldown_min_sec);
+        next.cooldown_max_sec = v.max(next.cooldown_min_sec);
     }
     if let Some(v) = req.min_market_score {
-        cfg.min_market_score = v.clamp(0.0, 100.0);
+        next.min_market_score = v.clamp(0.0, 100.0);
     }
     if let Some(v) = req.active_top_n_markets {
-        cfg.active_top_n_markets = v;
+        next.active_top_n_markets = v;
     }
     if let Some(v) = req.markout_1s_caution_bps {
-        cfg.markout_1s_caution_bps = v;
+        next.markout_1s_caution_bps = v;
     }
     if let Some(v) = req.markout_5s_caution_bps {
-        cfg.markout_5s_caution_bps = v;
+        next.markout_5s_caution_bps = v;
     }
     if let Some(v) = req.markout_10s_caution_bps {
-        cfg.markout_10s_caution_bps = v;
+        next.markout_10s_caution_bps = v;
     }
     if let Some(v) = req.markout_1s_danger_bps {
-        cfg.markout_1s_danger_bps = v;
+        next.markout_1s_danger_bps = v;
     }
     if let Some(v) = req.markout_5s_danger_bps {
-        cfg.markout_5s_danger_bps = v;
+        next.markout_5s_danger_bps = v;
     }
     if let Some(v) = req.markout_10s_danger_bps {
-        cfg.markout_10s_danger_bps = v;
+        next.markout_10s_danger_bps = v;
     }
-    if cfg.safe_threshold > cfg.caution_threshold {
-        let safe = cfg.safe_threshold;
-        cfg.safe_threshold = cfg.caution_threshold;
-        cfg.caution_threshold = safe;
+    if next.safe_threshold > next.caution_threshold {
+        let safe = next.safe_threshold;
+        next.safe_threshold = next.caution_threshold;
+        next.caution_threshold = safe;
     }
-    if cfg.markout_1s_caution_bps < cfg.markout_1s_danger_bps {
-        let v = cfg.markout_1s_caution_bps;
-        cfg.markout_1s_caution_bps = cfg.markout_1s_danger_bps;
-        cfg.markout_1s_danger_bps = v;
+    if next.markout_1s_caution_bps < next.markout_1s_danger_bps {
+        let v = next.markout_1s_caution_bps;
+        next.markout_1s_caution_bps = next.markout_1s_danger_bps;
+        next.markout_1s_danger_bps = v;
     }
-    if cfg.markout_5s_caution_bps < cfg.markout_5s_danger_bps {
-        let v = cfg.markout_5s_caution_bps;
-        cfg.markout_5s_caution_bps = cfg.markout_5s_danger_bps;
-        cfg.markout_5s_danger_bps = v;
+    if next.markout_5s_caution_bps < next.markout_5s_danger_bps {
+        let v = next.markout_5s_caution_bps;
+        next.markout_5s_caution_bps = next.markout_5s_danger_bps;
+        next.markout_5s_danger_bps = v;
     }
-    if cfg.markout_10s_caution_bps < cfg.markout_10s_danger_bps {
-        let v = cfg.markout_10s_caution_bps;
-        cfg.markout_10s_caution_bps = cfg.markout_10s_danger_bps;
-        cfg.markout_10s_danger_bps = v;
+    if next.markout_10s_caution_bps < next.markout_10s_danger_bps {
+        let v = next.markout_10s_caution_bps;
+        next.markout_10s_caution_bps = next.markout_10s_danger_bps;
+        next.markout_10s_danger_bps = v;
     }
+    *state.toxicity_cfg.write().await = std::sync::Arc::new(next.clone());
     append_jsonl(
         &dataset_path("reports", "toxicity_reload.jsonl"),
-        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "config": *cfg}),
+        &serde_json::json!({"ts_ms": Utc::now().timestamp_millis(), "config": next}),
     );
-    Json(cfg.clone())
+    Json(next)
 }
 
 async fn reload_perf_profile(
diff --git a/crates/app_runner/src/main.rs b/crates/app_runner/src/main.rs
index 8a1a0c6..3a45ec0 100644
--- a/crates/app_runner/src/main.rs
+++ b/crates/app_runner/src/main.rs
@@ -15,12 +15,14 @@ use axum::routing::{get, post};
 use axum::{Json, Router};
 use chrono::Utc;
 use core_types::{
-    new_id, BookTop, ControlCommand, EdgeAttribution, EngineEvent, EnginePnLBreakdown,
-    ExecutionStyle, ExecutionVenue, FairValueModel, InventoryState, MarketFeed, MarketHealth,
-    OrderAck, OrderIntentV2, OrderSide, OrderTimeInForce, QuoteEval, QuoteIntent, QuotePolicy,
-    RefPriceFeed, RefTick, RiskContext, RiskManager, ShadowOutcome, ShadowShot, ToxicDecision,
-    ToxicFeatures, ToxicRegime,
+    new_id, BookTop, CapitalUpdate, ControlCommand, Direction, DirectionSignal, EdgeAttribution,
+    EngineEvent, EnginePnLBreakdown, ExecutionStyle, ExecutionVenue, FairValueModel, InventoryState,
+    MarketFeed, MarketHealth, OrderAck, OrderIntentV2, OrderSide, OrderTimeInForce, QuoteEval,
+    QuoteIntent, QuotePolicy, RefPriceFeed, RefTick, RiskContext, RiskManager, ShadowOutcome,
+    ShadowShot, Signal, TimeframeClass, TimeframeOpp, ToxicDecision, ToxicFeatures, ToxicRegime,
 };
+use dashmap::DashMap;
+use direction_detector::{DirectionConfig, DirectionDetector};
 use execution_clob::{ClobExecution, ExecutionMode};
 use fair_value::{BasisMrConfig, BasisMrFairValue};
 use feed_polymarket::PolymarketFeed;
@@ -34,8 +36,11 @@ use portfolio::PortfolioBook;
 use reqwest::Client;
 use risk_engine::{DefaultRiskManager, RiskLimits};
 use serde::{Deserialize, Serialize};
+use settlement_compounder::{CompounderConfig, SettlementCompounder};
 use sha2::{Digest, Sha256};
 use strategy_maker::{MakerConfig, MakerQuotePolicy};
+use taker_sniper::{TakerAction, TakerSniper, TakerSniperConfig};
+use timeframe_router::{RouterConfig, TimeframeRouter};
 use tokio::sync::{mpsc, RwLock};
 
 mod control_api;
@@ -48,8 +53,8 @@ use engine_core::{
     is_quote_reject_reason, normalize_reject_code,
 };
 use stats_utils::{
-    freshness_ms, now_ns, percentile, percentile_deque, policy_block_ratio, push_capped,
-    quote_block_ratio, robust_filter_iqr, value_to_f64,
+    freshness_ms, now_ns, percentile, policy_block_ratio, push_capped,
+    percentile_deque_capped, quote_block_ratio, robust_filter_iqr, value_to_f64,
 };
 
 #[derive(Clone)]
@@ -60,14 +65,15 @@ struct AppState {
     execution: Arc<ClobExecution>,
     _shadow: Arc<ShadowExecutor>,
     prometheus: metrics_exporter_prometheus::PrometheusHandle,
-    strategy_cfg: Arc<RwLock<MakerConfig>>,
+    strategy_cfg: Arc<RwLock<Arc<MakerConfig>>>,
     fair_value_cfg: Arc<StdRwLock<BasisMrConfig>>,
-    toxicity_cfg: Arc<RwLock<ToxicityConfig>>,
+    toxicity_cfg: Arc<RwLock<Arc<ToxicityConfig>>>,
     allocator_cfg: Arc<RwLock<AllocatorConfig>>,
     risk_limits: Arc<StdRwLock<RiskLimits>>,
     tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
     shadow_stats: Arc<ShadowStats>,
     perf_profile: Arc<RwLock<PerfProfile>>,
+    shared: Arc<EngineShared>,
 }
 
 #[derive(Debug, Clone)]
@@ -84,20 +90,66 @@ struct ScoringState {
     fetched_at: Instant,
 }
 
+#[derive(Debug, Clone)]
+struct SignalCacheEntry {
+    signal: Signal,
+    ts_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+#[serde(rename_all = "snake_case")]
+enum PredatorCPriority {
+    MakerFirst,
+    TakerFirst,
+    TakerOnly,
+}
+
+impl Default for PredatorCPriority {
+    fn default() -> Self {
+        Self::TakerFirst
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+struct PredatorCConfig {
+    enabled: bool,
+    priority: PredatorCPriority,
+    direction_detector: DirectionConfig,
+    taker_sniper: TakerSniperConfig,
+    router: RouterConfig,
+    compounder: CompounderConfig,
+}
+
+impl Default for PredatorCConfig {
+    fn default() -> Self {
+        Self {
+            enabled: false,
+            priority: PredatorCPriority::TakerFirst,
+            direction_detector: DirectionConfig::default(),
+            taker_sniper: TakerSniperConfig::default(),
+            router: RouterConfig::default(),
+            compounder: CompounderConfig::default(),
+        }
+    }
+}
+
 #[derive(Clone)]
 struct EngineShared {
     latest_books: Arc<RwLock<HashMap<String, BookTop>>>,
+    latest_signals: Arc<DashMap<String, SignalCacheEntry>>,
     market_to_symbol: Arc<RwLock<HashMap<String, String>>>,
     token_to_symbol: Arc<RwLock<HashMap<String, String>>>,
+    market_to_timeframe: Arc<RwLock<HashMap<String, TimeframeClass>>>,
+    symbol_to_markets: Arc<RwLock<HashMap<String, Vec<String>>>>,
     fee_cache: Arc<RwLock<HashMap<String, FeeRateEntry>>>,
     fee_refresh_inflight: Arc<RwLock<HashMap<String, Instant>>>,
     scoring_cache: Arc<RwLock<HashMap<String, ScoringState>>>,
     scoring_refresh_inflight: Arc<RwLock<HashMap<String, Instant>>>,
     http: Client,
     clob_endpoint: String,
-    strategy_cfg: Arc<RwLock<MakerConfig>>,
+    strategy_cfg: Arc<RwLock<Arc<MakerConfig>>>,
     fair_value_cfg: Arc<StdRwLock<BasisMrConfig>>,
-    toxicity_cfg: Arc<RwLock<ToxicityConfig>>,
+    toxicity_cfg: Arc<RwLock<Arc<ToxicityConfig>>>,
     risk_manager: Arc<DefaultRiskManager>,
     universe_symbols: Arc<Vec<String>>,
     universe_market_types: Arc<Vec<String>>,
@@ -106,6 +158,12 @@ struct EngineShared {
     scoring_rebate_factor: f64,
     tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
     shadow_stats: Arc<ShadowStats>,
+    predator_cfg: Arc<RwLock<PredatorCConfig>>,
+    predator_direction_detector: Arc<RwLock<DirectionDetector>>,
+    predator_latest_direction: Arc<RwLock<HashMap<String, DirectionSignal>>>,
+    predator_taker_sniper: Arc<RwLock<TakerSniper>>,
+    predator_router: Arc<RwLock<TimeframeRouter>>,
+    predator_compounder: Arc<RwLock<SettlementCompounder>>,
 }
 
 #[derive(Serialize)]
@@ -240,6 +298,8 @@ struct ExecutionConfig {
     rate_limit_rps: f64,
     http_timeout_ms: u64,
     clob_endpoint: String,
+    #[serde(default)]
+    order_endpoint: Option<String>,
 }
 
 impl Default for ExecutionConfig {
@@ -249,6 +309,7 @@ impl Default for ExecutionConfig {
             rate_limit_rps: 15.0,
             http_timeout_ms: 3000,
             clob_endpoint: "https://clob.polymarket.com".to_string(),
+            order_endpoint: None,
         }
     }
 }
@@ -334,6 +395,7 @@ struct MarketToxicState {
     symbol_missing: u64,
     last_tox_score: f64,
     last_regime: ToxicRegime,
+    market_score: f64,
     cooldown_until_ms: i64,
 }
 
@@ -349,6 +411,7 @@ impl Default for MarketToxicState {
             symbol_missing: 0,
             last_tox_score: 0.0,
             last_regime: ToxicRegime::Safe,
+            market_score: 80.0,
             cooldown_until_ms: 0,
         }
     }
@@ -545,6 +608,17 @@ struct ShadowLiveReport {
     blocked_reason_counts: HashMap<String, u64>,
     latency: LatencyBreakdown,
     market_scorecard: Vec<MarketScoreRow>,
+    predator_c_enabled: bool,
+    direction_signals_up: u64,
+    direction_signals_down: u64,
+    direction_signals_neutral: u64,
+    taker_sniper_fired: u64,
+    taker_sniper_skipped: u64,
+    taker_sniper_skip_reasons_top: Vec<(String, u64)>,
+    router_locked_by_tf_usdc: HashMap<String, f64>,
+    capital_available_usdc: f64,
+    capital_base_quote_size: f64,
+    capital_halt: bool,
 }
 
 #[derive(Debug, Serialize)]
@@ -652,26 +726,10 @@ struct ShadowStats {
     last_book_tick_ms: AtomicI64,
     shots: RwLock<Vec<ShadowShot>>,
     outcomes: RwLock<Vec<ShadowOutcome>>,
-    decision_queue_wait_ms: RwLock<Vec<f64>>,
-    decision_compute_ms: RwLock<Vec<f64>>,
-    tick_to_decision_ms: RwLock<Vec<f64>>,
-    ack_only_ms: RwLock<Vec<f64>>,
-    tick_to_ack_ms: RwLock<Vec<f64>>,
-    feed_in_ms: RwLock<Vec<f64>>,
-    source_latency_ms: RwLock<Vec<f64>>,
-    local_backlog_ms: RwLock<Vec<f64>>,
-    book_top_lag_ms: RwLock<Vec<f64>>,
+    samples: RwLock<ShadowSamples>,
     book_top_lag_by_symbol_ms: RwLock<HashMap<String, Vec<f64>>>,
     survival_probe_overall: RwLock<SurvivalProbeCounters>,
     survival_probe_by_symbol: RwLock<HashMap<String, SurvivalProbeCounters>>,
-    signal_us: RwLock<Vec<f64>>,
-    quote_us: RwLock<Vec<f64>>,
-    risk_us: RwLock<Vec<f64>>,
-    shadow_fill_ms: RwLock<Vec<f64>>,
-    queue_depth: RwLock<Vec<f64>>,
-    event_backlog: RwLock<Vec<f64>>,
-    parse_us: RwLock<Vec<f64>>,
-    io_queue_depth: RwLock<Vec<f64>>,
     data_total: AtomicU64,
     data_invalid: AtomicU64,
     seq_gap: AtomicU64,
@@ -682,6 +740,37 @@ struct ShadowStats {
     paused: AtomicBool,
     paused_since_ms: AtomicU64,
     paused_total_ms: AtomicU64,
+    predator_c_enabled: AtomicBool,
+    predator_dir_up: AtomicU64,
+    predator_dir_down: AtomicU64,
+    predator_dir_neutral: AtomicU64,
+    predator_taker_fired: AtomicU64,
+    predator_taker_skipped: AtomicU64,
+    predator_taker_skip_reasons: RwLock<HashMap<String, u64>>,
+    predator_router_locked_by_tf_usdc: RwLock<HashMap<String, f64>>,
+    predator_capital: RwLock<CapitalUpdate>,
+    predator_capital_halt: AtomicBool,
+}
+
+#[derive(Debug, Clone, Default)]
+struct ShadowSamples {
+    decision_queue_wait_ms: Vec<f64>,
+    decision_compute_ms: Vec<f64>,
+    tick_to_decision_ms: Vec<f64>,
+    ack_only_ms: Vec<f64>,
+    tick_to_ack_ms: Vec<f64>,
+    feed_in_ms: Vec<f64>,
+    source_latency_ms: Vec<f64>,
+    local_backlog_ms: Vec<f64>,
+    book_top_lag_ms: Vec<f64>,
+    signal_us: Vec<f64>,
+    quote_us: Vec<f64>,
+    risk_us: Vec<f64>,
+    shadow_fill_ms: Vec<f64>,
+    queue_depth: Vec<f64>,
+    event_backlog: Vec<f64>,
+    parse_us: Vec<f64>,
+    io_queue_depth: Vec<f64>,
 }
 
 impl ShadowStats {
@@ -710,26 +799,10 @@ impl ShadowStats {
             last_book_tick_ms: AtomicI64::new(0),
             shots: RwLock::new(Vec::new()),
             outcomes: RwLock::new(Vec::new()),
-            decision_queue_wait_ms: RwLock::new(Vec::new()),
-            decision_compute_ms: RwLock::new(Vec::new()),
-            tick_to_decision_ms: RwLock::new(Vec::new()),
-            ack_only_ms: RwLock::new(Vec::new()),
-            tick_to_ack_ms: RwLock::new(Vec::new()),
-            feed_in_ms: RwLock::new(Vec::new()),
-            source_latency_ms: RwLock::new(Vec::new()),
-            local_backlog_ms: RwLock::new(Vec::new()),
-            book_top_lag_ms: RwLock::new(Vec::new()),
+            samples: RwLock::new(ShadowSamples::default()),
             book_top_lag_by_symbol_ms: RwLock::new(HashMap::new()),
             survival_probe_overall: RwLock::new(SurvivalProbeCounters::default()),
             survival_probe_by_symbol: RwLock::new(HashMap::new()),
-            signal_us: RwLock::new(Vec::new()),
-            quote_us: RwLock::new(Vec::new()),
-            risk_us: RwLock::new(Vec::new()),
-            shadow_fill_ms: RwLock::new(Vec::new()),
-            queue_depth: RwLock::new(Vec::new()),
-            event_backlog: RwLock::new(Vec::new()),
-            parse_us: RwLock::new(Vec::new()),
-            io_queue_depth: RwLock::new(Vec::new()),
             data_total: AtomicU64::new(0),
             data_invalid: AtomicU64::new(0),
             seq_gap: AtomicU64::new(0),
@@ -740,6 +813,20 @@ impl ShadowStats {
             paused: AtomicBool::new(false),
             paused_since_ms: AtomicU64::new(0),
             paused_total_ms: AtomicU64::new(0),
+            predator_c_enabled: AtomicBool::new(false),
+            predator_dir_up: AtomicU64::new(0),
+            predator_dir_down: AtomicU64::new(0),
+            predator_dir_neutral: AtomicU64::new(0),
+            predator_taker_fired: AtomicU64::new(0),
+            predator_taker_skipped: AtomicU64::new(0),
+            predator_taker_skip_reasons: RwLock::new(HashMap::new()),
+            predator_router_locked_by_tf_usdc: RwLock::new(HashMap::new()),
+            predator_capital: RwLock::new(CapitalUpdate {
+                available_usdc: 0.0,
+                base_quote_size: 0.0,
+                ts_ms: 0,
+            }),
+            predator_capital_halt: AtomicBool::new(false),
         }
     }
 
@@ -764,26 +851,10 @@ impl ShadowStats {
         self.blocked_reasons.write().await.clear();
         self.shots.write().await.clear();
         self.outcomes.write().await.clear();
-        self.decision_queue_wait_ms.write().await.clear();
-        self.decision_compute_ms.write().await.clear();
-        self.tick_to_decision_ms.write().await.clear();
-        self.ack_only_ms.write().await.clear();
-        self.tick_to_ack_ms.write().await.clear();
-        self.feed_in_ms.write().await.clear();
-        self.source_latency_ms.write().await.clear();
-        self.local_backlog_ms.write().await.clear();
-        self.book_top_lag_ms.write().await.clear();
+        *self.samples.write().await = ShadowSamples::default();
         self.book_top_lag_by_symbol_ms.write().await.clear();
         *self.survival_probe_overall.write().await = SurvivalProbeCounters::default();
         self.survival_probe_by_symbol.write().await.clear();
-        self.signal_us.write().await.clear();
-        self.quote_us.write().await.clear();
-        self.risk_us.write().await.clear();
-        self.shadow_fill_ms.write().await.clear();
-        self.queue_depth.write().await.clear();
-        self.event_backlog.write().await.clear();
-        self.parse_us.write().await.clear();
-        self.io_queue_depth.write().await.clear();
         self.data_total.store(0, Ordering::Relaxed);
         self.data_invalid.store(0, Ordering::Relaxed);
         self.seq_gap.store(0, Ordering::Relaxed);
@@ -794,6 +865,20 @@ impl ShadowStats {
         self.paused.store(false, Ordering::Relaxed);
         self.paused_since_ms.store(0, Ordering::Relaxed);
         self.paused_total_ms.store(0, Ordering::Relaxed);
+        self.predator_c_enabled.store(false, Ordering::Relaxed);
+        self.predator_dir_up.store(0, Ordering::Relaxed);
+        self.predator_dir_down.store(0, Ordering::Relaxed);
+        self.predator_dir_neutral.store(0, Ordering::Relaxed);
+        self.predator_taker_fired.store(0, Ordering::Relaxed);
+        self.predator_taker_skipped.store(0, Ordering::Relaxed);
+        self.predator_taker_skip_reasons.write().await.clear();
+        self.predator_router_locked_by_tf_usdc.write().await.clear();
+        *self.predator_capital.write().await = CapitalUpdate {
+            available_usdc: 0.0,
+            base_quote_size: 0.0,
+            ts_ms: 0,
+        };
+        self.predator_capital_halt.store(false, Ordering::Relaxed);
         window_id
     }
 
@@ -848,49 +933,46 @@ impl ShadowStats {
     }
 
     async fn push_tick_to_decision_ms(&self, ms: f64) {
-        let mut v = self.tick_to_decision_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.tick_to_decision_ms, ms, Self::SAMPLE_CAP);
+    }
+
+    async fn push_depth_sample(&self, event_backlog: f64, queue_depth: f64, io_queue_depth: f64) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.event_backlog, event_backlog, Self::SAMPLE_CAP);
+        push_capped(&mut s.queue_depth, queue_depth, Self::SAMPLE_CAP);
+        push_capped(&mut s.io_queue_depth, io_queue_depth, Self::SAMPLE_CAP);
     }
 
-    async fn push_decision_queue_wait_ms(&self, ms: f64) {
-        let mut v = self.decision_queue_wait_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
+    async fn push_latency_sample(&self, feed_in_ms: f64, source_latency_ms: f64, local_backlog_ms: f64) {
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.feed_in_ms, feed_in_ms, Self::SAMPLE_CAP);
+        push_capped(&mut s.source_latency_ms, source_latency_ms, Self::SAMPLE_CAP);
+        push_capped(&mut s.local_backlog_ms, local_backlog_ms, Self::SAMPLE_CAP);
+        // Contract: decision_queue_wait is the queue/backlog time we spent waiting locally.
+        push_capped(&mut s.decision_queue_wait_ms, local_backlog_ms, Self::SAMPLE_CAP);
     }
 
     async fn push_decision_compute_ms(&self, ms: f64) {
-        let mut v = self.decision_compute_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.decision_compute_ms, ms, Self::SAMPLE_CAP);
     }
 
     async fn push_ack_only_ms(&self, ms: f64) {
-        let mut v = self.ack_only_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.ack_only_ms, ms, Self::SAMPLE_CAP);
     }
 
     async fn push_tick_to_ack_ms(&self, ms: f64) {
-        let mut v = self.tick_to_ack_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_feed_in_ms(&self, ms: f64) {
-        let mut v = self.feed_in_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_source_latency_ms(&self, ms: f64) {
-        let mut v = self.source_latency_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_local_backlog_ms(&self, ms: f64) {
-        let mut v = self.local_backlog_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.tick_to_ack_ms, ms, Self::SAMPLE_CAP);
     }
 
     async fn push_book_top_lag_ms(&self, symbol: &str, ms: f64) {
-        let mut v = self.book_top_lag_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-        drop(v);
+        {
+            let mut s = self.samples.write().await;
+            push_capped(&mut s.book_top_lag_ms, ms, Self::SAMPLE_CAP);
+        }
 
         let mut by_symbol = self.book_top_lag_by_symbol_ms.write().await;
         let entry = by_symbol.entry(symbol.to_string()).or_default();
@@ -908,43 +990,28 @@ impl ShadowStats {
     }
 
     async fn push_signal_us(&self, us: f64) {
-        let mut v = self.signal_us.write().await;
-        push_capped(&mut v, us, Self::SAMPLE_CAP);
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.signal_us, us, Self::SAMPLE_CAP);
     }
 
     async fn push_quote_us(&self, us: f64) {
-        let mut v = self.quote_us.write().await;
-        push_capped(&mut v, us, Self::SAMPLE_CAP);
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.quote_us, us, Self::SAMPLE_CAP);
     }
 
     async fn push_risk_us(&self, us: f64) {
-        let mut v = self.risk_us.write().await;
-        push_capped(&mut v, us, Self::SAMPLE_CAP);
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.risk_us, us, Self::SAMPLE_CAP);
     }
 
     async fn push_shadow_fill_ms(&self, ms: f64) {
-        let mut v = self.shadow_fill_ms.write().await;
-        push_capped(&mut v, ms, Self::SAMPLE_CAP);
-    }
-
-    async fn push_queue_depth(&self, depth: f64) {
-        let mut v = self.queue_depth.write().await;
-        push_capped(&mut v, depth, Self::SAMPLE_CAP);
-    }
-
-    async fn push_event_backlog(&self, depth: f64) {
-        let mut v = self.event_backlog.write().await;
-        push_capped(&mut v, depth, Self::SAMPLE_CAP);
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.shadow_fill_ms, ms, Self::SAMPLE_CAP);
     }
 
     async fn push_parse_us(&self, us: f64) {
-        let mut v = self.parse_us.write().await;
-        push_capped(&mut v, us, Self::SAMPLE_CAP);
-    }
-
-    async fn push_io_queue_depth(&self, depth: f64) {
-        let mut v = self.io_queue_depth.write().await;
-        push_capped(&mut v, depth, Self::SAMPLE_CAP);
+        let mut s = self.samples.write().await;
+        push_capped(&mut s.parse_us, us, Self::SAMPLE_CAP);
     }
 
     fn mark_attempted(&self) {
@@ -1049,6 +1116,43 @@ impl ShadowStats {
         }
     }
 
+    fn set_predator_enabled(&self, v: bool) {
+        self.predator_c_enabled.store(v, Ordering::Relaxed);
+    }
+
+    fn mark_predator_direction(&self, dir: &Direction) {
+        match dir {
+            Direction::Up => {
+                self.predator_dir_up.fetch_add(1, Ordering::Relaxed);
+            }
+            Direction::Down => {
+                self.predator_dir_down.fetch_add(1, Ordering::Relaxed);
+            }
+            Direction::Neutral => {
+                self.predator_dir_neutral.fetch_add(1, Ordering::Relaxed);
+            }
+        }
+    }
+
+    fn mark_predator_taker_fired(&self) {
+        self.predator_taker_fired.fetch_add(1, Ordering::Relaxed);
+    }
+
+    async fn mark_predator_taker_skipped(&self, reason: &str) {
+        self.predator_taker_skipped.fetch_add(1, Ordering::Relaxed);
+        let mut reasons = self.predator_taker_skip_reasons.write().await;
+        *reasons.entry(reason.to_string()).or_insert(0) += 1;
+    }
+
+    async fn set_predator_router_locked_by_tf_usdc(&self, locked: HashMap<String, f64>) {
+        *self.predator_router_locked_by_tf_usdc.write().await = locked;
+    }
+
+    async fn set_predator_capital(&self, update: CapitalUpdate, halt: bool) {
+        *self.predator_capital.write().await = update;
+        self.predator_capital_halt.store(halt, Ordering::Relaxed);
+    }
+
     fn uptime_pct(&self, elapsed: Duration) -> f64 {
         let elapsed_ms = elapsed.as_millis() as u64;
         if elapsed_ms == 0 {
@@ -1077,24 +1181,26 @@ impl ShadowStats {
         const PRIMARY_DELAY_MS: u64 = 10;
         let shots = self.shots.read().await.clone();
         let outcomes = self.outcomes.read().await.clone();
-        let decision_queue_wait_ms = self.decision_queue_wait_ms.read().await.clone();
-        let decision_compute_ms = self.decision_compute_ms.read().await.clone();
-        let tick_to_decision_ms = self.tick_to_decision_ms.read().await.clone();
-        let ack_only_ms = self.ack_only_ms.read().await.clone();
-        let tick_to_ack_ms = self.tick_to_ack_ms.read().await.clone();
-        let feed_in_ms = self.feed_in_ms.read().await.clone();
-        let source_latency_ms = self.source_latency_ms.read().await.clone();
-        let local_backlog_ms = self.local_backlog_ms.read().await.clone();
-        let book_top_lag_ms = self.book_top_lag_ms.read().await.clone();
+        let ShadowSamples {
+            decision_queue_wait_ms,
+            decision_compute_ms,
+            tick_to_decision_ms,
+            ack_only_ms,
+            tick_to_ack_ms,
+            feed_in_ms,
+            source_latency_ms,
+            local_backlog_ms,
+            book_top_lag_ms,
+            signal_us,
+            quote_us,
+            risk_us,
+            shadow_fill_ms,
+            queue_depth,
+            event_backlog,
+            parse_us,
+            io_queue_depth,
+        } = self.samples.read().await.clone();
         let book_top_lag_by_symbol_ms = self.book_top_lag_by_symbol_ms.read().await.clone();
-        let signal_us = self.signal_us.read().await.clone();
-        let quote_us = self.quote_us.read().await.clone();
-        let risk_us = self.risk_us.read().await.clone();
-        let shadow_fill_ms = self.shadow_fill_ms.read().await.clone();
-        let queue_depth = self.queue_depth.read().await.clone();
-        let event_backlog = self.event_backlog.read().await.clone();
-        let parse_us = self.parse_us.read().await.clone();
-        let io_queue_depth = self.io_queue_depth.read().await.clone();
         let blocked_reason_counts = self.blocked_reasons.read().await.clone();
         let survival_probe_overall = *self.survival_probe_overall.read().await;
         let survival_probe_by_symbol = self.survival_probe_by_symbol.read().await.clone();
@@ -1285,6 +1391,20 @@ impl ShadowStats {
             local_backlog_p99_ms: percentile(&local_backlog_ms, 0.99).unwrap_or(0.0),
         };
 
+        let predator_c_enabled = self.predator_c_enabled.load(Ordering::Relaxed);
+        let direction_signals_up = self.predator_dir_up.load(Ordering::Relaxed);
+        let direction_signals_down = self.predator_dir_down.load(Ordering::Relaxed);
+        let direction_signals_neutral = self.predator_dir_neutral.load(Ordering::Relaxed);
+        let taker_sniper_fired = self.predator_taker_fired.load(Ordering::Relaxed);
+        let taker_sniper_skipped = self.predator_taker_skipped.load(Ordering::Relaxed);
+        let skip_reasons = self.predator_taker_skip_reasons.read().await.clone();
+        let mut skip_top = skip_reasons.into_iter().collect::<Vec<_>>();
+        skip_top.sort_by(|a, b| b.1.cmp(&a.1));
+        skip_top.truncate(10);
+        let router_locked_by_tf_usdc = self.predator_router_locked_by_tf_usdc.read().await.clone();
+        let capital = self.predator_capital.read().await.clone();
+        let capital_halt = self.predator_capital_halt.load(Ordering::Relaxed);
+
         let mut live = ShadowLiveReport {
             window_id: self.window_id.load(Ordering::Relaxed),
             window_shots: shots.len(),
@@ -1361,6 +1481,17 @@ impl ShadowStats {
             blocked_reason_counts,
             latency,
             market_scorecard: scorecard,
+            predator_c_enabled,
+            direction_signals_up,
+            direction_signals_down,
+            direction_signals_neutral,
+            taker_sniper_fired,
+            taker_sniper_skipped,
+            taker_sniper_skip_reasons_top: skip_top,
+            router_locked_by_tf_usdc,
+            capital_available_usdc: capital.available_usdc,
+            capital_base_quote_size: capital.base_quote_size,
+            capital_halt,
         };
         live.gate_fail_reasons =
             gate_eval::compute_gate_fail_reasons(&live, Self::GATE_MIN_OUTCOMES);
@@ -1497,20 +1628,32 @@ async fn async_main() -> Result<()> {
     let universe_cfg = load_universe_config();
     let bus = RingBus::new(16_384);
     let portfolio = Arc::new(PortfolioBook::default());
-    let exec_mode = if execution_cfg.mode.eq_ignore_ascii_case("live") {
+    let live_armed = std::env::var("POLYEDGE_LIVE_ARMED")
+        .map(|v| v.eq_ignore_ascii_case("true") || v == "1")
+        .unwrap_or(false);
+    let exec_mode = if execution_cfg.mode.eq_ignore_ascii_case("live") && live_armed {
         ExecutionMode::Live
     } else {
+        if execution_cfg.mode.eq_ignore_ascii_case("live") && !live_armed {
+            tracing::warn!(
+                "execution.mode=live but POLYEDGE_LIVE_ARMED is not true; forcing paper mode"
+            );
+        }
         ExecutionMode::Paper
     };
+    let order_endpoint = execution_cfg
+        .order_endpoint
+        .clone()
+        .unwrap_or_else(|| execution_cfg.clob_endpoint.clone());
     let execution = Arc::new(ClobExecution::new_with_timeout(
         exec_mode,
-        execution_cfg.clob_endpoint.clone(),
+        order_endpoint,
         Duration::from_millis(execution_cfg.http_timeout_ms),
     ));
     let shadow = Arc::new(ShadowExecutor::default());
-    let strategy_cfg = Arc::new(RwLock::new(load_strategy_config()));
+    let strategy_cfg = Arc::new(RwLock::new(Arc::new(load_strategy_config())));
     let fair_value_cfg = Arc::new(StdRwLock::new(load_fair_value_config()));
-    let toxicity_cfg = Arc::new(RwLock::new(ToxicityConfig::default()));
+    let toxicity_cfg = Arc::new(RwLock::new(Arc::new(ToxicityConfig::default())));
     let risk_limits = Arc::new(StdRwLock::new(load_risk_limits_config()));
     let perf_profile = Arc::new(RwLock::new(load_perf_profile_config()));
     let allocator_cfg = {
@@ -1531,23 +1674,6 @@ async fn async_main() -> Result<()> {
     let universe_timeframes = Arc::new(universe_cfg.timeframes.clone());
     init_jsonl_writer(perf_profile.clone()).await;
 
-    let state = AppState {
-        paused: paused.clone(),
-        bus: bus.clone(),
-        portfolio: portfolio.clone(),
-        execution: execution.clone(),
-        _shadow: shadow.clone(),
-        prometheus,
-        strategy_cfg: strategy_cfg.clone(),
-        fair_value_cfg: fair_value_cfg.clone(),
-        toxicity_cfg: toxicity_cfg.clone(),
-        allocator_cfg: allocator_cfg.clone(),
-        risk_limits: risk_limits.clone(),
-        tox_state: tox_state.clone(),
-        shadow_stats: shadow_stats.clone(),
-        perf_profile: perf_profile.clone(),
-    };
-
     let scoring_rebate_factor = std::env::var("POLYEDGE_SCORING_REBATE_FACTOR")
         .ok()
         .and_then(|v| v.parse::<f64>().ok())
@@ -1556,10 +1682,26 @@ async fn async_main() -> Result<()> {
         .clamp(0.0, 1.0);
 
     let risk_manager = Arc::new(DefaultRiskManager::new(risk_limits.clone()));
+    let predator_cfg = Arc::new(RwLock::new(load_predator_c_config()));
+    let predator_cfg0 = predator_cfg.read().await.clone();
+    let predator_direction_detector = Arc::new(RwLock::new(DirectionDetector::new(
+        predator_cfg0.direction_detector.clone(),
+    )));
+    let predator_latest_direction = Arc::new(RwLock::new(HashMap::new()));
+    let predator_taker_sniper = Arc::new(RwLock::new(TakerSniper::new(
+        predator_cfg0.taker_sniper.clone(),
+    )));
+    let predator_router = Arc::new(RwLock::new(TimeframeRouter::new(predator_cfg0.router.clone())));
+    let predator_compounder = Arc::new(RwLock::new(SettlementCompounder::new(
+        predator_cfg0.compounder.clone(),
+    )));
     let shared = Arc::new(EngineShared {
         latest_books: Arc::new(RwLock::new(HashMap::new())),
+        latest_signals: Arc::new(DashMap::new()),
         market_to_symbol: Arc::new(RwLock::new(HashMap::new())),
         token_to_symbol: Arc::new(RwLock::new(HashMap::new())),
+        market_to_timeframe: Arc::new(RwLock::new(HashMap::new())),
+        symbol_to_markets: Arc::new(RwLock::new(HashMap::new())),
         fee_cache: Arc::new(RwLock::new(HashMap::new())),
         fee_refresh_inflight: Arc::new(RwLock::new(HashMap::new())),
         scoring_cache: Arc::new(RwLock::new(HashMap::new())),
@@ -1577,8 +1719,32 @@ async fn async_main() -> Result<()> {
         scoring_rebate_factor,
         tox_state,
         shadow_stats,
+        predator_cfg: predator_cfg.clone(),
+        predator_direction_detector,
+        predator_latest_direction,
+        predator_taker_sniper,
+        predator_router,
+        predator_compounder,
     });
 
+    let state = AppState {
+        paused: paused.clone(),
+        bus: bus.clone(),
+        portfolio: portfolio.clone(),
+        execution: execution.clone(),
+        _shadow: shadow.clone(),
+        prometheus,
+        strategy_cfg: shared.strategy_cfg.clone(),
+        fair_value_cfg: shared.fair_value_cfg.clone(),
+        toxicity_cfg: shared.toxicity_cfg.clone(),
+        allocator_cfg: allocator_cfg.clone(),
+        risk_limits: risk_limits.clone(),
+        tox_state: shared.tox_state.clone(),
+        shadow_stats: shared.shadow_stats.clone(),
+        perf_profile: perf_profile.clone(),
+        shared: shared.clone(),
+    };
+
     spawn_reference_feed(
         bus.clone(),
         shared.shadow_stats.clone(),
@@ -1625,6 +1791,7 @@ fn install_rustls_provider() {
 
 fn spawn_reference_feed(bus: RingBus<EngineEvent>, stats: Arc<ShadowStats>, symbols: Vec<String>) {
     const TS_INVERSION_TOLERANCE_MS: i64 = 250;
+    const TS_BACKJUMP_RESET_MS: i64 = 5_000;
     tokio::spawn(async move {
         let feed = MultiSourceRefFeed::new(Duration::from_millis(50));
         if symbols.is_empty() {
@@ -1656,7 +1823,12 @@ fn spawn_reference_feed(bus: RingBus<EngineEvent>, stats: Arc<ShadowStats>, symb
                     let stream_key = format!("{}:{}", tick.source, tick.symbol);
                     if let Some(prev) = last_source_ts_by_stream.get(&stream_key).copied() {
                         if source_ts + TS_INVERSION_TOLERANCE_MS < prev {
-                            stats.mark_ts_inversion();
+                            let back_jump_ms = prev.saturating_sub(source_ts);
+                            if back_jump_ms > TS_BACKJUMP_RESET_MS {
+                                stats.record_issue("ref_ts_backjump_reset").await;
+                            } else {
+                                stats.mark_ts_inversion();
+                            }
                         }
                     }
                     last_source_ts_by_stream.insert(stream_key, source_ts);
@@ -1698,6 +1870,7 @@ fn spawn_market_feed(
     timeframes: Vec<String>,
 ) {
     const TS_INVERSION_TOLERANCE_MS: i64 = 250;
+    const TS_BACKJUMP_RESET_MS: i64 = 5_000;
     tokio::spawn(async move {
         let feed = PolymarketFeed::new_with_universe(
             Duration::from_millis(50),
@@ -1727,7 +1900,12 @@ fn spawn_market_feed(
                     stats.mark_data_validity(valid);
                     if let Some(prev) = last_source_ts_by_market.get(&book.market_id).copied() {
                         if source_ts + TS_INVERSION_TOLERANCE_MS < prev {
-                            stats.mark_ts_inversion();
+                            let back_jump_ms = prev.saturating_sub(source_ts);
+                            if back_jump_ms > TS_BACKJUMP_RESET_MS {
+                                stats.record_issue("book_ts_backjump_reset").await;
+                            } else {
+                                stats.mark_ts_inversion();
+                            }
                         }
                     }
                     last_source_ts_by_market.insert(book.market_id.clone(), source_ts);
@@ -1803,6 +1981,13 @@ fn spawn_strategy_engine(
                 EngineEvent::RefTick(tick) => {
                     let parse_us = dispatch_start.elapsed().as_secs_f64() * 1_000_000.0;
                     shared.shadow_stats.push_parse_us(parse_us).await;
+                    if !is_anchor_ref_source(tick.source.as_str()) {
+                        shared
+                            .predator_direction_detector
+                            .write()
+                            .await
+                            .on_tick(&tick);
+                    }
                     insert_latest_ref_tick(&mut latest_fast_ticks, &mut latest_anchor_ticks, tick);
                 }
                 EngineEvent::BookTop(mut book) => {
@@ -1820,6 +2005,13 @@ fn spawn_strategy_engine(
                                 coalesced += 1;
                             }
                             Ok(EngineEvent::RefTick(next_tick)) => {
+                                if !is_anchor_ref_source(next_tick.source.as_str()) {
+                                    shared
+                                        .predator_direction_detector
+                                        .write()
+                                        .await
+                                        .on_tick(&next_tick);
+                                }
                                 insert_latest_ref_tick(
                                     &mut latest_fast_ticks,
                                     &mut latest_anchor_ticks,
@@ -1845,13 +2037,14 @@ fn spawn_strategy_engine(
                     }
 
                     let backlog_depth = rx.len() as f64;
-                    shared.shadow_stats.push_event_backlog(backlog_depth).await;
                     metrics::histogram!("runtime.event_backlog_depth").record(backlog_depth);
                     let queue_depth = execution.open_orders_count() as f64;
-                    shared.shadow_stats.push_queue_depth(queue_depth).await;
                     metrics::histogram!("runtime.open_order_depth").record(queue_depth);
                     let io_depth = current_jsonl_queue_depth() as f64;
-                    shared.shadow_stats.push_io_queue_depth(io_depth).await;
+                    shared
+                        .shadow_stats
+                        .push_depth_sample(backlog_depth, queue_depth, io_depth)
+                        .await;
                     metrics::histogram!("runtime.jsonl_queue_depth").record(io_depth);
                     shared
                         .latest_books
@@ -1968,18 +2161,13 @@ fn spawn_strategy_engine(
                         shared.shadow_stats.record_issue("stale_tick_dropped").await;
                         continue;
                     }
-                    shared.shadow_stats.push_feed_in_ms(feed_in_ms).await;
                     shared
                         .shadow_stats
-                        .push_source_latency_ms(latency_sample.source_latency_ms)
-                        .await;
-                    shared
-                        .shadow_stats
-                        .push_local_backlog_ms(latency_sample.local_backlog_ms)
-                        .await;
-                    shared
-                        .shadow_stats
-                        .push_decision_queue_wait_ms(latency_sample.local_backlog_ms)
+                        .push_latency_sample(
+                            feed_in_ms,
+                            latency_sample.source_latency_ms,
+                            latency_sample.local_backlog_ms,
+                        )
                         .await;
                     metrics::histogram!("latency.feed_in_ms").record(feed_in_ms);
                     metrics::histogram!("latency.source_latency_ms")
@@ -1995,6 +2183,13 @@ fn spawn_strategy_engine(
                     shared.shadow_stats.push_signal_us(signal_us).await;
                     metrics::histogram!("latency.signal_us").record(signal_us);
                     let _ = bus.publish(EngineEvent::Signal(signal.clone()));
+                    shared.latest_signals.insert(
+                        book.market_id.clone(),
+                        SignalCacheEntry {
+                            signal: signal.clone(),
+                            ts_ms: Utc::now().timestamp_millis(),
+                        },
+                    );
                     if should_sample_book_lag && book_top_lag_ms >= 5.0 {
                         // "Orderless" survival probe: measure whether an observed top-of-book
                         // price survives for + ms, independent of order placement.
@@ -2042,97 +2237,126 @@ fn spawn_strategy_engine(
                         markout_10s_p25,
                         active_by_rank,
                     ) = {
-                        let mut states = shared.tox_state.write().await;
+                        // Step A: snapshot (read-lock) the state needed for computation.
                         let (
-                            features,
-                            decision,
-                            score,
-                            pending_exposure,
-                            no_quote_rate,
-                            symbol_missing_rate,
-                            markout_samples,
+                            attempted0,
+                            no_quote0,
+                            symbol_missing0,
+                            cooldown_until_ms0,
+                            markout_samples0,
+                            markout_1s_p50,
+                            markout_5s_p50,
                             markout_10s_p50,
                             markout_10s_p25,
                         ) = {
+                            let states = shared.tox_state.read().await;
+                            if let Some(st) = states.get(&book.market_id) {
+                                let samples = st
+                                    .markout_1s
+                                    .len()
+                                    .max(st.markout_5s.len())
+                                    .max(st.markout_10s.len());
+                                (
+                                    st.attempted,
+                                    st.no_quote,
+                                    st.symbol_missing,
+                                    st.cooldown_until_ms,
+                                    samples,
+                                    percentile_deque_capped(&st.markout_1s, 0.50, 1024)
+                                        .unwrap_or(0.0),
+                                    percentile_deque_capped(&st.markout_5s, 0.50, 1024)
+                                        .unwrap_or(0.0),
+                                    percentile_deque_capped(&st.markout_10s, 0.50, 2048)
+                                        .unwrap_or(0.0),
+                                    percentile_deque_capped(&st.markout_10s, 0.25, 2048)
+                                        .unwrap_or(0.0),
+                                )
+                            } else {
+                                (0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0)
+                            }
+                        };
+
+                        // Step B: compute without holding a write lock.
+                        let attempted1 = attempted0.saturating_add(1).max(1);
+                        let tox_features = build_toxic_features(
+                            &book,
+                            &symbol,
+                            feed_in_ms,
+                            signal.fair_yes,
+                            attempted1,
+                            no_quote0,
+                            markout_1s_p50,
+                            markout_5s_p50,
+                            markout_10s_p50,
+                        );
+                        let mut tox_decision = evaluate_toxicity(&tox_features, &tox_cfg);
+                        let score_scale = (tox_cfg.k_spread / 1.5).clamp(0.25, 4.0);
+                        tox_decision.tox_score = (tox_decision.tox_score * score_scale).clamp(0.0, 1.0);
+                        tox_decision.regime = if tox_decision.tox_score >= tox_cfg.caution_threshold {
+                            ToxicRegime::Danger
+                        } else if tox_decision.tox_score >= tox_cfg.safe_threshold {
+                            ToxicRegime::Caution
+                        } else {
+                            ToxicRegime::Safe
+                        };
+
+                        let now_ms = Utc::now().timestamp_millis();
+                        let mut cooldown_until_ms1 = cooldown_until_ms0;
+                        if now_ms < cooldown_until_ms0 {
+                            tox_decision.regime = ToxicRegime::Danger;
+                            tox_decision.reason_codes.push("cooldown_active".to_string());
+                        }
+                        // Note: cooldown is based on the pre-warmup regime, matching the old behavior.
+                        if matches!(tox_decision.regime, ToxicRegime::Danger) {
+                            let cool = cooldown_secs_for_score(tox_decision.tox_score, &tox_cfg);
+                            cooldown_until_ms1 =
+                                cooldown_until_ms1.max(now_ms + (cool as i64) * 1_000);
+                        }
+                        let markout_samples = markout_samples0;
+                        if markout_samples < 20 {
+                            tox_decision.tox_score =
+                                tox_decision.tox_score.min(tox_cfg.safe_threshold * 0.8);
+                            tox_decision.regime = ToxicRegime::Safe;
+                            tox_decision
+                                .reason_codes
+                                .push("warmup_samples_lt_20".to_string());
+                        }
+
+                        let market_score = compute_market_score_from_snapshot(
+                            attempted1,
+                            no_quote0,
+                            symbol_missing0,
+                            tox_decision.tox_score,
+                            markout_samples,
+                            markout_10s_p50,
+                        );
+                        let no_quote_rate = (no_quote0 as f64 / attempted1 as f64).clamp(0.0, 1.0);
+                        let symbol_missing_rate =
+                            (symbol_missing0 as f64 / attempted1 as f64).clamp(0.0, 1.0);
+
+                        // Step C: short write-back only.
+                        {
+                            let mut states = shared.tox_state.write().await;
                             let st = states.entry(book.market_id.clone()).or_default();
                             st.attempted = st.attempted.saturating_add(1);
                             st.symbol = symbol.clone();
+                            st.last_tox_score = tox_decision.tox_score;
+                            st.last_regime = tox_decision.regime.clone();
+                            st.cooldown_until_ms = st.cooldown_until_ms.max(cooldown_until_ms1);
+                            st.market_score = market_score;
+                        }
 
-                            let features = build_toxic_features(
-                                &book,
-                                &symbol,
-                                feed_in_ms,
-                                signal.fair_yes,
-                                st,
-                            );
-                            let mut decision = evaluate_toxicity(&features, &tox_cfg);
-                            let score_scale = (tox_cfg.k_spread / 1.5).clamp(0.25, 4.0);
-                            decision.tox_score = (decision.tox_score * score_scale).clamp(0.0, 1.0);
-                            decision.regime = if decision.tox_score >= tox_cfg.caution_threshold {
-                                ToxicRegime::Danger
-                            } else if decision.tox_score >= tox_cfg.safe_threshold {
-                                ToxicRegime::Caution
-                            } else {
-                                ToxicRegime::Safe
-                            };
-                            let now_ms = Utc::now().timestamp_millis();
-
-                            if now_ms < st.cooldown_until_ms {
-                                decision.regime = ToxicRegime::Danger;
-                                decision.reason_codes.push("cooldown_active".to_string());
-                            }
-                            if matches!(decision.regime, ToxicRegime::Danger) {
-                                let cool = cooldown_secs_for_score(decision.tox_score, &tox_cfg);
-                                st.cooldown_until_ms =
-                                    st.cooldown_until_ms.max(now_ms + (cool as i64) * 1_000);
-                            }
-                            let markout_samples = st
-                                .markout_1s
-                                .len()
-                                .max(st.markout_5s.len())
-                                .max(st.markout_10s.len());
-                            if markout_samples < 20 {
-                                decision.tox_score =
-                                    decision.tox_score.min(tox_cfg.safe_threshold * 0.8);
-                                decision.regime = ToxicRegime::Safe;
-                                decision
-                                    .reason_codes
-                                    .push("warmup_samples_lt_20".to_string());
-                            }
-                            st.last_tox_score = decision.tox_score;
-                            st.last_regime = decision.regime.clone();
-                            let score =
-                                compute_market_score(st, decision.tox_score, markout_samples);
-                            let markout_10s_p50 =
-                                percentile_deque(&st.markout_10s, 0.50).unwrap_or(0.0);
-                            let markout_10s_p25 =
-                                percentile_deque(&st.markout_10s, 0.25).unwrap_or(0.0);
-                            let pending_exposure = pending_market_exposure;
-                            let attempted = st.attempted.max(1);
-                            let no_quote_rate = st.no_quote as f64 / attempted as f64;
-                            let symbol_missing_rate = st.symbol_missing as f64 / attempted as f64;
-                            (
-                                features,
-                                decision,
-                                score,
-                                pending_exposure,
-                                no_quote_rate,
-                                symbol_missing_rate,
-                                markout_samples,
-                                markout_10s_p50,
-                                markout_10s_p25,
-                            )
+                        // Step D: rank decision (read-lock, uses updated market_score).
+                        let active_by_rank = {
+                            let states = shared.tox_state.read().await;
+                            is_market_in_top_n(&states, &book.market_id, tox_cfg.active_top_n_markets)
                         };
-                        let active_by_rank = is_market_in_top_n(
-                            &states,
-                            &book.market_id,
-                            tox_cfg.active_top_n_markets,
-                        );
+
                         (
-                            features,
-                            decision,
-                            score,
-                            pending_exposure,
+                            tox_features,
+                            tox_decision,
+                            market_score,
+                            pending_market_exposure,
                             no_quote_rate,
                             symbol_missing_rate,
                             markout_samples,
@@ -2257,7 +2481,38 @@ fn spawn_strategy_engine(
                         continue;
                     }
 
-                    let mut effective_cfg = cfg.clone();
+                    let predator_cfg = shared.predator_cfg.read().await.clone();
+                    if predator_cfg.enabled
+                        && matches!(
+                            predator_cfg.priority,
+                            PredatorCPriority::TakerFirst | PredatorCPriority::TakerOnly
+                        )
+                    {
+                        let now_ms = Utc::now().timestamp_millis();
+                        let res = run_predator_c_for_symbol(
+                            &shared,
+                            &bus,
+                            &portfolio,
+                            &execution,
+                            &shadow,
+                            &mut market_rate_budget,
+                            &mut global_rate_budget,
+                            &predator_cfg,
+                            &symbol,
+                            now_ms,
+                        )
+                        .await;
+                        if matches!(predator_cfg.priority, PredatorCPriority::TakerOnly) {
+                            continue;
+                        }
+                        if matches!(predator_cfg.priority, PredatorCPriority::TakerFirst)
+                            && res.attempted > 0
+                        {
+                            continue;
+                        }
+                    }
+
+                    let mut effective_cfg = (*cfg).clone();
                     effective_cfg.min_edge_bps = effective_min_edge_bps;
                     let policy = MakerQuotePolicy::new(effective_cfg);
                     let mut intents =
@@ -2300,6 +2555,24 @@ fn spawn_strategy_engine(
                                 .mark_blocked_with_reason("no_quote_policy")
                                 .await;
                         }
+                        if predator_cfg.enabled
+                            && matches!(predator_cfg.priority, PredatorCPriority::MakerFirst)
+                        {
+                            let now_ms = Utc::now().timestamp_millis();
+                            let _ = run_predator_c_for_symbol(
+                                &shared,
+                                &bus,
+                                &portfolio,
+                                &execution,
+                                &shadow,
+                                &mut market_rate_budget,
+                                &mut global_rate_budget,
+                                &predator_cfg,
+                                &symbol,
+                                now_ms,
+                            )
+                            .await;
+                        }
                         continue;
                     }
 
@@ -2412,7 +2685,9 @@ fn spawn_strategy_engine(
                                     .shadow_stats
                                     .mark_blocked_with_reason("taker_slippage_budget")
                                     .await;
-                                continue;
+                                // If the market moved too far for a safe taker cross, keep the
+                                // passive maker quote instead of dropping the opportunity.
+                                force_taker = false;
                             }
                         }
                         let per_market_rps = (shared.rate_limit_rps / 8.0).max(0.5);
@@ -2451,8 +2726,13 @@ fn spawn_strategy_engine(
                             ExecutionStyle::Maker => OrderTimeInForce::PostOnly,
                             ExecutionStyle::Taker | ExecutionStyle::Arb => OrderTimeInForce::Fak,
                         };
+                        let token_id = match intent.side {
+                            OrderSide::BuyYes | OrderSide::SellYes => book.token_id_yes.clone(),
+                            OrderSide::BuyNo | OrderSide::SellNo => book.token_id_no.clone(),
+                        };
                         let v2_intent = OrderIntentV2 {
                             market_id: intent.market_id.clone(),
+                            token_id: Some(token_id),
                             side: intent.side.clone(),
                             price: intent.price,
                             size: intent.size,
@@ -2462,6 +2742,7 @@ fn spawn_strategy_engine(
                             max_slippage_bps: cfg.taker_max_slippage_bps,
                             fee_rate_bps: fee_bps,
                             expected_edge_net_bps: edge_net,
+                            client_order_id: Some(new_id()),
                             hold_to_resolution: false,
                         };
                         match execution.place_order_v2(v2_intent).await {
@@ -2602,6 +2883,460 @@ fn spawn_strategy_engine(
     });
 }
 
+#[derive(Debug, Default, Clone, Copy)]
+struct PredatorExecResult {
+    attempted: u64,
+    executed: u64,
+}
+
+async fn run_predator_c_for_symbol(
+    shared: &Arc<EngineShared>,
+    bus: &RingBus<EngineEvent>,
+    portfolio: &Arc<PortfolioBook>,
+    execution: &Arc<ClobExecution>,
+    shadow: &Arc<ShadowExecutor>,
+    market_rate_budget: &mut HashMap<String, TokenBucket>,
+    global_rate_budget: &mut TokenBucket,
+    predator_cfg: &PredatorCConfig,
+    symbol: &str,
+    now_ms: i64,
+) -> PredatorExecResult {
+    shared.shadow_stats.set_predator_enabled(predator_cfg.enabled);
+    if !predator_cfg.enabled {
+        return PredatorExecResult::default();
+    }
+
+    let direction_signal = {
+        let det = shared.predator_direction_detector.read().await;
+        det.evaluate(symbol, now_ms)
+    };
+    let Some(direction_signal) = direction_signal else {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped("no_direction_signal")
+            .await;
+        return PredatorExecResult::default();
+    };
+
+    shared.shadow_stats.mark_predator_direction(&direction_signal.direction);
+    {
+        let mut map = shared.predator_latest_direction.write().await;
+        map.insert(symbol.to_string(), direction_signal.clone());
+    }
+    let _ = bus.publish(EngineEvent::DirectionSignal(direction_signal.clone()));
+
+    if matches!(direction_signal.direction, Direction::Neutral) {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped("neutral_direction")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    let market_ids = shared
+        .symbol_to_markets
+        .read()
+        .await
+        .get(symbol)
+        .cloned()
+        .unwrap_or_default();
+    if market_ids.is_empty() {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped("no_symbol_markets")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    let maker_cfg = shared.strategy_cfg.read().await.clone();
+
+    let (quote_notional_usdc, total_capital_usdc) = if predator_cfg.compounder.enabled {
+        let c = shared.predator_compounder.read().await;
+        (c.recommended_quote_notional_usdc(), c.available())
+    } else {
+        (0.0, predator_cfg.compounder.initial_capital_usdc.max(0.0))
+    };
+
+    let side = match direction_signal.direction {
+        Direction::Up => OrderSide::BuyYes,
+        Direction::Down => OrderSide::BuyNo,
+        Direction::Neutral => OrderSide::BuyYes,
+    };
+
+    // Build candidate opportunities using cached fair values per market (do NOT call fair.evaluate
+    // here; the fair model is stateful per symbol and would be advanced multiple times).
+    #[derive(Debug, Clone)]
+    struct PredatorCandIn {
+        market_id: String,
+        timeframe: TimeframeClass,
+        entry_price: f64,
+        spread: f64,
+        fee_bps: f64,
+        edge_gross_bps: f64,
+        edge_net_bps: f64,
+        size: f64,
+    }
+
+    let market_ids = market_ids.into_iter().take(32).collect::<Vec<_>>();
+    let tf_by_market = {
+        let map = shared.market_to_timeframe.read().await;
+        market_ids
+            .iter()
+            .filter_map(|id| map.get(id).cloned().map(|tf| (id.clone(), tf)))
+            .collect::<HashMap<String, TimeframeClass>>()
+    };
+    let book_by_market = {
+        let map = shared.latest_books.read().await;
+        market_ids
+            .iter()
+            .filter_map(|id| map.get(id).cloned().map(|b| (id.clone(), b)))
+            .collect::<HashMap<String, BookTop>>()
+    };
+
+    let mut cand_inputs = Vec::<PredatorCandIn>::new();
+    for market_id in market_ids {
+        let Some(timeframe) = tf_by_market.get(&market_id).cloned() else {
+            continue;
+        };
+        let Some(book) = book_by_market.get(&market_id).cloned() else {
+            continue;
+        };
+        let sig_entry = shared
+            .latest_signals
+            .get(&market_id)
+            .map(|v| v.value().clone());
+        let Some(sig_entry) = sig_entry else {
+            continue;
+        };
+        if now_ms.saturating_sub(sig_entry.ts_ms) > 5_000 {
+            continue;
+        }
+
+        let entry_price = aggressive_price_for_side(&book, &side);
+        let spread = spread_for_side(&book, &side);
+        let fee_bps = get_fee_rate_bps_cached(shared, &market_id).await;
+        let rebate_est_bps = get_rebate_bps_cached(shared, &market_id, fee_bps).await;
+        let edge_gross_bps =
+            edge_gross_bps_for_side(sig_entry.signal.fair_yes, &side, entry_price);
+        let edge_net_bps = edge_gross_bps - fee_bps + rebate_est_bps;
+        let size = if predator_cfg.compounder.enabled {
+            (quote_notional_usdc / entry_price.max(1e-6)).max(0.01)
+        } else {
+            maker_cfg.base_quote_size.max(0.01)
+        };
+
+        cand_inputs.push(PredatorCandIn {
+            market_id,
+            timeframe,
+            entry_price,
+            spread,
+            fee_bps,
+            edge_gross_bps,
+            edge_net_bps,
+            size,
+        });
+    }
+
+    let mut candidates: Vec<TimeframeOpp> = Vec::new();
+    let mut skip_reasons: Vec<String> = Vec::new();
+    {
+        let mut sniper = shared.predator_taker_sniper.write().await;
+        for cin in cand_inputs {
+            let decision = sniper.evaluate(
+                &cin.market_id,
+                symbol,
+                cin.timeframe.clone(),
+                &direction_signal,
+                cin.entry_price,
+                cin.spread,
+                cin.fee_bps,
+                cin.edge_gross_bps,
+                cin.edge_net_bps,
+                cin.size,
+                now_ms,
+            );
+            match decision.action {
+                TakerAction::Fire => {
+                    if let Some(opp) = decision.opportunity {
+                        candidates.push(opp);
+                    }
+                }
+                TakerAction::Skip => {
+                    skip_reasons.push(decision.reason);
+                }
+            }
+        }
+    }
+    for reason in skip_reasons {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped(reason.as_str())
+            .await;
+    }
+
+    if candidates.is_empty() {
+        return PredatorExecResult::default();
+    }
+
+    // Router selects + locks.
+    let mut locked_opps: Vec<TimeframeOpp> = Vec::new();
+    let mut locked_by_tf_usdc: HashMap<String, f64> = HashMap::new();
+    {
+        let mut router = shared.predator_router.write().await;
+        let selected = router.route(candidates, total_capital_usdc.max(0.0), now_ms);
+        for opp in selected {
+            if router.lock(&opp, now_ms) {
+                locked_opps.push(opp);
+            }
+        }
+        for (tf, v) in router.locked_by_tf_usdc(now_ms) {
+            locked_by_tf_usdc.insert(tf.to_string(), v);
+        }
+    }
+    shared
+        .shadow_stats
+        .set_predator_router_locked_by_tf_usdc(locked_by_tf_usdc)
+        .await;
+
+    if locked_opps.is_empty() {
+        return PredatorExecResult::default();
+    }
+
+    let mut out = PredatorExecResult::default();
+    for opp in locked_opps {
+        shared.shadow_stats.mark_predator_taker_fired();
+        let res = predator_execute_opportunity(
+            shared,
+            bus,
+            portfolio,
+            execution,
+            shadow,
+            market_rate_budget,
+            global_rate_budget,
+            &maker_cfg,
+            predator_cfg,
+            &direction_signal,
+            &opp,
+            now_ms,
+        )
+        .await;
+        out.attempted = out.attempted.saturating_add(res.attempted);
+        out.executed = out.executed.saturating_add(res.executed);
+    }
+    out
+}
+
+async fn predator_execute_opportunity(
+    shared: &Arc<EngineShared>,
+    bus: &RingBus<EngineEvent>,
+    portfolio: &Arc<PortfolioBook>,
+    execution: &Arc<ClobExecution>,
+    shadow: &Arc<ShadowExecutor>,
+    market_rate_budget: &mut HashMap<String, TokenBucket>,
+    global_rate_budget: &mut TokenBucket,
+    maker_cfg: &MakerConfig,
+    predator_cfg: &PredatorCConfig,
+    _direction_signal: &DirectionSignal,
+    opp: &TimeframeOpp,
+    now_ms: i64,
+) -> PredatorExecResult {
+    let mut intent = QuoteIntent {
+        market_id: opp.market_id.clone(),
+        side: opp.side.clone(),
+        price: opp.entry_price,
+        size: opp.size,
+        ttl_ms: 150,
+    };
+
+    shared.shadow_stats.mark_attempted();
+
+    let book = shared.latest_books.read().await.get(&intent.market_id).cloned();
+    let Some(book) = book else {
+        shared
+            .shadow_stats
+            .mark_predator_taker_skipped("book_missing")
+            .await;
+        return PredatorExecResult::default();
+    };
+
+    let proposed_notional_usdc = (intent.price.max(0.0) * intent.size.max(0.0)).max(0.0);
+    let inventory = inventory_for_market(portfolio, &intent.market_id);
+    let pending_market_exposure = execution.open_order_notional_for_market(&intent.market_id);
+    let pending_total_exposure = execution.open_order_notional_total();
+    let drawdown = portfolio.snapshot().max_drawdown_pct;
+    let ctx = RiskContext {
+        market_id: intent.market_id.clone(),
+        symbol: opp.symbol.clone(),
+        order_count: execution.open_orders_count(),
+        proposed_size: intent.size,
+        proposed_notional_usdc,
+        market_notional: inventory.exposure_notional + pending_market_exposure,
+        asset_notional: inventory.exposure_notional + pending_total_exposure,
+        drawdown_pct: drawdown,
+        loss_streak: shared.shadow_stats.loss_streak(),
+        now_ms,
+    };
+    let decision = shared.risk_manager.evaluate(&ctx);
+    if !decision.allow {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason(&format!("risk:{}", decision.reason))
+            .await;
+        return PredatorExecResult::default();
+    }
+    if decision.capped_size <= 0.0 {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("risk_capped_zero")
+            .await;
+        return PredatorExecResult::default();
+    }
+    intent.size = intent.size.min(decision.capped_size);
+
+    let intended_notional_usdc = (intent.price.max(0.0) * intent.size.max(0.0)).max(0.0);
+    if intended_notional_usdc < maker_cfg.min_eval_notional_usdc {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("tiny_notional")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    let edge_net_usdc = (opp.edge_net_bps / 10_000.0) * intended_notional_usdc;
+    if edge_net_usdc < maker_cfg.min_expected_edge_usdc {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("edge_notional_too_small")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    let per_market_rps = (shared.rate_limit_rps / 8.0).max(0.5);
+    let market_bucket = market_rate_budget
+        .entry(intent.market_id.clone())
+        .or_insert_with(|| TokenBucket::new(per_market_rps, (per_market_rps * 2.0).max(1.0)));
+    if !global_rate_budget.try_take(1.0) {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("rate_budget_global")
+            .await;
+        return PredatorExecResult::default();
+    }
+    if !market_bucket.try_take(1.0) {
+        shared
+            .shadow_stats
+            .mark_blocked_with_reason("rate_budget_market")
+            .await;
+        return PredatorExecResult::default();
+    }
+
+    shared.shadow_stats.mark_eligible();
+    let place_start = Instant::now();
+    let token_id = match intent.side {
+        OrderSide::BuyYes | OrderSide::SellYes => book.token_id_yes.clone(),
+        OrderSide::BuyNo | OrderSide::SellNo => book.token_id_no.clone(),
+    };
+    let v2_intent = OrderIntentV2 {
+        market_id: intent.market_id.clone(),
+        token_id: Some(token_id),
+        side: intent.side.clone(),
+        price: intent.price,
+        size: intent.size,
+        ttl_ms: intent.ttl_ms,
+        style: ExecutionStyle::Taker,
+        tif: OrderTimeInForce::Fak,
+        max_slippage_bps: maker_cfg.taker_max_slippage_bps,
+        fee_rate_bps: opp.fee_bps,
+        expected_edge_net_bps: opp.edge_net_bps,
+        client_order_id: Some(new_id()),
+        hold_to_resolution: false,
+    };
+
+    let mut out = PredatorExecResult::default();
+    out.attempted = out.attempted.saturating_add(1);
+
+    match execution.place_order_v2(v2_intent).await {
+        Ok(ack_v2) if ack_v2.accepted => {
+            let accepted_size = ack_v2.accepted_size.max(0.0).min(intent.size);
+            if accepted_size <= 0.0 {
+                shared
+                    .shadow_stats
+                    .mark_blocked_with_reason("exchange_reject_zero_size")
+                    .await;
+                return out;
+            }
+            intent.size = accepted_size;
+            shared.shadow_stats.mark_executed();
+            out.executed = out.executed.saturating_add(1);
+
+            let ack_only_ms = if ack_v2.exchange_latency_ms > 0.0 {
+                ack_v2.exchange_latency_ms
+            } else {
+                place_start.elapsed().as_secs_f64() * 1_000.0
+            };
+            shared.shadow_stats.push_ack_only_ms(ack_only_ms).await;
+            shared
+                .shadow_stats
+                .push_tick_to_ack_ms(ack_only_ms)
+                .await;
+
+            let ack = OrderAck {
+                order_id: ack_v2.order_id,
+                market_id: ack_v2.market_id,
+                accepted: true,
+                ts_ms: ack_v2.ts_ms,
+            };
+            let _ = bus.publish(EngineEvent::OrderAck(ack.clone()));
+            shadow.register_order(&ack, intent.clone());
+
+            for delay_ms in [5_u64, 10_u64, 25_u64] {
+                let shot = ShadowShot {
+                    shot_id: new_id(),
+                    market_id: intent.market_id.clone(),
+                    symbol: opp.symbol.clone(),
+                    side: intent.side.clone(),
+                    execution_style: ExecutionStyle::Taker,
+                    survival_probe_price: aggressive_price_for_side(&book, &intent.side),
+                    intended_price: intent.price,
+                    size: intent.size,
+                    edge_gross_bps: opp.edge_gross_bps,
+                    edge_net_bps: opp.edge_net_bps,
+                    fee_paid_bps: opp.fee_bps,
+                    rebate_est_bps: 0.0,
+                    delay_ms,
+                    t0_ns: now_ns(),
+                    min_edge_bps: predator_cfg.taker_sniper.min_edge_net_bps,
+                    tox_score: 0.0,
+                    ttl_ms: intent.ttl_ms,
+                };
+                shared.shadow_stats.push_shot(shot.clone()).await;
+                let _ = bus.publish(EngineEvent::ShadowShot(shot.clone()));
+                spawn_shadow_outcome_task(shared.clone(), bus.clone(), shot);
+            }
+        }
+        Ok(ack_v2) => {
+            let reject_code = ack_v2
+                .reject_code
+                .as_deref()
+                .map(normalize_reject_code)
+                .unwrap_or_else(|| "unknown".to_string());
+            shared
+                .shadow_stats
+                .mark_blocked_with_reason(&format!("exchange_reject_{reject_code}"))
+                .await;
+            metrics::counter!("execution.place_rejected").increment(1);
+        }
+        Err(err) => {
+            let reason = classify_execution_error_reason(&err);
+            shared.shadow_stats.mark_blocked_with_reason(reason).await;
+            tracing::warn!(?err, "predator place_order failed");
+            metrics::counter!("execution.place_error").increment(1);
+        }
+    }
+
+    out
+}
+
 fn spawn_shadow_outcome_task(
     shared: Arc<EngineShared>,
     bus: RingBus<EngineEvent>,
@@ -2715,6 +3450,32 @@ fn spawn_shadow_outcome_task(
         shared.shadow_stats.push_outcome(outcome.clone()).await;
         update_toxic_state_from_outcome(&shared, &outcome).await;
         if shot.delay_ms == 10 {
+            if let Some(pnl_usdc) = outcome.net_markout_10s_usdc {
+                let compounder_enabled = shared.predator_cfg.read().await.compounder.enabled;
+                if compounder_enabled {
+                    let (update, halt) = {
+                        let mut c = shared.predator_compounder.write().await;
+                        let update = c.on_markout(pnl_usdc);
+                        (update, c.halted())
+                    };
+                    shared
+                        .shadow_stats
+                        .set_predator_capital(update.clone(), halt)
+                        .await;
+                    let _ = bus.publish(EngineEvent::CapitalUpdate(update));
+
+                    if halt {
+                        let live_armed = std::env::var("POLYEDGE_LIVE_ARMED")
+                            .map(|v| v.eq_ignore_ascii_case("true") || v == "1")
+                            .unwrap_or(false);
+                        if live_armed {
+                            shared.shadow_stats.record_issue("capital_halt").await;
+                            let _ = bus.publish(EngineEvent::Control(ControlCommand::Pause));
+                            let _ = bus.publish(EngineEvent::Control(ControlCommand::Flatten));
+                        }
+                    }
+                }
+            }
             let eval = QuoteEval {
                 market_id: shot.market_id.clone(),
                 symbol: shot.symbol.clone(),
@@ -2772,8 +3533,21 @@ async fn refresh_market_symbol_map(shared: &EngineShared) {
         Ok(markets) => {
             let mut market_map = HashMap::new();
             let mut token_map = HashMap::new();
+            let mut timeframe_map = HashMap::new();
+            let mut symbol_to_markets = HashMap::<String, Vec<String>>::new();
             for m in markets {
                 market_map.insert(m.market_id.clone(), m.symbol.clone());
+                symbol_to_markets
+                    .entry(m.symbol.clone())
+                    .or_default()
+                    .push(m.market_id.clone());
+                if let Some(tf) = m
+                    .timeframe
+                    .as_deref()
+                    .and_then(parse_timeframe_class)
+                {
+                    timeframe_map.insert(m.market_id.clone(), tf);
+                }
                 if let Some(t) = m.token_id_yes {
                     token_map.insert(t, m.symbol.clone());
                 }
@@ -2781,6 +3555,10 @@ async fn refresh_market_symbol_map(shared: &EngineShared) {
                     token_map.insert(t, m.symbol.clone());
                 }
             }
+            for v in symbol_to_markets.values_mut() {
+                v.sort();
+                v.dedup();
+            }
             {
                 let mut map = shared.market_to_symbol.write().await;
                 *map = market_map;
@@ -2789,6 +3567,14 @@ async fn refresh_market_symbol_map(shared: &EngineShared) {
                 let mut map = shared.token_to_symbol.write().await;
                 *map = token_map;
             }
+            {
+                let mut map = shared.market_to_timeframe.write().await;
+                *map = timeframe_map;
+            }
+            {
+                let mut map = shared.symbol_to_markets.write().await;
+                *map = symbol_to_markets;
+            }
         }
         Err(err) => {
             tracing::warn!(?err, "market discovery refresh failed");
@@ -2796,6 +3582,16 @@ async fn refresh_market_symbol_map(shared: &EngineShared) {
     }
 }
 
+fn parse_timeframe_class(tf: &str) -> Option<TimeframeClass> {
+    match tf.trim().to_ascii_lowercase().as_str() {
+        "5m" | "tf5m" => Some(TimeframeClass::Tf5m),
+        "15m" | "tf15m" => Some(TimeframeClass::Tf15m),
+        "1h" | "tf1h" => Some(TimeframeClass::Tf1h),
+        "1d" | "tf1d" => Some(TimeframeClass::Tf1d),
+        _ => None,
+    }
+}
+
 async fn pick_market_symbol(shared: &EngineShared, book: &BookTop) -> Option<String> {
     if let Some(v) = shared
         .market_to_symbol
@@ -2849,7 +3645,11 @@ fn build_toxic_features(
     symbol: &str,
     stale_ms: f64,
     fair_yes: f64,
-    state: &MarketToxicState,
+    attempted: u64,
+    no_quote: u64,
+    markout_1s_p50: f64,
+    markout_5s_p50: f64,
+    markout_10s_p50: f64,
 ) -> ToxicFeatures {
     let mid_yes = ((book.bid_yes + book.ask_yes) * 0.5).max(0.0001);
     let spread_bps = ((book.ask_yes - book.bid_yes).max(0.0) / mid_yes) * 10_000.0;
@@ -2860,15 +3660,15 @@ fn build_toxic_features(
     } else {
         ((book.bid_yes + book.ask_no) - (book.ask_yes + book.bid_no)) / imbalance_den
     };
-    let attempted = state.attempted.max(1);
-    let cancel_burst = (state.no_quote as f64 / attempted as f64).clamp(0.0, 1.0);
+    let attempted = attempted.max(1);
+    let cancel_burst = (no_quote as f64 / attempted as f64).clamp(0.0, 1.0);
 
     ToxicFeatures {
         market_id: book.market_id.clone(),
         symbol: symbol.to_string(),
-        markout_1s: percentile_deque(&state.markout_1s, 0.50).unwrap_or(0.0),
-        markout_5s: percentile_deque(&state.markout_5s, 0.50).unwrap_or(0.0),
-        markout_10s: percentile_deque(&state.markout_10s, 0.50).unwrap_or(0.0),
+        markout_1s: markout_1s_p50,
+        markout_5s: markout_5s_p50,
+        markout_10s: markout_10s_p50,
         spread_bps,
         microprice_drift,
         stale_ms,
@@ -2974,7 +3774,7 @@ fn compute_market_score(state: &MarketToxicState, tox_score: f64, markout_sample
     let attempted = state.attempted.max(1);
     let no_quote_rate = state.no_quote as f64 / attempted as f64;
     let symbol_missing_rate = state.symbol_missing as f64 / attempted as f64;
-    let markout_10s = percentile_deque(&state.markout_10s, 0.50).unwrap_or(0.0);
+    let markout_10s = percentile_deque_capped(&state.markout_10s, 0.50, 2048).unwrap_or(0.0);
     if markout_samples < 20 {
         let warmup_score = 80.0 - no_quote_rate * 6.0 - symbol_missing_rate * 6.0;
         return warmup_score.clamp(45.0, 100.0);
@@ -2986,6 +3786,28 @@ fn compute_market_score(state: &MarketToxicState, tox_score: f64, markout_sample
     score.clamp(0.0, 100.0)
 }
 
+fn compute_market_score_from_snapshot(
+    attempted: u64,
+    no_quote: u64,
+    symbol_missing: u64,
+    tox_score: f64,
+    markout_samples: usize,
+    markout_10s_p50: f64,
+) -> f64 {
+    let attempted = attempted.max(1);
+    let no_quote_rate = no_quote as f64 / attempted as f64;
+    let symbol_missing_rate = symbol_missing as f64 / attempted as f64;
+    if markout_samples < 20 {
+        let warmup_score = 80.0 - no_quote_rate * 6.0 - symbol_missing_rate * 6.0;
+        return warmup_score.clamp(45.0, 100.0);
+    }
+    let score = 70.0 + (markout_10s_p50 * 1.5).clamp(-30.0, 30.0)
+        - no_quote_rate * 25.0
+        - symbol_missing_rate * 30.0
+        - tox_score * 20.0;
+    score.clamp(0.0, 100.0)
+}
+
 fn adaptive_min_edge_bps(
     base_min_edge_bps: f64,
     tox_score: f64,
@@ -3161,17 +3983,7 @@ fn is_market_in_top_n(
     }
     let mut ranked = states
         .iter()
-        .map(|(id, st)| {
-            let samples = st
-                .markout_1s
-                .len()
-                .max(st.markout_5s.len())
-                .max(st.markout_10s.len());
-            (
-                id.clone(),
-                compute_market_score(st, st.last_tox_score, samples),
-            )
-        })
+        .map(|(id, st)| (id.clone(), st.market_score))
         .collect::<Vec<_>>();
     if ranked.is_empty() {
         return true;
@@ -3227,6 +4039,12 @@ async fn update_toxic_state_from_outcome(shared: &EngineShared, outcome: &Shadow
     if let Some(v) = outcome.net_markout_10s_bps.or(outcome.pnl_10s_bps) {
         push_rolling(&mut st.markout_10s, v, 2048);
     }
+    let samples = st
+        .markout_1s
+        .len()
+        .max(st.markout_5s.len())
+        .max(st.markout_10s.len());
+    st.market_score = compute_market_score(st, st.last_tox_score, samples);
 }
 
 fn push_rolling(dst: &mut VecDeque<f64>, value: f64, cap: usize) {
@@ -3765,12 +4583,39 @@ fn aggressive_price_for_side(book: &BookTop, side: &OrderSide) -> f64 {
     }
 }
 
+fn spread_for_side(book: &BookTop, side: &OrderSide) -> f64 {
+    match side {
+        OrderSide::BuyYes | OrderSide::SellYes => (book.ask_yes - book.bid_yes).max(0.0),
+        OrderSide::BuyNo | OrderSide::SellNo => (book.ask_no - book.bid_no).max(0.0),
+    }
+}
+
+fn fair_for_side(fair_yes: f64, side: &OrderSide) -> f64 {
+    match side {
+        OrderSide::BuyYes | OrderSide::SellYes => fair_yes,
+        OrderSide::BuyNo | OrderSide::SellNo => (1.0 - fair_yes).clamp(0.001, 0.999),
+    }
+}
+
+fn edge_gross_bps_for_side(fair_yes: f64, side: &OrderSide, entry_price: f64) -> f64 {
+    let fair = fair_for_side(fair_yes, side);
+    let px = entry_price.max(1e-6);
+    match side {
+        OrderSide::BuyYes | OrderSide::BuyNo => ((fair - px) / px) * 10_000.0,
+        OrderSide::SellYes | OrderSide::SellNo => ((px - fair) / px) * 10_000.0,
+    }
+}
+
 fn edge_for_intent(fair_yes: f64, intent: &QuoteIntent) -> f64 {
     let px = intent.price.max(1e-6);
+    let fair = match intent.side {
+        OrderSide::BuyYes | OrderSide::SellYes => fair_yes,
+        OrderSide::BuyNo | OrderSide::SellNo => (1.0 - fair_yes).clamp(0.001, 0.999),
+    };
     match intent.side {
         // Expected edge vs. intended entry price in bps of entry.
-        OrderSide::BuyYes | OrderSide::BuyNo => ((fair_yes - px) / px) * 10_000.0,
-        OrderSide::SellYes | OrderSide::SellNo => ((px - fair_yes) / px) * 10_000.0,
+        OrderSide::BuyYes | OrderSide::BuyNo => ((fair - px) / px) * 10_000.0,
+        OrderSide::SellYes | OrderSide::SellNo => ((px - fair) / px) * 10_000.0,
     }
 }
 
@@ -3778,7 +4623,7 @@ async fn build_toxicity_live_report(
     tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
     shadow_stats: Arc<ShadowStats>,
     execution: Arc<ClobExecution>,
-    toxicity_cfg: Arc<RwLock<ToxicityConfig>>,
+    toxicity_cfg: Arc<RwLock<Arc<ToxicityConfig>>>,
 ) -> ToxicityLiveReport {
     let cfg = toxicity_cfg.read().await.clone();
     let states = tox_state.read().await.clone();
@@ -3810,13 +4655,17 @@ async fn build_toxicity_live_report(
         let attempted = st.attempted.max(1);
         let no_quote_rate = st.no_quote as f64 / attempted as f64;
         let symbol_missing_rate = st.symbol_missing as f64 / attempted as f64;
-        let markout_10s_bps = percentile_deque(&st.markout_10s, 0.50).unwrap_or(0.0);
+        let markout_10s_bps = percentile_deque_capped(&st.markout_10s, 0.50, 2048).unwrap_or(0.0);
         let markout_samples = st
             .markout_1s
             .len()
             .max(st.markout_5s.len())
             .max(st.markout_10s.len());
-        let market_score = compute_market_score(&st, st.last_tox_score, markout_samples);
+        let market_score = if st.market_score > 0.0 {
+            st.market_score
+        } else {
+            compute_market_score(&st, st.last_tox_score, markout_samples)
+        };
         let pending_exposure = execution.open_order_notional_for_market(&market_id);
 
         tox_sum += st.last_tox_score;
@@ -4137,6 +4986,231 @@ fn load_strategy_config() -> MakerConfig {
     cfg
 }
 
+fn load_predator_c_config() -> PredatorCConfig {
+    let path = Path::new("configs/strategy.toml");
+    let Ok(raw) = fs::read_to_string(path) else {
+        return PredatorCConfig::default();
+    };
+
+    let mut cfg = PredatorCConfig::default();
+
+    let mut in_root = false;
+    let mut in_dir = false;
+    let mut in_sniper = false;
+    let mut in_router = false;
+    let mut in_compounder = false;
+
+    for line in raw.lines() {
+        let line = line.trim();
+        if line.is_empty() || line.starts_with('#') {
+            continue;
+        }
+        if line.starts_with('[') && line.ends_with(']') {
+            in_root = line == "[predator_c]";
+            in_dir = line == "[predator_c.direction_detector]";
+            in_sniper = line == "[predator_c.taker_sniper]";
+            in_router = line == "[predator_c.router]";
+            in_compounder = line == "[predator_c.compounder]";
+            continue;
+        }
+        if !(in_root || in_dir || in_sniper || in_router || in_compounder) {
+            continue;
+        }
+
+        let Some((k, v)) = line.split_once('=') else {
+            continue;
+        };
+        let key = k.trim();
+        let val = v.trim().trim_matches('"');
+
+        if in_root {
+            match key {
+                "enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.enabled = parsed;
+                    }
+                }
+                "priority" => {
+                    let norm = val.trim().to_ascii_lowercase();
+                    cfg.priority = match norm.as_str() {
+                        "maker_first" => PredatorCPriority::MakerFirst,
+                        "taker_first" => PredatorCPriority::TakerFirst,
+                        "taker_only" => PredatorCPriority::TakerOnly,
+                        _ => cfg.priority.clone(),
+                    };
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_dir {
+            match key {
+                "window_max_sec" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.direction_detector.window_max_sec = parsed.max(10);
+                    }
+                }
+                "threshold_5m_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.threshold_5m_pct = parsed.max(0.0);
+                    }
+                }
+                "threshold_15m_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.threshold_15m_pct = parsed.max(0.0);
+                    }
+                }
+                "threshold_1h_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.threshold_1h_pct = parsed.max(0.0);
+                    }
+                }
+                "threshold_1d_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.direction_detector.threshold_1d_pct = parsed.max(0.0);
+                    }
+                }
+                "lookback_short_sec" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.direction_detector.lookback_short_sec = parsed.max(1);
+                    }
+                }
+                "lookback_long_sec" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.direction_detector.lookback_long_sec = parsed.max(1);
+                    }
+                }
+                "min_sources_for_high_confidence" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        cfg.direction_detector.min_sources_for_high_confidence = parsed.max(1);
+                    }
+                }
+                "min_ticks_for_signal" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        cfg.direction_detector.min_ticks_for_signal = parsed.max(1);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_sniper {
+            match key {
+                "min_direction_confidence" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.taker_sniper.min_direction_confidence = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "min_edge_net_bps" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.taker_sniper.min_edge_net_bps = parsed.max(0.0);
+                    }
+                }
+                "max_spread" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.taker_sniper.max_spread = parsed.max(0.0001);
+                    }
+                }
+                "cooldown_ms_per_market" => {
+                    if let Ok(parsed) = val.parse::<u64>() {
+                        cfg.taker_sniper.cooldown_ms_per_market = parsed;
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_router {
+            match key {
+                "max_locked_pct_5m" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_locked_pct_5m = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_locked_pct_15m" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_locked_pct_15m = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_locked_pct_1h" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_locked_pct_1h = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_locked_pct_1d" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_locked_pct_1d = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "max_concurrent_positions" => {
+                    if let Ok(parsed) = val.parse::<usize>() {
+                        cfg.router.max_concurrent_positions = parsed.max(1);
+                    }
+                }
+                "liquidity_reserve_pct" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.liquidity_reserve_pct = parsed.clamp(0.0, 0.95);
+                    }
+                }
+                "max_order_notional_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_order_notional_usdc = parsed.max(0.0);
+                    }
+                }
+                "max_total_notional_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.router.max_total_notional_usdc = parsed.max(0.0);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+
+        if in_compounder {
+            match key {
+                "enabled" => {
+                    if let Ok(parsed) = val.parse::<bool>() {
+                        cfg.compounder.enabled = parsed;
+                    }
+                }
+                "initial_capital_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.initial_capital_usdc = parsed.max(0.0);
+                    }
+                }
+                "compound_ratio" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.compound_ratio = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "position_fraction" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.position_fraction = parsed.clamp(0.0, 1.0);
+                    }
+                }
+                "min_quote_size" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.min_quote_size = parsed.max(0.0);
+                    }
+                }
+                "daily_loss_cap_usdc" => {
+                    if let Ok(parsed) = val.parse::<f64>() {
+                        cfg.compounder.daily_loss_cap_usdc = parsed.max(0.0);
+                    }
+                }
+                _ => {}
+            }
+            continue;
+        }
+    }
+
+    cfg
+}
+
 fn load_risk_limits_config() -> RiskLimits {
     let path = Path::new("configs/risk.toml");
     let Ok(raw) = fs::read_to_string(path) else {
@@ -4245,6 +5319,14 @@ fn load_execution_config() -> ExecutionConfig {
                 }
             }
             "clob_endpoint" => cfg.clob_endpoint = val.to_string(),
+            "order_endpoint" => {
+                let v = val.to_string();
+                if v.is_empty() {
+                    cfg.order_endpoint = None;
+                } else {
+                    cfg.order_endpoint = Some(v);
+                }
+            }
             _ => {}
         }
     }
diff --git a/crates/app_runner/src/orchestration.rs b/crates/app_runner/src/orchestration.rs
index 34ba575..d113bc6 100644
--- a/crates/app_runner/src/orchestration.rs
+++ b/crates/app_runner/src/orchestration.rs
@@ -4,7 +4,7 @@ pub(super) fn spawn_periodic_report_persistor(
     stats: Arc<ShadowStats>,
     tox_state: Arc<RwLock<HashMap<String, MarketToxicState>>>,
     execution: Arc<ClobExecution>,
-    toxicity_cfg: Arc<RwLock<ToxicityConfig>>,
+    toxicity_cfg: Arc<RwLock<Arc<ToxicityConfig>>>,
 ) {
     tokio::spawn(async move {
         let mut last_final = Instant::now() - Duration::from_secs(600);
@@ -40,6 +40,15 @@ pub(super) fn spawn_data_reconcile_task(
 ) {
     tokio::spawn(async move {
         let mut interval = tokio::time::interval(Duration::from_secs(600));
+        // The raw JSONL files are bucketed by date, while `ShadowStats` counters are reset on
+        // `/control/reset_shadow` (window reset). Comparing absolute totals would therefore
+        // generate false "gap" alarms after any reset. Track deltas between intervals and
+        // automatically re-baseline on resets/rotations.
+        let mut last_window_id: u64 = 0;
+        let mut last_ref_lines: i64 = 0;
+        let mut last_book_lines: i64 = 0;
+        let mut last_ref_expected: i64 = 0;
+        let mut last_book_expected: i64 = 0;
         loop {
             interval.tick().await;
             let live = stats.build_live_report().await;
@@ -47,21 +56,41 @@ pub(super) fn spawn_data_reconcile_task(
             let book_lines = count_jsonl_lines(&dataset_path("raw", "book_tops.jsonl"));
             let ref_expected = live.ref_ticks_total as i64;
             let book_expected = live.book_ticks_total as i64;
-            let ref_gap_ratio = if ref_expected <= 0 {
-                0.0
-            } else {
-                ((ref_lines - ref_expected).abs() as f64) / (ref_expected as f64)
-            };
-            let book_gap_ratio = if book_expected <= 0 {
-                0.0
+            let baseline_reset = last_window_id == 0
+                || live.window_id != last_window_id
+                || ref_lines < last_ref_lines
+                || book_lines < last_book_lines
+                || ref_expected < last_ref_expected
+                || book_expected < last_book_expected;
+
+            let (ref_gap_ratio, book_gap_ratio) = if baseline_reset {
+                (0.0, 0.0)
             } else {
-                ((book_lines - book_expected).abs() as f64) / (book_expected as f64)
+                let ref_lines_delta = ref_lines - last_ref_lines;
+                let book_lines_delta = book_lines - last_book_lines;
+                let ref_expected_delta = ref_expected - last_ref_expected;
+                let book_expected_delta = book_expected - last_book_expected;
+                let ref_gap = if ref_expected_delta <= 0 {
+                    0.0
+                } else {
+                    ((ref_lines_delta - ref_expected_delta).abs() as f64)
+                        / (ref_expected_delta as f64)
+                };
+                let book_gap = if book_expected_delta <= 0 {
+                    0.0
+                } else {
+                    ((book_lines_delta - book_expected_delta).abs() as f64)
+                        / (book_expected_delta as f64)
+                };
+                (ref_gap, book_gap)
             };
-            let reconcile_fail = ref_gap_ratio > 0.05
-                || book_gap_ratio > 0.05
-                || live.data_valid_ratio < 0.999
-                || live.seq_gap_rate > 0.001
-                || live.ts_inversion_rate > 0.0005;
+
+            let reconcile_fail = !baseline_reset
+                && (ref_gap_ratio > 0.05
+                    || book_gap_ratio > 0.05
+                    || live.data_valid_ratio < 0.999
+                    || live.seq_gap_rate > 0.001
+                    || live.ts_inversion_rate > 0.0005);
 
             if reconcile_fail {
                 stats.set_observe_only(true);
@@ -86,9 +115,16 @@ pub(super) fn spawn_data_reconcile_task(
                     "ref_gap_ratio": ref_gap_ratio,
                     "book_gap_ratio": book_gap_ratio,
                     "reconcile_fail": reconcile_fail,
+                    "baseline_reset": baseline_reset,
                     "observe_only": stats.observe_only()
                 }),
             );
+
+            last_window_id = live.window_id;
+            last_ref_lines = ref_lines;
+            last_book_lines = book_lines;
+            last_ref_expected = ref_expected;
+            last_book_expected = book_expected;
         }
     });
 }
diff --git a/crates/app_runner/src/stats_utils.rs b/crates/app_runner/src/stats_utils.rs
index d7ab368..6f9c8d6 100644
--- a/crates/app_runner/src/stats_utils.rs
+++ b/crates/app_runner/src/stats_utils.rs
@@ -1,5 +1,6 @@
 use chrono::Utc;
 use std::collections::VecDeque;
+use std::cmp::Ordering;
 
 pub fn push_capped<T>(dst: &mut Vec<T>, value: T, cap: usize) {
     dst.push(value);
@@ -19,15 +20,21 @@ pub fn percentile(values: &[f64], p: f64) -> Option<f64> {
     v.get(idx).copied()
 }
 
-pub fn percentile_deque(values: &VecDeque<f64>, p: f64) -> Option<f64> {
+pub fn percentile_deque_capped(values: &VecDeque<f64>, p: f64, cap: usize) -> Option<f64> {
     if values.is_empty() {
         return None;
     }
-    // Avoid calling `percentile(&vec)` which would clone again internally.
-    let mut v: Vec<f64> = values.iter().copied().collect();
-    v.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
+    let n = values.len().min(cap.max(1));
+    if n == 0 {
+        return None;
+    }
+    // Most recent samples are more relevant; take from the back.
+    let mut v: Vec<f64> = values.iter().rev().take(n).copied().collect();
     let idx = ((v.len() as f64 - 1.0) * p.clamp(0.0, 1.0)).round() as usize;
-    v.get(idx).copied()
+    let (_, nth, _) = v.select_nth_unstable_by(idx, |a, b| {
+        a.partial_cmp(b).unwrap_or(Ordering::Equal)
+    });
+    Some(*nth)
 }
 
 pub fn robust_filter_iqr(values: &[f64]) -> (Vec<f64>, f64) {
diff --git a/crates/core_types/src/lib.rs b/crates/core_types/src/lib.rs
index cb13499..dafb3a3 100644
--- a/crates/core_types/src/lib.rs
+++ b/crates/core_types/src/lib.rs
@@ -99,6 +99,72 @@ pub struct Signal {
     pub confidence: f64,
 }
 
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
+pub enum TimeframeClass {
+    Tf5m,
+    Tf15m,
+    Tf1h,
+    Tf1d,
+}
+
+impl fmt::Display for TimeframeClass {
+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+        let value = match self {
+            Self::Tf5m => "5m",
+            Self::Tf15m => "15m",
+            Self::Tf1h => "1h",
+            Self::Tf1d => "1d",
+        };
+        f.write_str(value)
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
+pub enum Direction {
+    Up,
+    Down,
+    Neutral,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct DirectionSignal {
+    pub symbol: String,
+    pub direction: Direction,
+    /// Price move magnitude in percentage points, e.g. 0.35 means +0.35%.
+    pub magnitude_pct: f64,
+    /// Confidence in [0,1], derived from multi-source consistency.
+    pub confidence: f64,
+    pub recommended_tf: TimeframeClass,
+    pub ts_ns: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct CapitalUpdate {
+    pub available_usdc: f64,
+    /// "Base quote size" used by Predator C+ sizing logic. Interpreted as USDC notional.
+    pub base_quote_size: f64,
+    pub ts_ms: i64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
+pub struct TimeframeOpp {
+    pub timeframe: TimeframeClass,
+    pub market_id: String,
+    pub symbol: String,
+    pub direction: Direction,
+    pub side: OrderSide,
+    pub entry_price: f64,
+    pub size: f64,
+    pub edge_gross_bps: f64,
+    pub edge_net_bps: f64,
+    pub edge_net_usdc: f64,
+    pub fee_bps: f64,
+    pub lock_minutes: f64,
+    pub density: f64,
+    pub confidence: f64,
+    pub ts_ms: i64,
+}
+
 #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
 pub enum OrderSide {
     BuyYes,
@@ -188,6 +254,8 @@ pub struct OrderAck {
 pub struct OrderIntentV2 {
     pub market_id: String,
     pub side: OrderSide,
+    #[serde(default)]
+    pub token_id: Option<String>,
     pub price: f64,
     pub size: f64,
     pub ttl_ms: u64,
@@ -196,6 +264,8 @@ pub struct OrderIntentV2 {
     #[serde(default = "default_order_tif")]
     pub tif: OrderTimeInForce,
     #[serde(default)]
+    pub client_order_id: Option<String>,
+    #[serde(default)]
     pub max_slippage_bps: f64,
     #[serde(default)]
     pub fee_rate_bps: f64,
@@ -210,11 +280,13 @@ impl From<QuoteIntent> for OrderIntentV2 {
         Self {
             market_id: value.market_id,
             side: value.side,
+            token_id: None,
             price: value.price,
             size: value.size,
             ttl_ms: value.ttl_ms,
             style: ExecutionStyle::Maker,
             tif: OrderTimeInForce::PostOnly,
+            client_order_id: None,
             max_slippage_bps: 0.0,
             fee_rate_bps: 0.0,
             expected_edge_net_bps: 0.0,
@@ -498,6 +570,7 @@ pub enum EngineEvent {
     BookDelta(BookDelta),
     BookDigest(OrderbookStateDigest),
     Signal(Signal),
+    DirectionSignal(DirectionSignal),
     ToxicFeatures(ToxicFeatures),
     ToxicDecision(ToxicDecision),
     QuoteIntent(QuoteIntent),
@@ -506,6 +579,7 @@ pub enum EngineEvent {
     Fill(FillEvent),
     ShadowShot(ShadowShot),
     ShadowOutcome(ShadowOutcome),
+    CapitalUpdate(CapitalUpdate),
     Pnl(PnLSnapshot),
     Control(ControlCommand),
 }
diff --git a/crates/execution_clob/src/lib.rs b/crates/execution_clob/src/lib.rs
index 17a5da5..9dc6502 100644
--- a/crates/execution_clob/src/lib.rs
+++ b/crates/execution_clob/src/lib.rs
@@ -134,12 +134,14 @@ impl ExecutionVenue for ClobExecution {
             ExecutionMode::Live => {
                 let payload = serde_json::json!({
                     "market_id": intent.market_id,
+                    "token_id": intent.token_id,
                     "side": intent.side.to_string(),
                     "price": intent.price,
                     "size": intent.size,
                     "ttl_ms": intent.ttl_ms,
                     "style": intent.style.to_string(),
                     "tif": intent.tif.to_string(),
+                    "client_order_id": intent.client_order_id,
                     "max_slippage_bps": intent.max_slippage_bps,
                     "fee_rate_bps": intent.fee_rate_bps,
                     "expected_edge_net_bps": intent.expected_edge_net_bps,
@@ -241,6 +243,16 @@ impl ExecutionVenue for ClobExecution {
 
     async fn flatten_all(&self) -> Result<()> {
         self.open_orders.write().clear();
-        Ok(())
+        match self.mode {
+            ExecutionMode::Paper => Ok(()),
+            ExecutionMode::Live => {
+                let base = self.clob_endpoint.trim_end_matches('/');
+                let res = self.http.post(format!("{base}/flatten")).send().await?;
+                if !res.status().is_success() {
+                    bail!("flatten failed with status {}", res.status());
+                }
+                Ok(())
+            }
+        }
     }
 }
diff --git a/crates/feed_polymarket/src/lib.rs b/crates/feed_polymarket/src/lib.rs
index 92fdd98..bcc4b59 100644
--- a/crates/feed_polymarket/src/lib.rs
+++ b/crates/feed_polymarket/src/lib.rs
@@ -200,12 +200,29 @@ impl PolymarketFeed {
 
         let mut ping = tokio::time::interval(Duration::from_secs(15));
         ping.set_missed_tick_behavior(tokio::time::MissedTickBehavior::Delay);
+        // Many Polymarket markets (especially 5m/15m contracts) expire quickly. If the WS
+        // connection stays up, we would otherwise keep subscribing to stale/closed assets and
+        // stop seeing updates. Force a periodic re-discovery + resubscribe.
+        let refresh_every = std::env::var("POLYEDGE_MARKET_REFRESH_SEC")
+            .ok()
+            .and_then(|v| v.parse::<u64>().ok())
+            .map(Duration::from_secs)
+            .unwrap_or(Duration::from_secs(120));
+        let refresh_deadline = tokio::time::sleep(refresh_every);
+        tokio::pin!(refresh_deadline);
         let mut parse_failures = 0_u64;
         let mut no_update_msgs = 0_u64;
         let mut seen_msgs = 0_u64;
 
         loop {
             tokio::select! {
+                _ = &mut refresh_deadline => {
+                    tracing::info!(
+                        refresh_sec = refresh_every.as_secs(),
+                        "polymarket market ws refresh triggered; resubscribing"
+                    );
+                    break;
+                }
                 _ = ping.tick() => {
                     // The Polymarket WS docs recommend an application-level "PING".
                     ws.send(Message::Text("PING".to_string().into()))
diff --git a/crates/market_discovery/src/lib.rs b/crates/market_discovery/src/lib.rs
index 969d470..155c336 100644
--- a/crates/market_discovery/src/lib.rs
+++ b/crates/market_discovery/src/lib.rs
@@ -11,6 +11,8 @@ pub struct MarketDescriptor {
     pub token_id_no: Option<String>,
     pub event_slug: Option<String>,
     pub end_date: Option<String>,
+    pub timeframe: Option<String>,    // "5m" / "15m" / "1h" / "1d"
+    pub market_type: Option<String>,  // "updown" / "above_below" / "range"
     pub best_bid: Option<f64>,
     pub best_ask: Option<f64>,
 }
@@ -130,16 +132,12 @@ impl MarketDiscovery {
                 {
                     continue;
                 }
+                let timeframe = classify_timeframe(&text);
                 if !self.cfg.timeframes.is_empty() {
-                    let Some(timeframe) = classify_timeframe(&text) else {
+                    let Some(tf) = timeframe else {
                         continue;
                     };
-                    if !self
-                        .cfg
-                        .timeframes
-                        .iter()
-                        .any(|t| t.eq_ignore_ascii_case(timeframe))
-                    {
+                    if !self.cfg.timeframes.iter().any(|t| t.eq_ignore_ascii_case(tf)) {
                         continue;
                     }
                 }
@@ -155,6 +153,8 @@ impl MarketDiscovery {
                     token_id_no: parse_token_pair(market.clob_token_ids.as_deref()).map(|x| x.1),
                     event_slug: market.event_slug,
                     end_date: market.end_date,
+                    timeframe: timeframe.map(|v| v.to_string()),
+                    market_type: Some(market_type.to_string()),
                     best_bid: market.best_bid,
                     best_ask: market.best_ask,
                 });
diff --git a/ops/systemd/polyedge.service b/ops/systemd/polyedge.service
index 8637664..d8799d3 100644
--- a/ops/systemd/polyedge.service
+++ b/ops/systemd/polyedge.service
@@ -8,6 +8,9 @@ Type=simple
 User=ubuntu
 WorkingDirectory=/home/ubuntu/PolyEdge
 Environment=RUST_LOG=info
+# Optional feed toggles (defaults are enabled in code). We disable Chainlink anchor input on
+# servers by default to avoid slow ticks impacting data validity and latency tails.
+Environment=POLYEDGE_ENABLE_CHAINLINK_ANCHOR=false
 # Run the built binary directly (faster restarts, avoids cargo spawning/port races).
 ExecStart=/home/ubuntu/PolyEdge/target/release/app_runner
 Restart=always
diff --git a/scripts/full_latency_sweep.py b/scripts/full_latency_sweep.py
index 49d00a0..6fc72cf 100644
--- a/scripts/full_latency_sweep.py
+++ b/scripts/full_latency_sweep.py
@@ -140,6 +140,10 @@ def parse_args() -> argparse.Namespace:
     p.add_argument("--poll-interval", type=float, default=None)
     p.add_argument("--symbols", default=",".join(SYMBOL_TO_NAME.keys()))
     p.add_argument("--out-root", default="datasets/reports")
+    # Optional: write artifacts under datasets/reports/<day>/runs/<run_id>/ for easier A/B comparison.
+    # When omitted, preserves the legacy location under datasets/reports/<day>/.
+    p.add_argument("--run-id", default=None)
+    p.add_argument("--skip-ws", action="store_true", help="skip CEX websocket latency probe (engine metrics only)")
     return p.parse_args()
 
 
@@ -153,6 +157,9 @@ def main() -> int:
     started_ms = int(time.time() * 1000)
     async def run_all() -> tuple[Dict[str, Any], Dict[str, Any]]:
         engine_task = asyncio.to_thread(collect_engine_series, args.base_url, seconds, poll_interval)
+        if args.skip_ws:
+            engine_res = await engine_task
+            return engine_res, {}
         ws_task = collect_ws_all(seconds, symbols)
         engine_res, ws_res = await asyncio.gather(engine_task, ws_task)
         return engine_res, ws_res
@@ -167,12 +174,17 @@ def main() -> int:
             "poll_interval": poll_interval,
             "symbols": symbols,
             "ts_ms": started_ms,
+            "run_id": args.run_id,
+            "skip_ws": bool(args.skip_ws),
         },
         "engine": engine,
         "ws": ws,
     }
 
-    out_dir = Path(args.out_root) / utc_day()
+    if args.run_id:
+        out_dir = Path(args.out_root) / utc_day() / "runs" / str(args.run_id)
+    else:
+        out_dir = Path(args.out_root) / utc_day()
     out_dir.mkdir(parents=True, exist_ok=True)
     out_path = out_dir / f"full_latency_sweep_{started_ms}.json"
     out_path.write_text(json.dumps(payload, ensure_ascii=True, indent=2), encoding="utf-8")
diff --git a/scripts/long_regression_orchestrator.py b/scripts/long_regression_orchestrator.py
index 702e3d0..65aad5c 100644
--- a/scripts/long_regression_orchestrator.py
+++ b/scripts/long_regression_orchestrator.py
@@ -116,9 +116,8 @@ def gate_pass(live: Dict[str, Any], min_outcomes: int) -> bool:
     )
 
 
-def run_param_regression(args: argparse.Namespace, cycle: int, budget_sec: int) -> None:
+def run_param_regression(args: argparse.Namespace, trial_run_id: str, budget_sec: int) -> None:
     script_path = Path(__file__).resolve().parent / "param_regression.py"
-    trial_run_id = f"{args.run_id}-c{cycle:02d}"
     cmd = [
         sys.executable,
         str(script_path),
@@ -148,8 +147,8 @@ def run_param_regression(args: argparse.Namespace, cycle: int, budget_sec: int)
     subprocess.run(cmd, check=True)
 
 
-def read_best_trial(day_dir: Path) -> Dict[str, Any] | None:
-    summary_json = day_dir / "regression_summary.json"
+def read_best_trial(day_dir: Path, trial_run_id: str) -> Dict[str, Any] | None:
+    summary_json = day_dir / "runs" / trial_run_id / "regression_summary.json"
     if not summary_json.exists():
         return None
     data = json.loads(summary_json.read_text(encoding="utf-8"))
@@ -292,8 +291,9 @@ def main() -> int:
         budget_remaining = 0
         if args.max_runtime_sec > 0:
             budget_remaining = max(1, int(args.max_runtime_sec - (time.monotonic() - started)))
-        run_param_regression(args, cycle, budget_remaining)
-        trial = read_best_trial(day_dir)
+        trial_run_id = f"{args.run_id}-c{cycle:02d}"
+        run_param_regression(args, trial_run_id, budget_remaining)
+        trial = read_best_trial(day_dir, trial_run_id)
         if trial is None:
             raise RuntimeError("No best trial found after param_regression")
 
diff --git a/scripts/param_regression.py b/scripts/param_regression.py
index 6a77dbd..aa33f0d 100644
--- a/scripts/param_regression.py
+++ b/scripts/param_regression.py
@@ -44,16 +44,27 @@ def parse_int_grid(raw: str) -> List[int]:
 
 PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
     "quick": {
-        "window_sec": 120,
+        # 5-hour sprint default: fewer trials, longer per-trial window, bounded runtime.
+        "window_sec": 300,
         "poll_interval_sec": 3.0,
-        "eval_window_sec": 120,
-        "max_trials": 2,
-        "max_runtime_sec": 480,
+        "eval_window_sec": 300,
+        "max_trials": 6,
+        "max_runtime_sec": 3600,
         "heartbeat_sec": 15.0,
-        "fail_fast_threshold": 1,
-        "min_outcomes": 10,
-        "min_edge_grid": "4.5,5.0",
-        "ttl_grid": "350,400",
+        # Don't stop after the first failure; we want at least a few parameter probes in quick mode.
+        "fail_fast_threshold": 3,
+        "min_outcomes": 30,
+        "min_edge_grid": "0.5,1.0,2.0",
+        "ttl_grid": "250,400,700",
+        "max_spread_grid": "0.03,0.05,0.08",
+        "base_quote_size_grid": "2,5",
+        "min_eval_notional_usdc_grid": "0.01,0.05",
+        "min_expected_edge_usdc_grid": "0.0002",
+        "taker_trigger_grid": "3,4,6",
+        "taker_max_slippage_grid": "20,30",
+        "stale_tick_filter_ms": 2000,
+        "market_tier_profile": "balanced_sol_guard",
+        "active_top_n_markets": 12,
         "basis_k_grid": "0.8",
         "basis_z_grid": "3.0",
         "safe_threshold_grid": "0.35",
@@ -70,8 +81,17 @@ PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
         "heartbeat_sec": 30.0,
         "fail_fast_threshold": 0,
         "min_outcomes": 30,
-        "min_edge_grid": "5,7,9",
+        "min_edge_grid": "0.5,1.0,2.0,3.0",
         "ttl_grid": "250,400,700",
+        "max_spread_grid": "0.03,0.05,0.08",
+        "base_quote_size_grid": "2,5",
+        "min_eval_notional_usdc_grid": "0.01,0.05",
+        "min_expected_edge_usdc_grid": "0.0002",
+        "taker_trigger_grid": "3,4,6",
+        "taker_max_slippage_grid": "20,30",
+        "stale_tick_filter_ms": 2000,
+        "market_tier_profile": "balanced_sol_guard",
+        "active_top_n_markets": 12,
         "basis_k_grid": "0.70,0.85,1.00",
         "basis_z_grid": "2.0,3.0",
         "safe_threshold_grid": "0.35",
@@ -88,8 +108,17 @@ PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = {
         "heartbeat_sec": 30.0,
         "fail_fast_threshold": 0,
         "min_outcomes": 50,
-        "min_edge_grid": "4.5,5,6,7,9",
+        "min_edge_grid": "0.5,1.0,2.0,3.0,4.0",
         "ttl_grid": "250,350,500,700",
+        "max_spread_grid": "0.03,0.05,0.08",
+        "base_quote_size_grid": "2,5,8",
+        "min_eval_notional_usdc_grid": "0.01,0.05,0.10",
+        "min_expected_edge_usdc_grid": "0.0002,0.001",
+        "taker_trigger_grid": "3,4,6,8",
+        "taker_max_slippage_grid": "15,20,30",
+        "stale_tick_filter_ms": 2000,
+        "market_tier_profile": "balanced_sol_guard",
+        "active_top_n_markets": 12,
         "basis_k_grid": "0.70,0.80,0.90,1.00",
         "basis_z_grid": "2.0,2.5,3.0",
         "safe_threshold_grid": "0.30,0.35",
@@ -123,6 +152,15 @@ class TrialResult:
     trial_index: int
     min_edge_bps: float
     ttl_ms: int
+    max_spread: float
+    base_quote_size: float
+    min_eval_notional_usdc: float
+    min_expected_edge_usdc: float
+    taker_trigger_bps: float
+    taker_max_slippage_bps: float
+    stale_tick_filter_ms: float
+    market_tier_profile: str
+    active_top_n_markets: int
     basis_k_revert: float
     basis_z_cap: float
     safe_threshold: float
@@ -150,6 +188,7 @@ class TrialResult:
     data_valid_ratio: float
     net_edge_p50_bps: float
     gate_fail_reasons: List[str]
+    blocked_reason_top: str
 
     def gate_pass(self) -> bool:
         return (
@@ -194,16 +233,45 @@ def score_trial(row: TrialResult) -> float:
     return score
 
 
-def fetch_json(session: requests.Session, url: str, timeout: float = 5.0) -> Dict[str, Any]:
-    resp = session.get(url, timeout=timeout)
-    resp.raise_for_status()
-    return resp.json()
-
-
-def post_json(session: requests.Session, url: str, payload: Dict[str, Any], timeout: float = 5.0) -> Dict[str, Any]:
-    resp = session.post(url, json=payload, timeout=timeout)
-    resp.raise_for_status()
-    return resp.json()
+def fetch_json(
+    session: requests.Session,
+    url: str,
+    timeout: float = 15.0,
+    retries: int = 3,
+    backoff_sec: float = 0.5,
+) -> Dict[str, Any]:
+    last_exc: Exception | None = None
+    for attempt in range(max(1, retries)):
+        try:
+            resp = session.get(url, timeout=timeout)
+            resp.raise_for_status()
+            return resp.json()
+        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as exc:
+            last_exc = exc
+            time.sleep(backoff_sec * float(attempt + 1))
+    assert last_exc is not None
+    raise last_exc
+
+
+def post_json(
+    session: requests.Session,
+    url: str,
+    payload: Dict[str, Any],
+    timeout: float = 10.0,
+    retries: int = 3,
+    backoff_sec: float = 0.5,
+) -> Dict[str, Any]:
+    last_exc: Exception | None = None
+    for attempt in range(max(1, retries)):
+        try:
+            resp = session.post(url, json=payload, timeout=timeout)
+            resp.raise_for_status()
+            return resp.json()
+        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as exc:
+            last_exc = exc
+            time.sleep(backoff_sec * float(attempt + 1))
+    assert last_exc is not None
+    raise last_exc
 
 
 def post_json_optional(
@@ -230,6 +298,15 @@ def run_trial(
     poll_interval_sec: float,
     min_edge_bps: float,
     ttl_ms: int,
+    max_spread: float,
+    base_quote_size: float,
+    min_eval_notional_usdc: float,
+    min_expected_edge_usdc: float,
+    taker_trigger_bps: float,
+    taker_max_slippage_bps: float,
+    stale_tick_filter_ms: float,
+    market_tier_profile: str,
+    active_top_n_markets: int,
     basis_k_revert: float,
     basis_z_cap: float,
     safe_threshold: float,
@@ -237,6 +314,8 @@ def run_trial(
     warmup_sec: int,
 ) -> TrialResult:
     base = base_url.rstrip("/")
+    # Ensure the runtime isn't stuck paused from a previous test cycle.
+    post_json_optional(session, f"{base}/control/resume", {})
     reset_resp = post_json(session, f"{base}/control/reset_shadow", {})
     reset_window_id = int(reset_resp.get("window_id", 0) or 0)
     post_json(
@@ -245,6 +324,10 @@ def run_trial(
         {
             "min_edge_bps": min_edge_bps,
             "ttl_ms": ttl_ms,
+            "max_spread": max_spread,
+            "base_quote_size": base_quote_size,
+            "min_eval_notional_usdc": min_eval_notional_usdc,
+            "min_expected_edge_usdc": min_expected_edge_usdc,
             "basis_k_revert": basis_k_revert,
             "basis_z_cap": basis_z_cap,
         },
@@ -253,10 +336,10 @@ def run_trial(
         session,
         f"{base}/control/reload_taker",
         {
-            "trigger_bps": max(1.0, min_edge_bps),
-            "max_slippage_bps": 25.0,
-            "stale_tick_filter_ms": 450.0,
-            "market_tier_profile": "balanced",
+            "trigger_bps": taker_trigger_bps,
+            "max_slippage_bps": taker_max_slippage_bps,
+            "stale_tick_filter_ms": stale_tick_filter_ms,
+            "market_tier_profile": market_tier_profile,
         },
     )
     post_json_optional(
@@ -265,7 +348,7 @@ def run_trial(
         {
             "capital_fraction_kelly": 0.35,
             "variance_penalty_lambda": 0.25,
-            "active_top_n_markets": 8,
+            "active_top_n_markets": active_top_n_markets,
             "taker_weight": 0.7,
             "maker_weight": 0.2,
             "arb_weight": 0.1,
@@ -304,10 +387,12 @@ def run_trial(
     gate_fail_reasons: List[str] = []
     observed_window_id = reset_window_id
     next_heartbeat = time.time() + max(1.0, heartbeat_sec)
+    last_live: Dict[str, Any] | None = None
 
     deadline = time.time() + min(window_sec, eval_window_sec)
     while time.time() < deadline:
         live = fetch_json(session, f"{base}/report/shadow/live")
+        last_live = live
         observed_window_id = int(live.get("window_id", observed_window_id) or observed_window_id)
         fillability.append(float(live.get("fillability_10ms", 0.0)))
         pnl10_raw.append(float(live.get("pnl_10s_p50_bps_raw", live.get("pnl_10s_p50_bps", 0.0))))
@@ -341,11 +426,27 @@ def run_trial(
             next_heartbeat = time.time() + max(1.0, heartbeat_sec)
         time.sleep(max(1.0, poll_interval_sec))
 
+    blocked_top = ""
+    if isinstance(last_live, dict):
+        br = last_live.get("blocked_reason_counts")
+        if isinstance(br, dict) and br:
+            top_items = sorted(br.items(), key=lambda kv: float(kv[1]), reverse=True)[:8]
+            blocked_top = ";".join(f"{k}:{int(v)}" for k, v in top_items)
+
     return TrialResult(
         run_id=run_id,
         trial_index=trial_index,
         min_edge_bps=min_edge_bps,
         ttl_ms=ttl_ms,
+        max_spread=max_spread,
+        base_quote_size=base_quote_size,
+        min_eval_notional_usdc=min_eval_notional_usdc,
+        min_expected_edge_usdc=min_expected_edge_usdc,
+        taker_trigger_bps=taker_trigger_bps,
+        taker_max_slippage_bps=taker_max_slippage_bps,
+        stale_tick_filter_ms=stale_tick_filter_ms,
+        market_tier_profile=market_tier_profile,
+        active_top_n_markets=active_top_n_markets,
         basis_k_revert=basis_k_revert,
         basis_z_cap=basis_z_cap,
         safe_threshold=safe_threshold,
@@ -376,6 +477,7 @@ def run_trial(
         data_valid_ratio=percentile(data_valid_ratio, 0.50),
         net_edge_p50_bps=percentile(net_edge, 0.50),
         gate_fail_reasons=gate_fail_reasons,
+        blocked_reason_top=blocked_top,
     )
 
 
@@ -387,6 +489,15 @@ def write_ablation_csv(path: Path, rows: Iterable[TrialResult]) -> None:
             [
                 "min_edge_bps",
                 "ttl_ms",
+                "max_spread",
+                "base_quote_size",
+                "min_eval_notional_usdc",
+                "min_expected_edge_usdc",
+                "taker_trigger_bps",
+                "taker_max_slippage_bps",
+                "stale_tick_filter_ms",
+                "market_tier_profile",
+                "active_top_n_markets",
                 "basis_k_revert",
                 "basis_z_cap",
                 "safe_threshold",
@@ -416,6 +527,7 @@ def write_ablation_csv(path: Path, rows: Iterable[TrialResult]) -> None:
                 "data_valid_ratio",
                 "net_edge_p50_bps",
                 "gate_pass",
+                "blocked_reason_top",
             ]
         )
         for row in rows:
@@ -423,6 +535,15 @@ def write_ablation_csv(path: Path, rows: Iterable[TrialResult]) -> None:
                 [
                     row.min_edge_bps,
                     row.ttl_ms,
+                    row.max_spread,
+                    row.base_quote_size,
+                    row.min_eval_notional_usdc,
+                    row.min_expected_edge_usdc,
+                    row.taker_trigger_bps,
+                    row.taker_max_slippage_bps,
+                    row.stale_tick_filter_ms,
+                    row.market_tier_profile,
+                    row.active_top_n_markets,
                     row.basis_k_revert,
                     row.basis_z_cap,
                     row.safe_threshold,
@@ -452,6 +573,7 @@ def write_ablation_csv(path: Path, rows: Iterable[TrialResult]) -> None:
                     f"{row.data_valid_ratio:.6f}",
                     f"{row.net_edge_p50_bps:.6f}",
                     row.gate_pass(),
+                    row.blocked_reason_top,
                 ]
             )
 
@@ -469,7 +591,10 @@ def write_summary_md(path: Path, rows: List[TrialResult]) -> None:
         lines.append(f"- best_gate_pass: {best.gate_pass()}")
         lines.append(f"- best_gate_ready: {best.gate_ready}")
         lines.append(
-            f"- best_params: edge={best.min_edge_bps}, ttl={best.ttl_ms}, "
+            f"- best_params: edge={best.min_edge_bps}, ttl={best.ttl_ms}, base_quote={best.base_quote_size}, "
+            f"min_eval_notional={best.min_eval_notional_usdc}, "
+            f"taker_trigger={best.taker_trigger_bps}, taker_slip={best.taker_max_slippage_bps}, "
+            f"stale_ms={best.stale_tick_filter_ms}, tier={best.market_tier_profile}, topn={best.active_top_n_markets}, "
             f"k={best.basis_k_revert}, z={best.basis_z_cap}, "
             f"safe={best.safe_threshold}, caution={best.caution_threshold}"
         )
@@ -478,7 +603,10 @@ def write_summary_md(path: Path, rows: List[TrialResult]) -> None:
     lines.append("## Top Trials")
     for i, row in enumerate(top, start=1):
         lines.append(
-                f"- #{i} edge={row.min_edge_bps}, ttl={row.ttl_ms}, "
+                f"- #{i} edge={row.min_edge_bps}, ttl={row.ttl_ms}, base_quote={row.base_quote_size}, "
+                f"min_eval_notional={row.min_eval_notional_usdc}, "
+                f"taker_trigger={row.taker_trigger_bps}, taker_slip={row.taker_max_slippage_bps}, "
+                f"stale_ms={row.stale_tick_filter_ms}, tier={row.market_tier_profile}, topn={row.active_top_n_markets}, "
                 f"k={row.basis_k_revert}, z={row.basis_z_cap}, "
                 f"pnl10_raw_p50={row.pnl_10s_p50_bps_raw:.3f}, "
                 f"pnl10_robust_p50={row.pnl_10s_p50_bps_robust:.3f}, "
@@ -490,6 +618,8 @@ def write_summary_md(path: Path, rows: List[TrialResult]) -> None:
                 f"ready={row.gate_ready}, "
                 f"tick_to_ack_p99={row.tick_to_ack_p99_ms:.3f}, gate={row.gate_pass()}"
             )
+        if row.blocked_reason_top:
+            lines.append(f"  blocked_top: {row.blocked_reason_top}")
     path.write_text("\n".join(lines) + "\n", encoding="utf-8")
 
 
@@ -556,6 +686,15 @@ def parse_args() -> argparse.Namespace:
     p.add_argument("--min-outcomes", type=int, default=None)
     p.add_argument("--min-edge-grid", default=None)
     p.add_argument("--ttl-grid", default=None)
+    p.add_argument("--max-spread-grid", default=None)
+    p.add_argument("--base-quote-size-grid", default=None)
+    p.add_argument("--min-eval-notional-usdc-grid", default=None)
+    p.add_argument("--min-expected-edge-usdc-grid", default=None)
+    p.add_argument("--taker-trigger-grid", default=None)
+    p.add_argument("--taker-max-slippage-grid", default=None)
+    p.add_argument("--stale-tick-filter-ms", type=float, default=None)
+    p.add_argument("--market-tier-profile", default=None)
+    p.add_argument("--active-top-n-markets", type=int, default=None)
     p.add_argument("--basis-k-grid", default=None)
     p.add_argument("--basis-z-grid", default=None)
     p.add_argument("--safe-threshold-grid", default=None)
@@ -573,18 +712,120 @@ def parse_args() -> argparse.Namespace:
 def main() -> int:
     args = apply_profile_defaults(parse_args())
     day_dir = Path(args.out_root) / utc_day()
+    run_dir = day_dir / "runs" / str(args.run_id)
+    run_dir.mkdir(parents=True, exist_ok=True)
     session = requests.Session()
     started = time.monotonic()
 
     edge_grid = parse_float_grid(args.min_edge_grid)
     ttl_grid = parse_int_grid(args.ttl_grid)
+    max_spread_grid = parse_float_grid(args.max_spread_grid)
+    base_quote_grid = parse_float_grid(args.base_quote_size_grid)
+    min_eval_grid = parse_float_grid(args.min_eval_notional_usdc_grid)
+    min_edge_usdc_grid = parse_float_grid(args.min_expected_edge_usdc_grid)
+    taker_trigger_grid = parse_float_grid(args.taker_trigger_grid)
+    taker_slip_grid = parse_float_grid(args.taker_max_slippage_grid)
     k_grid = parse_float_grid(args.basis_k_grid)
     z_grid = parse_float_grid(args.basis_z_grid)
     safe_grid = parse_float_grid(args.safe_threshold_grid)
     caution_grid = parse_float_grid(args.caution_threshold_grid)
 
-    combos = list(itertools.product(edge_grid, ttl_grid, k_grid, z_grid, safe_grid, caution_grid))
-    combos = combos[: max(1, args.max_trials)]
+    # For small max_trials, prefer a deterministic OFAT-style set instead of a huge cartesian product.
+    def pick_default(seq: List[Any], prefer_last: bool = False) -> Any:
+        if not seq:
+            raise ValueError("empty grid")
+        return seq[-1] if prefer_last else seq[0]
+
+    base = {
+        "edge": edge_grid[min(1, len(edge_grid) - 1)] if edge_grid else 1.0,
+        "ttl": ttl_grid[min(1, len(ttl_grid) - 1)] if ttl_grid else 400,
+        "max_spread": pick_default(max_spread_grid, prefer_last=True) if max_spread_grid else 0.03,
+        "base_quote": pick_default(base_quote_grid, prefer_last=True),
+        "min_eval": pick_default(min_eval_grid, prefer_last=False),
+        "min_edge_usdc": pick_default(min_edge_usdc_grid, prefer_last=False),
+        "taker_trigger": taker_trigger_grid[min(1, len(taker_trigger_grid) - 1)]
+        if taker_trigger_grid
+        else 4.0,
+        "taker_slip": pick_default(taker_slip_grid, prefer_last=True),
+        "k": pick_default(k_grid, prefer_last=False),
+        "z": pick_default(z_grid, prefer_last=False),
+        "safe": pick_default(safe_grid, prefer_last=False),
+        "caution": pick_default(caution_grid, prefer_last=False),
+    }
+
+    combos: List[tuple[Any, ...]] = []
+    combos.append(
+        (
+            base["edge"],
+            base["ttl"],
+            base["max_spread"],
+            base["base_quote"],
+            base["min_eval"],
+            base["min_edge_usdc"],
+            base["taker_trigger"],
+            base["taker_slip"],
+            base["k"],
+            base["z"],
+            base["safe"],
+            base["caution"],
+        )
+    )
+
+    def add_variants(key: str, grid: List[Any]) -> None:
+        for v in grid:
+            if len(combos) >= max(1, args.max_trials):
+                return
+            if v == base[key]:
+                continue
+            spec = dict(base)
+            spec[key] = v
+            combos.append(
+                (
+                    spec["edge"],
+                    spec["ttl"],
+                    spec["max_spread"],
+                    spec["base_quote"],
+                    spec["min_eval"],
+                    spec["min_edge_usdc"],
+                    spec["taker_trigger"],
+                    spec["taker_slip"],
+                    spec["k"],
+                    spec["z"],
+                    spec["safe"],
+                    spec["caution"],
+                )
+            )
+
+    add_variants("edge", edge_grid)
+    add_variants("ttl", ttl_grid)
+    add_variants("max_spread", max_spread_grid)
+    add_variants("base_quote", base_quote_grid)
+    add_variants("min_eval", min_eval_grid)
+    add_variants("taker_trigger", taker_trigger_grid)
+    add_variants("taker_slip", taker_slip_grid)
+
+    # If still short, fall back to cartesian product, deterministic order.
+    if len(combos) < max(1, args.max_trials):
+        prod = itertools.product(
+            edge_grid,
+            ttl_grid,
+            max_spread_grid,
+            base_quote_grid,
+            min_eval_grid,
+            min_edge_usdc_grid,
+            taker_trigger_grid,
+            taker_slip_grid,
+            k_grid,
+            z_grid,
+            safe_grid,
+            caution_grid,
+        )
+        for row in prod:
+            if len(combos) >= max(1, args.max_trials):
+                break
+            if row in combos:
+                continue
+            combos.append(row)
 
     per_trial_sec = max(1, int(args.warmup_sec + min(args.window_sec, args.eval_window_sec)))
     estimated_full_sec = per_trial_sec * len(combos)
@@ -604,12 +845,29 @@ def main() -> int:
 
     rows: List[TrialResult] = []
     consecutive_failures = 0
-    for idx, (edge, ttl, k, z, safe, caution) in enumerate(combos, start=1):
+    for idx, combo in enumerate(combos, start=1):
         if args.max_runtime_sec > 0 and (time.monotonic() - started) >= args.max_runtime_sec:
             print("[stop] max-runtime-sec reached; ending regression loop")
             break
+        (
+            edge,
+            ttl,
+            max_spread,
+            base_quote_size,
+            min_eval_notional_usdc,
+            min_expected_edge_usdc,
+            taker_trigger_bps,
+            taker_max_slippage_bps,
+            k,
+            z,
+            safe,
+            caution,
+        ) = combo  # type: ignore[misc]
         print(
             f"[trial {idx}/{len(combos)}] edge={edge} ttl={ttl} "
+            f"max_spread={max_spread} "
+            f"base_quote={base_quote_size} min_eval={min_eval_notional_usdc} min_edge_usdc={min_expected_edge_usdc} "
+            f"taker_trigger={taker_trigger_bps} taker_slip={taker_max_slippage_bps} "
             f"k={k} z={z} safe={safe} caution={caution}"
         )
         row = run_trial(
@@ -624,6 +882,15 @@ def main() -> int:
             poll_interval_sec=args.poll_interval_sec,
             min_edge_bps=edge,
             ttl_ms=ttl,
+            max_spread=max_spread,
+            base_quote_size=base_quote_size,
+            min_eval_notional_usdc=min_eval_notional_usdc,
+            min_expected_edge_usdc=min_expected_edge_usdc,
+            taker_trigger_bps=taker_trigger_bps,
+            taker_max_slippage_bps=taker_max_slippage_bps,
+            stale_tick_filter_ms=float(args.stale_tick_filter_ms),
+            market_tier_profile=str(args.market_tier_profile),
+            active_top_n_markets=int(args.active_top_n_markets),
             basis_k_revert=k,
             basis_z_cap=z,
             safe_threshold=safe,
@@ -654,14 +921,14 @@ def main() -> int:
         reverse=True,
     )
 
-    ablation_path = day_dir / "ablation_toxicity.csv"
-    summary_path = day_dir / "regression_summary.md"
-    fixlist_path = day_dir / "next_fixlist.md"
+    ablation_path = run_dir / "ablation_toxicity.csv"
+    summary_path = run_dir / "regression_summary.md"
+    fixlist_path = run_dir / "next_fixlist.md"
     write_ablation_csv(ablation_path, rows)
     write_summary_md(summary_path, rows)
     write_fixlist(fixlist_path, rows[0] if rows else None)
 
-    out_json = day_dir / "regression_summary.json"
+    out_json = run_dir / "regression_summary.json"
     best = rows[0] if rows else None
     out_json.write_text(
         json.dumps(
@@ -677,6 +944,14 @@ def main() -> int:
                     {
                         "min_edge_bps": best.min_edge_bps,
                         "ttl_ms": best.ttl_ms,
+                        "base_quote_size": best.base_quote_size,
+                        "min_eval_notional_usdc": best.min_eval_notional_usdc,
+                        "min_expected_edge_usdc": best.min_expected_edge_usdc,
+                        "taker_trigger_bps": best.taker_trigger_bps,
+                        "taker_max_slippage_bps": best.taker_max_slippage_bps,
+                        "stale_tick_filter_ms": best.stale_tick_filter_ms,
+                        "market_tier_profile": best.market_tier_profile,
+                        "active_top_n_markets": best.active_top_n_markets,
                         "basis_k_revert": best.basis_k_revert,
                         "basis_z_cap": best.basis_z_cap,
                         "safe_threshold": best.safe_threshold,
diff --git a/scripts/remote_deploy_validate.ps1 b/scripts/remote_deploy_validate.ps1
index 0ed2f30..630ea95 100644
--- a/scripts/remote_deploy_validate.ps1
+++ b/scripts/remote_deploy_validate.ps1
@@ -56,7 +56,15 @@ Invoke-Remote $buildCmd
 
 Write-Host "[5/7] Restart runtime"
 $restartTemplate = @'
-cd __REPO_DIR__ || exit 1; pkill -x app_runner >/dev/null 2>&1 || true; nohup env RUST_LOG=info ./target/release/app_runner >/tmp/polyedge_app.log 2>&1 & true
+set -e
+cd __REPO_DIR__ || exit 1
+if command -v systemctl >/dev/null 2>&1 && systemctl --quiet is-enabled polyedge.service 2>/dev/null; then
+  sudo systemctl daemon-reload || true
+  sudo systemctl restart polyedge.service
+else
+  pkill -x app_runner >/dev/null 2>&1 || true
+  nohup env RUST_LOG=info POLYEDGE_ENABLE_CHAINLINK_ANCHOR=false ./target/release/app_runner >/tmp/polyedge_app.log 2>&1 & true
+fi
 '@
 $restartCmd = $restartTemplate.Replace("__REPO_DIR__", $RepoDir)
 Invoke-Remote $restartCmd
diff --git a/scripts/storm_test.py b/scripts/storm_test.py
index c2b7e5d..3f5910b 100644
--- a/scripts/storm_test.py
+++ b/scripts/storm_test.py
@@ -82,12 +82,20 @@ def parse_args() -> argparse.Namespace:
     p.add_argument("--heartbeat-sec", type=float, default=30.0)
     p.add_argument("--run-id", default=f"storm-{int(time.time())}")
     p.add_argument("--out-root", default="datasets/reports")
+    # When enabled, write artifacts under datasets/reports/<day>/runs/<run_id>/ to avoid overwriting
+    # day-level legacy files (storm_test_summary.json / storm_test_trace.jsonl).
+    p.add_argument("--use-run-dir", action="store_true")
     p.add_argument("--fail-fast-threshold", type=int, default=20)
+    # Default is safe: do NOT leave the engine paused after a test. Enable only when
+    # explicitly testing pause/resume semantics.
+    p.add_argument("--churn-pause-resume", action="store_true")
     p.add_argument("--once", action="store_true")
     return p.parse_args()
 
 
-def maybe_control_churn(session: requests.Session, base_url: str, timeout_sec: float) -> List[ProbeResult]:
+def maybe_control_churn(
+    session: requests.Session, base_url: str, timeout_sec: float, churn_pause_resume: bool
+) -> List[ProbeResult]:
     jitter = random.uniform(-2.5, 2.5)
     maker_payload = {
         "min_edge_bps": max(1.0, 6.0 + jitter),
@@ -115,9 +123,14 @@ def maybe_control_churn(session: requests.Session, base_url: str, timeout_sec: f
         ("POST", f"{base_url}/control/reload_taker", maker_payload),
         ("POST", f"{base_url}/control/reload_allocator", alloc_payload),
         ("POST", f"{base_url}/control/reload_risk", risk_payload),
-        ("POST", f"{base_url}/control/pause", {}),
-        ("POST", f"{base_url}/control/resume", {}),
     ]
+    if churn_pause_resume:
+        ops.extend(
+            [
+                ("POST", f"{base_url}/control/pause", {}),
+                ("POST", f"{base_url}/control/resume", {}),
+            ]
+        )
     out: List[ProbeResult] = []
     for method, url, payload in ops:
         out.append(request_json(session, method, url, timeout_sec, payload))
@@ -138,7 +151,10 @@ def main() -> int:
     next_control = started + max(1.0, args.control_interval_sec)
 
     day = utc_day()
-    out_dir = Path(args.out_root) / day
+    if args.use_run_dir:
+        out_dir = Path(args.out_root) / day / "runs" / str(args.run_id)
+    else:
+        out_dir = Path(args.out_root) / day
     summary_path = out_dir / "storm_test_summary.json"
     trace_path = out_dir / "storm_test_trace.jsonl"
     out_dir.mkdir(parents=True, exist_ok=True)
@@ -148,81 +164,89 @@ def main() -> int:
     consecutive_failures = 0
     samples: List[ProbeResult] = []
 
-    with concurrent.futures.ThreadPoolExecutor(max_workers=max(1, args.concurrency)) as pool:
-        if args.once:
-            probe = request_json(session, "GET", f"{args.base_url}/report/shadow/live", args.timeout_sec)
-            samples.append(probe)
-        else:
-            while True:
-                now = time.monotonic()
-                if now >= deadline:
-                    break
-                if now >= hard_deadline:
-                    break
-
-                burst = max(1, args.burst_rps)
-                futures = [
-                    pool.submit(
-                        request_json,
-                        session,
-                        "GET",
-                        f"{args.base_url}/report/shadow/live",
-                        args.timeout_sec,
-                        None,
-                    )
-                    for _ in range(burst)
-                ]
-                for f in futures:
-                    r = f.result()
-                    samples.append(r)
-                    if not r.ok:
-                        errors += 1
-                        consecutive_failures += 1
-                    else:
-                        consecutive_failures = 0
-                    with trace_path.open("a", encoding="utf-8") as fp:
-                        fp.write(
-                            json.dumps(
-                                {
-                                    "ts_ms": now_ms(),
-                                    "ok": r.ok,
-                                    "latency_ms": round(r.latency_ms, 3),
-                                    "status": r.status,
-                                    "endpoint": r.endpoint,
-                                    "error": r.error,
-                                },
-                                ensure_ascii=True,
-                                separators=(",", ":"),
-                            )
-                            + "\n"
-                        )
+    try:
+        with concurrent.futures.ThreadPoolExecutor(max_workers=max(1, args.concurrency)) as pool:
+            if args.once:
+                probe = request_json(session, "GET", f"{args.base_url}/report/shadow/live", args.timeout_sec)
+                samples.append(probe)
+            else:
+                while True:
+                    now = time.monotonic()
+                    if now >= deadline:
+                        break
+                    if now >= hard_deadline:
+                        break
 
-                if now >= next_control:
-                    for ctrl in maybe_control_churn(session, args.base_url, args.timeout_sec):
-                        samples.append(ctrl)
-                        if not ctrl.ok:
+                    burst = max(1, args.burst_rps)
+                    futures = [
+                        pool.submit(
+                            request_json,
+                            session,
+                            "GET",
+                            f"{args.base_url}/report/shadow/live",
+                            args.timeout_sec,
+                            None,
+                        )
+                        for _ in range(burst)
+                    ]
+                    for f in futures:
+                        r = f.result()
+                        samples.append(r)
+                        if not r.ok:
                             errors += 1
                             consecutive_failures += 1
-                    next_control = now + max(1.0, args.control_interval_sec)
-
-                if consecutive_failures >= max(1, args.fail_fast_threshold):
-                    break
-                if errors >= max(1, args.max_errors):
-                    break
-                if now >= heartbeat_at:
-                    elapsed = int(now - started)
-                    print(
-                        f"[heartbeat] elapsed={elapsed}s samples={len(samples)} errors={errors} "
-                        f"consecutive_failures={consecutive_failures}"
-                    )
-                    heartbeat_at = now + max(1.0, args.heartbeat_sec)
-                time.sleep(1.0)
+                        else:
+                            consecutive_failures = 0
+                        with trace_path.open("a", encoding="utf-8") as fp:
+                            fp.write(
+                                json.dumps(
+                                    {
+                                        "ts_ms": now_ms(),
+                                        "ok": r.ok,
+                                        "latency_ms": round(r.latency_ms, 3),
+                                        "status": r.status,
+                                        "endpoint": r.endpoint,
+                                        "error": r.error,
+                                    },
+                                    ensure_ascii=True,
+                                    separators=(",", ":"),
+                                )
+                                + "\n"
+                            )
+
+                    if now >= next_control:
+                        for ctrl in maybe_control_churn(
+                            session, args.base_url, args.timeout_sec, args.churn_pause_resume
+                        ):
+                            samples.append(ctrl)
+                            if not ctrl.ok:
+                                errors += 1
+                                consecutive_failures += 1
+                        next_control = now + max(1.0, args.control_interval_sec)
+
+                    if consecutive_failures >= max(1, args.fail_fast_threshold):
+                        break
+                    if errors >= max(1, args.max_errors):
+                        break
+                    if now >= heartbeat_at:
+                        elapsed = int(now - started)
+                        print(
+                            f"[heartbeat] elapsed={elapsed}s samples={len(samples)} errors={errors} "
+                            f"consecutive_failures={consecutive_failures}"
+                        )
+                        heartbeat_at = now + max(1.0, args.heartbeat_sec)
+                    time.sleep(1.0)
+    finally:
+        # Safety: never leave the engine paused after a stress run.
+        _ = request_json(session, "POST", f"{args.base_url}/control/resume", 2.0, {})
 
     lat_ok = [s.latency_ms for s in samples if s.ok]
     lat_fail = [s.latency_ms for s in samples if not s.ok]
     summary: Dict[str, Any] = {
         "ts_ms": now_ms(),
         "run_id": args.run_id,
+        "use_run_dir": bool(args.use_run_dir),
+        "out_dir": str(out_dir),
         "base_url": args.base_url,
         "duration_sec": int(time.monotonic() - started),
         "sample_count": len(samples),
